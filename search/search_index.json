{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"about/","text":"Divi MarkdownGuide Reference \u00b6 Link Markdown Cheat Sheet \u00b6 Link Extended Syntax \u00b6 Link MkDocs Markdown Support \u00b6 Link Markdown Hacks \u00b6 Link Some of these words will be underlined . Avatar Material for MkDocs \u00b6 Reference: Link Setup: Link Blockquotes: Dorothy followed her through many of the beautiful rooms in her castle. Bold Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Blockquotes with Other Elements: The quarterly results look great! \u00b6 Revenue was off the chart. Profits were higher than ever. Everything is going according to plan . Ordered List Best Practices: First item Second item Unordered Lists: First item Second item Third item Indented item Indented item Fourth item Admonitions: Options: abstract: info: tip: success: question: warning: failure: danger: bug: example: quote: danger Each of the supported admonition types has a distinct icon First item Indented item Second item Link My favorite search engine is Duck Duck Go . URLs and Email Addresses To quickly turn a URL or email address into a link, enclose it in angle brackets. https://www.markdownguide.org fake@example.com Formatting Links: I love supporting the EFF . This is the Markdown Guide . See the section on code . fedora brand mark color second heading \u00b6 one two third heading \u00b6 dots fourth heading \u00b6 Italic \"asset\" Subscribe to our newsletter Subscribe to our newsletter Send import tensorflow as tf apt install htop Method Description GET Fetch resource PUT Update resource DELETE Delete resource Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. This was marked This was inserted This was deleted Ctrl + Alt + Del Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque The HTML specification is maintained by the W3C .","title":"Heading"},{"location":"about/#divi-markdownguide-reference","text":"Link","title":"Divi MarkdownGuide Reference"},{"location":"about/#markdown-cheat-sheet","text":"Link","title":"Markdown Cheat Sheet"},{"location":"about/#extended-syntax","text":"Link","title":"Extended Syntax"},{"location":"about/#mkdocs-markdown-support","text":"Link","title":"MkDocs Markdown Support"},{"location":"about/#markdown-hacks","text":"Link Some of these words will be underlined . Avatar","title":"Markdown Hacks"},{"location":"about/#material-for-mkdocs","text":"Reference: Link Setup: Link Blockquotes: Dorothy followed her through many of the beautiful rooms in her castle. Bold Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Blockquotes with Other Elements:","title":"Material for MkDocs"},{"location":"about/#the-quarterly-results-look-great","text":"Revenue was off the chart. Profits were higher than ever. Everything is going according to plan . Ordered List Best Practices: First item Second item Unordered Lists: First item Second item Third item Indented item Indented item Fourth item Admonitions: Options: abstract: info: tip: success: question: warning: failure: danger: bug: example: quote: danger Each of the supported admonition types has a distinct icon First item Indented item Second item Link My favorite search engine is Duck Duck Go . URLs and Email Addresses To quickly turn a URL or email address into a link, enclose it in angle brackets. https://www.markdownguide.org fake@example.com Formatting Links: I love supporting the EFF . This is the Markdown Guide . See the section on code . fedora brand mark color","title":"The quarterly results look great!"},{"location":"about/#second-heading","text":"one two","title":"second heading"},{"location":"about/#third-heading","text":"dots","title":"third heading"},{"location":"about/#fourth-heading","text":"Italic \"asset\" Subscribe to our newsletter Subscribe to our newsletter Send import tensorflow as tf apt install htop Method Description GET Fetch resource PUT Update resource DELETE Delete resource Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. This was marked This was inserted This was deleted Ctrl + Alt + Del Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque The HTML specification is maintained by the W3C .","title":"fourth heading"},{"location":"android/","text":"These are the Android operating systems, devices, and apps we recommend to maximize your mobile device's security and privacy. We also have additional Android-related information: General Android Overview and Recommendations GrapheneOS vs CalyxOS Comparison AOSP Derivatives \u00b6 We recommend installing one of these custom Android operating systems on your device, listed in order of preference, depending on your device's compatibility with these operating systems. Note End-of-life devices (such as GrapheneOS or CalyxOS's \"extended support\" devices) do not have full security patches (firmware updates) due to the OEM discontinuing support. These devices cannot be considered completely secure regardless of installed software. GrapheneOS \u00b6 Recommendation GrapheneOS is the best choice when it comes to privacy and security. GrapheneOS provides additional security hardening and privacy improvements. It has a hardened memory allocator , network and sensor permissions, and various other security features . GrapheneOS also comes with full firmware updates and signed builds, so verified boot is fully supported. Homepage Privacy Policy GrapheneOS supports Sandboxed Google Play , which runs Google Play Services fully sandboxed like any other regular app. This means you can take advantage of most Google Play Services, such as push notifications , while giving you full control over their permissions and access, and while containing them to a specific work profile or user profile of your choice. Google Pixel phones are the only devices that currently meet GrapheneOS's hardware security requirements . CalyxOS \u00b6 Recommendation CalyxOS is a system with some privacy features on top of AOSP , including Datura firewall, Signal integration in the dialer app, and a built in panic button. CalyxOS also comes with firmware updates and signed builds, so verified boot is fully supported. Homepage Privacy Policy For people who need Google Play Services, CalyxOS optionally includes microG . CalyxOS also includes alternate location services, Mozilla and DejaVu . CalyxOS only supports Google Pixel phones. However, support for the OnePlus 8T/9 and Fairphone 4 is currently in beta . DivestOS \u00b6 Recommendation DivestOS is a soft- fork of LineageOS . DivestOS inherits many supported devices from LineageOS. It has signed builds, making it possible to have verified boot on some non-Pixel devices. Homepage Privacy Policy DivestOS has automated kernel vulnerability ( CVE ) patching , fewer proprietary blobs, a custom hosts file, and F-Droid as the app store. It includes UnifiedNlp for network location. Its hardened WebView, Mulch , enables CFI for all architectures and includes network state partitioning . DivestOS also includes kernel patches from GrapheneOS and enables all available kernel security features via defconfig hardening . All kernels newer than version 3.4 include full page sanitization and all ~22 Clang-compiled kernels have -ftrivial-auto-var-init=zero enabled. DivestOS implements some system hardening patches originally developed for GrapheneOS. DivestOS 16.0, 17.1, and 18.1 implements GrapheneOS's INTERNET permission toggle, hardened memory allocator , exec-spawning , JNI constification , and partial bionic hardening patchsets. 17.1 and 18.1 feature GrapheneOS's per-network full MAC randomization option, and ptrace_scope control, and automatic reboot/Wi-Fi/Bluetooth timeout options . Warning DivestOS firmware update status and quality control varies across the devices it supports. We still recommend GrapheneOS or CalyxOS depending on your device's compatibility. For other devices, DivestOS is a good alternative. Not all of the supported devices have verified boot, and some perform it better than others. Android Devices \u00b6 Avoid buying phones from mobile network operators. These often have a locked bootloader and do not support OEM unlocking . These phone variants will prevent you from installing any kind of alternative Android distribution. Be very careful about buying second hand phones from online marketplaces. Always check the reputation of the seller. If the device is stolen there's a possibility of IMEI blacklisting . There is also a risk involved with you being associated with the activity of the previous owner. A few more tips regarding Android devices and operating system compatibility: Do not buy devices that have reached or are near their end-of-life, additional firmware updates must be provided by the manufacturer. Do not buy preloaded LineageOS or /e/ OS phones or any Android phones without proper Verified Boot support and firmware updates. These devices also have no way for you to check whether they've been tampered with. In short, if a device or Android distribution is not listed here, there is probably a good reason, so check our discussions page. Google Pixel \u00b6 Recommendation Google Pixel devices are known to have good security and properly support Verified Boot , even when installing custom operating systems. Beginning with the Pixel 6 and 6 Pro , Pixel devices receive a minimum of 5 years of guaranteed security updates, ensuring a much longer lifespan compared to the 2-4 years competing OEMs typically offer. Store Unless you have a need for specific CalyxOS features that are unavailable on GrapheneOS, we strongly recommend GrapheneOS over other operating system choices on Pixel devices. The installation of GrapheneOS on a Pixel phone is easy with their web installer . If you don't feel comfortable doing it yourself and are willing to spend a bit of extra money, check out the NitroPhone as they come preloaded with GrapheneOS from the reputable Nitrokey company. A few more tips for purchasing a Google Pixel: If you're after a bargain on a Pixel device, we suggest buying an \" a \" model, just after the next flagship is released. Discounts are usually available because Google will be trying to clear their stock. Consider price beating options and specials offered at brick and mortar stores. Look at online community bargain sites in your country. These can alert you to good sales. Google provides a list showing the support cycle for each one of their devices. The price per day for a device can be calculated as: \\(\\text{Cost} \\over \\text {EOL Date }-\\text{ Current Date}\\) , meaning that the longer use of the device the lower cost per day. Other Devices \u00b6 Important Google Pixel phones are the only devices we recommend for purchase. Pixel phones have stronger hardware security than any other Android devices currently on the market, due to proper AVB support for third party operating systems and Google's custom Titan security chips acting as the Secure Element. Secure Elements are more limited than the processor's Trusted Execution Environment used by most other phones as they are only used for secrets storage, hardware attestation and rate limiting but not running \"trusted\" programs. Phones without a Secure Element have to use the TEE for secrets storage, rate limiting, and trusted computing, which results in a larger attack surface . The following OEMs are only mentioned as they have phones compatible with the operating systems recommended by us. If you are purchasing a new device, we only recommend purchasing a Google Pixel. When purchasing a device, we recommend getting one as new as possible. The software and firmware of mobile devices are only supported for a limited time, so buying new extends that lifespan as much as possible. OnePlus \u00b6 If you are unable to obtain a Google Pixel, recent OnePlus devices are the next best option if you want to run a custom OS without privileged Play Services. OnePlus 8 and later devices will receive 4 years of security updates from their initial launch date. CalyxOS has experimental support for the OnePlus 8T and 9 . DivestOS has support for most OnePlus devices up to the OnePlus 7T Pro , with varying levels of support. Fairphone \u00b6 Danger The Fairphone 3 and 4 are not secure by default, as the stock bootloader trusts the public AVB signing key . This breaks verified boot on a stock Fairphone device, as the system will boot alternative Android operating systems such (such as /e/) without any warning about custom operating system usage. This problem is somewhat mitigated when you install a custom operating system such as CalyxOS or DivestOS and trust the developer's signing keys rather than the stock system keys, however a vulnerability in CalyxOS or DivestOS's recovery environments could still potentially allow an attacker to bypass AVB . To reiterate, you must install a custom operating system with custom boot keys to use Fairphone devices in a secure manner. CalyxOS has experimental support for the Fairphone 4 . DivestOS has builds available for the Fairphone 3 . Fairphone markets their devices as receiving 6 years of support. However, the SoC (Qualcomm Snapdragon 750G on the Fairphone 4) has a considerably shorter EOL date. This means that firmware security updates from Qualcomm for the Fairphone 4 will end in September 2023, regardless of whether Fairphone continues to release software security updates. General Apps \u00b6 Orbot \u00b6 Recommendation Orbot is a free proxy app that routes your connections through the Tor Network. Homepage Downloads Google Play f-droid F-Droid Source Source Orbot can proxy individual apps if they support SOCKS or HTTP proxying. It can also proxy all your network connections using VpnService and can be used with the VPN killswitch in Settings \u2192 Network & internet \u2192 VPN \u2192 \u2192 Block connections without VPN . For resistance against traffic analysis attacks, consider enabling Isolate Destination Address in \u2192 Settings \u2192 Connectivity . This will use a completely different Tor Circuit (different middle relay and exit nodes) for every domain you connect to. Tip Orbot is often outdated on the Guardian Project's F-Droid repository and Google Play so consider downloading directly from the GitHub repository instead. All versions are signed using the same signature so they should be compatible with each other. Shelter \u00b6 Recommendation Shelter is an app that helps you leverage the Android work profile to isolate other apps. Shelter supports blocking contact search cross profiles and sharing files across profiles via the default file manager ( DocumentsUI ). Project Info Downloads Google Play f-droid F-Droid Source Warning As CalyxOS includes a device controller, we recommend using their built in work profile instead. Shelter is recommended over Insular and Island as it supports contact search blocking . When using Shelter, you are placing complete trust in its developer as Shelter would be acting as a Device Admin for the work profile and has extensive access to the data stored within it. Auditor \u00b6 Recommendation Auditor is an app which leverages hardware security features to provide device integrity monitoring for supported devices . Currently it works with GrapheneOS and the device's stock operating system. Website Downloads Google Play Source Auditor performs attestation and intrusion detection by: Using a Trust On First Use (TOFU) model between an auditor and auditee , the pair establish a private key in the hardware-backed keystore of the Auditor . The auditor can either be another instance of the Auditor app or the Remote Attestation Service . The auditor records the current state and configuration of the auditee . Should tampering with the operating system of the auditee after the pairing is complete, the auditor will be aware of the change in the device state and configurations. You will be alerted to the change. No personally identifiable information is submitted to the attestation service. We recommend that you sign up with an anonymous account and enable remote attestation for continuous monitoring. If your threat model requires privacy you could consider using Orbot or a VPN to hide your IP address from the attestation service. To make sure that your hardware and operating system is genuine, perform local attestation immediately after the device has been installed and prior to any internet connection. Secure Camera \u00b6 Recommendation Secure Camera is an camera app focused on privacy and security which can capture images, videos, and QR codes. CameraX vendor extensions (Portrait, HDR, Night Sight, Face Retouch, and Auto) are also supported on available devices. Source Code Downloads Google Play Source Main privacy features include: Auto removal of Exif metadata (enabled by default) Use of the new Media API, therefore storage permissions are not required Microphone permission not required unless you want to record sound Note Metadata is not currently deleted from video files but that is planned. The image orientation metadata is not deleted. If you enable location (in Secure Camera) that won't be deleted either. If you want to delete that later you will need to use an external app such as Scrambled Exif . Secure PDF Viewer \u00b6 Recommendation Secure PDF Viewer is a PDF viewer based on pdf.js that doesn't require any permissions. The PDF is fed into a sandboxed webview . This means that it doesn't require permission directly to access content or files. Content-Security-Policy is used to enforce that the JavaScript and styling properties within the WebView are entirely static content. App Info Downloads Google Play Source PrivacyBlur \u00b6 Recommendation PrivacyBlur is a free app which can blur sensitive portions of pictures before sharing them online. Website Downloads Google Play f-droid F-Droid Source Warning You should never use blur to redact text in images . If you want to redact text in an image, draw a box over the text. For this we suggest Pocket Paint or Imagepipe . Obtaining Applications \u00b6 GrapheneOS App Store \u00b6 GrapheneOS's app store is available on GitHub . It supports Android 12 and above and is capable of updating itself. The app store has standalone applications built by the GrapheneOS project such as the Auditor , Camera , and PDF Viewer . If you are looking for these applications, we highly recommend that you get them from GrapheneOS's app store instead of the Play Store, as the apps on their store are signed by the GrapheneOS's project own signature that Google does not have access to. Aurora Store \u00b6 The Google Play Store requires a Google account to login which is not great for privacy. The Aurora Store (a Google Play Store proxy) does not, and works most of the time. F-Droid \u00b6 F-Droid is often recommended as an alternative to Google Play, particularly in the privacy community. The option to add third party repositories and not be confined to Google's walled garden has led to its popularity. F-Droid additionally has reproducible builds for some applications, and is dedicated to free and open source software. However, there are problems with the official F-Droid client, their quality control, and how they build, sign and deliver packages, outlined in this post . Sometimes the official F-Droid repository may fall behind on updates. F-Droid maintainers reuse package IDs while signing apps with their own keys, which is not ideal as it does give the F-Droid team ultimate trust. The Google Play version of some apps may contain unwanted telemetry or lack features that are available in the F-Droid version. We have these general tips: Check if the app developers have their own F-Droid repository first, e.g. Bitwarden , Samourai Wallet , or Newpipe , which have their own repositories with less telemetry, additional features or faster updates. This is the ideal situation and you should be using these repositories if possible. Check if an app is available on the IzzyOnDroid repository. The IzzyOnDroid repository pulls builds directly from GitHub and is the next best thing to the developers' own repositories. We recommend that you download the GitHub builds and install them manually first, then use IzzyOnDroid for any subsequent updates. This will ensure that the signature of the applications you get from IzzyOnDroid matches that of the developer and the packages have not been tampered with. Check if there are any differences between the F-Droid version and the Google Play Store version. Some applications like IVPN do not include certain features (eg AntiTracker ) in their Google Play Store build out of fear of censorship by Google. Evaluate whether the additional features in the F-Droid build are worth the slower updates. Also think about whether faster updates from the Google Play Store are worth the potential privacy issues in your threat model . Neo Store \u00b6 The official F-Droid client targets a low API level and does not utilize the seamless updates feature introduced in Android 12. Targeting lower API levels means that the F-Droid client cannot take advantage of the new improvements in the application sandboxes that comes with higher API levels. For automatic updates to work, the F-Droid client requires that the Privileged Extension be included in the operating system, granting it more privileges than what a normal app would have, which is not great for security. To mitigate these problems, we recommend Neo Store as it supports seamless updates on Android 12 and above without needing any special privileges and targets a higher API level. Recommendation Neo Store is a modern F-Droid client made with MaterialUI, forked from Foxy Droid . Unlike the official F-Droid client, Neo Store supports seamless updates on Android 12 and above without the need for a privileged extension. If your Android distribution is on Android 12 or above and does not include the F-Droid privileged extension , it is highly recommended that you use Neo Store instead of the official client. Downloads APK Download Source Manually with RSS Notifications \u00b6 If an app is released on a platform like GitHub, you may be able to add an RSS feed to your news aggregator that will help you be aware of new releases. Using Secure Camera as an example, you would navigate to its releases page on GitHub and append .atom to the URL: https://github.com/GrapheneOS/Camera/releases.atom Verifying APK Fingerprints \u00b6 If you download APK files to install manually, you can verify their signature with the apksigner tool, which is a part of Android build-tools . Install Java JDK . Download the Android Studio command line tools . Extract the downloaded archive: unzip commandlinetools-*.zip cd cmdline-tools ./bin/sdkmanager --sdk_root = ./ \"build-tools;29.0.3\" Run the signature verification command: ./build-tools/29.0.3/apksigner verify --print-certs ../Camera-37.apk The resulting hashes can then be compared with another source. Some developers such as Signal show the fingerprints on their website. Signer #1 certificate DN: CN=GrapheneOS Signer #1 certificate SHA-256 digest: 6436b155b917c2f9a9ed1d15c4993a5968ffabc94947c13f2aeee14b7b27ed59 Signer #1 certificate SHA-1 digest: 23e108677a2e1b1d6e6b056f3bb951df7ad5570c Signer #1 certificate MD5 digest: dbbcd0cac71bd6fa2102a0297c6e0dd3","title":"Android"},{"location":"android/#aosp-derivatives","text":"We recommend installing one of these custom Android operating systems on your device, listed in order of preference, depending on your device's compatibility with these operating systems. Note End-of-life devices (such as GrapheneOS or CalyxOS's \"extended support\" devices) do not have full security patches (firmware updates) due to the OEM discontinuing support. These devices cannot be considered completely secure regardless of installed software.","title":"AOSP Derivatives"},{"location":"android/#grapheneos","text":"Recommendation GrapheneOS is the best choice when it comes to privacy and security. GrapheneOS provides additional security hardening and privacy improvements. It has a hardened memory allocator , network and sensor permissions, and various other security features . GrapheneOS also comes with full firmware updates and signed builds, so verified boot is fully supported. Homepage Privacy Policy GrapheneOS supports Sandboxed Google Play , which runs Google Play Services fully sandboxed like any other regular app. This means you can take advantage of most Google Play Services, such as push notifications , while giving you full control over their permissions and access, and while containing them to a specific work profile or user profile of your choice. Google Pixel phones are the only devices that currently meet GrapheneOS's hardware security requirements .","title":"GrapheneOS"},{"location":"android/#calyxos","text":"Recommendation CalyxOS is a system with some privacy features on top of AOSP , including Datura firewall, Signal integration in the dialer app, and a built in panic button. CalyxOS also comes with firmware updates and signed builds, so verified boot is fully supported. Homepage Privacy Policy For people who need Google Play Services, CalyxOS optionally includes microG . CalyxOS also includes alternate location services, Mozilla and DejaVu . CalyxOS only supports Google Pixel phones. However, support for the OnePlus 8T/9 and Fairphone 4 is currently in beta .","title":"CalyxOS"},{"location":"android/#divestos","text":"Recommendation DivestOS is a soft- fork of LineageOS . DivestOS inherits many supported devices from LineageOS. It has signed builds, making it possible to have verified boot on some non-Pixel devices. Homepage Privacy Policy DivestOS has automated kernel vulnerability ( CVE ) patching , fewer proprietary blobs, a custom hosts file, and F-Droid as the app store. It includes UnifiedNlp for network location. Its hardened WebView, Mulch , enables CFI for all architectures and includes network state partitioning . DivestOS also includes kernel patches from GrapheneOS and enables all available kernel security features via defconfig hardening . All kernels newer than version 3.4 include full page sanitization and all ~22 Clang-compiled kernels have -ftrivial-auto-var-init=zero enabled. DivestOS implements some system hardening patches originally developed for GrapheneOS. DivestOS 16.0, 17.1, and 18.1 implements GrapheneOS's INTERNET permission toggle, hardened memory allocator , exec-spawning , JNI constification , and partial bionic hardening patchsets. 17.1 and 18.1 feature GrapheneOS's per-network full MAC randomization option, and ptrace_scope control, and automatic reboot/Wi-Fi/Bluetooth timeout options . Warning DivestOS firmware update status and quality control varies across the devices it supports. We still recommend GrapheneOS or CalyxOS depending on your device's compatibility. For other devices, DivestOS is a good alternative. Not all of the supported devices have verified boot, and some perform it better than others.","title":"DivestOS"},{"location":"android/#android-devices","text":"Avoid buying phones from mobile network operators. These often have a locked bootloader and do not support OEM unlocking . These phone variants will prevent you from installing any kind of alternative Android distribution. Be very careful about buying second hand phones from online marketplaces. Always check the reputation of the seller. If the device is stolen there's a possibility of IMEI blacklisting . There is also a risk involved with you being associated with the activity of the previous owner. A few more tips regarding Android devices and operating system compatibility: Do not buy devices that have reached or are near their end-of-life, additional firmware updates must be provided by the manufacturer. Do not buy preloaded LineageOS or /e/ OS phones or any Android phones without proper Verified Boot support and firmware updates. These devices also have no way for you to check whether they've been tampered with. In short, if a device or Android distribution is not listed here, there is probably a good reason, so check our discussions page.","title":"Android Devices"},{"location":"android/#google-pixel","text":"Recommendation Google Pixel devices are known to have good security and properly support Verified Boot , even when installing custom operating systems. Beginning with the Pixel 6 and 6 Pro , Pixel devices receive a minimum of 5 years of guaranteed security updates, ensuring a much longer lifespan compared to the 2-4 years competing OEMs typically offer. Store Unless you have a need for specific CalyxOS features that are unavailable on GrapheneOS, we strongly recommend GrapheneOS over other operating system choices on Pixel devices. The installation of GrapheneOS on a Pixel phone is easy with their web installer . If you don't feel comfortable doing it yourself and are willing to spend a bit of extra money, check out the NitroPhone as they come preloaded with GrapheneOS from the reputable Nitrokey company. A few more tips for purchasing a Google Pixel: If you're after a bargain on a Pixel device, we suggest buying an \" a \" model, just after the next flagship is released. Discounts are usually available because Google will be trying to clear their stock. Consider price beating options and specials offered at brick and mortar stores. Look at online community bargain sites in your country. These can alert you to good sales. Google provides a list showing the support cycle for each one of their devices. The price per day for a device can be calculated as: \\(\\text{Cost} \\over \\text {EOL Date }-\\text{ Current Date}\\) , meaning that the longer use of the device the lower cost per day.","title":"Google Pixel"},{"location":"android/#other-devices","text":"Important Google Pixel phones are the only devices we recommend for purchase. Pixel phones have stronger hardware security than any other Android devices currently on the market, due to proper AVB support for third party operating systems and Google's custom Titan security chips acting as the Secure Element. Secure Elements are more limited than the processor's Trusted Execution Environment used by most other phones as they are only used for secrets storage, hardware attestation and rate limiting but not running \"trusted\" programs. Phones without a Secure Element have to use the TEE for secrets storage, rate limiting, and trusted computing, which results in a larger attack surface . The following OEMs are only mentioned as they have phones compatible with the operating systems recommended by us. If you are purchasing a new device, we only recommend purchasing a Google Pixel. When purchasing a device, we recommend getting one as new as possible. The software and firmware of mobile devices are only supported for a limited time, so buying new extends that lifespan as much as possible.","title":"Other Devices"},{"location":"android/#oneplus","text":"If you are unable to obtain a Google Pixel, recent OnePlus devices are the next best option if you want to run a custom OS without privileged Play Services. OnePlus 8 and later devices will receive 4 years of security updates from their initial launch date. CalyxOS has experimental support for the OnePlus 8T and 9 . DivestOS has support for most OnePlus devices up to the OnePlus 7T Pro , with varying levels of support.","title":"OnePlus"},{"location":"android/#fairphone","text":"Danger The Fairphone 3 and 4 are not secure by default, as the stock bootloader trusts the public AVB signing key . This breaks verified boot on a stock Fairphone device, as the system will boot alternative Android operating systems such (such as /e/) without any warning about custom operating system usage. This problem is somewhat mitigated when you install a custom operating system such as CalyxOS or DivestOS and trust the developer's signing keys rather than the stock system keys, however a vulnerability in CalyxOS or DivestOS's recovery environments could still potentially allow an attacker to bypass AVB . To reiterate, you must install a custom operating system with custom boot keys to use Fairphone devices in a secure manner. CalyxOS has experimental support for the Fairphone 4 . DivestOS has builds available for the Fairphone 3 . Fairphone markets their devices as receiving 6 years of support. However, the SoC (Qualcomm Snapdragon 750G on the Fairphone 4) has a considerably shorter EOL date. This means that firmware security updates from Qualcomm for the Fairphone 4 will end in September 2023, regardless of whether Fairphone continues to release software security updates.","title":"Fairphone"},{"location":"android/#general-apps","text":"","title":"General Apps"},{"location":"android/#orbot","text":"Recommendation Orbot is a free proxy app that routes your connections through the Tor Network. Homepage Downloads Google Play f-droid F-Droid Source Source Orbot can proxy individual apps if they support SOCKS or HTTP proxying. It can also proxy all your network connections using VpnService and can be used with the VPN killswitch in Settings \u2192 Network & internet \u2192 VPN \u2192 \u2192 Block connections without VPN . For resistance against traffic analysis attacks, consider enabling Isolate Destination Address in \u2192 Settings \u2192 Connectivity . This will use a completely different Tor Circuit (different middle relay and exit nodes) for every domain you connect to. Tip Orbot is often outdated on the Guardian Project's F-Droid repository and Google Play so consider downloading directly from the GitHub repository instead. All versions are signed using the same signature so they should be compatible with each other.","title":"Orbot"},{"location":"android/#shelter","text":"Recommendation Shelter is an app that helps you leverage the Android work profile to isolate other apps. Shelter supports blocking contact search cross profiles and sharing files across profiles via the default file manager ( DocumentsUI ). Project Info Downloads Google Play f-droid F-Droid Source Warning As CalyxOS includes a device controller, we recommend using their built in work profile instead. Shelter is recommended over Insular and Island as it supports contact search blocking . When using Shelter, you are placing complete trust in its developer as Shelter would be acting as a Device Admin for the work profile and has extensive access to the data stored within it.","title":"Shelter"},{"location":"android/#auditor","text":"Recommendation Auditor is an app which leverages hardware security features to provide device integrity monitoring for supported devices . Currently it works with GrapheneOS and the device's stock operating system. Website Downloads Google Play Source Auditor performs attestation and intrusion detection by: Using a Trust On First Use (TOFU) model between an auditor and auditee , the pair establish a private key in the hardware-backed keystore of the Auditor . The auditor can either be another instance of the Auditor app or the Remote Attestation Service . The auditor records the current state and configuration of the auditee . Should tampering with the operating system of the auditee after the pairing is complete, the auditor will be aware of the change in the device state and configurations. You will be alerted to the change. No personally identifiable information is submitted to the attestation service. We recommend that you sign up with an anonymous account and enable remote attestation for continuous monitoring. If your threat model requires privacy you could consider using Orbot or a VPN to hide your IP address from the attestation service. To make sure that your hardware and operating system is genuine, perform local attestation immediately after the device has been installed and prior to any internet connection.","title":"Auditor"},{"location":"android/#secure-camera","text":"Recommendation Secure Camera is an camera app focused on privacy and security which can capture images, videos, and QR codes. CameraX vendor extensions (Portrait, HDR, Night Sight, Face Retouch, and Auto) are also supported on available devices. Source Code Downloads Google Play Source Main privacy features include: Auto removal of Exif metadata (enabled by default) Use of the new Media API, therefore storage permissions are not required Microphone permission not required unless you want to record sound Note Metadata is not currently deleted from video files but that is planned. The image orientation metadata is not deleted. If you enable location (in Secure Camera) that won't be deleted either. If you want to delete that later you will need to use an external app such as Scrambled Exif .","title":"Secure Camera"},{"location":"android/#secure-pdf-viewer","text":"Recommendation Secure PDF Viewer is a PDF viewer based on pdf.js that doesn't require any permissions. The PDF is fed into a sandboxed webview . This means that it doesn't require permission directly to access content or files. Content-Security-Policy is used to enforce that the JavaScript and styling properties within the WebView are entirely static content. App Info Downloads Google Play Source","title":"Secure PDF Viewer"},{"location":"android/#privacyblur","text":"Recommendation PrivacyBlur is a free app which can blur sensitive portions of pictures before sharing them online. Website Downloads Google Play f-droid F-Droid Source Warning You should never use blur to redact text in images . If you want to redact text in an image, draw a box over the text. For this we suggest Pocket Paint or Imagepipe .","title":"PrivacyBlur"},{"location":"android/#obtaining-applications","text":"","title":"Obtaining Applications"},{"location":"android/#grapheneos-app-store","text":"GrapheneOS's app store is available on GitHub . It supports Android 12 and above and is capable of updating itself. The app store has standalone applications built by the GrapheneOS project such as the Auditor , Camera , and PDF Viewer . If you are looking for these applications, we highly recommend that you get them from GrapheneOS's app store instead of the Play Store, as the apps on their store are signed by the GrapheneOS's project own signature that Google does not have access to.","title":"GrapheneOS App Store"},{"location":"android/#aurora-store","text":"The Google Play Store requires a Google account to login which is not great for privacy. The Aurora Store (a Google Play Store proxy) does not, and works most of the time.","title":"Aurora Store"},{"location":"android/#f-droid","text":"F-Droid is often recommended as an alternative to Google Play, particularly in the privacy community. The option to add third party repositories and not be confined to Google's walled garden has led to its popularity. F-Droid additionally has reproducible builds for some applications, and is dedicated to free and open source software. However, there are problems with the official F-Droid client, their quality control, and how they build, sign and deliver packages, outlined in this post . Sometimes the official F-Droid repository may fall behind on updates. F-Droid maintainers reuse package IDs while signing apps with their own keys, which is not ideal as it does give the F-Droid team ultimate trust. The Google Play version of some apps may contain unwanted telemetry or lack features that are available in the F-Droid version. We have these general tips: Check if the app developers have their own F-Droid repository first, e.g. Bitwarden , Samourai Wallet , or Newpipe , which have their own repositories with less telemetry, additional features or faster updates. This is the ideal situation and you should be using these repositories if possible. Check if an app is available on the IzzyOnDroid repository. The IzzyOnDroid repository pulls builds directly from GitHub and is the next best thing to the developers' own repositories. We recommend that you download the GitHub builds and install them manually first, then use IzzyOnDroid for any subsequent updates. This will ensure that the signature of the applications you get from IzzyOnDroid matches that of the developer and the packages have not been tampered with. Check if there are any differences between the F-Droid version and the Google Play Store version. Some applications like IVPN do not include certain features (eg AntiTracker ) in their Google Play Store build out of fear of censorship by Google. Evaluate whether the additional features in the F-Droid build are worth the slower updates. Also think about whether faster updates from the Google Play Store are worth the potential privacy issues in your threat model .","title":"F-Droid"},{"location":"android/#neo-store","text":"The official F-Droid client targets a low API level and does not utilize the seamless updates feature introduced in Android 12. Targeting lower API levels means that the F-Droid client cannot take advantage of the new improvements in the application sandboxes that comes with higher API levels. For automatic updates to work, the F-Droid client requires that the Privileged Extension be included in the operating system, granting it more privileges than what a normal app would have, which is not great for security. To mitigate these problems, we recommend Neo Store as it supports seamless updates on Android 12 and above without needing any special privileges and targets a higher API level. Recommendation Neo Store is a modern F-Droid client made with MaterialUI, forked from Foxy Droid . Unlike the official F-Droid client, Neo Store supports seamless updates on Android 12 and above without the need for a privileged extension. If your Android distribution is on Android 12 or above and does not include the F-Droid privileged extension , it is highly recommended that you use Neo Store instead of the official client. Downloads APK Download Source","title":"Neo Store"},{"location":"android/#manually-with-rss-notifications","text":"If an app is released on a platform like GitHub, you may be able to add an RSS feed to your news aggregator that will help you be aware of new releases. Using Secure Camera as an example, you would navigate to its releases page on GitHub and append .atom to the URL: https://github.com/GrapheneOS/Camera/releases.atom","title":"Manually with RSS Notifications"},{"location":"android/#verifying-apk-fingerprints","text":"If you download APK files to install manually, you can verify their signature with the apksigner tool, which is a part of Android build-tools . Install Java JDK . Download the Android Studio command line tools . Extract the downloaded archive: unzip commandlinetools-*.zip cd cmdline-tools ./bin/sdkmanager --sdk_root = ./ \"build-tools;29.0.3\" Run the signature verification command: ./build-tools/29.0.3/apksigner verify --print-certs ../Camera-37.apk The resulting hashes can then be compared with another source. Some developers such as Signal show the fingerprints on their website. Signer #1 certificate DN: CN=GrapheneOS Signer #1 certificate SHA-256 digest: 6436b155b917c2f9a9ed1d15c4993a5968ffabc94947c13f2aeee14b7b27ed59 Signer #1 certificate SHA-1 digest: 23e108677a2e1b1d6e6b056f3bb951df7ad5570c Signer #1 certificate MD5 digest: dbbcd0cac71bd6fa2102a0297c6e0dd3","title":"Verifying APK Fingerprints"},{"location":"browsers/","text":"These are our currently recommended web browsers and configurations. In general, we recommend keeping extensions to a minimum: they have privileged access within your browser, require you to trust the developer, can make you stand out , and weaken site isolation. General Recommendations \u00b6 Tor Browser \u00b6 Recommendation Tor Browser is the choice if you need anonymity. This browser provides you with access to the Tor Bridges and Tor Network , along with extensions that can be automatically configured to fit its three security levels: Standard , Safer and Safest . We recommend that you do not change any of Tor Browser's default configurations outside of the standard security levels. Homepage tor Privacy Policy Downloads Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid Source Danger You should never install any additional extensions on Tor Browser, including the ones we suggest for Firefox. Browser extensions make you stand out from others on the Tor network, thus making your browser easier to fingerprint . Desktop Recommendations \u00b6 Firefox \u00b6 Recommendation Firefox provides strong privacy settings such as Enhanced Tracking Protection , which can help block various types of tracking . Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Source Warning Firefox includes a unique download token in downloads from Mozilla's website and uses telemetry in Firefox to send the token. The token is not included in releases from the Mozilla FTP . Recommended Configuration \u00b6 Tor Browser is the only way to truly browse the internet anonymously. When you use Firefox we recommend changing the following settings to protect your privacy from certain parties, but all browsers other than Tor Browser will be traceable by somebody in some regard or another. These options can be found in \u2192 Settings \u2192 Privacy & Security . Enhanced Tracking Protection \u00b6 Select Strict Enhanced Tracking Protection This protects you by blocking social media trackers, fingerprinting scripts (note that this does not protect you from all fingerprinting), cryptominers, cross-site tracking cookies, and some other tracking content. ETP protects against many common threats, but it does not block all tracking avenues because it is designed to have minimal to no impact on site usability. Sanitize on Close \u00b6 If you want to stay logged in to particular sites, you can allow exceptions in Cookies and Site Data \u2192 Manage Exceptions... Check Delete cookies and site data when Firefox is closed This protects you from persistent cookies, but does not protect you against cookies acquired during any one browsing session. When this is enabled, it becomes possible to easily cleanse your browser cookies by simply restarting Firefox. You can set exceptions on a per-site basis, if you wish to stay logged in to a particular site you visit often. Search Suggestions \u00b6 Disable Suggestions from the web Disable Suggestions from sponsors Disable Improve the Firefox Suggest experience Search suggestion features may not be available in your region. Search suggestions send everything you type in the address bar to the default search engine, regardless of whether you submit an actual search. Disabling search suggestions allows you to more precisely control what data you send to your search engine provider. Telemetry \u00b6 Uncheck Allow Firefox to send technical and interaction data to Mozilla Uncheck Allow Firefox to install and run studies Uncheck Allow Firefox to send backlogged crash reports on your behalf Firefox sends data about your Firefox version and language; device operating system and hardware configuration; memory, basic information about crashes and errors; outcome of automated processes like updates, safebrowsing, and activation to us. When Firefox sends data to us, your IP address is temporarily collected as part of our server logs. HTTPS -Only Mode \u00b6 Select Enable HTTPS -Only Mode in all windows This prevents you from unintentionally connecting to a website in plain-text HTTP . Sites without HTTPS are uncommon nowadays, so this should have little to no impact on your day to day browsing. Sync \u00b6 Firefox Sync allows your browsing data (history, bookmarks, etc.) to be accessible on all your devices and protects it with E2EE . Arkenfox (advanced) \u00b6 The Arkenfox project provides a set of carefully considered options for Firefox. If you decide to use Arkenfox, a few options are subjectively strict and/or may cause some websites to not work properly - which you can easily change to suit your needs. We strongly recommend reading through their full wiki . Arkenfox also enables container support. Brave \u00b6 Recommendation Brave Browser includes a built in content blocker and privacy features , many of which are enabled by default. Brave is built upon the Chromium web browser project, so it should feel familiar and have minimal website compatibility issues. We don't recommend Brave's mobile browser offerings as there are better options for mobile platforms. Homepage Privacy Policy Downloads Windows macOS Linux (1) Source We advise against using the Flatpak version of Brave as it is believed to feature a weaker sandboxing system. As well, the package is not maintained by Brave Software, Inc. Recommended Configuration \u00b6 Tor Browser is the only way to truly browse the internet anonymously. When you use Brave we recommend changing the following settings to protect your privacy from certain parties, but all browsers other than the Tor Browser will be traceable by somebody in some regard or another. These options can be found in \u2192 Settings . Shields \u00b6 Brave includes some anti-fingerprinting measures in its Shields feature. We suggest configuring these options globally across all pages that you visit. Shields' options can be downgraded on a per-site basis as needed, but by default we recommend setting the following: Select Aggressive under Trackers & ads blocking Use default filter lists Brave allows you to select additional content filters within the internal brave://adblock page. We advise against using this feature; instead, keep the default filter lists. Using extra lists will make you stand out from other Brave users and may also increase attack surface if there is an exploit in Brave and a malicious rule is added to one of the lists you use. (Optional) Select Block Scripts (1) Select Strict, may break sites under Block fingerprinting This option provides functionality similar to uBlock Origin's advanced blocking modes or the NoScript extension. Social media blocking \u00b6 Uncheck all social media components Privacy and Security \u00b6 Select Disable Non-Proxied UDP under WebRTC IP Handling Policy Uncheck Use Google services for push messaging Uncheck Allow privacy-preserving product analytics (P3A) Uncheck Automatically send daily usage ping to Brave Select Always use secure connections in the Security menu Sanitizing on Close Select Clear cookies and site data when you close all windows in the Cookies and other site data menu If you wish to stay logged in to a particular site you visit often, you can set exceptions on a per-site basis under the Customized behaviors section. Extensions \u00b6 Disable built-in extensions you do not use in Extensions Uncheck Hangouts Uncheck Private window with Tor (1) Uncheck WebTorrent Brave is not as resistant to fingerprinting as the Tor Browser and far fewer people use Brave with Tor, so you will stand out. Where strong anonymity is required use the Tor Browser . IPFS \u00b6 InterPlanetary File System (IPFS) is a decentralized, peer-to-peer network for storing and sharing data in a distributed filesystem. Unless you use the feature, disable it. Select Disabled on Method to resolve IPFS resources Additional settings \u00b6 Under the system System menu Uncheck Continue running apps when Brave is closed to disable background apps (1) This option is not present on all platforms. Mobile Recommendations \u00b6 On Android, Firefox is still less secure than Chromium-based alternatives: Mozilla's engine, GeckoView , has yet to support site isolation or enable isolatedProcess . On iOS, any app that can browse the web is restricted to using an Apple-provided WebKit framework , so there is little reason to use a third-party web browser. Bromite \u00b6 Recommendation Bromite is a Chromium-based browser with privacy and security enhancements, built-in ad blocking, and some fingerprinting randomization. Homepage Privacy Policy Downloads f-droid F-Droid (1) Source Neo Store users can enable the Bromite repository in \u2192 Repositories These options can be found in \u2192 Settings \u2192 Privacy and Security . Recommended Configuration \u00b6 HTTPS -Only Mode \u00b6 Select Always use secure connections This prevents you from unintentionally connecting to a website in plain-text HTTP . The HTTP protocol is extremely uncommon nowadays, so this should have little to no impact on your day to day browsing. Always-on Incognito Mode \u00b6 Select Open links in incognito tabs always Select Close all open tabs on exit Select Open external links in incognito Safari \u00b6 Recommendation Safari is the default browser in iOS. It includes privacy features such as Intelligent Tracking Protection, Privacy Report, isolated Private Browsing tabs, iCloud Private Relay, and automatic HTTPS upgrades. Website Privacy Policy Recommended Configuration \u00b6 These options can be found in Settings \u2192 Safari \u2192 Privacy and Security . Cross-Site Tracking Prevention \u00b6 Enable Prevent Cross-Site Tracking This enables WebKit's Intelligent Tracking Protection . The feature helps protect against unwanted tracking by using on-device machine learning to stop trackers. ITP protects against many common threats, but it does not block all tracking avenues because it is designed to not interfere with website usability. Privacy Report \u00b6 Privacy Report provides a snapshot of cross-site trackers currently prevented from profiling you on the website you're visiting. It can also display a weekly report to show which trackers have been blocked over time. Privacy Report is accessible via the Page Settings menu ( ). Privacy Preserving Ad Measurement \u00b6 Disable Privacy Preserving Ad Measurement Ad click measurement has traditionally used tracking technology that infringes on user privacy. Private Click Measurement is a WebKit feature and proposed web standard aimed towards allowing advertisers to measure the effectiveness of web campaigns without compromising on user privacy. The feature has little privacy concerns on its own, so while you can choose to leave it on, we consider the fact that it's automatically disabled in Private Browsing to be an indicator for disabling the feature. Apple Pay \u00b6 If you do not use Apple Pay, you can toggle off the ability for websites to check for it. Disable Allow websites to check for Apple Pay and Apple Card Always-on Private Browsing \u00b6 Open Safari and tap the Tabs button, located in the bottom right. Then, expand the Tab Groups list. Select Private Safari's Private Browsing mode offers additional privacy protections. Private Browsing uses a new ephemeral session for each tab, meaning tabs are isolated from one another. There are also other smaller privacy benefits with Private Browsing, such as not sending a webpage\u2019s address to Apple when using Safari's translation feature. Do note that Private Browsing does not save cookies and website data, so it won't be possible to remain signed into sites. This may be an inconvenience. iCloud Sync \u00b6 Synchronization of Safari History, Tab Groups, iCloud Tabs, and saved passwords are E2EE . However, bookmarks are not . Apple can decrypt and access them in accordance with their privacy policy . If you use iCloud, we also recommend checking to ensure Safari's default download location is set to locally on your device. This option can be found in Settings \u2192 Safari \u2192 General \u2192 Downloads . Additional Resources \u00b6 We generally do not recommend installing any extensions as they increase your attack surface . However, uBlock Origin or AdGuard may prove useful if you value content blocking functionality. uBlock Origin \u00b6 Recommendation uBlock Origin is a popular content blocker that could help you block ads, trackers, and fingerprinting scripts. Extension Info Downloads Firefox Chrome Edge Opera Source We suggest leaving the extension in its default configuration. Additional filter lists can impact performance and may increase attack surface , so only apply what you need. If there is a vulnerability in uBlock Origin a third party filter could add malicious rules that can potentially steal user data. uBlock Origin is also a Mozilla Recommended Extension . Recommended extensions are manually reviewed by Mozilla staff security experts to ensure they meet the highest standards of security, functionality, and user experience. AdGuard for Safari \u00b6 Recommendation AdGuard for Safari is a free and open-source content-blocking extension for Safari that uses the native Content Blocker API . We suggest enabling the filters labled #recommended under the \"Ad Blocking\" and \"Privacy\" content blockers . The #recommended filters can also be enabled for the \"Social Widgets\" and \"Annoyances\" content blockers, but they may break some social media functions. Website Privacy Policy Downloads Safari App Store Source Additional filter lists do slow things down and may increase your attack surface , so only apply what you need. There is also AdGuard for iOS which is able to perform system-wide content blocking by means of DNS filtering. Snowflake \u00b6 Recommendation Snowflake allows you to donate bandwidth to the Tor Project by operating a \"Snowflake proxy\" within your browser. People who are censored can use Snowflake proxies to connect to the Tor network. Snowflake is a great way to contribute to the network even if you don't have the technical know-how to run a Tor relay or bridge. Website Downloads Browser (Leave page open to continue being a Snowflake proxy) Firefox Chrome Snowflake does not increase your privacy in any way, nor is it used to connect to the Tor network within your personal browser. However, if your internet connection is uncensored, you should consider running it to help people in censored networks achieve better privacy themselves. There is no need to worry about which websites people are accessing through your proxy\u2014their visible browsing IP address will match their Tor exit node, not yours. Running a Snowflake proxy is low-risk, even moreso than running a Tor relay or bridge which are already not particularly risky endeavours. However, it does still proxy traffic through your network which can be impactful in some ways, especially if your network is bandwidth-limited. Make sure you understand how Snowflake works before deciding whether to run a proxy. You can enable Snowflake in your browser by clicking the switch below and leaving this page open . You can also install Snowflake as a browser extension to have it always run while your browser is open, however adding third-party extensions can increase your attack surface . Terms of Service; Didn't Read \u00b6 Recommendation Terms of Service; Didn't Read grades websites based on their terms of service agreements and privacy policies. It also gives short summaries of those agreements. The analyses and ratings are published transparently by a community of reviewers. Website Privacy Policy We do not recommend installing ToS;DR as a browser extension; the same information is also provided on their website.","title":"Web Browsers"},{"location":"browsers/#general-recommendations","text":"","title":"General Recommendations"},{"location":"browsers/#tor-browser","text":"Recommendation Tor Browser is the choice if you need anonymity. This browser provides you with access to the Tor Bridges and Tor Network , along with extensions that can be automatically configured to fit its three security levels: Standard , Safer and Safest . We recommend that you do not change any of Tor Browser's default configurations outside of the standard security levels. Homepage tor Privacy Policy Downloads Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid Source Danger You should never install any additional extensions on Tor Browser, including the ones we suggest for Firefox. Browser extensions make you stand out from others on the Tor network, thus making your browser easier to fingerprint .","title":"Tor Browser"},{"location":"browsers/#desktop-recommendations","text":"","title":"Desktop Recommendations"},{"location":"browsers/#firefox","text":"Recommendation Firefox provides strong privacy settings such as Enhanced Tracking Protection , which can help block various types of tracking . Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Source Warning Firefox includes a unique download token in downloads from Mozilla's website and uses telemetry in Firefox to send the token. The token is not included in releases from the Mozilla FTP .","title":"Firefox"},{"location":"browsers/#recommended-configuration","text":"Tor Browser is the only way to truly browse the internet anonymously. When you use Firefox we recommend changing the following settings to protect your privacy from certain parties, but all browsers other than Tor Browser will be traceable by somebody in some regard or another. These options can be found in \u2192 Settings \u2192 Privacy & Security .","title":"Recommended Configuration"},{"location":"browsers/#sync","text":"Firefox Sync allows your browsing data (history, bookmarks, etc.) to be accessible on all your devices and protects it with E2EE .","title":"Sync"},{"location":"browsers/#arkenfox-advanced","text":"The Arkenfox project provides a set of carefully considered options for Firefox. If you decide to use Arkenfox, a few options are subjectively strict and/or may cause some websites to not work properly - which you can easily change to suit your needs. We strongly recommend reading through their full wiki . Arkenfox also enables container support.","title":"Arkenfox (advanced)"},{"location":"browsers/#brave","text":"Recommendation Brave Browser includes a built in content blocker and privacy features , many of which are enabled by default. Brave is built upon the Chromium web browser project, so it should feel familiar and have minimal website compatibility issues. We don't recommend Brave's mobile browser offerings as there are better options for mobile platforms. Homepage Privacy Policy Downloads Windows macOS Linux (1) Source We advise against using the Flatpak version of Brave as it is believed to feature a weaker sandboxing system. As well, the package is not maintained by Brave Software, Inc.","title":"Brave"},{"location":"browsers/#recommended-configuration_1","text":"Tor Browser is the only way to truly browse the internet anonymously. When you use Brave we recommend changing the following settings to protect your privacy from certain parties, but all browsers other than the Tor Browser will be traceable by somebody in some regard or another. These options can be found in \u2192 Settings .","title":"Recommended Configuration"},{"location":"browsers/#mobile-recommendations","text":"On Android, Firefox is still less secure than Chromium-based alternatives: Mozilla's engine, GeckoView , has yet to support site isolation or enable isolatedProcess . On iOS, any app that can browse the web is restricted to using an Apple-provided WebKit framework , so there is little reason to use a third-party web browser.","title":"Mobile Recommendations"},{"location":"browsers/#bromite","text":"Recommendation Bromite is a Chromium-based browser with privacy and security enhancements, built-in ad blocking, and some fingerprinting randomization. Homepage Privacy Policy Downloads f-droid F-Droid (1) Source Neo Store users can enable the Bromite repository in \u2192 Repositories These options can be found in \u2192 Settings \u2192 Privacy and Security .","title":"Bromite"},{"location":"browsers/#recommended-configuration_2","text":"","title":"Recommended Configuration"},{"location":"browsers/#safari","text":"Recommendation Safari is the default browser in iOS. It includes privacy features such as Intelligent Tracking Protection, Privacy Report, isolated Private Browsing tabs, iCloud Private Relay, and automatic HTTPS upgrades. Website Privacy Policy","title":"Safari"},{"location":"browsers/#recommended-configuration_3","text":"These options can be found in Settings \u2192 Safari \u2192 Privacy and Security .","title":"Recommended Configuration"},{"location":"browsers/#additional-resources","text":"We generally do not recommend installing any extensions as they increase your attack surface . However, uBlock Origin or AdGuard may prove useful if you value content blocking functionality.","title":"Additional Resources"},{"location":"browsers/#ublock-origin","text":"Recommendation uBlock Origin is a popular content blocker that could help you block ads, trackers, and fingerprinting scripts. Extension Info Downloads Firefox Chrome Edge Opera Source We suggest leaving the extension in its default configuration. Additional filter lists can impact performance and may increase attack surface , so only apply what you need. If there is a vulnerability in uBlock Origin a third party filter could add malicious rules that can potentially steal user data. uBlock Origin is also a Mozilla Recommended Extension . Recommended extensions are manually reviewed by Mozilla staff security experts to ensure they meet the highest standards of security, functionality, and user experience.","title":"uBlock Origin"},{"location":"browsers/#adguard-for-safari","text":"Recommendation AdGuard for Safari is a free and open-source content-blocking extension for Safari that uses the native Content Blocker API . We suggest enabling the filters labled #recommended under the \"Ad Blocking\" and \"Privacy\" content blockers . The #recommended filters can also be enabled for the \"Social Widgets\" and \"Annoyances\" content blockers, but they may break some social media functions. Website Privacy Policy Downloads Safari App Store Source Additional filter lists do slow things down and may increase your attack surface , so only apply what you need. There is also AdGuard for iOS which is able to perform system-wide content blocking by means of DNS filtering.","title":"AdGuard for Safari"},{"location":"browsers/#snowflake","text":"Recommendation Snowflake allows you to donate bandwidth to the Tor Project by operating a \"Snowflake proxy\" within your browser. People who are censored can use Snowflake proxies to connect to the Tor network. Snowflake is a great way to contribute to the network even if you don't have the technical know-how to run a Tor relay or bridge. Website Downloads Browser (Leave page open to continue being a Snowflake proxy) Firefox Chrome Snowflake does not increase your privacy in any way, nor is it used to connect to the Tor network within your personal browser. However, if your internet connection is uncensored, you should consider running it to help people in censored networks achieve better privacy themselves. There is no need to worry about which websites people are accessing through your proxy\u2014their visible browsing IP address will match their Tor exit node, not yours. Running a Snowflake proxy is low-risk, even moreso than running a Tor relay or bridge which are already not particularly risky endeavours. However, it does still proxy traffic through your network which can be impactful in some ways, especially if your network is bandwidth-limited. Make sure you understand how Snowflake works before deciding whether to run a proxy. You can enable Snowflake in your browser by clicking the switch below and leaving this page open . You can also install Snowflake as a browser extension to have it always run while your browser is open, however adding third-party extensions can increase your attack surface .","title":"Snowflake"},{"location":"browsers/#terms-of-service-didnt-read","text":"Recommendation Terms of Service; Didn't Read grades websites based on their terms of service agreements and privacy policies. It also gives short summaries of those agreements. The analyses and ratings are published transparently by a community of reviewers. Website Privacy Policy We do not recommend installing ToS;DR as a browser extension; the same information is also provided on their website.","title":"Terms of Service; Didn't Read"},{"location":"calendar-contacts/","text":"Calendaring and contacts are some of the most sensitive data posess. Use only products that use E2EE at rest. This prevents a provider from reading your data. Cloud/ SaaS Providers \u00b6 These products are included with an subscription with their respective email providers . Tutanota \u00b6 Recommendation Tutanota offers a free and encrypted calendar across their supported platforms. Features include: automatic E2EE of all data, sharing features, import/export functionality, and more . Multiple calendars and extended sharing functionality is limited to paid subscribers. Website Privacy Policy Downloads Web Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid App Store Source Proton Calendar \u00b6 Recommendation Proton Calendar is an encrypted calendar serivce available to ProtonMail members. Features include: automatic E2EE of all data, sharing features, import/export functionality, and more . Those on the free tier get access to a single calendar, whereas paid subscribers can create up to 20 calendars. Extended sharing functionality is also limited to paid subscribers. Proton Calendar is currently only available for the web and Android. Website Privacy Policy Downloads Web Google Play Source Self-hostable \u00b6 Some of these options are self-hostable, but could be offered by third party SaaS providers for a fee: EteSync \u00b6 Recommendation EteSync is a secure, end-to-end encrypted, and privacy-respecting cloud backup and synchronization software for your personal information (e.g. contacts and calendars). There are native clients for Android, iOS, and the web, and an adapter layer for most desktop clients. EteSync also offers optional software as a service for $24 per year to use, or you can host the server yourself for free. Website Privacy Policy Downloads Client Instructions Google Play f-droid F-Droid App Store Source Nextcloud \u00b6 Recommendation Nextcloud is a suite of client-server software for creating and using file hosting services. This includes calendar sync via CalDAV and contacts sync via CardDAV. Nextcloud is free and open-source, thereby allowing anyone to install and operate it without charge on a private server. You can self host Nextcloud or pay for service from a provider . Homepage Downloads Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid App Store Source DecSync CC \u00b6 Recommendation DecSync CC synchronizes contacts, calendars and tasks using DecSync. It stores this data in a shared directory, using Syncthing , or any other file synchronization service. There are plugins to sync other types of data such as RSS . Project Info Downloads Google Play f-droid F-Droid","title":"Calendar and Contact Sync"},{"location":"calendar-contacts/#cloudsaas-providers","text":"These products are included with an subscription with their respective email providers .","title":"Cloud/SaaS Providers"},{"location":"calendar-contacts/#tutanota","text":"Recommendation Tutanota offers a free and encrypted calendar across their supported platforms. Features include: automatic E2EE of all data, sharing features, import/export functionality, and more . Multiple calendars and extended sharing functionality is limited to paid subscribers. Website Privacy Policy Downloads Web Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid App Store Source","title":"Tutanota"},{"location":"calendar-contacts/#proton-calendar","text":"Recommendation Proton Calendar is an encrypted calendar serivce available to ProtonMail members. Features include: automatic E2EE of all data, sharing features, import/export functionality, and more . Those on the free tier get access to a single calendar, whereas paid subscribers can create up to 20 calendars. Extended sharing functionality is also limited to paid subscribers. Proton Calendar is currently only available for the web and Android. Website Privacy Policy Downloads Web Google Play Source","title":"Proton Calendar"},{"location":"calendar-contacts/#self-hostable","text":"Some of these options are self-hostable, but could be offered by third party SaaS providers for a fee:","title":"Self-hostable"},{"location":"calendar-contacts/#etesync","text":"Recommendation EteSync is a secure, end-to-end encrypted, and privacy-respecting cloud backup and synchronization software for your personal information (e.g. contacts and calendars). There are native clients for Android, iOS, and the web, and an adapter layer for most desktop clients. EteSync also offers optional software as a service for $24 per year to use, or you can host the server yourself for free. Website Privacy Policy Downloads Client Instructions Google Play f-droid F-Droid App Store Source","title":"EteSync"},{"location":"calendar-contacts/#nextcloud","text":"Recommendation Nextcloud is a suite of client-server software for creating and using file hosting services. This includes calendar sync via CalDAV and contacts sync via CardDAV. Nextcloud is free and open-source, thereby allowing anyone to install and operate it without charge on a private server. You can self host Nextcloud or pay for service from a provider . Homepage Downloads Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid App Store Source","title":"Nextcloud"},{"location":"calendar-contacts/#decsync-cc","text":"Recommendation DecSync CC synchronizes contacts, calendars and tasks using DecSync. It stores this data in a shared directory, using Syncthing , or any other file synchronization service. There are plugins to sync other types of data such as RSS . Project Info Downloads Google Play f-droid F-Droid","title":"DecSync CC"},{"location":"cloud/","text":"Many cloud storage providers require your full trust that they will not look at your files. The alternatives listed below eliminate the need for trust by either putting you in control of your data or by implementing E2EE . If these alternatives do not fit your needs, we suggest you look into Encryption Software . Nextcloud \u00b6 Recommendation Nextcloud is a suite of free and open-source client-server software for creating your own file hosting services on a private server you control. It also comes with experimental E2EE . Homepage Privacy Policy Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Google Play f-droid F-Droid App Store Source We recommend checking if your Nextcloud provider supports E2EE , otherwise you have to trust the provider to not look at your files. When self hosting Nextcloud, you should also enable E2EE to protect against your hosting provider snooping on your data. Proton Drive \u00b6 Recommendation Proton Drive is an E2EE general file storage service by the popular encrypted email provider ProtonMail . Website Privacy Policy Downloads Source Proton Drive is currently in beta and only is only available through a web client. When using a web client, you are placing trust in the server to send you proper JavaScript code to derive the decryption key and authentication token locally in your browser. A compromised server can send you malicious JavaScript code to steal your master password and decrypt your data. If this does not fit your threat model , consider using an alternative. Cryptee \u00b6 Recommendation Cryptee is an encrypted, secure photo storage service, and an encrypted documents editor. Website Privacy Policy Downloads Source Tahoe-LAFS \u00b6 Note Due to the complexity of the system and the amount of nodes needed to set it up, Tahoe-LAFS is only recommended for seasoned system administrators. Recommendation Tahoe-LAFS is a free, open, and decentralized cloud storage system. It distributes your data across multiple servers. Even if some of the servers fail or are taken over by an attacker, the entire file store continues to function correctly, preserving your privacy and security. The servers used as storage pools do not have access to your data. Homepage Downloads Windows macOS Linux netbsd NetBSD Source","title":"Cloud Storage"},{"location":"cloud/#nextcloud","text":"Recommendation Nextcloud is a suite of free and open-source client-server software for creating your own file hosting services on a private server you control. It also comes with experimental E2EE . Homepage Privacy Policy Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Google Play f-droid F-Droid App Store Source We recommend checking if your Nextcloud provider supports E2EE , otherwise you have to trust the provider to not look at your files. When self hosting Nextcloud, you should also enable E2EE to protect against your hosting provider snooping on your data.","title":"Nextcloud"},{"location":"cloud/#proton-drive","text":"Recommendation Proton Drive is an E2EE general file storage service by the popular encrypted email provider ProtonMail . Website Privacy Policy Downloads Source Proton Drive is currently in beta and only is only available through a web client. When using a web client, you are placing trust in the server to send you proper JavaScript code to derive the decryption key and authentication token locally in your browser. A compromised server can send you malicious JavaScript code to steal your master password and decrypt your data. If this does not fit your threat model , consider using an alternative.","title":"Proton Drive"},{"location":"cloud/#cryptee","text":"Recommendation Cryptee is an encrypted, secure photo storage service, and an encrypted documents editor. Website Privacy Policy Downloads Source","title":"Cryptee"},{"location":"cloud/#tahoe-lafs","text":"Note Due to the complexity of the system and the amount of nodes needed to set it up, Tahoe-LAFS is only recommended for seasoned system administrators. Recommendation Tahoe-LAFS is a free, open, and decentralized cloud storage system. It distributes your data across multiple servers. Even if some of the servers fail or are taken over by an attacker, the entire file store continues to function correctly, preserving your privacy and security. The servers used as storage pools do not have access to your data. Homepage Downloads Windows macOS Linux netbsd NetBSD Source","title":"Tahoe-LAFS"},{"location":"dns/","text":"Should I use encrypted DNS ? Encrypted DNS with third party servers should only be used to get around basic DNS blocking when you can be sure there won't be any consequences. Encrypted DNS will not help you hide any of your browsing activity. Learn more about DNS Recommended Providers \u00b6 DNS Provider Privacy Policy Protocols Logging ECS Filtering AdGuard Cleartext DoH DoT DNSCrypt Some 1 No Based on server choice. Filter list being used can be found here. Cloudflare Cleartext DoH DoT Some 2 No Based on server choice. Mullvad DoH DoT No 4 No Based on server choice. Filter list being used can be found here. NextDNS Cleartext DoH DoT DNSCrypt Optional 5 Optional Based on server choice. Quad9 Cleartext DoH DoT DNSCrypt Some 6 Optional Based on server choice, Malware blocking by default. The criteria for the servers listed above are: Must support DNSSEC Must have anycast support QNAME Minimization Allow for ECS to be disabled Native Operating System Support \u00b6 Android \u00b6 Android 9 and above support DNS over TLS . Android 13 will support DNS over HTTPS . The settings can be found in: Settings \u2192 Network & Internet \u2192 Private DNS . Apple Devices \u00b6 The latest versions of iOS, iPadOS, tvOS, and macOS, support both DoT and DoH . Both protocols are supported natively via configuration profiles or through the DNS Settings API . After installation of either a configuration profile or an app that utilizes the DNS Settings API, the DNS configuration can be selected. If a VPN is active, resolution within the VPN tunnel will use the VPN 's DNS settings and not your system-wide settings. Signed Profiles \u00b6 Apple does not provide a native interface for creating encrypted DNS profiles. Secure DNS profile creator is an unofficial tool for creating your own encrypted DNS profiles, however they will not be signed. Signed profiles are preferred; signing validates a profile's origin and helps to ensure the integrity of the profiles. A green \"Verified\" label is given to signed configuration profiles. For more information on code signing, see About Code Signing . Signed profiles are offered by AdGuard , NextDNS , and Quad9 . iOS/iPadOS \u00b6 Select Settings \u2192 General \u2192 VPN , DNS , & Device Management \u2192 DNS macOS \u00b6 Select System Preferences \u2192 Profiles or System Preferences \u2192 Network \u2192 Advanced , (depending on if you have configuration profiles installed). tvOS \u00b6 Select Settings \u2192 General \u2192 Privacy \u2192 Share Apple TV Analytics \u2192 then press the Play button on the remote. Windows \u00b6 You can turn on DoH by accessing Windows settings in the control panel. Select Settings \u2192 Network & Internet \u2192 Ethernet or WiFi , \u2192 Edit DNS Settings \u2192 Preferred DNS encryption \u2192 Encrypted only ( DNS over HTTPS ) . Linux \u00b6 systemd-resolved , which many Linux distributions use to do their DNS lookups, doesn't yet support DoH . If you want to use DoH , you'll need to install a proxy like dnscrypt-proxy and configure it to take all the DNS queries from your system resolver and forward them over HTTPS . Encrypted DNS Proxies \u00b6 Encrypted DNS proxy software provides a local proxy for the unencrypted DNS resolver to forward to. Typically it is used on platforms that don't natively support encrypted DNS . RethinkDNS \u00b6 Recommendation RethinkDNS is an open-source Android client supporting DNS -over- HTTPS , DNS -over- TLS , DNSCrypt and DNS Proxy along with caching DNS responses, locally logging DNS queries and can be used as a firewall too. Website Privacy Policy Downloads Google Play f-droid F-Droid Source DNSCloak \u00b6 Recommendation DNSCloak is an open-source iOS client supporting DNS -over- HTTPS , DNSCrypt , and dnscrypt-proxy options such as caching DNS responses, locally logging DNS queries, and custom block lists. You can add custom resolvers by DNS stamp . Project Info Privacy Policy Downloads App Store Source dnscrypt-proxy \u00b6 Recommendation dnscrypt-proxy is a DNS proxy with support for DNSCrypt , DNS -over- HTTPS , and Anonymized DNS . The anonymized DNS feature does not anonymize other network traffic. Wiki Privacy Policy Downloads Windows macOS Linux Source AdGuard stores aggregated performance metrics of their DNS servers, namely the number of complete requests to a particular server, the number of blocked requests, and the speed of processing requests. They also keep and store the database of domains requested in within last 24 hours. \"We need this information to identify and block new trackers and threats.\" \"We also log how many times this or that tracker has been blocked. We need this information to remove outdated rules from our filters.\" https://adguard.com/en/privacy/dns.html \u21a9 Cloudflare collects and stores only the limited DNS query data that is sent to the 1.1.1.1 resolver. The 1.1.1.1 resolver service does not log personal data, and the bulk of the limited non-personally identifiable query data is stored only for 25 hours. https://developers.cloudflare.com/1.1.1.1/privacy/public-dns-resolver/ \u21a9 Neither ControlD's free nor premium plans have logging enabled by default. Premium subscribers can enable logging/analytics at will. https://controld.com/privacy \u21a9 Mullvad's DNS service is available to both subscribers and non-subscribers of Mullvad VPN . Their privacy policy explicitly claims they do not log DNS requests in any way. https://mullvad.net/en/help/no-logging-data-policy/ \u21a9 NextDNS can provide insights and logging features on an opt-in basis. You can choose retention times and log storage locations for any logs you choose to keep. If it's not specifically requested, no data is logged. https://nextdns.io/privacy \u21a9 Quad9 collects some data for the purposes of threat monitoring and response. That data may then be remixed and shared, such as for the purpose of security research. Quad9 does not collect or record IP addresses or other data they deem personally identifiable. https://www.quad9.net/privacy/policy/ \u21a9","title":"DNS Resolvers"},{"location":"dns/#recommended-providers","text":"DNS Provider Privacy Policy Protocols Logging ECS Filtering AdGuard Cleartext DoH DoT DNSCrypt Some 1 No Based on server choice. Filter list being used can be found here. Cloudflare Cleartext DoH DoT Some 2 No Based on server choice. Mullvad DoH DoT No 4 No Based on server choice. Filter list being used can be found here. NextDNS Cleartext DoH DoT DNSCrypt Optional 5 Optional Based on server choice. Quad9 Cleartext DoH DoT DNSCrypt Some 6 Optional Based on server choice, Malware blocking by default. The criteria for the servers listed above are: Must support DNSSEC Must have anycast support QNAME Minimization Allow for ECS to be disabled","title":"Recommended Providers"},{"location":"dns/#native-operating-system-support","text":"","title":"Native Operating System Support"},{"location":"dns/#android","text":"Android 9 and above support DNS over TLS . Android 13 will support DNS over HTTPS . The settings can be found in: Settings \u2192 Network & Internet \u2192 Private DNS .","title":"Android"},{"location":"dns/#apple-devices","text":"The latest versions of iOS, iPadOS, tvOS, and macOS, support both DoT and DoH . Both protocols are supported natively via configuration profiles or through the DNS Settings API . After installation of either a configuration profile or an app that utilizes the DNS Settings API, the DNS configuration can be selected. If a VPN is active, resolution within the VPN tunnel will use the VPN 's DNS settings and not your system-wide settings.","title":"Apple Devices"},{"location":"dns/#signed-profiles","text":"Apple does not provide a native interface for creating encrypted DNS profiles. Secure DNS profile creator is an unofficial tool for creating your own encrypted DNS profiles, however they will not be signed. Signed profiles are preferred; signing validates a profile's origin and helps to ensure the integrity of the profiles. A green \"Verified\" label is given to signed configuration profiles. For more information on code signing, see About Code Signing . Signed profiles are offered by AdGuard , NextDNS , and Quad9 .","title":"Signed Profiles"},{"location":"dns/#iosipados","text":"Select Settings \u2192 General \u2192 VPN , DNS , & Device Management \u2192 DNS","title":"iOS/iPadOS"},{"location":"dns/#macos","text":"Select System Preferences \u2192 Profiles or System Preferences \u2192 Network \u2192 Advanced , (depending on if you have configuration profiles installed).","title":"macOS"},{"location":"dns/#tvos","text":"Select Settings \u2192 General \u2192 Privacy \u2192 Share Apple TV Analytics \u2192 then press the Play button on the remote.","title":"tvOS"},{"location":"dns/#windows","text":"You can turn on DoH by accessing Windows settings in the control panel. Select Settings \u2192 Network & Internet \u2192 Ethernet or WiFi , \u2192 Edit DNS Settings \u2192 Preferred DNS encryption \u2192 Encrypted only ( DNS over HTTPS ) .","title":"Windows"},{"location":"dns/#linux","text":"systemd-resolved , which many Linux distributions use to do their DNS lookups, doesn't yet support DoH . If you want to use DoH , you'll need to install a proxy like dnscrypt-proxy and configure it to take all the DNS queries from your system resolver and forward them over HTTPS .","title":"Linux"},{"location":"dns/#encrypted-dns-proxies","text":"Encrypted DNS proxy software provides a local proxy for the unencrypted DNS resolver to forward to. Typically it is used on platforms that don't natively support encrypted DNS .","title":"Encrypted DNS Proxies"},{"location":"dns/#rethinkdns","text":"Recommendation RethinkDNS is an open-source Android client supporting DNS -over- HTTPS , DNS -over- TLS , DNSCrypt and DNS Proxy along with caching DNS responses, locally logging DNS queries and can be used as a firewall too. Website Privacy Policy Downloads Google Play f-droid F-Droid Source","title":"RethinkDNS"},{"location":"dns/#dnscloak","text":"Recommendation DNSCloak is an open-source iOS client supporting DNS -over- HTTPS , DNSCrypt , and dnscrypt-proxy options such as caching DNS responses, locally logging DNS queries, and custom block lists. You can add custom resolvers by DNS stamp . Project Info Privacy Policy Downloads App Store Source","title":"DNSCloak"},{"location":"dns/#dnscrypt-proxy","text":"Recommendation dnscrypt-proxy is a DNS proxy with support for DNSCrypt , DNS -over- HTTPS , and Anonymized DNS . The anonymized DNS feature does not anonymize other network traffic. Wiki Privacy Policy Downloads Windows macOS Linux Source AdGuard stores aggregated performance metrics of their DNS servers, namely the number of complete requests to a particular server, the number of blocked requests, and the speed of processing requests. They also keep and store the database of domains requested in within last 24 hours. \"We need this information to identify and block new trackers and threats.\" \"We also log how many times this or that tracker has been blocked. We need this information to remove outdated rules from our filters.\" https://adguard.com/en/privacy/dns.html \u21a9 Cloudflare collects and stores only the limited DNS query data that is sent to the 1.1.1.1 resolver. The 1.1.1.1 resolver service does not log personal data, and the bulk of the limited non-personally identifiable query data is stored only for 25 hours. https://developers.cloudflare.com/1.1.1.1/privacy/public-dns-resolver/ \u21a9 Neither ControlD's free nor premium plans have logging enabled by default. Premium subscribers can enable logging/analytics at will. https://controld.com/privacy \u21a9 Mullvad's DNS service is available to both subscribers and non-subscribers of Mullvad VPN . Their privacy policy explicitly claims they do not log DNS requests in any way. https://mullvad.net/en/help/no-logging-data-policy/ \u21a9 NextDNS can provide insights and logging features on an opt-in basis. You can choose retention times and log storage locations for any logs you choose to keep. If it's not specifically requested, no data is logged. https://nextdns.io/privacy \u21a9 Quad9 collects some data for the purposes of threat monitoring and response. That data may then be remixed and shared, such as for the purpose of security research. Quad9 does not collect or record IP addresses or other data they deem personally identifiable. https://www.quad9.net/privacy/policy/ \u21a9","title":"dnscrypt-proxy"},{"location":"email-clients/","text":"Our recommendation list contains email clients that support both OpenPGP and strong authentication such as Open Authorization (OAuth) . OAuth allows you to use Multi-Factor Authentication and prevent account theft. Email does not provide forward secrecy When using end-to-end encryption ( E2EE ) technology like OpenPGP , email will still have some metadata that is not encrypted in the header of the email. OpenPGP also does not support forward secrecy , which means if either your or the recipient's private key is ever stolen, all previous messages encrypted with it will be exposed: How do I protect my private keys? . Consider using a medium that provides forward secrecy: Real-time Communication Thunderbird \u00b6 Recommendation Thunderbird is a free, open source, cross-platform email, newsgroup, news feed, and chat ( XMPP , IRC, Twitter) client developed by the Thunderbird community, and previously by the Mozilla Foundation. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Source Apple Mail \u00b6 Note For iOS devices we suggest Canary Mail as it has PGP support which means you can send end-to-end encrypted email. Recommendation Apple Mail is included in macOS and can be extended to have OpenPGP support with GPG Suite , which adds the ability to send encrypted email. Website Privacy Policy GNOME Evolution \u00b6 Recommendation Evolution is a personal information management application that provides integrated mail, calendaring and address book functionality. Evolution has extensive documentation to help you get started. Website Privacy Policy Downloads flathub Flatpak Source Kontact \u00b6 Recommendation Kontact is a personal information manager (PIM) application from the KDE project. It provides a mail client, address book, organizer and RSS client. Website Privacy Policy Downloads Linux flathub Flatpak Source Mailvelope \u00b6 Recommendation Mailvelope is a browser extension that enables the exchange of encrypted emails following the OpenPGP encryption standard. Homepage Privacy Policy Downloads Firefox Chrome Edge Source K-9 Mail \u00b6 Recommendation K-9 Mail is an independent mail application that supports both POP3 and IMAP mailboxes, but only supports push mail for IMAP . Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source Canary Mail \u00b6 Recommendation Canary Mail is a paid email client designed to make end-to-end encryption seamless with security features such as a biometric app lock. Homepage Privacy Policy Downloads Windows Mac App Store App Store Google Play Attention Canary Mail only recently released a Windows and Android client, we don't believe they are as stable as their iOS and Mac counterparts. Canary Mail is closed source. We recommend it, due to the few choices there are for email clients on iOS that support PGP E2EE . NeoMutt \u00b6 Recommendation NeoMutt is an open-source command line mail reader (or MUA) for Linux and BSD. It's a fork of Mutt with added features. NeoMutt is a text-based client that has a steep learning curve. It is however, very customizable. Homepage Downloads Linux macOS Source","title":"Email Clients"},{"location":"email-clients/#thunderbird","text":"Recommendation Thunderbird is a free, open source, cross-platform email, newsgroup, news feed, and chat ( XMPP , IRC, Twitter) client developed by the Thunderbird community, and previously by the Mozilla Foundation. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Source","title":"Thunderbird"},{"location":"email-clients/#apple-mail","text":"Note For iOS devices we suggest Canary Mail as it has PGP support which means you can send end-to-end encrypted email. Recommendation Apple Mail is included in macOS and can be extended to have OpenPGP support with GPG Suite , which adds the ability to send encrypted email. Website Privacy Policy","title":"Apple Mail"},{"location":"email-clients/#gnome-evolution","text":"Recommendation Evolution is a personal information management application that provides integrated mail, calendaring and address book functionality. Evolution has extensive documentation to help you get started. Website Privacy Policy Downloads flathub Flatpak Source","title":"GNOME Evolution"},{"location":"email-clients/#kontact","text":"Recommendation Kontact is a personal information manager (PIM) application from the KDE project. It provides a mail client, address book, organizer and RSS client. Website Privacy Policy Downloads Linux flathub Flatpak Source","title":"Kontact"},{"location":"email-clients/#mailvelope","text":"Recommendation Mailvelope is a browser extension that enables the exchange of encrypted emails following the OpenPGP encryption standard. Homepage Privacy Policy Downloads Firefox Chrome Edge Source","title":"Mailvelope"},{"location":"email-clients/#k-9-mail","text":"Recommendation K-9 Mail is an independent mail application that supports both POP3 and IMAP mailboxes, but only supports push mail for IMAP . Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source","title":"K-9 Mail"},{"location":"email-clients/#canary-mail","text":"Recommendation Canary Mail is a paid email client designed to make end-to-end encryption seamless with security features such as a biometric app lock. Homepage Privacy Policy Downloads Windows Mac App Store App Store Google Play Attention Canary Mail only recently released a Windows and Android client, we don't believe they are as stable as their iOS and Mac counterparts. Canary Mail is closed source. We recommend it, due to the few choices there are for email clients on iOS that support PGP E2EE .","title":"Canary Mail"},{"location":"email-clients/#neomutt","text":"Recommendation NeoMutt is an open-source command line mail reader (or MUA) for Linux and BSD. It's a fork of Mutt with added features. NeoMutt is a text-based client that has a steep learning curve. It is however, very customizable. Homepage Downloads Linux macOS Source","title":"NeoMutt"},{"location":"email/","text":"Email is practically a necessity for using any online service, however we do not recommend it for person-to-person conversations. Rather than using email to contact other people, consider using an instant messaging medium that supports forward secrecy. Recommended Instant Messengers For everything else, we recommend a variety of email providers based on sustainable business models and built-in security and privacy features. Warning When using E2EE technology like OpenPGP , email will still have some metadata that is not encrypted in the header of the email. Read more about email metadata. OpenPGP also does not support Forward secrecy, which means if either your or the recipient's private key is ever stolen, all previous messages encrypted with it will be exposed. How do I protect my private keys? Recommended Email Providers \u00b6 ProtonMail \u00b6 Recommendation ProtonMail is an email service with a focus on privacy, encryption, security, and ease of use. They have been in operation since 2013 . ProtonMail is based in Gen\u00e8ve, Switzerland. Accounts start with 500 MB storage with their free plan. Free accounts have some limitations, such as not being able to search body text and not having access to ProtonMail Bridge , which is required to use a recommended desktop email client (e.g. Thunderbird). Paid accounts are available starting at \u20ac48/y which include features like ProtonMail Bridge, additional storage, and custom domain support. Free Website Privacy Policy Custom Domains and Aliases Paid ProtonMail subscribers can use their own domain with the service. Catch-all addresses are supported with custom domains for Professional and Visionary plans. ProtonMail also supports subaddressing , which is useful for people who don't want to purchase a domain. Private Payment Methods ProtonMail accepts Bitcoin in addition to accepting credit/debit cards and PayPal. Account Security ProtonMail supports TOTP two factor authentication only. The use of a U2F security key is not yet supported. ProtonMail is planning to implement U2F upon completion of their Single Sign On (SSO) code. Data Security ProtonMail has zero access encryption at rest for your emails, address book contacts , and calendars . This means the messages and other data stored in your account are only readable by you. Email Encryption ProtonMail has integrated OpenPGP encryption in their webmail. Emails to other ProtonMail accounts are encrypted automatically, and encryption to non-ProtonMail addresses with an OpenPGP key can be enabled easily in your account settings. They also allow you to encrypt messages to non-ProtonMail addresses without the need for them to sign up for a ProtonMail account or use software like OpenPGP . ProtonMail also supports the discovery of public keys via HTTP from their Web Key Directory (WKD) . This allows people who don't use ProtonMail to find the OpenPGP keys of ProtonMail accounts easily, for cross-provider E2EE . Additional Functionality ProtonMail's login and services are accessible over Tor, protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion ProtonMail offers a \"Visionary\" account for \u20ac24/Month, which also enables access to ProtonVPN in addition to providing multiple accounts, domains, aliases, and extra storage. Mailbox.org \u00b6 Recommendation Mailbox.org is an email service with a focus on being secure, ad-free, and privately powered by 100% eco-friendly energy. They have been in operation since 2014. Mailbox.org is based in Berlin, Germany. Accounts start with 2 GB of storage, which can be upgraded as needed. EUR \u20ac12/year Website Privacy Policy Custom Domains and Aliases Mailbox.org lets you use your own domain, and they support catch-all addresses. Mailbox.org also supports subaddressing , which is useful if you don't want to purchase a domain. Private Payment Methods Mailbox.org doesn't accept Bitcoin or any other cryptocurrencies as a result of their payment processor BitPay suspending operations in Germany. However, they do accept Cash by mail, cash payment to bank account, bank transfer, credit card, PayPal and couple of German-specific processors: paydirekt and Sofort\u00fcberweisung. Account Security Mailbox.org supports two factor authentication for their webmail only. You can use either TOTP or a Yubikey via the Yubicloud . Web standards such as WebAuthn are not yet supported. Data Security Mailbox.org allows for encryption of incoming mail using their encrypted mailbox . New messages that you receive will then be immediately encrypted with your public key. However, Open-Exchange , the software platform used by Mailbox.org, does not support the encryption of your address book and calendar. A standalone option may be more appropriate for that information. Email Encryption Mailbox.org has integrated encryption in their webmail, which simplifies sending messages to people with public OpenPGP keys. They also allow remote recipients to decrypt an email on Mailbox.org's servers. This feature is useful when the remote recipient does not have OpenPGP and cannot decrypt a copy of the email in their own mailbox. Mailbox.org also supports the discovery of public keys via HTTP from their Web Key Directory (WKD) . This allows people outside of Mailbox.org to find the OpenPGP keys of Mailbox.org accounts easily, for cross-provider E2EE . Additional Functionality You can access your Mailbox.org account via IMAP / SMTP using their .onion service . However, their webmail interface cannot be accessed via their .onion service, and you may experience TLS certificate errors. All accounts come with limited cloud storage that can be encrypted . Mailbox.org also offers the alias @secure.mailbox.org , which enforces the TLS encryption on the connection between mail servers, otherwise the message will not be sent at all. Mailbox.org also supports Exchange ActiveSync in addition to standard access protocols like IMAP and POP3. Tutanota \u00b6 Recommendation Tutanota.com is an email service with a focus on security and privacy through the use of encryption. Tutanota has been in operation since 2011 and is based in Hanover, Germany. Accounts start with 1GB storage with their free plan. Free Website Privacy Policy Tutanota doesn't allow the use of third-party email clients . Tutanota has no plans pull email from external email accounts using the IMAP protocol. Email import is currently not possible. Emails can be exported individually or by bulk selection . Tutanota does not allow for subfolders as you might expect with other email providers. Tutanota is working on a desktop client and they have an app available in F-Droid . They also have their app in conventional stores such as App Store on iOS and Google Play for Android. Custom Domains and Aliases Paid Tutanota accounts can use up to 5 aliases and custom domains . Tutanota doesn't allow for subaddressing (plus addresses) , but you can use a catch-all with a custom domain. Private Payment Methods Tutanota only directly accepts credit cards and PayPal, however Bitcoin and Monero can be used to purchase gift cards via their partnership with Proxystore. Account Security Tutanota supports two factor authentication with either TOTP or U2F . U2F support is not yet available on Android . Data Security Tutanota has zero access encryption at rest for your emails, address book contacts , and calendars . This means the messages and other data stored in your account are only readable by you. Email Encryption Tutanota does not use OpenPGP . Tutanota accounts can only receive encrypted emails from non-Tutanota email accounts when sent via a temporary Tutanota mailbox . Tutanota does have plans to support AutoCrypt . This would allow for non-Tutanota emails to send encrypted emails to Tutanota accounts as long as their email client supports the AutoCrypt headers. Additional Functionality Tutanota offers the business version of Tutanota to non-profit organizations for free or with a heavy discount. Tutanota also has a business feature called Secure Connect . This ensures customer contact to the business uses E2EE . The feature costs \u20ac240/y. StartMail \u00b6 Recommendation StartMail is an email service with a focus on security and privacy through the use of standard OpenPGP encryption. StartMail has been in operation since 2014 and is based in Boulevard 11, Zeist Netherlands. Accounts start with 10GB. They offer a 30-day trial. USD $59.95/year Website Privacy Policy Custom Domains and Aliases Personal accounts can use Custom or Quick aliases. Custom domains are also available. Private Payment Methods StartMail accepts Visa, MasterCard, American Express and Paypal. StartMail also has other payment options such as Bitcoin (currently only for Personal accounts) and SEPA Direct Debit for accounts older than a year. Account Security StartMail supports TOTP two factor authentication for webmail only . They do not allow U2F security key authentication. Data Security StartMail has zero access encryption at rest , using their \"user vault\" system. When you log in, the vault is opened, and the email is then moved to the vault out of the queue where it is decrypted by the corresponding private key. StartMail supports importing contacts however, they are only accessible in the webmail and not through protocols such as CalDAV . Contacts are also not stored using zero knowledge encryption, so a standalone option may be more appropriate. Email Encryption StartMail has integrated encryption in their webmail, which simplifies sending encrypted messages with public OpenPGP keys. Additional Functionality StartMail allows for proxying of images within emails. If you allow the remote image to be loaded, the sender won't know what your IP address is. Email Aliasing Services \u00b6 An email aliasing service allows you to easily generate a new email address for every website you register for. The email aliases you generate are then forwarded to an email address of your choosing, hiding both your \"main\" email address and the identity of your email provider. True email aliasing is better than plus addressing commonly used and supported by many providers, which allows you to create aliases like yourname+[anythinghere]@example.com, because websites, advertisers, and tracking networks can trivially remove anything after the + sign to know your true email address. Email aliasing can act as a safeguard in case your email provider ever ceases operation. In that scenario, you can easily re-route your aliases to a new email address. In turn, however, you are placing trust in the aliasing service to continue functioning. Using a dedicated email aliasing service also has a number of benefits over a catch-all alias on a custom domain: Aliases can be turned on and off individually when you need them, preventing websites from emailing you randomly. Replies are sent from the alias address, shielding your real email address. They also have a number of benefits over \"temporary email\" services: Aliases are permanent, and can be turned on again if you need to receive something like a password reset. Emails are sent to your trusted mailbox rather than stored by the alias provider. Temporary email services typically have public mailboxes which can be accessed by anyone who knows the address, aliases are private to you. Our email aliasing recommendations are providers that allow you to create aliases on domains they control, as well as your own custom domain(s) for a modest yearly fee. They can also be self-hosted if you want maximum control. However, using a custom domain can have privacy-related drawbacks: If you are the only person using your custom domain, your actions can be easily tracked across websites simply by looking at the domain name in the email address and ignoring everything before the at (@) sign. Using an aliasing service requires trusting both your email provider and your aliasing provider with your unencrypted messages. Some providers mitigate this slightly with automatic PGP encryption, which reduces the number of parties you need to trust from 2 to 1 by encrypting incoming emails before they are delivered to your final mailbox provider. SimpleLogin \u00b6 Recommendation SimpleLogin (now owned by ProtonMail) is a free service which provides email aliases on a variety of shared domain names, and optionally provides features like unlimited aliases and custom domains for $30/year. Source code on GitHub . Website Privacy Policy Downloads Firefox Chrome Edge Safari App Store Google Play f-droid F-Droid Source SimpleLogin is owned by ProtonMail as of April 8, 2022. If you use ProtonMail for your primary mailbox, this makes SimpleLogin a great choice: You now only have to trust a single email provider and SimpleLogin will be more tightly integrated with ProtonMail's offerings in the future. Nonetheless, SimpleLogin continues to support forwarding to any email provider of your chosing. Notable free features: 15 Shared Aliases Unlimited Replies 1 Recepient Mailbox AnonAddy \u00b6 Recommendation AnonAddy lets you create 20 domain aliases on a shared domain for free, or unlimited \"standard\" aliases which are less anonymous. It has two premium plans at $12/year and $36/year which provide additional features. Source code on GitHub . Website Privacy Policy Downloads Firefox Chrome iOS Android Source The number of shared aliases (which end in a shared domain like @anonaddy.me) that you can create is limited to 20 on AnonAddy's free plan and 50 on their $12/month plan. You can create unlimited standard aliases (which end in a domain like @[username].anonaddy.com or a custom domain on paid plans), however, as previously mentioned, this can be detrimental to privacy because people can trivially tie your standard aliases together based on the domain name alone. Unlimited shared aliases are available for $36/year. Notable free features: 20 Shared Aliases Unlimited Standard Aliases No Outgoing Replies 2 Receipent Mailboxes Automatic PGP Encryption Self-Hosting Email \u00b6 Advanced system administrators may consider setting up their own email server. Mailservers require attention and continuous maintenance in order to keep things secure and mail delivery reliable. Combined software solutions \u00b6 Recommendation Mail-in-a-Box is an automated setup script for deploying a mail server on Ubuntu. Its goal is to make it easier for people to set up their own mail server. Recommendation Mailcow is a more advanced mail server perfect for those with a bit more Linux experience. It has everything you need in a Docker container: A mailserver with DKIM support, antivirus and spam monitoring, webmail and ActiveSync with SOGo, and web-based administration with 2FA support. Mailcow Dockerized docs For a more manual approach we've picked out these two articles. Setting up a mail server with OpenSMTPD, Dovecot and Rspamd (2019) How To Run Your Own Mail Server (August 2017) Our Criteria \u00b6 Please note we are not affiliated with any of the providers we recommend. This allows us to provide completely objective recommendations. We have developed a clear set of requirements for any Email provider wishing to be recommended, including implementing industry best practices, modern technology and more. We suggest you familiarize yourself with this list before choosing an Email provider, and conduct your own research to ensure the Email provider you choose is the right choice for you. Jurisdiction \u00b6 Operating outside the five/nine/fourteen-eyes countries is not necessarily a guarantee of privacy, and there are other factors to consider. Minimum to Qualify: Operating outside the USA or other Five Eyes countries. Best Case: Operating outside the USA or other Fourteen Eyes countries. Operating inside a country with strong consumer protection laws. Technology \u00b6 We regard these features as important in order to provide a safe and optimal service. You should consider whether the provider which has the features you require. Minimum to Qualify: Encrypts email account data at rest with zero-access encryption. Integrated webmail E2EE / PGP encryption provided as a convenience. Best Case: Encrypts all account data (Contacts, Calendars etc) at rest with zero-access encryption. Allow users to use their own domain name . Custom domain names are important to users because it allows them to maintain their agency from the service, should it turn bad or be acquired by another company which doesn't prioritize privacy etc. Support for WKD to allow improved discovery of public OpenPGP keys via HTTP . GnuPG users can get a key by typing: gpg --locate-key example_user@example.com Support for a temporary mailbox for external users. This is useful when you want to send an encrypted email, without sending an actual copy to your recipient. These emails usually have a limited lifespan and then are automatically deleted. They also don't require the recipient to configure any cryptography like OpenPGP . Availability of the email provider's services via an onion service . Subaddressing support. Catch-all or alias functionality for those who own their own domains. Use of standard email access protocols such as IMAP , SMTP or JMAP . Standard access protocols ensure customers can easily download all of their email, should they want to switch to another provider. Privacy \u00b6 We prefer our recommended providers to collect as little data as possible. Minimum to Qualify: Protect sender's IP address. Filter it from showing in the Received header field. Don't require personally identifiable information ( PII ) besides username and password. Privacy policy that meets the requirements defined by the GDPR Best Case: Accepts Bitcoin, cash, and other forms of cryptocurrency and/or anonymous payment options (gift cards, etc.) Security \u00b6 Email servers deal with a lot of very sensitive data. We expect that providers will adopt best industry practices in order to protect their members. Minimum to Qualify: Protection of webmail with 2FA , such as TOTP . Encryption at rest, (e.g. dm-crypt ) this protects the contents of the servers in case of unlawful seizure. DNSSEC support. No TLS errors/vulnerabilities when being profiled by tools such as Hardenize , testssl.sh or Qualys SSL Labs , this includes certificate related errors, poor or weak ciphers suites, weak DH parameters such as those that led to Logjam . A valid MTA-STS and TLS -RPT policy. Valid DANE records. Valid SPF and DKIM records. Have a proper DMARC record and policy or utilize ARC for authentication. If DMARC authentication is being used, the policy must be set to reject or quarantine . A server suite preference of TLS 1.2 or later and a plan for Deprecating TLSv1.0 and TLSv1.1 . SMTPS submission, assuming SMTP is used. Website security standards such as: HTTP Strict Transport Security Subresource Integrity if loading things from external domains. Best Case: Support for hardware authentication, ie U2F and WebAuthn . U2F and WebAuthn are more secure as they use a private key stored on a client-side hardware device to authenticate people, as opposed to a shared secret that is stored on the web server and on the client side when using TOTP . Furthermore, U2F and WebAuthn are more resistant to phishing as their authentication response is based on the authenticated domain name . Zero access encryption, builds on encryption at rest. The difference being the provider does not have the decryption keys to the data they hold. This prevents a rogue employee leaking data they have access to or remote adversary from releasing data they have stolen by gaining unauthorized access to the server. DNS Certification Authority Authorization (CAA) Resource Record in addition to DANE support. Implementation of Authenticated Received Chain (ARC) , this is useful for people who post to mailing lists RFC8617 . Bug-bounty programs and/or a coordinated vulnerability-disclosure process. Website security standards such as: Content Security Policy (CSP) Expect-CT Trust \u00b6 You wouldn't trust your finances to someone with a fake identity, so why trust them with your email? We require our recommended providers to be public about their ownership or leadership. We also would like to see frequent transparency reports, especially in regard to how government requests are handled. Minimum to Qualify: Public-facing leadership or ownership. Best Case: Public-facing leadership. Frequent transparency reports. Marketing \u00b6 With the email providers we recommend we like to see responsible marketing. Minimum to Qualify: Must self host analytics (no Google Analytics etc). The provider's site must also comply with DNT (Do Not Track) for those who wish to opt-out. Must not have any marketing which is irresponsible: Claims of \"unbreakable encryption\". Encryption should be used with the intention that it may not be secret in the future when the technology exists to crack it. Making guarantees of protecting anonymity 100%. When someone makes a claim that something is 100% it means there is no certainty for failure. We know people can quite easily deanonymize themselves in a number of ways, e.g.: Reusing personal information e.g. (email accounts, unique pseudonyms etc) that they accessed without anonymity software (Tor, VPN etc) Browser fingerprinting Best Case: Clear and easy to read documentation. This includes things like, setting up 2FA , email clients, OpenPGP , etc. Additional Functionality \u00b6 While not strictly requirements, there are some other convenience or privacy factors we looked into when determining which providers to recommend. Email Encryption Overview \u00b6 What is end-to-end encryption ( E2EE ) in email? \u00b6 E2EE is a way of encrypting email contents so that nobody but the recipient(s) can read the email message. How can I encrypt my email? \u00b6 The standard way to do email E2EE and have it work between different email providers is with OpenPGP . There are different implementations of the OpenPGP standard, the most common being GnuPG and OpenPGP .js . There is another standard that was popular with business called S/MIME , however it requires a certificate issued from a Certificate Authority (not all of them issue S/MIME certificates). It has support in Google Workplace and Outlook for Web or Exchange Server 2016, 2019 . What software can I use to get E2EE ? \u00b6 Email providers which allow you to use standard access protocols like IMAP and SMTP can be used with any of the email clients we recommend . This can be less secure as you are now relying on email providers to ensure that their encryption implementation works and has not been compromised in anyway. How do I protect my private keys? \u00b6 A smartcard (such as a Yubikey or Nitrokey ) works by receiving an encrypted email message from a device (phone, tablet, computer etc) running an email/webmail client. The message is then decrypted by the smartcard and the decrypted content is sent back to the device. It is advantageous for the decryption to occur on the smartcard so as to avoid possibly exposing your private key to a compromised device. Email Metadata Overview \u00b6 Who can see the email metadata? \u00b6 Email metadata is able to be seen by your email client software (or webmail) and any servers relaying the message from you to any recipients. Sometimes email servers will also use external parties to protect against spam. What is email metadata? \u00b6 Email software will often show some visible headers that you may have seen such as: To , From , Cc , Date , Subject . When is email metadata used? \u00b6 Client software may use it to show who a message is from and what time it was received. Servers may use it to determine where an email message must be sent, among other purposes which are not always transparent. Where is the email metadata? \u00b6 Email metadata is stored in the message header of the email message. Why can't email metadata be E2EE ? \u00b6 Email metadata is crucial to the most basic functionality of email (where it came from, and where it has to go). E2EE was not built into the email protocols originally and is also optional, therefore, only the message content is protected. How is my metadata protected? \u00b6 When emails travel between email providers an encrypted connection is negotiated using Opportunistic TLS . This protects the metadata from outside observers, but as it is not E2EE , server administrators can snoop on the metadata of an email. Additional Reading \u00b6 An NFC PGP SmartCard For Android Aging 'Privacy' Law Leaves Cloud E-Mail Open to Cops (2011) The Government Can (Still) Read Most Of Your Emails Without A Warrant (2013)","title":"Email Services"},{"location":"email/#recommended-email-providers","text":"","title":"Recommended Email Providers"},{"location":"email/#protonmail","text":"Recommendation ProtonMail is an email service with a focus on privacy, encryption, security, and ease of use. They have been in operation since 2013 . ProtonMail is based in Gen\u00e8ve, Switzerland. Accounts start with 500 MB storage with their free plan. Free accounts have some limitations, such as not being able to search body text and not having access to ProtonMail Bridge , which is required to use a recommended desktop email client (e.g. Thunderbird). Paid accounts are available starting at \u20ac48/y which include features like ProtonMail Bridge, additional storage, and custom domain support. Free Website Privacy Policy Custom Domains and Aliases Paid ProtonMail subscribers can use their own domain with the service. Catch-all addresses are supported with custom domains for Professional and Visionary plans. ProtonMail also supports subaddressing , which is useful for people who don't want to purchase a domain. Private Payment Methods ProtonMail accepts Bitcoin in addition to accepting credit/debit cards and PayPal. Account Security ProtonMail supports TOTP two factor authentication only. The use of a U2F security key is not yet supported. ProtonMail is planning to implement U2F upon completion of their Single Sign On (SSO) code. Data Security ProtonMail has zero access encryption at rest for your emails, address book contacts , and calendars . This means the messages and other data stored in your account are only readable by you. Email Encryption ProtonMail has integrated OpenPGP encryption in their webmail. Emails to other ProtonMail accounts are encrypted automatically, and encryption to non-ProtonMail addresses with an OpenPGP key can be enabled easily in your account settings. They also allow you to encrypt messages to non-ProtonMail addresses without the need for them to sign up for a ProtonMail account or use software like OpenPGP . ProtonMail also supports the discovery of public keys via HTTP from their Web Key Directory (WKD) . This allows people who don't use ProtonMail to find the OpenPGP keys of ProtonMail accounts easily, for cross-provider E2EE . Additional Functionality ProtonMail's login and services are accessible over Tor, protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion ProtonMail offers a \"Visionary\" account for \u20ac24/Month, which also enables access to ProtonVPN in addition to providing multiple accounts, domains, aliases, and extra storage.","title":"ProtonMail"},{"location":"email/#mailboxorg","text":"Recommendation Mailbox.org is an email service with a focus on being secure, ad-free, and privately powered by 100% eco-friendly energy. They have been in operation since 2014. Mailbox.org is based in Berlin, Germany. Accounts start with 2 GB of storage, which can be upgraded as needed. EUR \u20ac12/year Website Privacy Policy Custom Domains and Aliases Mailbox.org lets you use your own domain, and they support catch-all addresses. Mailbox.org also supports subaddressing , which is useful if you don't want to purchase a domain. Private Payment Methods Mailbox.org doesn't accept Bitcoin or any other cryptocurrencies as a result of their payment processor BitPay suspending operations in Germany. However, they do accept Cash by mail, cash payment to bank account, bank transfer, credit card, PayPal and couple of German-specific processors: paydirekt and Sofort\u00fcberweisung. Account Security Mailbox.org supports two factor authentication for their webmail only. You can use either TOTP or a Yubikey via the Yubicloud . Web standards such as WebAuthn are not yet supported. Data Security Mailbox.org allows for encryption of incoming mail using their encrypted mailbox . New messages that you receive will then be immediately encrypted with your public key. However, Open-Exchange , the software platform used by Mailbox.org, does not support the encryption of your address book and calendar. A standalone option may be more appropriate for that information. Email Encryption Mailbox.org has integrated encryption in their webmail, which simplifies sending messages to people with public OpenPGP keys. They also allow remote recipients to decrypt an email on Mailbox.org's servers. This feature is useful when the remote recipient does not have OpenPGP and cannot decrypt a copy of the email in their own mailbox. Mailbox.org also supports the discovery of public keys via HTTP from their Web Key Directory (WKD) . This allows people outside of Mailbox.org to find the OpenPGP keys of Mailbox.org accounts easily, for cross-provider E2EE . Additional Functionality You can access your Mailbox.org account via IMAP / SMTP using their .onion service . However, their webmail interface cannot be accessed via their .onion service, and you may experience TLS certificate errors. All accounts come with limited cloud storage that can be encrypted . Mailbox.org also offers the alias @secure.mailbox.org , which enforces the TLS encryption on the connection between mail servers, otherwise the message will not be sent at all. Mailbox.org also supports Exchange ActiveSync in addition to standard access protocols like IMAP and POP3.","title":"Mailbox.org"},{"location":"email/#tutanota","text":"Recommendation Tutanota.com is an email service with a focus on security and privacy through the use of encryption. Tutanota has been in operation since 2011 and is based in Hanover, Germany. Accounts start with 1GB storage with their free plan. Free Website Privacy Policy Tutanota doesn't allow the use of third-party email clients . Tutanota has no plans pull email from external email accounts using the IMAP protocol. Email import is currently not possible. Emails can be exported individually or by bulk selection . Tutanota does not allow for subfolders as you might expect with other email providers. Tutanota is working on a desktop client and they have an app available in F-Droid . They also have their app in conventional stores such as App Store on iOS and Google Play for Android. Custom Domains and Aliases Paid Tutanota accounts can use up to 5 aliases and custom domains . Tutanota doesn't allow for subaddressing (plus addresses) , but you can use a catch-all with a custom domain. Private Payment Methods Tutanota only directly accepts credit cards and PayPal, however Bitcoin and Monero can be used to purchase gift cards via their partnership with Proxystore. Account Security Tutanota supports two factor authentication with either TOTP or U2F . U2F support is not yet available on Android . Data Security Tutanota has zero access encryption at rest for your emails, address book contacts , and calendars . This means the messages and other data stored in your account are only readable by you. Email Encryption Tutanota does not use OpenPGP . Tutanota accounts can only receive encrypted emails from non-Tutanota email accounts when sent via a temporary Tutanota mailbox . Tutanota does have plans to support AutoCrypt . This would allow for non-Tutanota emails to send encrypted emails to Tutanota accounts as long as their email client supports the AutoCrypt headers. Additional Functionality Tutanota offers the business version of Tutanota to non-profit organizations for free or with a heavy discount. Tutanota also has a business feature called Secure Connect . This ensures customer contact to the business uses E2EE . The feature costs \u20ac240/y.","title":"Tutanota"},{"location":"email/#startmail","text":"Recommendation StartMail is an email service with a focus on security and privacy through the use of standard OpenPGP encryption. StartMail has been in operation since 2014 and is based in Boulevard 11, Zeist Netherlands. Accounts start with 10GB. They offer a 30-day trial. USD $59.95/year Website Privacy Policy Custom Domains and Aliases Personal accounts can use Custom or Quick aliases. Custom domains are also available. Private Payment Methods StartMail accepts Visa, MasterCard, American Express and Paypal. StartMail also has other payment options such as Bitcoin (currently only for Personal accounts) and SEPA Direct Debit for accounts older than a year. Account Security StartMail supports TOTP two factor authentication for webmail only . They do not allow U2F security key authentication. Data Security StartMail has zero access encryption at rest , using their \"user vault\" system. When you log in, the vault is opened, and the email is then moved to the vault out of the queue where it is decrypted by the corresponding private key. StartMail supports importing contacts however, they are only accessible in the webmail and not through protocols such as CalDAV . Contacts are also not stored using zero knowledge encryption, so a standalone option may be more appropriate. Email Encryption StartMail has integrated encryption in their webmail, which simplifies sending encrypted messages with public OpenPGP keys. Additional Functionality StartMail allows for proxying of images within emails. If you allow the remote image to be loaded, the sender won't know what your IP address is.","title":"StartMail"},{"location":"email/#email-aliasing-services","text":"An email aliasing service allows you to easily generate a new email address for every website you register for. The email aliases you generate are then forwarded to an email address of your choosing, hiding both your \"main\" email address and the identity of your email provider. True email aliasing is better than plus addressing commonly used and supported by many providers, which allows you to create aliases like yourname+[anythinghere]@example.com, because websites, advertisers, and tracking networks can trivially remove anything after the + sign to know your true email address. Email aliasing can act as a safeguard in case your email provider ever ceases operation. In that scenario, you can easily re-route your aliases to a new email address. In turn, however, you are placing trust in the aliasing service to continue functioning. Using a dedicated email aliasing service also has a number of benefits over a catch-all alias on a custom domain: Aliases can be turned on and off individually when you need them, preventing websites from emailing you randomly. Replies are sent from the alias address, shielding your real email address. They also have a number of benefits over \"temporary email\" services: Aliases are permanent, and can be turned on again if you need to receive something like a password reset. Emails are sent to your trusted mailbox rather than stored by the alias provider. Temporary email services typically have public mailboxes which can be accessed by anyone who knows the address, aliases are private to you. Our email aliasing recommendations are providers that allow you to create aliases on domains they control, as well as your own custom domain(s) for a modest yearly fee. They can also be self-hosted if you want maximum control. However, using a custom domain can have privacy-related drawbacks: If you are the only person using your custom domain, your actions can be easily tracked across websites simply by looking at the domain name in the email address and ignoring everything before the at (@) sign. Using an aliasing service requires trusting both your email provider and your aliasing provider with your unencrypted messages. Some providers mitigate this slightly with automatic PGP encryption, which reduces the number of parties you need to trust from 2 to 1 by encrypting incoming emails before they are delivered to your final mailbox provider.","title":"Email Aliasing Services"},{"location":"email/#simplelogin","text":"Recommendation SimpleLogin (now owned by ProtonMail) is a free service which provides email aliases on a variety of shared domain names, and optionally provides features like unlimited aliases and custom domains for $30/year. Source code on GitHub . Website Privacy Policy Downloads Firefox Chrome Edge Safari App Store Google Play f-droid F-Droid Source SimpleLogin is owned by ProtonMail as of April 8, 2022. If you use ProtonMail for your primary mailbox, this makes SimpleLogin a great choice: You now only have to trust a single email provider and SimpleLogin will be more tightly integrated with ProtonMail's offerings in the future. Nonetheless, SimpleLogin continues to support forwarding to any email provider of your chosing. Notable free features: 15 Shared Aliases Unlimited Replies 1 Recepient Mailbox","title":"SimpleLogin"},{"location":"email/#anonaddy","text":"Recommendation AnonAddy lets you create 20 domain aliases on a shared domain for free, or unlimited \"standard\" aliases which are less anonymous. It has two premium plans at $12/year and $36/year which provide additional features. Source code on GitHub . Website Privacy Policy Downloads Firefox Chrome iOS Android Source The number of shared aliases (which end in a shared domain like @anonaddy.me) that you can create is limited to 20 on AnonAddy's free plan and 50 on their $12/month plan. You can create unlimited standard aliases (which end in a domain like @[username].anonaddy.com or a custom domain on paid plans), however, as previously mentioned, this can be detrimental to privacy because people can trivially tie your standard aliases together based on the domain name alone. Unlimited shared aliases are available for $36/year. Notable free features: 20 Shared Aliases Unlimited Standard Aliases No Outgoing Replies 2 Receipent Mailboxes Automatic PGP Encryption","title":"AnonAddy"},{"location":"email/#self-hosting-email","text":"Advanced system administrators may consider setting up their own email server. Mailservers require attention and continuous maintenance in order to keep things secure and mail delivery reliable.","title":"Self-Hosting Email"},{"location":"email/#combined-software-solutions","text":"Recommendation Mail-in-a-Box is an automated setup script for deploying a mail server on Ubuntu. Its goal is to make it easier for people to set up their own mail server. Recommendation Mailcow is a more advanced mail server perfect for those with a bit more Linux experience. It has everything you need in a Docker container: A mailserver with DKIM support, antivirus and spam monitoring, webmail and ActiveSync with SOGo, and web-based administration with 2FA support. Mailcow Dockerized docs For a more manual approach we've picked out these two articles. Setting up a mail server with OpenSMTPD, Dovecot and Rspamd (2019) How To Run Your Own Mail Server (August 2017)","title":"Combined software solutions"},{"location":"email/#our-criteria","text":"Please note we are not affiliated with any of the providers we recommend. This allows us to provide completely objective recommendations. We have developed a clear set of requirements for any Email provider wishing to be recommended, including implementing industry best practices, modern technology and more. We suggest you familiarize yourself with this list before choosing an Email provider, and conduct your own research to ensure the Email provider you choose is the right choice for you.","title":"Our Criteria"},{"location":"email/#jurisdiction","text":"Operating outside the five/nine/fourteen-eyes countries is not necessarily a guarantee of privacy, and there are other factors to consider. Minimum to Qualify: Operating outside the USA or other Five Eyes countries. Best Case: Operating outside the USA or other Fourteen Eyes countries. Operating inside a country with strong consumer protection laws.","title":"Jurisdiction"},{"location":"email/#technology","text":"We regard these features as important in order to provide a safe and optimal service. You should consider whether the provider which has the features you require. Minimum to Qualify: Encrypts email account data at rest with zero-access encryption. Integrated webmail E2EE / PGP encryption provided as a convenience. Best Case: Encrypts all account data (Contacts, Calendars etc) at rest with zero-access encryption. Allow users to use their own domain name . Custom domain names are important to users because it allows them to maintain their agency from the service, should it turn bad or be acquired by another company which doesn't prioritize privacy etc. Support for WKD to allow improved discovery of public OpenPGP keys via HTTP . GnuPG users can get a key by typing: gpg --locate-key example_user@example.com Support for a temporary mailbox for external users. This is useful when you want to send an encrypted email, without sending an actual copy to your recipient. These emails usually have a limited lifespan and then are automatically deleted. They also don't require the recipient to configure any cryptography like OpenPGP . Availability of the email provider's services via an onion service . Subaddressing support. Catch-all or alias functionality for those who own their own domains. Use of standard email access protocols such as IMAP , SMTP or JMAP . Standard access protocols ensure customers can easily download all of their email, should they want to switch to another provider.","title":"Technology"},{"location":"email/#privacy","text":"We prefer our recommended providers to collect as little data as possible. Minimum to Qualify: Protect sender's IP address. Filter it from showing in the Received header field. Don't require personally identifiable information ( PII ) besides username and password. Privacy policy that meets the requirements defined by the GDPR Best Case: Accepts Bitcoin, cash, and other forms of cryptocurrency and/or anonymous payment options (gift cards, etc.)","title":"Privacy"},{"location":"email/#security","text":"Email servers deal with a lot of very sensitive data. We expect that providers will adopt best industry practices in order to protect their members. Minimum to Qualify: Protection of webmail with 2FA , such as TOTP . Encryption at rest, (e.g. dm-crypt ) this protects the contents of the servers in case of unlawful seizure. DNSSEC support. No TLS errors/vulnerabilities when being profiled by tools such as Hardenize , testssl.sh or Qualys SSL Labs , this includes certificate related errors, poor or weak ciphers suites, weak DH parameters such as those that led to Logjam . A valid MTA-STS and TLS -RPT policy. Valid DANE records. Valid SPF and DKIM records. Have a proper DMARC record and policy or utilize ARC for authentication. If DMARC authentication is being used, the policy must be set to reject or quarantine . A server suite preference of TLS 1.2 or later and a plan for Deprecating TLSv1.0 and TLSv1.1 . SMTPS submission, assuming SMTP is used. Website security standards such as: HTTP Strict Transport Security Subresource Integrity if loading things from external domains. Best Case: Support for hardware authentication, ie U2F and WebAuthn . U2F and WebAuthn are more secure as they use a private key stored on a client-side hardware device to authenticate people, as opposed to a shared secret that is stored on the web server and on the client side when using TOTP . Furthermore, U2F and WebAuthn are more resistant to phishing as their authentication response is based on the authenticated domain name . Zero access encryption, builds on encryption at rest. The difference being the provider does not have the decryption keys to the data they hold. This prevents a rogue employee leaking data they have access to or remote adversary from releasing data they have stolen by gaining unauthorized access to the server. DNS Certification Authority Authorization (CAA) Resource Record in addition to DANE support. Implementation of Authenticated Received Chain (ARC) , this is useful for people who post to mailing lists RFC8617 . Bug-bounty programs and/or a coordinated vulnerability-disclosure process. Website security standards such as: Content Security Policy (CSP) Expect-CT","title":"Security"},{"location":"email/#trust","text":"You wouldn't trust your finances to someone with a fake identity, so why trust them with your email? We require our recommended providers to be public about their ownership or leadership. We also would like to see frequent transparency reports, especially in regard to how government requests are handled. Minimum to Qualify: Public-facing leadership or ownership. Best Case: Public-facing leadership. Frequent transparency reports.","title":"Trust"},{"location":"email/#marketing","text":"With the email providers we recommend we like to see responsible marketing. Minimum to Qualify: Must self host analytics (no Google Analytics etc). The provider's site must also comply with DNT (Do Not Track) for those who wish to opt-out. Must not have any marketing which is irresponsible: Claims of \"unbreakable encryption\". Encryption should be used with the intention that it may not be secret in the future when the technology exists to crack it. Making guarantees of protecting anonymity 100%. When someone makes a claim that something is 100% it means there is no certainty for failure. We know people can quite easily deanonymize themselves in a number of ways, e.g.: Reusing personal information e.g. (email accounts, unique pseudonyms etc) that they accessed without anonymity software (Tor, VPN etc) Browser fingerprinting Best Case: Clear and easy to read documentation. This includes things like, setting up 2FA , email clients, OpenPGP , etc.","title":"Marketing"},{"location":"email/#additional-functionality","text":"While not strictly requirements, there are some other convenience or privacy factors we looked into when determining which providers to recommend.","title":"Additional Functionality"},{"location":"email/#email-encryption-overview","text":"","title":"Email Encryption Overview"},{"location":"email/#what-is-end-to-end-encryption-e2ee-in-email","text":"E2EE is a way of encrypting email contents so that nobody but the recipient(s) can read the email message.","title":"What is end-to-end encryption (E2EE) in email?"},{"location":"email/#how-can-i-encrypt-my-email","text":"The standard way to do email E2EE and have it work between different email providers is with OpenPGP . There are different implementations of the OpenPGP standard, the most common being GnuPG and OpenPGP .js . There is another standard that was popular with business called S/MIME , however it requires a certificate issued from a Certificate Authority (not all of them issue S/MIME certificates). It has support in Google Workplace and Outlook for Web or Exchange Server 2016, 2019 .","title":"How can I encrypt my email?"},{"location":"email/#what-software-can-i-use-to-get-e2ee","text":"Email providers which allow you to use standard access protocols like IMAP and SMTP can be used with any of the email clients we recommend . This can be less secure as you are now relying on email providers to ensure that their encryption implementation works and has not been compromised in anyway.","title":"What software can I use to get E2EE?"},{"location":"email/#how-do-i-protect-my-private-keys","text":"A smartcard (such as a Yubikey or Nitrokey ) works by receiving an encrypted email message from a device (phone, tablet, computer etc) running an email/webmail client. The message is then decrypted by the smartcard and the decrypted content is sent back to the device. It is advantageous for the decryption to occur on the smartcard so as to avoid possibly exposing your private key to a compromised device.","title":"How do I protect my private keys?"},{"location":"email/#email-metadata-overview","text":"","title":"Email Metadata Overview"},{"location":"email/#who-can-see-the-email-metadata","text":"Email metadata is able to be seen by your email client software (or webmail) and any servers relaying the message from you to any recipients. Sometimes email servers will also use external parties to protect against spam.","title":"Who can see the email metadata?"},{"location":"email/#what-is-email-metadata","text":"Email software will often show some visible headers that you may have seen such as: To , From , Cc , Date , Subject .","title":"What is email metadata?"},{"location":"email/#when-is-email-metadata-used","text":"Client software may use it to show who a message is from and what time it was received. Servers may use it to determine where an email message must be sent, among other purposes which are not always transparent.","title":"When is email metadata used?"},{"location":"email/#where-is-the-email-metadata","text":"Email metadata is stored in the message header of the email message.","title":"Where is the email metadata?"},{"location":"email/#why-cant-email-metadata-be-e2ee","text":"Email metadata is crucial to the most basic functionality of email (where it came from, and where it has to go). E2EE was not built into the email protocols originally and is also optional, therefore, only the message content is protected.","title":"Why can't email metadata be E2EE?"},{"location":"email/#how-is-my-metadata-protected","text":"When emails travel between email providers an encrypted connection is negotiated using Opportunistic TLS . This protects the metadata from outside observers, but as it is not E2EE , server administrators can snoop on the metadata of an email.","title":"How is my metadata protected?"},{"location":"email/#additional-reading","text":"An NFC PGP SmartCard For Android Aging 'Privacy' Law Leaves Cloud E-Mail Open to Cops (2011) The Government Can (Still) Read Most Of Your Emails Without A Warrant (2013)","title":"Additional Reading"},{"location":"encryption/","text":"Encryption of data is the only way to control who can access it. If you are currently not using encryption software for your hard disk, emails, or files, you should pick an option here. Multi-platform \u00b6 The options listed here are multi-platform and great for creating encrypted backups of your data. VeraCrypt \u00b6 Recommendation VeraCrypt is a source-available freeware utility used for on-the-fly encryption. It can create a virtual encrypted disk within a file, encrypt a partition, or encrypt the entire storage device with pre-boot authentication. Homepage Downloads Windows macOS Linux Source VeraCrypt is a fork of the discontinued TrueCrypt project. According to its developers, security improvements have been implemented and issues raised by the initial TrueCrypt code audit have been addressed. When encrypting with VeraCrypt, you have the option to select from different hash functions . We suggest you only select SHA-512 and stick to the AES block cipher. Truecrypt has been audited a number of times and VeraCrypt has also been audited seperately . Cryptomator \u00b6 Recommendation Cryptomator is an encryption solution designed for privately saving files to any cloud provider. It allows you to create vaults that are stored on a virtual drive, the contents of which are encrypted and synced with your cloud storage provider. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid App Store Source Cryptomator utilizes AES-256 encryption to encrypt both files and filenames. Cryptomator cannot encrypt some metadata such as access, modification, and creation timestamps, nor the number and size of files and folders. Some Cryptomator cryptographic libraries have been audited by Cure53. The scope of the audited libraries include: cryptolib , cryptofs , siv-mode and cryptomator-objc-cryptor . The audit did not extend to cryptolib-swift , which is a library used by Cryptomator for iOS. Cryptomator's documentation details its intended security target , security architecture , and best practices for use in further detail. Picocrypt \u00b6 Recommendation Picocrypt is a small and simple encryption tool that provides modern encryption. Picocrypt uses the secure XChaCha20 cipher and the Argon2id key derivation function to provide a high level of security. It uses Go's standard x/crypto modules for its encryption features. Project Info Downloads Windows macOS Linux Source OS Full Disk Encryption \u00b6 Modern operating systems include FDE and will utilize a secure cryptoprocessor . BitLocker \u00b6 Recommendation BitLocker is the full volume encryption solution bundled with Microsoft Windows. The main reason we recommend it is because of its use of TPM . ElcomSoft , a forensics company, has written about it in Understanding BitLocker TPM Protection . Overview BitLocker is only supported on Pro, Enterprise, and Education editions of Windows. It can be enabled on Home editions provided that they meet the prerequisites. Enabling BitLocker on Windows Home To enable BitLocker on \"Home\" editions of Windows, you must partitions formatted with formatted with a GUID Partition Table and have a dedicated TPM (v1.2, 2.0+) module. Open Windows PowerShell . Start \"PowerShell\" Check to see partition table format: powershell Get-Disk 0 | findstr GPT && echo This is a GPT system disk! Check TPM version. The value returned must be \"3 True\". The spec must be 1.2 or above. powershell Get-WmiObject -Namespace \"root/cimv2/security/microsofttpm\" -Class WIN32_tpm | findstr \"IsActivated IsEnabled IsOwned SpecVersion\" Access Advanced Startup Options . You need to reboot while pressing the F8 key before Windows starts and go into the command prompt in Troubleshoot \u2192 Advanced Options \u2192 Command Prompt . Login with your account that has admin privileges and type this to start encryption: manage-bde -on c: -used Close the command prompt, and enter into PowerShell: manage-bde c: -protectors -add -rp -tpm manage-bde -protectors -enable c: manage-bde -protectors -get c: > %UserProfile%\\Desktop\\BitLocker-Recovery-Key.txt Warning Backup BitLocker-Recovery-Key.txt on a separate storage device. Loss of this recovery code, may result in loss of data. FileVault \u00b6 Recommendation FileVault is the on-the-fly volume encryption solution built into macOS. FileVault is recommended because it leverages hardware security capabilities present on an Apple silicon SoC or T2 Security Chip. Article We recommend storing a local recovery key in a secure place as opposed to utilizing iCloud FileVault recovery. As well, FileVault should be enabled after a complete macOS installation as more pseudorandom number generator ( PRNG ) entropy will be available. Linux Unified Key Setup \u00b6 Recommendation LUKS is the default FDE method for Linux. It can be used to encrypt full volumes, partitions, or create encrypted containers. Project Wiki Creating and opening encrypted containers dd if=/dev/urandom of=/path-to-file bs=1M count=1024 status=progress sudo cryptsetup luksFormat /path-to-file Opening encrypted containers \u00b6 We recommend opening containers and volumes with udisksctl as this uses Polkit . Most file managers, such as those included with popular desktop environments, can unlock encrypted files. Tools like udiskie can run in the system tray and provide a helpful user interface. udisksctl loop-setup -f /path-to-file udisksctl unlock -b /dev/loop0 Remember to back up volume headers We recommend you always back up your LUKS headers in case of partial drive failure. This can be done with: cryptsetup luksHeaderBackup /dev/device --header-backup-file /mnt/backup/file.img Browser-based \u00b6 Browser-based encryption can be useful when you need to encrypt a file but cannot install software or apps on your device. hat.sh \u00b6 Recommendation Hat.sh is a web application that provides secure client-side file encryption in your browser. It can also be self-hosted and is useful if you need to encrypt a file but cannot install any software on your device due to organizational policies. Homepage Downloads Source Command-line \u00b6 Tools with command-line interfaces are useful for intergrating shell scripts . Kryptor \u00b6 Recommendation Kryptor is a free and open source file encryption and signing tool that makes use of modern and secure cryptographic algorithms. It aims to be a better version of age and Minisign to provide a simple, easier alternative to GPG . Homepage Privacy Policy Downloads Windows macOS Linux Source Tomb \u00b6 Recommendation Tomb is an is a command-line shell wrapper for LUKS . It supports steganography via third-party tools . Homepage Downloads Source OpenPGP \u00b6 OpenPGP is sometimes needed for specific tasks such as digitally signing and encrypting email. PGP has many features and is complex as it has been around a long time. For tasks such as signing or encrypting files, we suggest the above options. When encrypting with PGP , you have the option to configure different options in your gpg.conf file. We recommend staying with the standard options specified in the GnuPG user FAQ . Use future defaults when generating a key When generating keys we suggest using the future-default command as this will instruct GnuPG use modern cryptography such as Curve25519 and Ed25519 : gpg --quick-gen-key alice@example.com future-default GNU Privacy Guard \u00b6 Recommendation GnuPG is a GPL-licensed alternative to the PGP suite of cryptographic software. GnuPG is compliant with RFC 4880 , which is the current IETF specification of OpenPGP . The GnuPG project has been working on an updated draft in an attempt to modernize OpenPGP . GnuPG is a part of the Free Software Foundation's GNU software project and has received major funding from the German government. Homepage Privacy Policy Downloads Windows macOS Linux Google Play Source GPG4win \u00b6 Recommendation GPG4win is a package for Windows from Intevation and g10 Code . It includes various tools that can assist you in using GPG on Microsoft Windows. The project was initiated and originally funded by Germany's Federal Office for Information Security (BSI) in 2005. Homepage Privacy Policy Downloads Windows Source GPG Suite \u00b6 Note We suggest Canary Mail for using PGP with email on iOS devices. Recommendation GPG Suite provides OpenPGP support for Apple Mail and macOS. GPG Mail costs $24\u20ac yearly for their support plan and includes a 30-day trial. For more details see the FAQ . We recommend taking a look at their First steps and Knowledge base for support. Homepage Privacy Policy Downloads macOS Source OpenKeychain \u00b6 Recommendation OpenKeychain is an Android implementation of GnuPG . It's commonly required by mail clients, such as K-9 Mail , and other Android apps to provide encryption support. Cure53 completed a security audit of OpenKeychain 3.6 in October 2015. Technical details about the audit and OpenKeychain's solutions can be found here . Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source","title":"Encryption Software"},{"location":"encryption/#multi-platform","text":"The options listed here are multi-platform and great for creating encrypted backups of your data.","title":"Multi-platform"},{"location":"encryption/#veracrypt","text":"Recommendation VeraCrypt is a source-available freeware utility used for on-the-fly encryption. It can create a virtual encrypted disk within a file, encrypt a partition, or encrypt the entire storage device with pre-boot authentication. Homepage Downloads Windows macOS Linux Source VeraCrypt is a fork of the discontinued TrueCrypt project. According to its developers, security improvements have been implemented and issues raised by the initial TrueCrypt code audit have been addressed. When encrypting with VeraCrypt, you have the option to select from different hash functions . We suggest you only select SHA-512 and stick to the AES block cipher. Truecrypt has been audited a number of times and VeraCrypt has also been audited seperately .","title":"VeraCrypt"},{"location":"encryption/#cryptomator","text":"Recommendation Cryptomator is an encryption solution designed for privately saving files to any cloud provider. It allows you to create vaults that are stored on a virtual drive, the contents of which are encrypted and synced with your cloud storage provider. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Google Play f-droid F-Droid App Store Source Cryptomator utilizes AES-256 encryption to encrypt both files and filenames. Cryptomator cannot encrypt some metadata such as access, modification, and creation timestamps, nor the number and size of files and folders. Some Cryptomator cryptographic libraries have been audited by Cure53. The scope of the audited libraries include: cryptolib , cryptofs , siv-mode and cryptomator-objc-cryptor . The audit did not extend to cryptolib-swift , which is a library used by Cryptomator for iOS. Cryptomator's documentation details its intended security target , security architecture , and best practices for use in further detail.","title":"Cryptomator"},{"location":"encryption/#picocrypt","text":"Recommendation Picocrypt is a small and simple encryption tool that provides modern encryption. Picocrypt uses the secure XChaCha20 cipher and the Argon2id key derivation function to provide a high level of security. It uses Go's standard x/crypto modules for its encryption features. Project Info Downloads Windows macOS Linux Source","title":"Picocrypt"},{"location":"encryption/#os-full-disk-encryption","text":"Modern operating systems include FDE and will utilize a secure cryptoprocessor .","title":"OS Full Disk Encryption"},{"location":"encryption/#bitlocker","text":"Recommendation BitLocker is the full volume encryption solution bundled with Microsoft Windows. The main reason we recommend it is because of its use of TPM . ElcomSoft , a forensics company, has written about it in Understanding BitLocker TPM Protection . Overview BitLocker is only supported on Pro, Enterprise, and Education editions of Windows. It can be enabled on Home editions provided that they meet the prerequisites. Enabling BitLocker on Windows Home To enable BitLocker on \"Home\" editions of Windows, you must partitions formatted with formatted with a GUID Partition Table and have a dedicated TPM (v1.2, 2.0+) module. Open Windows PowerShell . Start \"PowerShell\" Check to see partition table format: powershell Get-Disk 0 | findstr GPT && echo This is a GPT system disk! Check TPM version. The value returned must be \"3 True\". The spec must be 1.2 or above. powershell Get-WmiObject -Namespace \"root/cimv2/security/microsofttpm\" -Class WIN32_tpm | findstr \"IsActivated IsEnabled IsOwned SpecVersion\" Access Advanced Startup Options . You need to reboot while pressing the F8 key before Windows starts and go into the command prompt in Troubleshoot \u2192 Advanced Options \u2192 Command Prompt . Login with your account that has admin privileges and type this to start encryption: manage-bde -on c: -used Close the command prompt, and enter into PowerShell: manage-bde c: -protectors -add -rp -tpm manage-bde -protectors -enable c: manage-bde -protectors -get c: > %UserProfile%\\Desktop\\BitLocker-Recovery-Key.txt Warning Backup BitLocker-Recovery-Key.txt on a separate storage device. Loss of this recovery code, may result in loss of data.","title":"BitLocker"},{"location":"encryption/#filevault","text":"Recommendation FileVault is the on-the-fly volume encryption solution built into macOS. FileVault is recommended because it leverages hardware security capabilities present on an Apple silicon SoC or T2 Security Chip. Article We recommend storing a local recovery key in a secure place as opposed to utilizing iCloud FileVault recovery. As well, FileVault should be enabled after a complete macOS installation as more pseudorandom number generator ( PRNG ) entropy will be available.","title":"FileVault"},{"location":"encryption/#linux-unified-key-setup","text":"Recommendation LUKS is the default FDE method for Linux. It can be used to encrypt full volumes, partitions, or create encrypted containers. Project Wiki Creating and opening encrypted containers dd if=/dev/urandom of=/path-to-file bs=1M count=1024 status=progress sudo cryptsetup luksFormat /path-to-file","title":"Linux Unified Key Setup"},{"location":"encryption/#opening-encrypted-containers","text":"We recommend opening containers and volumes with udisksctl as this uses Polkit . Most file managers, such as those included with popular desktop environments, can unlock encrypted files. Tools like udiskie can run in the system tray and provide a helpful user interface. udisksctl loop-setup -f /path-to-file udisksctl unlock -b /dev/loop0 Remember to back up volume headers We recommend you always back up your LUKS headers in case of partial drive failure. This can be done with: cryptsetup luksHeaderBackup /dev/device --header-backup-file /mnt/backup/file.img","title":"Opening encrypted containers"},{"location":"encryption/#browser-based","text":"Browser-based encryption can be useful when you need to encrypt a file but cannot install software or apps on your device.","title":"Browser-based"},{"location":"encryption/#hatsh","text":"Recommendation Hat.sh is a web application that provides secure client-side file encryption in your browser. It can also be self-hosted and is useful if you need to encrypt a file but cannot install any software on your device due to organizational policies. Homepage Downloads Source","title":"hat.sh"},{"location":"encryption/#command-line","text":"Tools with command-line interfaces are useful for intergrating shell scripts .","title":"Command-line"},{"location":"encryption/#kryptor","text":"Recommendation Kryptor is a free and open source file encryption and signing tool that makes use of modern and secure cryptographic algorithms. It aims to be a better version of age and Minisign to provide a simple, easier alternative to GPG . Homepage Privacy Policy Downloads Windows macOS Linux Source","title":"Kryptor"},{"location":"encryption/#tomb","text":"Recommendation Tomb is an is a command-line shell wrapper for LUKS . It supports steganography via third-party tools . Homepage Downloads Source","title":"Tomb"},{"location":"encryption/#openpgp","text":"OpenPGP is sometimes needed for specific tasks such as digitally signing and encrypting email. PGP has many features and is complex as it has been around a long time. For tasks such as signing or encrypting files, we suggest the above options. When encrypting with PGP , you have the option to configure different options in your gpg.conf file. We recommend staying with the standard options specified in the GnuPG user FAQ . Use future defaults when generating a key When generating keys we suggest using the future-default command as this will instruct GnuPG use modern cryptography such as Curve25519 and Ed25519 : gpg --quick-gen-key alice@example.com future-default","title":"OpenPGP"},{"location":"encryption/#gnu-privacy-guard","text":"Recommendation GnuPG is a GPL-licensed alternative to the PGP suite of cryptographic software. GnuPG is compliant with RFC 4880 , which is the current IETF specification of OpenPGP . The GnuPG project has been working on an updated draft in an attempt to modernize OpenPGP . GnuPG is a part of the Free Software Foundation's GNU software project and has received major funding from the German government. Homepage Privacy Policy Downloads Windows macOS Linux Google Play Source","title":"GNU Privacy Guard"},{"location":"encryption/#gpg4win","text":"Recommendation GPG4win is a package for Windows from Intevation and g10 Code . It includes various tools that can assist you in using GPG on Microsoft Windows. The project was initiated and originally funded by Germany's Federal Office for Information Security (BSI) in 2005. Homepage Privacy Policy Downloads Windows Source","title":"GPG4win"},{"location":"encryption/#gpg-suite","text":"Note We suggest Canary Mail for using PGP with email on iOS devices. Recommendation GPG Suite provides OpenPGP support for Apple Mail and macOS. GPG Mail costs $24\u20ac yearly for their support plan and includes a 30-day trial. For more details see the FAQ . We recommend taking a look at their First steps and Knowledge base for support. Homepage Privacy Policy Downloads macOS Source","title":"GPG Suite"},{"location":"encryption/#openkeychain","text":"Recommendation OpenKeychain is an Android implementation of GnuPG . It's commonly required by mail clients, such as K-9 Mail , and other Android apps to provide encryption support. Cure53 completed a security audit of OpenKeychain 3.6 in October 2015. Technical details about the audit and OpenKeychain's solutions can be found here . Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source","title":"OpenKeychain"},{"location":"file-sharing/","text":"Discover how to privately share your files between your devices, with your friends and family, or anonymously online. File Sharing \u00b6 OnionShare \u00b6 Recommendation OnionShare is an open-source tool that lets you securely and anonymously share a file of any size. It works by starting a web server accessible as a Tor onion service, with an unguessable URL that you can share with the recipients to download or send files. Homepage tor Downloads Windows macOS Linux Source Magic Wormhole \u00b6 Recommendation Magic Wormhole is a package that provides a library and a command-line tool named wormhole, which makes it possible to get arbitrary-sized files and directories (or short pieces of text) from one computer to another. Their motto: \"Get things from one computer to another, safely. Homepage Downloads Windows macOS Linux Source FreedomBox \u00b6 Recommendation FreedomBox is an operating system designed to be run on a single-board computer (SBC) . The purpose is to make it easy to set up server applications that you might want to selfhost. Homepage Downloads Source File Sync \u00b6 Syncthing \u00b6 Recommendation Syncthing is an open-source peer-to-peer continuous file synchronization utility. It is used to synchronize files between two or more devices over the local network or the internet. Syncthing does not use a centralized server; it uses the Block Exchange Protocol to transfer data between devices. All data is encrypted using TLS. Homepage Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Google Play f-droid F-Droid Source git-annex \u00b6 Recommendation git-annex allows managing files with git, without checking the file contents into git. While that may seem paradoxical, it is useful when dealing with files larger than git can currently easily handle, whether due to limitations in memory, time, or disk space. Homepage Privacy Policy Downloads Windows macOS Linux Source","title":"File Sharing and Sync"},{"location":"file-sharing/#file-sharing","text":"","title":"File Sharing"},{"location":"file-sharing/#onionshare","text":"Recommendation OnionShare is an open-source tool that lets you securely and anonymously share a file of any size. It works by starting a web server accessible as a Tor onion service, with an unguessable URL that you can share with the recipients to download or send files. Homepage tor Downloads Windows macOS Linux Source","title":"OnionShare"},{"location":"file-sharing/#magic-wormhole","text":"Recommendation Magic Wormhole is a package that provides a library and a command-line tool named wormhole, which makes it possible to get arbitrary-sized files and directories (or short pieces of text) from one computer to another. Their motto: \"Get things from one computer to another, safely. Homepage Downloads Windows macOS Linux Source","title":"Magic Wormhole"},{"location":"file-sharing/#freedombox","text":"Recommendation FreedomBox is an operating system designed to be run on a single-board computer (SBC) . The purpose is to make it easy to set up server applications that you might want to selfhost. Homepage Downloads Source","title":"FreedomBox"},{"location":"file-sharing/#file-sync","text":"","title":"File Sync"},{"location":"file-sharing/#syncthing","text":"Recommendation Syncthing is an open-source peer-to-peer continuous file synchronization utility. It is used to synchronize files between two or more devices over the local network or the internet. Syncthing does not use a centralized server; it uses the Block Exchange Protocol to transfer data between devices. All data is encrypted using TLS. Homepage Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Google Play f-droid F-Droid Source","title":"Syncthing"},{"location":"file-sharing/#git-annex","text":"Recommendation git-annex allows managing files with git, without checking the file contents into git. While that may seem paradoxical, it is useful when dealing with files larger than git can currently easily handle, whether due to limitations in memory, time, or disk space. Homepage Privacy Policy Downloads Windows macOS Linux Source","title":"git-annex"},{"location":"","text":"Linux Atheism Veganism Universe Movies","title":"Home"},{"location":"linux-desktop/","text":"Linux distributions are commonly recommended for privacy protection and software freedom. General Linux Overview If you don't already use Linux, below are some distributions we suggest trying out, as well as some general privacy and security improvement tips that are applicable to many Linux distributions. Traditional Distributions \u00b6 Fedora Workstation \u00b6 Recommendation Fedora Workstation is our recommended distribution for people new to Linux. Fedora generally adopts newer technologies before other distributions e.g., Wayland , PipeWire , and soon, FS-Verity . These new technologies often come with improvements in security, privacy, and usability in general. Homepage Fedora has a semi- rolling release cycle. While some packages like GNOME are frozen until the next Fedora release, most packages (including the kernel) are updated frequently throughout the lifespan of the release. Each Fedora release is supported for one year, with a new version released every 6 months. openSUSE Tumbleweed \u00b6 Recommendation openSUSE Tumbleweed is a stable rolling release distribution. openSUSE Tumbleweed has a transactional update system that uses Btrfs and Snapper to ensure that snapshots can be rolled back should there be a problem. Homepage Tumbleweed follows a rolling release model where each update is released as a snapshot of the distribution. When you upgrade your system, a new snapshot is downloaded. Each snapshot is run through a series of automated tests by openQA to ensure its quality. Arch Linux \u00b6 Recommendation Arch Linux is a lightweight, do-it-yourself (DIY) distribution meaning that you only get what you install. For more information see their FAQ . Homepage Arch Linux has a rolling release cycle. There is no fixed release schedule and packages are updated very frequently. Being a DIY distribution, you are expected to set up and maintain your system on your own. Arch has an official installer to make the installation process a little easier. A large portion of Arch Linux\u2019s packages are reproducible . Immutable Distributions \u00b6 Fedora Silverblue \u00b6 Recommendation Fedora Silverblue and Fedora Kinoite are immutable variants of Fedora with a strong focus on container workflows. Silverblue comes with the GNOME desktop environment while Kinoite comes with KDE . Silverblue and Kinoite follow the same release schedule as Fedora Workstation, benefiting from the same fast updates and staying very close to upstream. Homepage Silverblue (and Kinoite) differ from Fedora Workstation as they replace the DNF package manager with a much more advanced alternative called rpm-ostree . The rpm-ostree package manager works by downloading a base image for the system, then overlaying packages over it in a git -like commit tree. When the system is updated, a new base image is downloaded and the overlays will be applied to that new image. After the update is complete you will reboot the system into the new deployment. rpm-ostree keeps two deployments of the system so that you can easily rollback if something breaks in the new deployment. There is also the option to pin more deployments as needed. Flatpak is the primary package installation method on these distributions, as rpm-ostree is only meant to overlay packages that cannot stay inside of a container on top of the base image. As an alternative to Flatpaks, there is the option of Toolbox to create Podman containers with a shared home directory with the host operating system and mimic a traditional Fedora environment, which is a useful feature for the discerning developer. NixOS \u00b6 Recommendation NixOS is an independent distribution based on the Nix package manager with a focus on reproducibility and reliability. Homepage NixOS\u2019s package manager keeps every version of every package in a different folder in the Nix store . Due to this you can have different versions of the same package installed on your system. After the package contents have been written to the folder, the folder is made read-only. NixOS also provides atomic updates; first it downloads (or builds) the packages and files for the new system generation and then switches to it. There are different ways to switch to a new generation; you can tell NixOS to activate it after reboot or you can switch to it at runtime. You can also test the new generation by switching to it at runtime, but not setting it as the current system generation. If something in the update process breaks, you can just reboot and automatically and return to a working version of your system. Nix the package manager uses a purely functional language - which is also called Nix - to define packages. Nixpkgs (the main source of packages) are contained in a single GitHub repository. You can also define your own packages in the same language and then easily include them in your config. Nix is a source-based package manager; if there\u2019s no pre-built available in the binary cache, Nix will just build the package from source using its definition. It builds each package in a sandboxed pure environment, which is as independent of the host system as possible, thus making binaries reproducible. Anonymity-Focused Distributions \u00b6 Whonix \u00b6 Recommendation Whonix is based on Kicksecure , a security-focused fork of Debian. It aims to provide privacy, security, and anonymity on the internet. Homepage Whonix is meant to run as two virtual machines: a \u201cWorkstation\u201d and a Tor \u201cGateway\u201d. All communications from the Workstation has to go through the Tor gateway, and will be routed through the Tor Network. Some of its features include Tor Stream Isolation, keystroke anonymization , encrypted swap , and a hardened memory allocator. Future versions of Whonix will likely include full system AppArmor policies and a sandbox app launcher to fully confine all processes on the system. Whonix is best used in conjunction with Qubes . Tails \u00b6 Recommendation Tails is a live operating system based on Debian that routes all communications through Tor. It can boot on almost any computer from a DVD, USB stick, or SD card. It aims to preserve privacy and anonymity while circumventing censorship and leaving no trace of itself on the computer it is used on. Homepage By design, Tails is meant to completely reset itself after each reboot. Encrypted persistent storage can be configured to store some data. General Recommendations \u00b6 Drive Encryption \u00b6 Most Linux distributions have an installer option for enabling LUKS FDE upon installation. If this option isn\u2019t set at installation time, you will have to backup your data and re-install, as encryption is applied after disk partitioning , but before file systems are formatted. When securely erasing storage devices such as a Solid-state drive (SSD) you should use the ATA Secure Erase command. This command can be issued from your UEFI setup. If the storage device is a regular hard drive (HDD), consider using nwipe . Swap \u00b6 Consider using ZRAM or encrypted swap instead of unencrypted swap to avoid potential security issues with sensitive data being pushed to swap space . Fedora based distributions use ZRAM by default . Wayland \u00b6 We recommend using a desktop environment that supports the Wayland display protocol as it developed with security in mind . Its predecessor, X11 , does not support GUI isolation, allowing all windows to record screen, log and inject inputs in other windows , making any attempt at sandboxing futile. While there are options to do nested X11 such as Xpra or Xephyr , they often come with negative performance consequences and are not convenient to set up and are not preferable over Wayland. Fortunately, common environments such as GNOME , KDE , and the window manager Sway have support for Wayland. Some distributions like Fedora and Tumbleweed use it by default and some others may do so in the future as X11 is in hard maintenance mode . If you\u2019re using one of those environments it is as easy as selecting the \u201cWayland\u201d session at the desktop display manager ( GDM , SDDM ). We recommend against using desktop environments or window managers that do not have Wayland support such as Cinnamon (default on Linux Mint), Pantheon (default on Elementary OS ), MATE, Xfce, and i3. Proprietary Firmware (Microcode Updates) \u00b6 Linux distributions such as those which are Linux-libre or DIY (Arch Linux) don\u2019t come with the proprietary microcode updates. Some notable examples of these vulnerabilities include Spectre , Meltdown , SSB , Foreshadow , MDS , SWAPGS , and other hardware vulnerabilities . We highly recommend that you install the microcode updates, as your CPU is already running the proprietary microcode from the factory. Fedora and openSUSE both have the microcode updates applied by default. Privacy Tweaks \u00b6 MAC Address Randomization \u00b6 Many desktop Linux distributions (Fedora, openSUSE etc) will come with NetworkManager , to configure Ethernet and Wi-Fi settings. It is possible to randomize the MAC address when using NetworkManager. This provides a bit more privacy on Wi-Fi networks as it makes it harder to track specific devices on the network you\u2019re connected to. It does not make you anonymous. We recommend changing the setting to random instead of stable , as suggested in the article . If you are using systemd-networkd , you will need to set MACAddressPolicy=random which will enable RFC 7844 (Anonymity Profiles for DHCP Clients) . There isn\u2019t much point in randomizing the MAC address for Ethernet connections as a system administrator can find you by looking at the port you are using on the network switch . Randomizing Wi-Fi MAC addresses depends on support from the Wi-Fi\u2019s firmware. Other Identifiers \u00b6 There are other system identifiers which you may wish to be careful about. You should give this some thought to see if it applies to your threat model : Hostnames: Your system's hostname is shared with the networks you connect to. You should avoid including identifying terms like your name or operating system in your hostname, instead sticking to generic terms or random strings. Usernames: Similarly, your username is used in a variety of ways across your system. Consider using generic terms like \"user\" rather than your actual name. Machine ID: : During installation a unique machine ID is generated and stored on your device. Consider setting it to a generic ID . System Counting \u00b6 The Fedora Project counts how many unique systems access its mirrors by using a countme variable instead of a unique ID. Fedora does this to determine load and provision better servers for updates where necessary. This option is currently off by default. We recommend adding countme=false to /etc/dnf/dnf.conf just in case it is enabled in the future. On systems that use rpm-ostree such as Silverblue, the countme option is disabled by masking the rpm-ostree-countme timer. openSUSE also uses a unique ID to count systems, which can be disabled by deleting the /var/lib/zypp/AnonymousUniqueId file.","title":"Linux"},{"location":"linux-desktop/#traditional-distributions","text":"","title":"Traditional Distributions"},{"location":"linux-desktop/#fedora-workstation","text":"Recommendation Fedora Workstation is our recommended distribution for people new to Linux. Fedora generally adopts newer technologies before other distributions e.g., Wayland , PipeWire , and soon, FS-Verity . These new technologies often come with improvements in security, privacy, and usability in general. Homepage Fedora has a semi- rolling release cycle. While some packages like GNOME are frozen until the next Fedora release, most packages (including the kernel) are updated frequently throughout the lifespan of the release. Each Fedora release is supported for one year, with a new version released every 6 months.","title":"Fedora Workstation"},{"location":"linux-desktop/#opensuse-tumbleweed","text":"Recommendation openSUSE Tumbleweed is a stable rolling release distribution. openSUSE Tumbleweed has a transactional update system that uses Btrfs and Snapper to ensure that snapshots can be rolled back should there be a problem. Homepage Tumbleweed follows a rolling release model where each update is released as a snapshot of the distribution. When you upgrade your system, a new snapshot is downloaded. Each snapshot is run through a series of automated tests by openQA to ensure its quality.","title":"openSUSE Tumbleweed"},{"location":"linux-desktop/#arch-linux","text":"Recommendation Arch Linux is a lightweight, do-it-yourself (DIY) distribution meaning that you only get what you install. For more information see their FAQ . Homepage Arch Linux has a rolling release cycle. There is no fixed release schedule and packages are updated very frequently. Being a DIY distribution, you are expected to set up and maintain your system on your own. Arch has an official installer to make the installation process a little easier. A large portion of Arch Linux\u2019s packages are reproducible .","title":"Arch Linux"},{"location":"linux-desktop/#immutable-distributions","text":"","title":"Immutable Distributions"},{"location":"linux-desktop/#fedora-silverblue","text":"Recommendation Fedora Silverblue and Fedora Kinoite are immutable variants of Fedora with a strong focus on container workflows. Silverblue comes with the GNOME desktop environment while Kinoite comes with KDE . Silverblue and Kinoite follow the same release schedule as Fedora Workstation, benefiting from the same fast updates and staying very close to upstream. Homepage Silverblue (and Kinoite) differ from Fedora Workstation as they replace the DNF package manager with a much more advanced alternative called rpm-ostree . The rpm-ostree package manager works by downloading a base image for the system, then overlaying packages over it in a git -like commit tree. When the system is updated, a new base image is downloaded and the overlays will be applied to that new image. After the update is complete you will reboot the system into the new deployment. rpm-ostree keeps two deployments of the system so that you can easily rollback if something breaks in the new deployment. There is also the option to pin more deployments as needed. Flatpak is the primary package installation method on these distributions, as rpm-ostree is only meant to overlay packages that cannot stay inside of a container on top of the base image. As an alternative to Flatpaks, there is the option of Toolbox to create Podman containers with a shared home directory with the host operating system and mimic a traditional Fedora environment, which is a useful feature for the discerning developer.","title":"Fedora Silverblue"},{"location":"linux-desktop/#nixos","text":"Recommendation NixOS is an independent distribution based on the Nix package manager with a focus on reproducibility and reliability. Homepage NixOS\u2019s package manager keeps every version of every package in a different folder in the Nix store . Due to this you can have different versions of the same package installed on your system. After the package contents have been written to the folder, the folder is made read-only. NixOS also provides atomic updates; first it downloads (or builds) the packages and files for the new system generation and then switches to it. There are different ways to switch to a new generation; you can tell NixOS to activate it after reboot or you can switch to it at runtime. You can also test the new generation by switching to it at runtime, but not setting it as the current system generation. If something in the update process breaks, you can just reboot and automatically and return to a working version of your system. Nix the package manager uses a purely functional language - which is also called Nix - to define packages. Nixpkgs (the main source of packages) are contained in a single GitHub repository. You can also define your own packages in the same language and then easily include them in your config. Nix is a source-based package manager; if there\u2019s no pre-built available in the binary cache, Nix will just build the package from source using its definition. It builds each package in a sandboxed pure environment, which is as independent of the host system as possible, thus making binaries reproducible.","title":"NixOS"},{"location":"linux-desktop/#anonymity-focused-distributions","text":"","title":"Anonymity-Focused Distributions"},{"location":"linux-desktop/#whonix","text":"Recommendation Whonix is based on Kicksecure , a security-focused fork of Debian. It aims to provide privacy, security, and anonymity on the internet. Homepage Whonix is meant to run as two virtual machines: a \u201cWorkstation\u201d and a Tor \u201cGateway\u201d. All communications from the Workstation has to go through the Tor gateway, and will be routed through the Tor Network. Some of its features include Tor Stream Isolation, keystroke anonymization , encrypted swap , and a hardened memory allocator. Future versions of Whonix will likely include full system AppArmor policies and a sandbox app launcher to fully confine all processes on the system. Whonix is best used in conjunction with Qubes .","title":"Whonix"},{"location":"linux-desktop/#tails","text":"Recommendation Tails is a live operating system based on Debian that routes all communications through Tor. It can boot on almost any computer from a DVD, USB stick, or SD card. It aims to preserve privacy and anonymity while circumventing censorship and leaving no trace of itself on the computer it is used on. Homepage By design, Tails is meant to completely reset itself after each reboot. Encrypted persistent storage can be configured to store some data.","title":"Tails"},{"location":"linux-desktop/#general-recommendations","text":"","title":"General Recommendations"},{"location":"linux-desktop/#drive-encryption","text":"Most Linux distributions have an installer option for enabling LUKS FDE upon installation. If this option isn\u2019t set at installation time, you will have to backup your data and re-install, as encryption is applied after disk partitioning , but before file systems are formatted. When securely erasing storage devices such as a Solid-state drive (SSD) you should use the ATA Secure Erase command. This command can be issued from your UEFI setup. If the storage device is a regular hard drive (HDD), consider using nwipe .","title":"Drive Encryption"},{"location":"linux-desktop/#swap","text":"Consider using ZRAM or encrypted swap instead of unencrypted swap to avoid potential security issues with sensitive data being pushed to swap space . Fedora based distributions use ZRAM by default .","title":"Swap"},{"location":"linux-desktop/#wayland","text":"We recommend using a desktop environment that supports the Wayland display protocol as it developed with security in mind . Its predecessor, X11 , does not support GUI isolation, allowing all windows to record screen, log and inject inputs in other windows , making any attempt at sandboxing futile. While there are options to do nested X11 such as Xpra or Xephyr , they often come with negative performance consequences and are not convenient to set up and are not preferable over Wayland. Fortunately, common environments such as GNOME , KDE , and the window manager Sway have support for Wayland. Some distributions like Fedora and Tumbleweed use it by default and some others may do so in the future as X11 is in hard maintenance mode . If you\u2019re using one of those environments it is as easy as selecting the \u201cWayland\u201d session at the desktop display manager ( GDM , SDDM ). We recommend against using desktop environments or window managers that do not have Wayland support such as Cinnamon (default on Linux Mint), Pantheon (default on Elementary OS ), MATE, Xfce, and i3.","title":"Wayland"},{"location":"linux-desktop/#proprietary-firmware-microcode-updates","text":"Linux distributions such as those which are Linux-libre or DIY (Arch Linux) don\u2019t come with the proprietary microcode updates. Some notable examples of these vulnerabilities include Spectre , Meltdown , SSB , Foreshadow , MDS , SWAPGS , and other hardware vulnerabilities . We highly recommend that you install the microcode updates, as your CPU is already running the proprietary microcode from the factory. Fedora and openSUSE both have the microcode updates applied by default.","title":"Proprietary Firmware (Microcode Updates)"},{"location":"linux-desktop/#privacy-tweaks","text":"","title":"Privacy Tweaks"},{"location":"linux-desktop/#mac-address-randomization","text":"Many desktop Linux distributions (Fedora, openSUSE etc) will come with NetworkManager , to configure Ethernet and Wi-Fi settings. It is possible to randomize the MAC address when using NetworkManager. This provides a bit more privacy on Wi-Fi networks as it makes it harder to track specific devices on the network you\u2019re connected to. It does not make you anonymous. We recommend changing the setting to random instead of stable , as suggested in the article . If you are using systemd-networkd , you will need to set MACAddressPolicy=random which will enable RFC 7844 (Anonymity Profiles for DHCP Clients) . There isn\u2019t much point in randomizing the MAC address for Ethernet connections as a system administrator can find you by looking at the port you are using on the network switch . Randomizing Wi-Fi MAC addresses depends on support from the Wi-Fi\u2019s firmware.","title":"MAC Address Randomization"},{"location":"linux-desktop/#other-identifiers","text":"There are other system identifiers which you may wish to be careful about. You should give this some thought to see if it applies to your threat model : Hostnames: Your system's hostname is shared with the networks you connect to. You should avoid including identifying terms like your name or operating system in your hostname, instead sticking to generic terms or random strings. Usernames: Similarly, your username is used in a variety of ways across your system. Consider using generic terms like \"user\" rather than your actual name. Machine ID: : During installation a unique machine ID is generated and stored on your device. Consider setting it to a generic ID .","title":"Other Identifiers"},{"location":"linux-desktop/#system-counting","text":"The Fedora Project counts how many unique systems access its mirrors by using a countme variable instead of a unique ID. Fedora does this to determine load and provision better servers for updates where necessary. This option is currently off by default. We recommend adding countme=false to /etc/dnf/dnf.conf just in case it is enabled in the future. On systems that use rpm-ostree such as Silverblue, the countme option is disabled by masking the rpm-ostree-countme timer. openSUSE also uses a unique ID to count systems, which can be disabled by deleting the /var/lib/zypp/AnonymousUniqueId file.","title":"System Counting"},{"location":"metadata-removal-tools/","text":"When sharing files, be sure to remove associated metadata. Image files commonly include Exif data. Photos sometimes even include GPS coordinates in the file metadata. Desktop \u00b6 MAT2 \u00b6 Recommendation MAT2 is free software, which allows the metadata to be removed from image, audio, torrent, and document file types. It provides both a command line tool and a graphical user interface via an extension for Nautilus , the default file manager of GNOME , and Dolphin , the default file manager of KDE . On Linux, a third party graphical tool Metadata Cleaner powered by MAT2 exists and is available on Flathub . Homepage Downloads Windows macOS Linux Web Source ExifCleaner \u00b6 Recommendation ExifCleaner is a freeware, open source graphical app that uses ExifTool to remove Exif metadata from images, videos, and PDF documents using a simple drag and drop interface. It supports multi-core batch processing and dark mode. Homepage Downloads Windows macOS Linux Source Mobile \u00b6 Scrambled Exif \u00b6 Recommendation Scrambled Exif is a metadata removal tool for Android. It can remove Exif data for many file formats and has been translated into many languages. Project Info Downloads Google Play f-droid F-Droid Source Imagepipe \u00b6 Recommendation Imagepipe is a a paint app for Android that can be used to redact photos and also delete Exif metadata. It has been translated into many languages. Project Info Downloads f-droid F-Droid Source Imagepipe is only available from F-Droid and not in Google Play. If you're looking for a paint app in Google Play we suggest Pocket Paint . Metapho \u00b6 Warning Metapho is closed source. We recommend it, due to the few choices there are for iOS devices. Recommendation Metapho is a simple and clean viewer for photo metadata such as date, file name, size, camera model, shutter speed, and location. Homepage Privacy Policy Downloads App Store Command-line \u00b6 ExifTool \u00b6 Recommendation ExifTool is the original perl library and command-line application for reading, writing, and editing meta information ( Exif , IPTC, XMP, and more) in a wide variety of file formats (JPEG, TIFF, PNG, PDF, RAW, and more). It's often a component of other Exif removal applications and is in most Linux distribution repositories. Homepage Downloads Windows macOS Linux Source Source Deleting data from a directory of files exiftool -all = *.file_extension","title":"Metadata Removal Tools"},{"location":"metadata-removal-tools/#desktop","text":"","title":"Desktop"},{"location":"metadata-removal-tools/#mat2","text":"Recommendation MAT2 is free software, which allows the metadata to be removed from image, audio, torrent, and document file types. It provides both a command line tool and a graphical user interface via an extension for Nautilus , the default file manager of GNOME , and Dolphin , the default file manager of KDE . On Linux, a third party graphical tool Metadata Cleaner powered by MAT2 exists and is available on Flathub . Homepage Downloads Windows macOS Linux Web Source","title":"MAT2"},{"location":"metadata-removal-tools/#exifcleaner","text":"Recommendation ExifCleaner is a freeware, open source graphical app that uses ExifTool to remove Exif metadata from images, videos, and PDF documents using a simple drag and drop interface. It supports multi-core batch processing and dark mode. Homepage Downloads Windows macOS Linux Source","title":"ExifCleaner"},{"location":"metadata-removal-tools/#mobile","text":"","title":"Mobile"},{"location":"metadata-removal-tools/#scrambled-exif","text":"Recommendation Scrambled Exif is a metadata removal tool for Android. It can remove Exif data for many file formats and has been translated into many languages. Project Info Downloads Google Play f-droid F-Droid Source","title":"Scrambled Exif"},{"location":"metadata-removal-tools/#imagepipe","text":"Recommendation Imagepipe is a a paint app for Android that can be used to redact photos and also delete Exif metadata. It has been translated into many languages. Project Info Downloads f-droid F-Droid Source Imagepipe is only available from F-Droid and not in Google Play. If you're looking for a paint app in Google Play we suggest Pocket Paint .","title":"Imagepipe"},{"location":"metadata-removal-tools/#metapho","text":"Warning Metapho is closed source. We recommend it, due to the few choices there are for iOS devices. Recommendation Metapho is a simple and clean viewer for photo metadata such as date, file name, size, camera model, shutter speed, and location. Homepage Privacy Policy Downloads App Store","title":"Metapho"},{"location":"metadata-removal-tools/#command-line","text":"","title":"Command-line"},{"location":"metadata-removal-tools/#exiftool","text":"Recommendation ExifTool is the original perl library and command-line application for reading, writing, and editing meta information ( Exif , IPTC, XMP, and more) in a wide variety of file formats (JPEG, TIFF, PNG, PDF, RAW, and more). It's often a component of other Exif removal applications and is in most Linux distribution repositories. Homepage Downloads Windows macOS Linux Source Source Deleting data from a directory of files exiftool -all = *.file_extension","title":"ExifTool"},{"location":"multi-factor-authentication/","text":"Hardware Security Keys \u00b6 YubiKey \u00b6 Recommendation The YubiKeys are among the most popular security keys. Some YubiKey models have a wide range of features such as: Universal 2nd Factor ( U2F ) , FIDO2 and WebAuthn , Yubico OTP , Personal Identity Verification (PIV) , OpenPGP , TOTP and HOTP authentication. One of the benefits of the YubiKey is that one key can do almost everything (YubiKey 5), you could expect from a hardware security key. We do encourage you to take the quiz before purchasing in order to make sure you make the right choice. Website Privacy Policy The comparison table shows the features and how the YubiKeys compare. We highly recommend that you select keys from the YubiKey 5 Series. YubiKeys can be programmed using the YubiKey Manager or YubiKey Personalization Tools . For managing TOTP codes, you can use the Yubico Authenticator . All of Yubico's clients are open source. For models which support HOTP and TOTP , there are 2 slots in the OTP interface which could be used for HOTP and 32 slots to store TOTP secrets. These secrets are stored encrypted on the key and never expose them to the devices they are plugged into. Once a seed (shared secret) is given to the Yubico Authenticator, it will only give out the six-digit codes, but never the seed. This security model helps limit what an attacker can do if they compromise one of the devices running the Yubico Authenticator and make the YubiKey resistant to a physical attacker. Warning The firmware of YubiKeys are not open source and are not updatable. If you want features in newer firmware versions, or if there is a vulnerability in the firmware version you are using, you would need to purchase a new key. Nitrokey / Librem Key \u00b6 Recommendation Nitrokey has a security key capable of FIDO2 and WebAuthn called the Nitrokey FIDO2 . For PGP support, you need to purchase one of their other keys such as the Nitrokey Start , Nitrokey Pro 2 or the Nitrokey Storage 2 . Website Privacy Policy The comparison table shows the features and how the Nitrokey models compare. The Nitrokey 3 listed will have a combined feature set. Nitrokey models can be configured using the Nitrokey app . For the models which support HOTP and TOTP , there are 3 slots for HOTP and 15 for TOTP . Some Nitrokeys can act as a password manager. They can store 16 different credentials and encrypt them using the same password as the OpenPGP interface. Warning While Nitrokeys do not release the HOTP / TOTP secrets to the device they are plugged into, the HOTP and TOTP storage is not encrypted and is vulnerable to physical attacks. Warning Resetting the OpenPGP interface on a Nitrokey will also make the password database inaccessible . The Nitrokey Pro 2, Nitrokey Storage 2, and the upcoming Nitrokey 3 supports system integrity verification for laptops with the Coreboot + Heads firmware. Purism's Librem Key is a rebranded NitroKey Pro 2 with similar firmware and can also be used for the same purposes. The Nitrokey has an open source firmware, unlike the YubiKey. The firmware on modern NitroKey models (except the NitroKey Pro 2 ) is updatable. Tip The Nitrokey app, while compatible with Librem Keys, requires libnitrokey version 3.6 or above to recognize them. Currently, the package is outdated on Windows, macOS, and most Linux distributions' repository, so you will likely have to compile the Nitrokey app yourself to get it working with the Librem Key. On Linux, you can obtain an up-to-date version from Flathub . Authenticator Apps \u00b6 Authenticator Apps implement a security standard adopted by the Internet Engineering Task Force (IETF) called Time-based One-time Passwords , or TOTP . This is a method where websites share a secret with you which is used by your authenticator app to generate a six (usually) digit code based on the current time, which you enter while logging in for the website to check. Typically these codes are regenerated every 30 seconds, and once a new code is generated the old one becomes useless. Even if a hacker gets one six-digit code, there is no way for them to reverse that code to get the original secret, or otherwise be able to predict what any future codes might be. We highly recommend that you use mobile TOTP apps instead of desktop alternatives as Android and IOS have better security and app isolation than most desktop operating systems. Aegis Authenticator \u00b6 Recommendation Aegis Authenticator is a free, secure and open source app to manage your 2-step verification tokens for your online services. Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source Raivo OTP \u00b6 Recommendation Raivo OTP is a native, lightweight and secure time-based ( TOTP ) & counter-based ( HOTP ) password client for iOS. Raivo OTP offers optional iCloud backup & sync. Raivo OTP is also available for macOS in the form of a status bar application, however the Mac app does not work independently of the iOS app. Project Info Privacy Policy Downloads App Store Mac App Store Source","title":"Multi-Factor Authenticators"},{"location":"multi-factor-authentication/#hardware-security-keys","text":"","title":"Hardware Security Keys"},{"location":"multi-factor-authentication/#yubikey","text":"Recommendation The YubiKeys are among the most popular security keys. Some YubiKey models have a wide range of features such as: Universal 2nd Factor ( U2F ) , FIDO2 and WebAuthn , Yubico OTP , Personal Identity Verification (PIV) , OpenPGP , TOTP and HOTP authentication. One of the benefits of the YubiKey is that one key can do almost everything (YubiKey 5), you could expect from a hardware security key. We do encourage you to take the quiz before purchasing in order to make sure you make the right choice. Website Privacy Policy The comparison table shows the features and how the YubiKeys compare. We highly recommend that you select keys from the YubiKey 5 Series. YubiKeys can be programmed using the YubiKey Manager or YubiKey Personalization Tools . For managing TOTP codes, you can use the Yubico Authenticator . All of Yubico's clients are open source. For models which support HOTP and TOTP , there are 2 slots in the OTP interface which could be used for HOTP and 32 slots to store TOTP secrets. These secrets are stored encrypted on the key and never expose them to the devices they are plugged into. Once a seed (shared secret) is given to the Yubico Authenticator, it will only give out the six-digit codes, but never the seed. This security model helps limit what an attacker can do if they compromise one of the devices running the Yubico Authenticator and make the YubiKey resistant to a physical attacker. Warning The firmware of YubiKeys are not open source and are not updatable. If you want features in newer firmware versions, or if there is a vulnerability in the firmware version you are using, you would need to purchase a new key.","title":"YubiKey"},{"location":"multi-factor-authentication/#nitrokey-librem-key","text":"Recommendation Nitrokey has a security key capable of FIDO2 and WebAuthn called the Nitrokey FIDO2 . For PGP support, you need to purchase one of their other keys such as the Nitrokey Start , Nitrokey Pro 2 or the Nitrokey Storage 2 . Website Privacy Policy The comparison table shows the features and how the Nitrokey models compare. The Nitrokey 3 listed will have a combined feature set. Nitrokey models can be configured using the Nitrokey app . For the models which support HOTP and TOTP , there are 3 slots for HOTP and 15 for TOTP . Some Nitrokeys can act as a password manager. They can store 16 different credentials and encrypt them using the same password as the OpenPGP interface. Warning While Nitrokeys do not release the HOTP / TOTP secrets to the device they are plugged into, the HOTP and TOTP storage is not encrypted and is vulnerable to physical attacks. Warning Resetting the OpenPGP interface on a Nitrokey will also make the password database inaccessible . The Nitrokey Pro 2, Nitrokey Storage 2, and the upcoming Nitrokey 3 supports system integrity verification for laptops with the Coreboot + Heads firmware. Purism's Librem Key is a rebranded NitroKey Pro 2 with similar firmware and can also be used for the same purposes. The Nitrokey has an open source firmware, unlike the YubiKey. The firmware on modern NitroKey models (except the NitroKey Pro 2 ) is updatable. Tip The Nitrokey app, while compatible with Librem Keys, requires libnitrokey version 3.6 or above to recognize them. Currently, the package is outdated on Windows, macOS, and most Linux distributions' repository, so you will likely have to compile the Nitrokey app yourself to get it working with the Librem Key. On Linux, you can obtain an up-to-date version from Flathub .","title":"Nitrokey / Librem Key"},{"location":"multi-factor-authentication/#authenticator-apps","text":"Authenticator Apps implement a security standard adopted by the Internet Engineering Task Force (IETF) called Time-based One-time Passwords , or TOTP . This is a method where websites share a secret with you which is used by your authenticator app to generate a six (usually) digit code based on the current time, which you enter while logging in for the website to check. Typically these codes are regenerated every 30 seconds, and once a new code is generated the old one becomes useless. Even if a hacker gets one six-digit code, there is no way for them to reverse that code to get the original secret, or otherwise be able to predict what any future codes might be. We highly recommend that you use mobile TOTP apps instead of desktop alternatives as Android and IOS have better security and app isolation than most desktop operating systems.","title":"Authenticator Apps"},{"location":"multi-factor-authentication/#aegis-authenticator","text":"Recommendation Aegis Authenticator is a free, secure and open source app to manage your 2-step verification tokens for your online services. Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source","title":"Aegis Authenticator"},{"location":"multi-factor-authentication/#raivo-otp","text":"Recommendation Raivo OTP is a native, lightweight and secure time-based ( TOTP ) & counter-based ( HOTP ) password client for iOS. Raivo OTP offers optional iCloud backup & sync. Raivo OTP is also available for macOS in the form of a status bar application, however the Mac app does not work independently of the iOS app. Project Info Privacy Policy Downloads App Store Mac App Store Source","title":"Raivo OTP"},{"location":"news-aggregators/","text":"A news aggregator is a way to keep up with your favourite blogs and news sites. Aggregator clients \u00b6 Fluent Reader \u00b6 Recommendation Fluent Reader is a secure cross-platform news aggregator that has useful privacy features such as deletion of cookies on exit, strict content security policies (CSP) and proxy support, meaning you can use it over Tor . Homepage Privacy Policy Downloads Windows Mac App Store Source GNOME Feeds \u00b6 Recommendation GNOME Feeds is an RSS and Atom news reader for GNOME . It has a simple interface and is quite fast. Homepage Downloads Linux flathub Flatpak Source Akregator \u00b6 Recommendation Akregator is a news feed reader that is a part of the KDE project. It comes with a fast search, advanced archiving functionality and an internal browser for easy news reading. Website Privacy Policy Downloads flathub Flatpak Source Handy News Reader \u00b6 Recommendation Handy News Reader is a fork of Flym that has many features and works well with folders of RSS feeds. It supports RSS , Atom and RDF . Homepage Downloads Google Play f-droid F-Droid Source NetNewsWire \u00b6 Recommendation NetNewsWire a free and open-source feed reader for macOS and iOS with a focus on a native design and feature set. It supports the typical feed formats alongside built-in support for Twitter and Reddit feeds. Homepage Privacy Policy Downloads macOS App Store Source Miniflux \u00b6 Recommendation Miniflux is a web-based news aggregator that you can self-host. It supports RSS , Atom , RDF and JSON Feed . Homepage Downloads Source Newsboat \u00b6 Recommendation Newsboat is an RSS/Atom feed reader for the text console. It's an actively maintained fork of Newsbeuter . It is very lightweight, and ideal for use over Secure Shell . Homepage Downloads Source Social media that supports RSS \u00b6 Some social media services also support RSS although it's not often advertised. YouTube \u00b6 You can subscribe YouTube channels without logging in and associating usage information with your Google Account. Example To subscribe to a YouTube channel with an RSS client, first look for your channel code , replace channel_id below: https://www.youtube.com/feeds/videos.xml?channel_id={{ channel id }} Reddit \u00b6 Reddit also supports subscription via RSS. Example Replace subreddit_name with the subreddit you wish to subscribe to. https://www.reddit.com/r/{{ subreddit_name }}/new/.rss Twitter \u00b6 Using any of the Nitter instances you can easily subscribe using RSS. Example Pick an instance and set nitter_instance . Replace twitter_account with the account name. https://{{ nitter_instance }}/{{ twitter_account }}/rss","title":"News Aggregators"},{"location":"news-aggregators/#aggregator-clients","text":"","title":"Aggregator clients"},{"location":"news-aggregators/#fluent-reader","text":"Recommendation Fluent Reader is a secure cross-platform news aggregator that has useful privacy features such as deletion of cookies on exit, strict content security policies (CSP) and proxy support, meaning you can use it over Tor . Homepage Privacy Policy Downloads Windows Mac App Store Source","title":"Fluent Reader"},{"location":"news-aggregators/#gnome-feeds","text":"Recommendation GNOME Feeds is an RSS and Atom news reader for GNOME . It has a simple interface and is quite fast. Homepage Downloads Linux flathub Flatpak Source","title":"GNOME Feeds"},{"location":"news-aggregators/#akregator","text":"Recommendation Akregator is a news feed reader that is a part of the KDE project. It comes with a fast search, advanced archiving functionality and an internal browser for easy news reading. Website Privacy Policy Downloads flathub Flatpak Source","title":"Akregator"},{"location":"news-aggregators/#handy-news-reader","text":"Recommendation Handy News Reader is a fork of Flym that has many features and works well with folders of RSS feeds. It supports RSS , Atom and RDF . Homepage Downloads Google Play f-droid F-Droid Source","title":"Handy News Reader"},{"location":"news-aggregators/#netnewswire","text":"Recommendation NetNewsWire a free and open-source feed reader for macOS and iOS with a focus on a native design and feature set. It supports the typical feed formats alongside built-in support for Twitter and Reddit feeds. Homepage Privacy Policy Downloads macOS App Store Source","title":"NetNewsWire"},{"location":"news-aggregators/#miniflux","text":"Recommendation Miniflux is a web-based news aggregator that you can self-host. It supports RSS , Atom , RDF and JSON Feed . Homepage Downloads Source","title":"Miniflux"},{"location":"news-aggregators/#newsboat","text":"Recommendation Newsboat is an RSS/Atom feed reader for the text console. It's an actively maintained fork of Newsbeuter . It is very lightweight, and ideal for use over Secure Shell . Homepage Downloads Source","title":"Newsboat"},{"location":"news-aggregators/#social-media-that-supports-rss","text":"Some social media services also support RSS although it's not often advertised.","title":"Social media that supports RSS"},{"location":"news-aggregators/#youtube","text":"You can subscribe YouTube channels without logging in and associating usage information with your Google Account. Example To subscribe to a YouTube channel with an RSS client, first look for your channel code , replace channel_id below: https://www.youtube.com/feeds/videos.xml?channel_id={{ channel id }}","title":"YouTube"},{"location":"news-aggregators/#reddit","text":"Reddit also supports subscription via RSS. Example Replace subreddit_name with the subreddit you wish to subscribe to. https://www.reddit.com/r/{{ subreddit_name }}/new/.rss","title":"Reddit"},{"location":"news-aggregators/#twitter","text":"Using any of the Nitter instances you can easily subscribe using RSS. Example Pick an instance and set nitter_instance . Replace twitter_account with the account name. https://{{ nitter_instance }}/{{ twitter_account }}/rss","title":"Twitter"},{"location":"notebooks/","text":"Keep track of your notes and journalings without giving them to a third party. If you are currently using an application like Evernote, Google Keep, or Microsoft OneNote, we suggest you pick an alternative here that supports E2EE . Cloud based \u00b6 Joplin \u00b6 Recommendation Joplin is a free, open-source, and fully-featured note-taking and to-do application which can handle a large number of markdown notes organized into notebooks and tags. It offers E2EE and can sync through Nextcloud, Dropbox, and more. It also offers easy import from Evernote and plain-text notes. Website Privacy Policy Downloads Windows macOS Linux Firefox Chrome App Store Google Play f-droid F-Droid Source Joplin does not support password/pin protection for the application itself or individual notes/notebooks . Data is still encrypted in transit and at the sync location using your master key. Standard Notes \u00b6 Recommendation Standard Notes is a simple and private notes app that makes your notes easy and available everywhere you are. It features E2EE on every platform, and a powerful desktop experience with themes and custom editors. It has also been independently audited (PDF) . Website Downloads Windows macOS Linux App Store Google Play f-droid F-Droid Browser Source EteSync Notes \u00b6 Recommendation EteSync Notes is a secure, end-to-end encrypted, and privacy-respecting note taking app. EteSync also offers optional software as a service for $24 per year , or you can host the server yourself for free. etebase , which is the foundation of EteSync, can also be used by other apps as a backend to store data end-to-end encrypted ( E2EE ). Website Privacy Policy Downloads Google Play f-droid F-Droid App Store Browser Source Local notebooks \u00b6 Org-mode \u00b6 Recommendation Org-mode is a major mode for GNU Emacs. Org-mode is for keeping notes, maintaining TODO lists, planning projects, and authoring documents with a fast and effective plain-text system. Synchronization is possible with file synchronization tools. Homepage Downloads Source","title":"Notebooks"},{"location":"notebooks/#cloud-based","text":"","title":"Cloud based"},{"location":"notebooks/#joplin","text":"Recommendation Joplin is a free, open-source, and fully-featured note-taking and to-do application which can handle a large number of markdown notes organized into notebooks and tags. It offers E2EE and can sync through Nextcloud, Dropbox, and more. It also offers easy import from Evernote and plain-text notes. Website Privacy Policy Downloads Windows macOS Linux Firefox Chrome App Store Google Play f-droid F-Droid Source Joplin does not support password/pin protection for the application itself or individual notes/notebooks . Data is still encrypted in transit and at the sync location using your master key.","title":"Joplin"},{"location":"notebooks/#standard-notes","text":"Recommendation Standard Notes is a simple and private notes app that makes your notes easy and available everywhere you are. It features E2EE on every platform, and a powerful desktop experience with themes and custom editors. It has also been independently audited (PDF) . Website Downloads Windows macOS Linux App Store Google Play f-droid F-Droid Browser Source","title":"Standard Notes"},{"location":"notebooks/#etesync-notes","text":"Recommendation EteSync Notes is a secure, end-to-end encrypted, and privacy-respecting note taking app. EteSync also offers optional software as a service for $24 per year , or you can host the server yourself for free. etebase , which is the foundation of EteSync, can also be used by other apps as a backend to store data end-to-end encrypted ( E2EE ). Website Privacy Policy Downloads Google Play f-droid F-Droid App Store Browser Source","title":"EteSync Notes"},{"location":"notebooks/#local-notebooks","text":"","title":"Local notebooks"},{"location":"notebooks/#org-mode","text":"Recommendation Org-mode is a major mode for GNU Emacs. Org-mode is for keeping notes, maintaining TODO lists, planning projects, and authoring documents with a fast and effective plain-text system. Synchronization is possible with file synchronization tools. Homepage Downloads Source","title":"Org-mode"},{"location":"passwords/","text":"Stay safe and secure online with an encrypted and open-source password manager. Password Best Practices \u00b6 Always use unique passwords. Don't make yourself a victim of \" credential stuffing \". Store an exported backup of your passwords in an encrypted container on another storage device. This can be useful if something happens to your device or the service you are using. If possible, store TOTP tokens in a separate TOTP app and not your password manager. TOTP codes are generated from a \" shared secret \". If the secret is obtained by an adversary they can generate TOTP values. Typically, mobile platforms have better app isolation and more secure methods for storing sensitive credentials. Local Password Managers \u00b6 These password managers store the password database locally. KeePassXC \u00b6 Recommendation KeePassXC is a community fork of KeePassX, a native cross-platform port of KeePass Password Safe, with the goal to extend and improve it with new features and bugfixes to provide a feature-rich, fully cross-platform and modern open-source password manager. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Firefox Chrome Source KeePassXC stores its export data as CSV files. This may mean data loss if you import this file into another password manager. We advise you check each record manually. KeePassDX \u00b6 Recommendation KeePassDX is a lightweight password manager for Android, allows editing encrypted data in a single file in KeePass format and can fill in the forms in a secure way. Contributor Pro allows unlocking cosmetic content and non-standard protocol features, but more importantly, it helps and encourages development. For more details, we recommend looking at their FAQ . Homepage Downloads Google Play f-droid F-Droid Source Cloud Syncing Password Managers \u00b6 These password managers sync up to a cloud server that may be self-hostable. Bitwarden \u00b6 Recommendation Bitwarden is a free and open-source password manager. It aims to solve password management problems for individuals, teams, and business organizations. Bitwarden is among the easiest and safest solutions to store all of your logins and passwords while conveniently keeping them synced between all of your devices. If you don't want to use the Bitwarden cloud, you can easily host your own Bitwarden server. Website Privacy Policy Downloads Windows Mac App Store Linux flathub Flatpak App Store Google Play f-droid F-Droid Firefox Chrome Edge Source Psono \u00b6 Recommendation Psono is a free and open source password manager from Germany, with a focus on password management for teams. It can be self-hosted . Psono supports secure sharing of passwords, files, bookmarks, and emails. All secrets are protected by a master password. Website Privacy Policy Downloads Firefox Chrome Google Play App Store Dockerhub Source Password Management Servers \u00b6 These products are self-hostable synchronization for cloud based password managers. Vaultwarden \u00b6 Recommendation Vaultwarden is an alternative implementation of the Bitwarden server API written in Rust and compatible with upstream Bitwarden clients, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal. Project Info Downloads Dockerhub Source Psono Server \u00b6 Recommendation Psono provides extensive documentation for their product. The web-client for Psono can be self hosted; alternatively, you can choose the the full Community Edition or the Enterprise Edition with additional features. Source Code Privacy Policy Downloads Dockerhub Source Minimal Password Managers \u00b6 These products are minimal password managers that can be used within scripting applications. gopass \u00b6 Recommendation gopass is a password manager for the command line written in Go. It works on all major desktop and server operating systems (Linux, macOS, BSD, Windows). Homepage Downloads Windows macOS Linux FreeBSD Source","title":"Password Managers"},{"location":"passwords/#password-best-practices","text":"Always use unique passwords. Don't make yourself a victim of \" credential stuffing \". Store an exported backup of your passwords in an encrypted container on another storage device. This can be useful if something happens to your device or the service you are using. If possible, store TOTP tokens in a separate TOTP app and not your password manager. TOTP codes are generated from a \" shared secret \". If the secret is obtained by an adversary they can generate TOTP values. Typically, mobile platforms have better app isolation and more secure methods for storing sensitive credentials.","title":"Password Best Practices"},{"location":"passwords/#local-password-managers","text":"These password managers store the password database locally.","title":"Local Password Managers"},{"location":"passwords/#keepassxc","text":"Recommendation KeePassXC is a community fork of KeePassX, a native cross-platform port of KeePass Password Safe, with the goal to extend and improve it with new features and bugfixes to provide a feature-rich, fully cross-platform and modern open-source password manager. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Firefox Chrome Source KeePassXC stores its export data as CSV files. This may mean data loss if you import this file into another password manager. We advise you check each record manually.","title":"KeePassXC"},{"location":"passwords/#keepassdx","text":"Recommendation KeePassDX is a lightweight password manager for Android, allows editing encrypted data in a single file in KeePass format and can fill in the forms in a secure way. Contributor Pro allows unlocking cosmetic content and non-standard protocol features, but more importantly, it helps and encourages development. For more details, we recommend looking at their FAQ . Homepage Downloads Google Play f-droid F-Droid Source","title":"KeePassDX"},{"location":"passwords/#cloud-syncing-password-managers","text":"These password managers sync up to a cloud server that may be self-hostable.","title":"Cloud Syncing Password Managers"},{"location":"passwords/#bitwarden","text":"Recommendation Bitwarden is a free and open-source password manager. It aims to solve password management problems for individuals, teams, and business organizations. Bitwarden is among the easiest and safest solutions to store all of your logins and passwords while conveniently keeping them synced between all of your devices. If you don't want to use the Bitwarden cloud, you can easily host your own Bitwarden server. Website Privacy Policy Downloads Windows Mac App Store Linux flathub Flatpak App Store Google Play f-droid F-Droid Firefox Chrome Edge Source","title":"Bitwarden"},{"location":"passwords/#psono","text":"Recommendation Psono is a free and open source password manager from Germany, with a focus on password management for teams. It can be self-hosted . Psono supports secure sharing of passwords, files, bookmarks, and emails. All secrets are protected by a master password. Website Privacy Policy Downloads Firefox Chrome Google Play App Store Dockerhub Source","title":"Psono"},{"location":"passwords/#password-management-servers","text":"These products are self-hostable synchronization for cloud based password managers.","title":"Password Management Servers"},{"location":"passwords/#vaultwarden","text":"Recommendation Vaultwarden is an alternative implementation of the Bitwarden server API written in Rust and compatible with upstream Bitwarden clients, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal. Project Info Downloads Dockerhub Source","title":"Vaultwarden"},{"location":"passwords/#psono-server","text":"Recommendation Psono provides extensive documentation for their product. The web-client for Psono can be self hosted; alternatively, you can choose the the full Community Edition or the Enterprise Edition with additional features. Source Code Privacy Policy Downloads Dockerhub Source","title":"Psono Server"},{"location":"passwords/#minimal-password-managers","text":"These products are minimal password managers that can be used within scripting applications.","title":"Minimal Password Managers"},{"location":"passwords/#gopass","text":"Recommendation gopass is a password manager for the command line written in Go. It works on all major desktop and server operating systems (Linux, macOS, BSD, Windows). Homepage Downloads Windows macOS Linux FreeBSD Source","title":"gopass"},{"location":"productivity/","text":"Get working and collaborating without sharing your documents with a middleman or trusting a cloud provider. Office Suites \u00b6 LibreOffice \u00b6 Recommendation LibreOffice is a free and open-source office suite with extensive functionality. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak FreeBSD openbsd OpenBSD netbsd NetBSD Google Play App Store Source OnlyOffice \u00b6 Recommendation OnlyOffice is a cloud-based free and open-source office suite with extensive functionality, including integration with Nextcloud. Homepage Privacy Policy Downloads Windows macOS Linux FreeBSD Google Play App Store Source Planning \u00b6 Framadate \u00b6 Recommendation Framadate is a free and open-source online service for planning an appointment or making a decision quickly and easily. No registration is required. Homepage Downloads Source Paste services \u00b6 PrivateBin \u00b6 Recommendation PrivateBin is a minimalist, open-source online pastebin where the server has zero knowledge of pasted data. Data is encrypted/decrypted in the browser using 256-bit AES. It is the improved version of ZeroBin. There is a list of instances . Website Downloads Source Warning PrivateBin uses JavaScript to handle encryption, so you must trust the provider to the extent that they do not inject any malicious JavaScript to get your private key. Consider self-hosting to mitigate this threat. CryptPad \u00b6 Recommendation CryptPad is a private-by-design alternative to popular office tools. All content is end-to-end encrypted. Website Privacy Policy Downloads Source Warning CryptPad uses JavaScript to handle encryption, so you must trust the provider to the extent that they do not inject any malicious JavaScript to get your private key. Consider self-hosting to mitigate this threat. Blogging \u00b6 Write.as \u00b6 Recommendation Write.as is a cross-platform, privacy-oriented blogging platform. It's anonymous by default, letting you publish without signing up. If you create an account, it doesn't require any personal information. No ads, distraction-free, and built on a sustainable business model. Website tor Privacy Policy Downloads Windows macOS Linux FreeBSD Google Play App Store Source Programming \u00b6 VSCodium \u00b6 Recommendation VSCodium is a free and open-source project featuring binaries of Visual Studio Code without Microsoft's branding/telemetry/licensing. Homepage Downloads Windows macOS Linux Source","title":"Productivity Tools"},{"location":"productivity/#office-suites","text":"","title":"Office Suites"},{"location":"productivity/#libreoffice","text":"Recommendation LibreOffice is a free and open-source office suite with extensive functionality. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak FreeBSD openbsd OpenBSD netbsd NetBSD Google Play App Store Source","title":"LibreOffice"},{"location":"productivity/#onlyoffice","text":"Recommendation OnlyOffice is a cloud-based free and open-source office suite with extensive functionality, including integration with Nextcloud. Homepage Privacy Policy Downloads Windows macOS Linux FreeBSD Google Play App Store Source","title":"OnlyOffice"},{"location":"productivity/#planning","text":"","title":"Planning"},{"location":"productivity/#framadate","text":"Recommendation Framadate is a free and open-source online service for planning an appointment or making a decision quickly and easily. No registration is required. Homepage Downloads Source","title":"Framadate"},{"location":"productivity/#paste-services","text":"","title":"Paste services"},{"location":"productivity/#privatebin","text":"Recommendation PrivateBin is a minimalist, open-source online pastebin where the server has zero knowledge of pasted data. Data is encrypted/decrypted in the browser using 256-bit AES. It is the improved version of ZeroBin. There is a list of instances . Website Downloads Source Warning PrivateBin uses JavaScript to handle encryption, so you must trust the provider to the extent that they do not inject any malicious JavaScript to get your private key. Consider self-hosting to mitigate this threat.","title":"PrivateBin"},{"location":"productivity/#cryptpad","text":"Recommendation CryptPad is a private-by-design alternative to popular office tools. All content is end-to-end encrypted. Website Privacy Policy Downloads Source Warning CryptPad uses JavaScript to handle encryption, so you must trust the provider to the extent that they do not inject any malicious JavaScript to get your private key. Consider self-hosting to mitigate this threat.","title":"CryptPad"},{"location":"productivity/#blogging","text":"","title":"Blogging"},{"location":"productivity/#writeas","text":"Recommendation Write.as is a cross-platform, privacy-oriented blogging platform. It's anonymous by default, letting you publish without signing up. If you create an account, it doesn't require any personal information. No ads, distraction-free, and built on a sustainable business model. Website tor Privacy Policy Downloads Windows macOS Linux FreeBSD Google Play App Store Source","title":"Write.as"},{"location":"productivity/#programming","text":"","title":"Programming"},{"location":"productivity/#vscodium","text":"Recommendation VSCodium is a free and open-source project featuring binaries of Visual Studio Code without Microsoft's branding/telemetry/licensing. Homepage Downloads Windows macOS Linux Source","title":"VSCodium"},{"location":"qubes/","text":"Recommendation Qubes is an open-source operating system designed to provide strong security for desktop computing. Qubes is based on Xen, the X Window System, and Linux, and can run most Linux applications and utilize most of the Linux drivers. Homepage tor Privacy Policy Downloads Disc image Source","title":"Qubes OS"},{"location":"real-time-communication/","text":"Encrypted Instant Messengers \u00b6 Signal \u00b6 Recommendation Signal is a mobile app developed by Signal Messenger LLC. The app provides instant messaging, as well as voice and video calling. All communications are E2EE . Contact lists are encrypted using your login PIN and the server does not have access to them. Personal profiles are also encrypted and only shared with contacts who add you. Homepage Privacy Policy Downloads Windows macOS Linux Google Play App Store Source Signal has minimal metadata when Sealed Sender is enabled. The sender address is encrypted along with the message body, and only the recipient address is visible to the server. Signal requires your phone number as a personal identifier. Sealed Sender is only enabled for people in your contacts list, but can be enabled for all recipients with the increased risk of receiving spam. The protocol was independently audited in 2016. The specification for the Signal protocol can be found in their documentation . Element \u00b6 Recommendation Element is the reference client for the Matrix protocol, an open standard for secure decentralized real-time communication. Messages and files shared in private rooms (those which require an invite) are by default E2EE as are 1 to 1 voice and video calls. Website Privacy Policy Downloads Windows macOS Linux Browser Google Play f-droid F-Droid App Store Source Profile pictures, reactions, and nicknames are not encrypted. Group voice and video calls are not E2EE , and use Jitsi, but this is expected to change with Native Group VoIP Signalling . Group calls have no authentication currently, meaning that non room participants can also join the calls. We recommend that you do not use this feature for private meetings. When using element-web , you must trust the server hosting the Element client. If your threat model requires stronger protection, then use a desktop or mobile client instead. The protocol was independently audited in 2016. The specification for the Matrix protocol can be found in their documentation . The Olm cryptographic ratchet used by Matrix is an implementation of Signal\u2019s Double Ratchet algorithm . Briar \u00b6 Recommendation Briar is an encrypted instant messenger that connects to other clients using the Tor Network. Briar can also connect via Wi-Fi or Bluetooth when in local proximity. Briar\u2019s local mesh mode can be useful when internet availability is a problem. Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source To add a contact on Briar, you must both add each other first. You can either exchange briar:// links or scan a contact\u2019s QR code if they are nearby. The client software was independently audited and the anonymous routing protocol uses the Tor network which has also been audited. Briar has a fully published specification . Briar supports perfect forward secrecy by using the Bramble Handshake and Transport protocol. Session \u00b6 Recommendation Session is a decentralized messenger with a focus on private, secure, and anonymous communications. Session offers support for direct messages, group chats, and voice calls. Session utilizes the decentralized Oxen Service Node Network to store and route messages. Every encrypted message is routed through three nodes in the Oxen Service Node Network, making it virtually impossible for the nodes to compile meaningful information on those using the network. Homepage Privacy Policy Downloads Windows macOS App Store Linux Google Play f-droid F-Droid Source Session allows for E2EE in one-on-one chats or closed groups which allow for up to 100 members. Open groups have no restriction on the number of members, but are open by design. Session does not support perfect forward secrecy, which is when an encryption system automatically and frequently changes the keys it uses to encrypt and decrypt information, such that if the latest key is compromised it exposes a smaller portion of sensitive information. Oxen requested an independent audit for Session in March of 2020. The audit concluded in April of 2021, \u201cThe overall security level of this application is good and makes it usable for privacy-concerned people.\u201d Session has a whitepaper describing the technicals of the app and protocol. Types of Communication Networks \u00b6 There are several network architectures commonly used to relay messages between people. These networks can provide different different privacy guarantees, which is why it's worth considering your threat model when making a decision about which app to use. Centralized Networks \u00b6 Centralized messengers are those where all participants are on the same server or network of servers controlled by the same organization. Some self-hosted messengers allow you to set up your own server. Self-hosting can provide additional privacy guarantees such as no usage logs or limited access to metadata (data about who is talking to whom). Self-hosted centralized messengers are isolated and everyone must be on the same server to communicate. Advantages: New features and changes can be implemented more quickly. Easier to get started with and to find contacts. Most mature and stable features ecosystems, as they are easier to program in a centralized software. Privacy issues may be reduced when you trust a server that you're self-hosting. Disadvantages: Can include restricted control or access . This can include things like: Being forbidden from connecting third-party clients to the centralized network that might provide for greater customization or a better experience. Often defined in Terms and Conditions of usage. Poor or no documentation for third-party developers. The ownership , privacy policy, and operations of the service can change easily when a single entity controls it, potentially compromising the service later on. Self hosting requires effort and knowledge of how to set up a service. Federated Networks \u00b6 Federated messengers use multiple, independent, decentralized servers that are able to talk to each other (email is one example of a federated service). Federation allows system administrators to control their own server and still be a part of the larger communications network. When self-hosted, members of a federated server can discover and communicate with members of other servers, although some servers may choose to remain private by being non-federated (e.g., work team server). Advantages: Allows for greater control over your own data when running your own server. Allows you to choose who to trust your data with by choosing between multiple \"public\" servers. Often allows for third party clients which can provide a more native, customized, or accessible experience. Server software can be verified that it matches public source code, assuming you have access to the server or you trust the person who does (e.g., a family member) Disadvantages: Adding new features is more complex, because these features need to be standardized and tested to ensure they work with all servers on the network. Due to the previous point, features can be lacking, or incomplete or working in unexpected ways compared to centralized platforms, such as message relay when offline or message deletion. Some metadata may be available (e.g., information like \"who is talking to whom,\" but not actual message content if E2EE is used). Federated servers generally require trusting your server's administrator. They may be a hobbyist or otherwise not a \"security professional,\" and may not serve standard documents like a privacy policy or terms of service detailing how your data is utilized. Server administrators sometimes choose to block other servers, which are a source of unmoderated abuse or break general rules of accepted behavior. This will hinder your ability to communicate with members of those servers. Peer-to-Peer Networks \u00b6 P2P messengers connect to a distributed network of nodes to relay a message to the recepient without a third-party server. Clients (peers) usually find each other through the use of a distributed computing network. Examples of this include Distributed Hash Tables (DHT), used by torrents and IPFS for example. Another approach is proximity based networks, where a connection is established over WiFi or Bluetooth (for example, Briar or the Scuttlebutt social network protocol). Once a peer has found a route to its contact via any of these methods, a direct connection between them is made. Although messages are usually encrypted, an observer can still deduce the location and identity of the sender and recipient. P2P networks do not use servers, as peers communicate directly between each other, and hence cannot be self-hosted. However, some additional services may rely on centralized servers, such as user discovery or relaying offline messages, which can benefit from self-hosting. Advantages: Minimal information is exposed to third parties. Modern P2P platforms implement E2EE by default. There are no servers that could potentially intercept and decrypt your transmissions, unlike centralized and federated models. Disadvantages: Reduced feature set: Messages can only be sent when both peers are online, however, your client may store messages locally to wait for the contact to return online. Generally increases battery usage on mobile devices, because the client must stay connected to the distributed network to learn about who is online. Some common messenger features may not be implemented or incompletely, such as message deletion. Your IP address and that of the contacts you're communicating with may be exposed if you do not use the software in conjunction with a VPN or self contained network , such as Tor or I2P . Many countries have some form of mass surveillance and/or metadata retention. Anonymous Routing \u00b6 A messenger using anonymous routing hides either the identity of the sender, the receiver, or evidence that they have been communicating. Ideally, a messenger should hide all three. There are many different ways to implement anonymous routing. One of the most famous is onion routing (i.e. Tor ), which communicates encrypted messages through a virtual overlay network that hides the location of each node as well as the recipient and sender of each message. The sender and recipient never interact directly, and only meet through a secret rendezvous node, so that there is no leak of IP addresses nor physical location. Nodes cannot decrypt messages nor the final destination, only the recipient can. Each intermediary node can only decrypt a part that indicates where to send the still encrypted message next, until it arrives at the recipient who can fully decrypt it, hence the \"onion layers\". Self-hosting a node in an anonymous routing network does not provide the hoster with additional privacy benefits, but rather contributes to the whole network's resilience against identification attacks for everyone's benefit. Advantages: Minimal to no information is exposed to other parties. Messages can be relayed in a decentralized manner even if one of the parties is offline. Disadvantages: Slow message propagation. Often limited to fewer media types, mostly text since the network is slow. Less reliable if nodes are selected by randomized routing, some nodes may be very far from the sender and receiver, adding latency or even failing to transmit messages if one of the nodes goes offline. More complex to get started as the creation and secured backup of a cryptographic private key is required. Just like other decentralized platforms, adding features is more complex for developers than on a centralized platform, hence features may be lacking or incompletely implemented, such as offline message relaying or message deletion.","title":"Real-Time Communication"},{"location":"real-time-communication/#encrypted-instant-messengers","text":"","title":"Encrypted Instant Messengers"},{"location":"real-time-communication/#signal","text":"Recommendation Signal is a mobile app developed by Signal Messenger LLC. The app provides instant messaging, as well as voice and video calling. All communications are E2EE . Contact lists are encrypted using your login PIN and the server does not have access to them. Personal profiles are also encrypted and only shared with contacts who add you. Homepage Privacy Policy Downloads Windows macOS Linux Google Play App Store Source Signal has minimal metadata when Sealed Sender is enabled. The sender address is encrypted along with the message body, and only the recipient address is visible to the server. Signal requires your phone number as a personal identifier. Sealed Sender is only enabled for people in your contacts list, but can be enabled for all recipients with the increased risk of receiving spam. The protocol was independently audited in 2016. The specification for the Signal protocol can be found in their documentation .","title":"Signal"},{"location":"real-time-communication/#element","text":"Recommendation Element is the reference client for the Matrix protocol, an open standard for secure decentralized real-time communication. Messages and files shared in private rooms (those which require an invite) are by default E2EE as are 1 to 1 voice and video calls. Website Privacy Policy Downloads Windows macOS Linux Browser Google Play f-droid F-Droid App Store Source Profile pictures, reactions, and nicknames are not encrypted. Group voice and video calls are not E2EE , and use Jitsi, but this is expected to change with Native Group VoIP Signalling . Group calls have no authentication currently, meaning that non room participants can also join the calls. We recommend that you do not use this feature for private meetings. When using element-web , you must trust the server hosting the Element client. If your threat model requires stronger protection, then use a desktop or mobile client instead. The protocol was independently audited in 2016. The specification for the Matrix protocol can be found in their documentation . The Olm cryptographic ratchet used by Matrix is an implementation of Signal\u2019s Double Ratchet algorithm .","title":"Element"},{"location":"real-time-communication/#briar","text":"Recommendation Briar is an encrypted instant messenger that connects to other clients using the Tor Network. Briar can also connect via Wi-Fi or Bluetooth when in local proximity. Briar\u2019s local mesh mode can be useful when internet availability is a problem. Homepage Privacy Policy Downloads Google Play f-droid F-Droid Source To add a contact on Briar, you must both add each other first. You can either exchange briar:// links or scan a contact\u2019s QR code if they are nearby. The client software was independently audited and the anonymous routing protocol uses the Tor network which has also been audited. Briar has a fully published specification . Briar supports perfect forward secrecy by using the Bramble Handshake and Transport protocol.","title":"Briar"},{"location":"real-time-communication/#session","text":"Recommendation Session is a decentralized messenger with a focus on private, secure, and anonymous communications. Session offers support for direct messages, group chats, and voice calls. Session utilizes the decentralized Oxen Service Node Network to store and route messages. Every encrypted message is routed through three nodes in the Oxen Service Node Network, making it virtually impossible for the nodes to compile meaningful information on those using the network. Homepage Privacy Policy Downloads Windows macOS App Store Linux Google Play f-droid F-Droid Source Session allows for E2EE in one-on-one chats or closed groups which allow for up to 100 members. Open groups have no restriction on the number of members, but are open by design. Session does not support perfect forward secrecy, which is when an encryption system automatically and frequently changes the keys it uses to encrypt and decrypt information, such that if the latest key is compromised it exposes a smaller portion of sensitive information. Oxen requested an independent audit for Session in March of 2020. The audit concluded in April of 2021, \u201cThe overall security level of this application is good and makes it usable for privacy-concerned people.\u201d Session has a whitepaper describing the technicals of the app and protocol.","title":"Session"},{"location":"real-time-communication/#types-of-communication-networks","text":"There are several network architectures commonly used to relay messages between people. These networks can provide different different privacy guarantees, which is why it's worth considering your threat model when making a decision about which app to use.","title":"Types of Communication Networks"},{"location":"real-time-communication/#centralized-networks","text":"Centralized messengers are those where all participants are on the same server or network of servers controlled by the same organization. Some self-hosted messengers allow you to set up your own server. Self-hosting can provide additional privacy guarantees such as no usage logs or limited access to metadata (data about who is talking to whom). Self-hosted centralized messengers are isolated and everyone must be on the same server to communicate. Advantages: New features and changes can be implemented more quickly. Easier to get started with and to find contacts. Most mature and stable features ecosystems, as they are easier to program in a centralized software. Privacy issues may be reduced when you trust a server that you're self-hosting. Disadvantages: Can include restricted control or access . This can include things like: Being forbidden from connecting third-party clients to the centralized network that might provide for greater customization or a better experience. Often defined in Terms and Conditions of usage. Poor or no documentation for third-party developers. The ownership , privacy policy, and operations of the service can change easily when a single entity controls it, potentially compromising the service later on. Self hosting requires effort and knowledge of how to set up a service.","title":"Centralized Networks"},{"location":"real-time-communication/#federated-networks","text":"Federated messengers use multiple, independent, decentralized servers that are able to talk to each other (email is one example of a federated service). Federation allows system administrators to control their own server and still be a part of the larger communications network. When self-hosted, members of a federated server can discover and communicate with members of other servers, although some servers may choose to remain private by being non-federated (e.g., work team server). Advantages: Allows for greater control over your own data when running your own server. Allows you to choose who to trust your data with by choosing between multiple \"public\" servers. Often allows for third party clients which can provide a more native, customized, or accessible experience. Server software can be verified that it matches public source code, assuming you have access to the server or you trust the person who does (e.g., a family member) Disadvantages: Adding new features is more complex, because these features need to be standardized and tested to ensure they work with all servers on the network. Due to the previous point, features can be lacking, or incomplete or working in unexpected ways compared to centralized platforms, such as message relay when offline or message deletion. Some metadata may be available (e.g., information like \"who is talking to whom,\" but not actual message content if E2EE is used). Federated servers generally require trusting your server's administrator. They may be a hobbyist or otherwise not a \"security professional,\" and may not serve standard documents like a privacy policy or terms of service detailing how your data is utilized. Server administrators sometimes choose to block other servers, which are a source of unmoderated abuse or break general rules of accepted behavior. This will hinder your ability to communicate with members of those servers.","title":"Federated Networks"},{"location":"real-time-communication/#peer-to-peer-networks","text":"P2P messengers connect to a distributed network of nodes to relay a message to the recepient without a third-party server. Clients (peers) usually find each other through the use of a distributed computing network. Examples of this include Distributed Hash Tables (DHT), used by torrents and IPFS for example. Another approach is proximity based networks, where a connection is established over WiFi or Bluetooth (for example, Briar or the Scuttlebutt social network protocol). Once a peer has found a route to its contact via any of these methods, a direct connection between them is made. Although messages are usually encrypted, an observer can still deduce the location and identity of the sender and recipient. P2P networks do not use servers, as peers communicate directly between each other, and hence cannot be self-hosted. However, some additional services may rely on centralized servers, such as user discovery or relaying offline messages, which can benefit from self-hosting. Advantages: Minimal information is exposed to third parties. Modern P2P platforms implement E2EE by default. There are no servers that could potentially intercept and decrypt your transmissions, unlike centralized and federated models. Disadvantages: Reduced feature set: Messages can only be sent when both peers are online, however, your client may store messages locally to wait for the contact to return online. Generally increases battery usage on mobile devices, because the client must stay connected to the distributed network to learn about who is online. Some common messenger features may not be implemented or incompletely, such as message deletion. Your IP address and that of the contacts you're communicating with may be exposed if you do not use the software in conjunction with a VPN or self contained network , such as Tor or I2P . Many countries have some form of mass surveillance and/or metadata retention.","title":"Peer-to-Peer Networks"},{"location":"real-time-communication/#anonymous-routing","text":"A messenger using anonymous routing hides either the identity of the sender, the receiver, or evidence that they have been communicating. Ideally, a messenger should hide all three. There are many different ways to implement anonymous routing. One of the most famous is onion routing (i.e. Tor ), which communicates encrypted messages through a virtual overlay network that hides the location of each node as well as the recipient and sender of each message. The sender and recipient never interact directly, and only meet through a secret rendezvous node, so that there is no leak of IP addresses nor physical location. Nodes cannot decrypt messages nor the final destination, only the recipient can. Each intermediary node can only decrypt a part that indicates where to send the still encrypted message next, until it arrives at the recipient who can fully decrypt it, hence the \"onion layers\". Self-hosting a node in an anonymous routing network does not provide the hoster with additional privacy benefits, but rather contributes to the whole network's resilience against identification attacks for everyone's benefit. Advantages: Minimal to no information is exposed to other parties. Messages can be relayed in a decentralized manner even if one of the parties is offline. Disadvantages: Slow message propagation. Often limited to fewer media types, mostly text since the network is slow. Less reliable if nodes are selected by randomized routing, some nodes may be very far from the sender and receiver, adding latency or even failing to transmit messages if one of the nodes goes offline. More complex to get started as the creation and secured backup of a cryptographic private key is required. Just like other decentralized platforms, adding features is more complex for developers than on a centralized platform, hence features may be lacking or incompletely implemented, such as offline message relaying or message deletion.","title":"Anonymous Routing"},{"location":"router/","text":"Below are a few alternative operating systems, that can be used on routers, Wi-Fi access points etc. OpenWrt \u00b6 Recommendation OpenWrt is an operating system (in particular, an embedded operating system) based on the Linux kernel, primarily used on embedded devices to route network traffic. The main components are the Linux kernel, util-linux, uClibc, and BusyBox. All components have been optimized for size, to be small enough for fitting into the limited storage and memory available in home routers. Homepage Downloads Source You can consult OpenWrt's table of hardware to check if your device is supported. pfSense \u00b6 Recommendation pfSense is an open source firewall/router computer software distribution based on FreeBSD. It is installed on a computer to make a dedicated firewall/router for a network and is noted for its reliability and offering features often only found in expensive commercial firewalls. pfSense is commonly deployed as a perimeter firewall, router, wireless access point, DHCP server, DNS server, and VPN endpoint. Homepage Privacy Policy Downloads Source","title":"Router Firmware"},{"location":"router/#openwrt","text":"Recommendation OpenWrt is an operating system (in particular, an embedded operating system) based on the Linux kernel, primarily used on embedded devices to route network traffic. The main components are the Linux kernel, util-linux, uClibc, and BusyBox. All components have been optimized for size, to be small enough for fitting into the limited storage and memory available in home routers. Homepage Downloads Source You can consult OpenWrt's table of hardware to check if your device is supported.","title":"OpenWrt"},{"location":"router/#pfsense","text":"Recommendation pfSense is an open source firewall/router computer software distribution based on FreeBSD. It is installed on a computer to make a dedicated firewall/router for a network and is noted for its reliability and offering features often only found in expensive commercial firewalls. pfSense is commonly deployed as a perimeter firewall, router, wireless access point, DHCP server, DNS server, and VPN endpoint. Homepage Privacy Policy Downloads Source","title":"pfSense"},{"location":"search-engines/","text":"Use a search engine that doesn't build an advertising profile based on your searches. The recommendations here are based on the merits of each service's privacy policy. There is no guarantee that these privacy policies are honored. Consider using a VPN or Tor if your threat model requires hiding your IP address from the search provider. DuckDuckGo \u00b6 Recommendation DuckDuckGo is one of the more mainstream private search engine options. Notable DuckDuckGo search features include bangs and many instant answers . The search engine relies on a commercial Bing API to serve most results, but it does use numerous other sources for instant answers and other non-primary results. While DuckDuckGo\u2019s primary service is its search engine, the company has recently been branching out by offering various other services and products. This includes their web browsers, email relay service, etc. DuckDuckGo is the default search engine for the Tor Browser and is one of the few available options on Apple\u2019s Safari browser. Website tor Privacy Policy DuckDuckGo is based in the United States. Their privacy policy states they do log your searches for product improvement purposes, but not your IP address or any other personally identifying information. DuckDuckGo offers two other versions of their search engine, both of which do not require JavaScript. These versions do lack features, however. These versions can also be used in conjunction with their Tor onion address by appending /lite or /html for the respective version. Startpage \u00b6 Recommendation Startpage is a private search engine known for serving Google search results. Startpage's flagship feature is Anonymous View , which puts forth efforts to standardize user activity to make it more difficult to be uniquely identified. Unlike the name suggests, the feature should not be relied upon for anonymity. If you are looking for anonymity, use the Tor Browser instead. The feature can be useful for hiding some network and browser properties\u2014see the technical document for more details. Startpage has been known to refuse access to those using a VPN service or Tor, so your mileage may vary. Website Privacy Policy Startpage is based in the Netherlands. According to their privacy policy , they only log details such as: operating system, type of browser, and language. They do not log your IP address, search queries, or other personally identifying information. Startpage's majority shareholder is System1 who is an adtech company. We don't believe that to be an issue as they have an distinctly separate privacy policy . The Privacy Guides team reached out to Startpage back in 2020 to clear up any concerns with System1's sizeable investment into the service. We were satisfied with the answers we received. Mojeek \u00b6 Recommendation Mojeek is another privacy friendly search engine. They use their own crawler to provide search data. Website Privacy Policy The company is based in the UK. According to their Privacy Policy , they log the originating country, time, page requested, and referral data of each query. IP addresses are not logged. SearXNG \u00b6 Recommendation SearXNG is an open-source, self-hostable, metasearch engine, aggregating the results of other search engines while not storing any information itself. It is an actively maintained fork of SearX . There is a list of public instances . Homepage Downloads Source SearXNG is a proxy between you and the search engines it aggregates from. Your search queries will still be sent to the search engines that SearXNG gets its results from. When self-hosting, it is important that you have other people using your instance so that the queries would blend in. You should be careful with where and how you are hosting SearXNG, as people looking up illegal content on your instance could draw unwanted attention from authorities. When you are using a SearXNG instance, be sure to go read their privacy policy. Since SearXNG instances may be modified by their owners, they do not necessarily reflect their privacy policy. Some instances run as a Tor hidden service, which may grant some privacy as long as your search queries does not contain PII .","title":"Search Engines"},{"location":"search-engines/#duckduckgo","text":"Recommendation DuckDuckGo is one of the more mainstream private search engine options. Notable DuckDuckGo search features include bangs and many instant answers . The search engine relies on a commercial Bing API to serve most results, but it does use numerous other sources for instant answers and other non-primary results. While DuckDuckGo\u2019s primary service is its search engine, the company has recently been branching out by offering various other services and products. This includes their web browsers, email relay service, etc. DuckDuckGo is the default search engine for the Tor Browser and is one of the few available options on Apple\u2019s Safari browser. Website tor Privacy Policy DuckDuckGo is based in the United States. Their privacy policy states they do log your searches for product improvement purposes, but not your IP address or any other personally identifying information. DuckDuckGo offers two other versions of their search engine, both of which do not require JavaScript. These versions do lack features, however. These versions can also be used in conjunction with their Tor onion address by appending /lite or /html for the respective version.","title":"DuckDuckGo"},{"location":"search-engines/#startpage","text":"Recommendation Startpage is a private search engine known for serving Google search results. Startpage's flagship feature is Anonymous View , which puts forth efforts to standardize user activity to make it more difficult to be uniquely identified. Unlike the name suggests, the feature should not be relied upon for anonymity. If you are looking for anonymity, use the Tor Browser instead. The feature can be useful for hiding some network and browser properties\u2014see the technical document for more details. Startpage has been known to refuse access to those using a VPN service or Tor, so your mileage may vary. Website Privacy Policy Startpage is based in the Netherlands. According to their privacy policy , they only log details such as: operating system, type of browser, and language. They do not log your IP address, search queries, or other personally identifying information. Startpage's majority shareholder is System1 who is an adtech company. We don't believe that to be an issue as they have an distinctly separate privacy policy . The Privacy Guides team reached out to Startpage back in 2020 to clear up any concerns with System1's sizeable investment into the service. We were satisfied with the answers we received.","title":"Startpage"},{"location":"search-engines/#mojeek","text":"Recommendation Mojeek is another privacy friendly search engine. They use their own crawler to provide search data. Website Privacy Policy The company is based in the UK. According to their Privacy Policy , they log the originating country, time, page requested, and referral data of each query. IP addresses are not logged.","title":"Mojeek"},{"location":"search-engines/#searxng","text":"Recommendation SearXNG is an open-source, self-hostable, metasearch engine, aggregating the results of other search engines while not storing any information itself. It is an actively maintained fork of SearX . There is a list of public instances . Homepage Downloads Source SearXNG is a proxy between you and the search engines it aggregates from. Your search queries will still be sent to the search engines that SearXNG gets its results from. When self-hosting, it is important that you have other people using your instance so that the queries would blend in. You should be careful with where and how you are hosting SearXNG, as people looking up illegal content on your instance could draw unwanted attention from authorities. When you are using a SearXNG instance, be sure to go read their privacy policy. Since SearXNG instances may be modified by their owners, they do not necessarily reflect their privacy policy. Some instances run as a Tor hidden service, which may grant some privacy as long as your search queries does not contain PII .","title":"SearXNG"},{"location":"self-contained-networks/","text":"These networks are designed to keep your traffic anonymous. Tor \u00b6 Recommendation The Tor network is a group of volunteer-operated servers that allows people to improve their privacy and security on the Internet. You use the Tor network by connecting through a series of virtual tunnels rather than making a direct connection to the site you're trying to visit, thus allowing both organizations and individuals to share information over public networks without compromising their privacy. Tor is an effective censorship circumvention tool. Homepage tor Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Google Play f-droid F-Droid Android Source Invisible Internet Project \u00b6 Recommendation I2P is a computer network layer that allows applications to send messages to each other pseudonymously and securely. Uses include anonymous Web surfing, chatting, blogging, and file transfers. The software that implements this layer is called an I2P router and a computer running I2P is called an I2P node. The software is free and open-source and is published under multiple licenses. Homepage i2p Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Android Google Play f-droid F-Droid Source The Freenet Project \u00b6 Recommendation Freenet is a peer-to-peer platform for censorship-resistant communication. It uses a decentralized distributed data store to keep and deliver information, and has a suite of free software for publishing and communicating on the Web without fear of censorship. Both Freenet and some of its associated tools were originally designed by Ian Clarke, who defined Freenet's goal as providing freedom of speech on the Internet with strong anonymity protection. Homepage Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Source","title":"Self-Contained Networks"},{"location":"self-contained-networks/#tor","text":"Recommendation The Tor network is a group of volunteer-operated servers that allows people to improve their privacy and security on the Internet. You use the Tor network by connecting through a series of virtual tunnels rather than making a direct connection to the site you're trying to visit, thus allowing both organizations and individuals to share information over public networks without compromising their privacy. Tor is an effective censorship circumvention tool. Homepage tor Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Google Play f-droid F-Droid Android Source","title":"Tor"},{"location":"self-contained-networks/#invisible-internet-project","text":"Recommendation I2P is a computer network layer that allows applications to send messages to each other pseudonymously and securely. Uses include anonymous Web surfing, chatting, blogging, and file transfers. The software that implements this layer is called an I2P router and a computer running I2P is called an I2P node. The software is free and open-source and is published under multiple licenses. Homepage i2p Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Android Google Play f-droid F-Droid Source","title":"Invisible Internet Project"},{"location":"self-contained-networks/#the-freenet-project","text":"Recommendation Freenet is a peer-to-peer platform for censorship-resistant communication. It uses a decentralized distributed data store to keep and deliver information, and has a suite of free software for publishing and communicating on the Web without fear of censorship. Both Freenet and some of its associated tools were originally designed by Ian Clarke, who defined Freenet's goal as providing freedom of speech on the Internet with strong anonymity protection. Homepage Downloads Windows macOS Linux FreeBSD openbsd OpenBSD netbsd NetBSD Source","title":"The Freenet Project"},{"location":"tools/","text":"If you're looking for a specific solution to something, these are the hardware and software tools we recommend in a variety of categories. Our recommended privacy tools are primarily chosen based on security features, with additional emphasis on decentralized and open-source tools. They are applicable to a variety of threat models ranging from protection against global mass surveillance programs and avoiding big tech companies to mitigating attacks, but only you can determine what will work best for your use case. If you want assistance figuring out the best privacy tools and alternative programs for your workload/use-case, start a discussion in our Reddit or Matrix communities! For your convenience, everything we recommend is listed below with a link to the project's homepage. For more details about each project, why they were chosen, and additional tips or tricks we recommend, click the \"Learn more\" link in each section. Web Browsers \u00b6 Tor Browser Firefox (Desktop) Brave (Desktop) Bromite (Android) Safari (iOS) Learn more Additional Resources: uBlock Origin AdGuard for Safari Snowflake (1) Terms of Service; Didn't Read (2) Snowflake does not increase privacy, however it allows you to easily contribute to the Tor network and help people in censored networks achieve better privacy. Learn more We do not recommend installing ToS;DR as a browser extension. The same information is provided on their website. Learn more Operating Systems \u00b6 Android \u00b6 GrapheneOS CalyxOS DivestOS Learn more Android Apps: Neo Store (F-Droid Client) Orbot (Tor Proxy) Shelter (Work Profiles) Auditor (Supported Devices) Secure Camera Secure PDF Viewer PrivacyBlur Learn more Linux \u00b6 Fedora Workstation OpenSUSE Tumbleweed Arch Linux Fedora Silverblue & Kinoite NixOS Whonix (Tor) Tails (Live Boot) Qubes OS (Xen VM Distribution) (1) Qubes uses Xen to provide strong sandboxing between multiple Linux virtual machine installations, and can run most Linux applications. Learn more about Qubes... Learn more Router Firmware \u00b6 OpenWrt pfSense Learn more Service Providers \u00b6 Cloud Storage \u00b6 Nextcloud (Self-Hostable) Proton Drive Cryptee Tahoe-LAFS (Advanced) Learn more DNS \u00b6 We recommend a number of encrypted DNS servers based on a variety of criteria, such as Mullvad and Quad9 amongst others. We recommend for you to read our pages on DNS before choosing a provider. In many cases, using an alternative DNS provider is not recommended. Learn more Email \u00b6 ProtonMail Mailbox.org Tutanota StartMail Learn more Email Aliasing Services: SimpleLogin AnonAddy Learn more Self-Hosting Email: Mail-in-a-Box mailcow Learn more Search Engines \u00b6 DuckDuckGo Startpage Mojeek SearXNG Learn more VPN Providers \u00b6 VPNs do not provide anonymity Using a VPN will not keep your browsing habits anonymous, nor will it add additional security to non-secure ( HTTP ) traffic. If you are looking for anonymity , you should use the Tor Browser instead of a VPN . If you're looking for added security , you should always ensure you're connecting to websites using HTTPS . A VPN is not a replacement for good security practices. Learn more Mullvad ProtonVPN IVPN Learn more Software \u00b6 Calendar/Contacts Sync \u00b6 Tutanota ( SaaS ) Proton Calendar ( SaaS ) EteSync Nextcloud DecSync CC Learn more Notebooks \u00b6 Joplin Standard Notes EteSync Notes Org-mode Learn more Email Clients \u00b6 Thunderbird Apple Mail GNOME Evolution (Linux) Kontact (Linux) Mailvelope ( PGP in standard webmail) K-9 Mail (Android) Canary Mail (iOS) NeoMutt ( CLI ) Learn more Encryption Tools \u00b6 Operating System Disk Encryption For encrypting your operating system drive, we typically recommend using whichever encryption tool your operating system provides, whether that is BitLocker on Windows, FileVault on macOS, or LUKS on Linux. These tools are included with the operating system and typically utilize hardware encryption elements such as a TPM that other full-disk encryption software like VeraCrypt do not. VeraCrypt is still suitable for non-operating system disks such as external drives, especially drives that may be accessed from multiple operating systems. Learn more VeraCrypt ( FDE ) Cryptomator Picocrypt Hat.sh (Browser-based) Kryptor Tomb Learn more OpenPGP Clients: GnuPG GPG4Win (Windows) GPG Suite (macOS) OpenKeychain Learn more File Sharing \u00b6 OnionShare Magic Wormhole FreedomBox Syncthing git-annex Learn more Metadata Removal Tools \u00b6 MAT2 ExifCleaner Scrambled Exif (Android) Imagepipe (Android) Metapho (iOS) ExifTool ( CLI ) Learn more Multi-Factor Authentication Tools \u00b6 YubiKey Nitrokey Aegis Authenticator Raivo OTP Learn more Password Managers \u00b6 KeePassXC KeePassDX (Android) Bitwarden Psono gopass Vaultwarden (Bitwarden Server) Learn more Productivity Tools \u00b6 LibreOffice OnlyOffice Framadate (Appointment Planning) PrivateBin (Pastebin) CryptPad Write.as (Blogging Platform) VSCodium (Source-Code Editor) Learn more Real-Time Communication \u00b6 Signal Element Briar (Android) Session Learn more News Aggregators \u00b6 Fluent Reader GNOME Feeds Akregator Handy News Reader NetNewsWire Miniflux Newsboat Learn more Self-Contained Networks \u00b6 Tor I2P Freenet Learn more Video Streaming Clients \u00b6 FreeTube (YouTube, Desktop) LBRY NewPipe (YouTube, Android) NewPipe x Sponsorblock Invidious (YouTube, Web) Piped (YouTube, Web) Learn more","title":"Privacy Tools"},{"location":"tools/#web-browsers","text":"Tor Browser Firefox (Desktop) Brave (Desktop) Bromite (Android) Safari (iOS) Learn more Additional Resources: uBlock Origin AdGuard for Safari Snowflake (1) Terms of Service; Didn't Read (2) Snowflake does not increase privacy, however it allows you to easily contribute to the Tor network and help people in censored networks achieve better privacy. Learn more We do not recommend installing ToS;DR as a browser extension. The same information is provided on their website. Learn more","title":"Web Browsers"},{"location":"tools/#operating-systems","text":"","title":"Operating Systems"},{"location":"tools/#android","text":"GrapheneOS CalyxOS DivestOS Learn more Android Apps: Neo Store (F-Droid Client) Orbot (Tor Proxy) Shelter (Work Profiles) Auditor (Supported Devices) Secure Camera Secure PDF Viewer PrivacyBlur Learn more","title":"Android"},{"location":"tools/#linux","text":"Fedora Workstation OpenSUSE Tumbleweed Arch Linux Fedora Silverblue & Kinoite NixOS Whonix (Tor) Tails (Live Boot) Qubes OS (Xen VM Distribution) (1) Qubes uses Xen to provide strong sandboxing between multiple Linux virtual machine installations, and can run most Linux applications. Learn more about Qubes... Learn more","title":"Linux"},{"location":"tools/#router-firmware","text":"OpenWrt pfSense Learn more","title":"Router Firmware"},{"location":"tools/#service-providers","text":"","title":"Service Providers"},{"location":"tools/#cloud-storage","text":"Nextcloud (Self-Hostable) Proton Drive Cryptee Tahoe-LAFS (Advanced) Learn more","title":"Cloud Storage"},{"location":"tools/#dns","text":"We recommend a number of encrypted DNS servers based on a variety of criteria, such as Mullvad and Quad9 amongst others. We recommend for you to read our pages on DNS before choosing a provider. In many cases, using an alternative DNS provider is not recommended. Learn more","title":"DNS"},{"location":"tools/#email","text":"ProtonMail Mailbox.org Tutanota StartMail Learn more Email Aliasing Services: SimpleLogin AnonAddy Learn more Self-Hosting Email: Mail-in-a-Box mailcow Learn more","title":"Email"},{"location":"tools/#search-engines","text":"DuckDuckGo Startpage Mojeek SearXNG Learn more","title":"Search Engines"},{"location":"tools/#vpn-providers","text":"VPNs do not provide anonymity Using a VPN will not keep your browsing habits anonymous, nor will it add additional security to non-secure ( HTTP ) traffic. If you are looking for anonymity , you should use the Tor Browser instead of a VPN . If you're looking for added security , you should always ensure you're connecting to websites using HTTPS . A VPN is not a replacement for good security practices. Learn more Mullvad ProtonVPN IVPN Learn more","title":"VPN Providers"},{"location":"tools/#software","text":"","title":"Software"},{"location":"tools/#calendarcontacts-sync","text":"Tutanota ( SaaS ) Proton Calendar ( SaaS ) EteSync Nextcloud DecSync CC Learn more","title":"Calendar/Contacts Sync"},{"location":"tools/#notebooks","text":"Joplin Standard Notes EteSync Notes Org-mode Learn more","title":"Notebooks"},{"location":"tools/#email-clients","text":"Thunderbird Apple Mail GNOME Evolution (Linux) Kontact (Linux) Mailvelope ( PGP in standard webmail) K-9 Mail (Android) Canary Mail (iOS) NeoMutt ( CLI ) Learn more","title":"Email Clients"},{"location":"tools/#encryption-tools","text":"Operating System Disk Encryption For encrypting your operating system drive, we typically recommend using whichever encryption tool your operating system provides, whether that is BitLocker on Windows, FileVault on macOS, or LUKS on Linux. These tools are included with the operating system and typically utilize hardware encryption elements such as a TPM that other full-disk encryption software like VeraCrypt do not. VeraCrypt is still suitable for non-operating system disks such as external drives, especially drives that may be accessed from multiple operating systems. Learn more VeraCrypt ( FDE ) Cryptomator Picocrypt Hat.sh (Browser-based) Kryptor Tomb Learn more OpenPGP Clients: GnuPG GPG4Win (Windows) GPG Suite (macOS) OpenKeychain Learn more","title":"Encryption Tools"},{"location":"tools/#file-sharing","text":"OnionShare Magic Wormhole FreedomBox Syncthing git-annex Learn more","title":"File Sharing"},{"location":"tools/#metadata-removal-tools","text":"MAT2 ExifCleaner Scrambled Exif (Android) Imagepipe (Android) Metapho (iOS) ExifTool ( CLI ) Learn more","title":"Metadata Removal Tools"},{"location":"tools/#multi-factor-authentication-tools","text":"YubiKey Nitrokey Aegis Authenticator Raivo OTP Learn more","title":"Multi-Factor Authentication Tools"},{"location":"tools/#password-managers","text":"KeePassXC KeePassDX (Android) Bitwarden Psono gopass Vaultwarden (Bitwarden Server) Learn more","title":"Password Managers"},{"location":"tools/#productivity-tools","text":"LibreOffice OnlyOffice Framadate (Appointment Planning) PrivateBin (Pastebin) CryptPad Write.as (Blogging Platform) VSCodium (Source-Code Editor) Learn more","title":"Productivity Tools"},{"location":"tools/#real-time-communication","text":"Signal Element Briar (Android) Session Learn more","title":"Real-Time Communication"},{"location":"tools/#news-aggregators","text":"Fluent Reader GNOME Feeds Akregator Handy News Reader NetNewsWire Miniflux Newsboat Learn more","title":"News Aggregators"},{"location":"tools/#self-contained-networks","text":"Tor I2P Freenet Learn more","title":"Self-Contained Networks"},{"location":"tools/#video-streaming-clients","text":"FreeTube (YouTube, Desktop) LBRY NewPipe (YouTube, Android) NewPipe x Sponsorblock Invidious (YouTube, Web) Piped (YouTube, Web) Learn more","title":"Video Streaming Clients"},{"location":"video-streaming/","text":"The primary threat when using a video streaming platform is that your streaming habits and subscription lists could be used to profile you. You should combine these tools with a VPN or Tor to make it harder to profile your usage. Clients \u00b6 FreeTube \u00b6 Recommendation FreeTube is a free and open source desktop application for YouTube . When using FreeTube, your subscription list and playlists are saved locally on your device. By default, FreeTube blocks all YouTube advertisements. In addition, FreeTube optionally integrates with SponsorBlock to help you skip sponsored video segments. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Source Warning When using FreeTube, your IP address may still be known to YouTube, Invidious , or SponsorBlock depending on your configuration. Consider using a VPN or Tor if your threat model requires hiding your IP address. LBRY \u00b6 Recommendation The LBRY network is a decentralized video sharing network. It uses a BitTorrent -like network to store the video content, and a blockchain to store the indexes for those videos. The main benefit of this design is censorship resistance. The LBRY desktop client helps you stream videos from the LBRY network and stores your subscription list in your own LBRY wallet. Website Privacy Policy Downloads Windows macOS Linux Source Note Only the LBRY desktop client is recommended, as the Odysee website and the LBRY clients in F-Droid, Play Store, and the App Store have mandatory synchronization and telemetry. Warning While watching and hosting videos, your IP address is visible to the LBRY network. Consider using a VPN or Tor if your threat model requires hiding your IP address. We recommend against synchronizing your wallet with LBRY Inc., as synchronizing encrypted wallets is not supported yet. If you synchronize your wallet with LBRY Inc., you have to trust them to not look at your subscription list, LBC funds, or take control of your channel. You can disable Save hosting data to help the LBRY network option in Settings \u2192 Advanced Settings , to avoid exposing your IP address and watched videos when using LBRY for a prolonged period of time. NewPipe \u00b6 Recommendation NewPipe is a free and open source Android application for YouTube , SoundCloud , media.ccc.de , FramaTube , and Bandcamp . Your subscription list and playlists are saved locally on your Android device. Homepage Privacy Policy Downloads F-Droid repo Source Note NewPipe is available on the main F-Droid 's repository. We recommend that you use NewPipe's own F-Droid repository instead to get faster updates. SponsorBlock \u00b6 NewPipe x SponsorBlock is a fork of NewPipe with SponsorBlock integrated to help you skip sponsored video segments. It also has integration with Return YouTube Dislike , and some experimental settings such as the ability to use the built-in player for local playback, an option to force fullscreen on landscape mode, and an option to disable error reporting prompts. github.com/polymorphicshade/NewPipe This fork is not endorsed by or affiliated with the upstream project. The NewPipe team has rejected integration with SponsorBlock and thus this fork is created to provide this functionality. Web-based Frontends \u00b6 Invidious \u00b6 Recommendation Invidious is a free and open source front end for YouTube that is also self-hostable. There are list of public instances . Some instances have Tor onion services support. Website Privacy Policy Downloads Instances Source Warning Invidious does not proxy the video stream through its server by default. Videos watched through Invidious will still make direct connections to Google's servers (googlevideo.com); however, some instances support video proxying. This can be enabled by adding &local=true to the URL. Tip Invidious is useful if you want to disable JavaScript in your browser, such as Tor Browser on the Safest security setting. It does not provide privacy by itself and we don\u2019t recommend logging into any accounts. When self-hosting, it is important that you have other people using your instance as well in order for you to blend in. You should be careful with where and how you are hosting Invidious, as other peoples' usage will be linked to your hosting. When you are using an Invidious instance, be sure to go read the Privacy Policy of that specific instance. Invidious instances can be modified by their owners and therefore may not reflect their associated privacy policy. Some instances have Tor .onion addresses which may grant some privacy as long as your search queries don't contain PII (Personally Identifiable Information). Piped \u00b6 Recommendation Piped is a free and open source front end for YouTube that is also self-hostable. Alternative instances can be selected from \"Preferences\". Piped requires JavaScript in order to function. Website Downloads Source Tip Piped is useful if you want to use SponsorBlock without installing an extension or to access age-restricted content without an account. It does not provide privacy by itself and we don\u2019t recommend logging into any accounts. When self-hosting, it is important that you have other people using your instance as well in order for you to blend in. You should be careful with where and how you are hosting Piped, as other peoples' usage will be linked to your hosting. When you are using a Piped instance, be sure to go read the Privacy Policy of that specific instance. Piped instances can be modified by their owners and therefore may not reflect their associated privacy policy.","title":"Video Streaming"},{"location":"video-streaming/#clients","text":"","title":"Clients"},{"location":"video-streaming/#freetube","text":"Recommendation FreeTube is a free and open source desktop application for YouTube . When using FreeTube, your subscription list and playlists are saved locally on your device. By default, FreeTube blocks all YouTube advertisements. In addition, FreeTube optionally integrates with SponsorBlock to help you skip sponsored video segments. Homepage Privacy Policy Downloads Windows macOS Linux flathub Flatpak Source Warning When using FreeTube, your IP address may still be known to YouTube, Invidious , or SponsorBlock depending on your configuration. Consider using a VPN or Tor if your threat model requires hiding your IP address.","title":"FreeTube"},{"location":"video-streaming/#lbry","text":"Recommendation The LBRY network is a decentralized video sharing network. It uses a BitTorrent -like network to store the video content, and a blockchain to store the indexes for those videos. The main benefit of this design is censorship resistance. The LBRY desktop client helps you stream videos from the LBRY network and stores your subscription list in your own LBRY wallet. Website Privacy Policy Downloads Windows macOS Linux Source Note Only the LBRY desktop client is recommended, as the Odysee website and the LBRY clients in F-Droid, Play Store, and the App Store have mandatory synchronization and telemetry. Warning While watching and hosting videos, your IP address is visible to the LBRY network. Consider using a VPN or Tor if your threat model requires hiding your IP address. We recommend against synchronizing your wallet with LBRY Inc., as synchronizing encrypted wallets is not supported yet. If you synchronize your wallet with LBRY Inc., you have to trust them to not look at your subscription list, LBC funds, or take control of your channel. You can disable Save hosting data to help the LBRY network option in Settings \u2192 Advanced Settings , to avoid exposing your IP address and watched videos when using LBRY for a prolonged period of time.","title":"LBRY"},{"location":"video-streaming/#newpipe","text":"Recommendation NewPipe is a free and open source Android application for YouTube , SoundCloud , media.ccc.de , FramaTube , and Bandcamp . Your subscription list and playlists are saved locally on your Android device. Homepage Privacy Policy Downloads F-Droid repo Source Note NewPipe is available on the main F-Droid 's repository. We recommend that you use NewPipe's own F-Droid repository instead to get faster updates.","title":"NewPipe"},{"location":"video-streaming/#sponsorblock","text":"NewPipe x SponsorBlock is a fork of NewPipe with SponsorBlock integrated to help you skip sponsored video segments. It also has integration with Return YouTube Dislike , and some experimental settings such as the ability to use the built-in player for local playback, an option to force fullscreen on landscape mode, and an option to disable error reporting prompts. github.com/polymorphicshade/NewPipe This fork is not endorsed by or affiliated with the upstream project. The NewPipe team has rejected integration with SponsorBlock and thus this fork is created to provide this functionality.","title":"SponsorBlock"},{"location":"video-streaming/#web-based-frontends","text":"","title":"Web-based Frontends"},{"location":"video-streaming/#invidious","text":"Recommendation Invidious is a free and open source front end for YouTube that is also self-hostable. There are list of public instances . Some instances have Tor onion services support. Website Privacy Policy Downloads Instances Source Warning Invidious does not proxy the video stream through its server by default. Videos watched through Invidious will still make direct connections to Google's servers (googlevideo.com); however, some instances support video proxying. This can be enabled by adding &local=true to the URL. Tip Invidious is useful if you want to disable JavaScript in your browser, such as Tor Browser on the Safest security setting. It does not provide privacy by itself and we don\u2019t recommend logging into any accounts. When self-hosting, it is important that you have other people using your instance as well in order for you to blend in. You should be careful with where and how you are hosting Invidious, as other peoples' usage will be linked to your hosting. When you are using an Invidious instance, be sure to go read the Privacy Policy of that specific instance. Invidious instances can be modified by their owners and therefore may not reflect their associated privacy policy. Some instances have Tor .onion addresses which may grant some privacy as long as your search queries don't contain PII (Personally Identifiable Information).","title":"Invidious"},{"location":"video-streaming/#piped","text":"Recommendation Piped is a free and open source front end for YouTube that is also self-hostable. Alternative instances can be selected from \"Preferences\". Piped requires JavaScript in order to function. Website Downloads Source Tip Piped is useful if you want to use SponsorBlock without installing an extension or to access age-restricted content without an account. It does not provide privacy by itself and we don\u2019t recommend logging into any accounts. When self-hosting, it is important that you have other people using your instance as well in order for you to blend in. You should be careful with where and how you are hosting Piped, as other peoples' usage will be linked to your hosting. When you are using a Piped instance, be sure to go read the Privacy Policy of that specific instance. Piped instances can be modified by their owners and therefore may not reflect their associated privacy policy.","title":"Piped"},{"location":"vpn/","text":"Find a no-logging VPN operator who isn\u2019t out to sell or read your web traffic. VPNs do not provide anonymity Using a VPN will not keep your browsing habits anonymous, nor will it add additional security to non-secure ( HTTP ) traffic. If you are looking for anonymity , you should use the Tor Browser instead of a VPN . If you're looking for added security , you should always ensure you're connecting to websites using HTTPS . A VPN is not a replacement for good security practices. Download Tor Tor Myths & FAQ When are VPNs useful? If you're looking for additional privacy from your ISP , on a public Wi-Fi network, or while torrenting files, a VPN may be the solution for you as long as you understand the risks involved. More Info Recommended Providers \u00b6 Criteria Our recommended providers are outside the US, use encryption, accept Monero, support WireGuard & OpenVPN, and have a no logging policy. Read our full list of criteria for more information. Mullvad \u00b6 Recommendation Mullvad is a fast and inexpensive VPN with a serious focus on transparency and security. They have been in operation since 2009 . Mullvad is based in Sweden and does not have a free trial. EUR \u20ac60/year Website tor 38 Countries Mullvad has servers in 38 countries (1). Picking a VPN provider with a server nearest to you will reduce latency of the network traffic you send. This is because of a shorter route (less hops) to the destination. We also think it's better for the security of the VPN provider's private keys if they use dedicated servers , instead of cheaper shared solutions (with other customers) such as virtual private servers . As of 2022/05/17 Independently Audited Mullvad's VPN clients have been audited by Cure53 and Assured AB in a pentest report published at cure53.de . The security researchers concluded: Cure53 and Assured AB are happy with the results of the audit and the software leaves an overall positive impression. With security dedication of the in-house team at the Mullvad VPN compound, the testers have no doubts about the project being on the right track from a security standpoint. In 2020 a second audit was announced and the final audit report was made available on Cure53's website: The results of this May-June 2020 project targeting the Mullvad complex are quite positive. [...] The overall application ecosystem used by Mullvad leaves a sound and structured impression. The overall structure of the application makes it easy to roll out patches and fixes in a structured manner. More than anything, the findings spotted by Cure53 showcase the importance of constantly auditing and re-assessing the current leak vectors, in order to always ensure privacy of the end-users. With that being said, Mullvad does a great job protecting the end-user from common PII leaks and privacy related risks. In 2021 an infrastructure audit was announced and the final audit report was made available on Cure53's website. Open Source Clients Mullvad provides the source code for their desktop and mobile clients in their GitHub organization . Accepts Cash and Monero Mullvad, in addition to accepting credit/debit cards and PayPal, accepts Bitcoin, Bitcoin Cash, Monero and cash/local currency as anonymous forms of payment. They also accept Swish and bank wire transfers. WireGuard Support Mullvad supports the WireGuard\u00ae protocol. WireGuard is a newer protocol that utilizes state-of-the-art cryptography . Additionally, WireGuard aims to be simpler and more performant. Mullvad recommends the use of WireGuard with their service. It is the default or only protocol on Mullvad's Android, iOS, macOS, and Linux apps, but on Windows you have to manually enable WireGuard. Mullvad also offers a WireGuard configuration generator for use with the official WireGuard apps . IPv6 Support Mullvad supports the future of networking IPv6 . Their network allows you to access services hosted on IPv6 as opposed to other providers who block IPv6 connections. Remote Port Forwarding Remote port forwarding is allowed for people who make one-time payments, but not allowed for accounts with a recurring/subscription-based payment method. This is to prevent Mullvad from being able to identify you based on your port usage and stored subscription information. See Port forwarding with Mullvad VPN for more information. Mobile Clients Mullvad has published App Store and Google Play clients, both supporting an easy-to use interface as opposed to requiring you to manually configure your WireGuard connection. The mobile client on Android is also available in F-Droid , which ensures that it is compiled with reproducible builds . Additional Functionality Mullvad is very transparent about which nodes they own or rent . They use ShadowSocks in their ShadowSocks + OpenVPN configuration, making them more resistant against firewalls with Deep Packet Inspection trying to block VPNs. Supposedly, China has to use a different method to block ShadowSocks servers . Mullvad's website is also accessible via Tor at o54hon2e2vj6c7m3aqqu6uyece65by3vgoxxhlqlsvkmacw6a7m7kiad.onion . ProtonVPN \u00b6 Recommendation ProtonVPN is a strong contender in the VPN space, and they have been in operation since 2016. ProtonVPN is based in Switzerland and offers a limited free pricing tier, as well as premium options. They offer a further 14% discount for buying a 2 year subscription. Free - Basic Plan USD $48/year - Plus Plan USD $96/year Website 63 Countries ProtonVPN has servers in 63 countries (1). Picking a VPN provider with a server nearest to you will reduce latency of the network traffic you send. This is because of a shorter route (less hops) to the destination. We also think it's better for the security of the VPN provider's private keys if they use dedicated servers , instead of cheaper shared solutions (with other customers) such as virtual private servers . As of 2022/05/17 Independently Audited As of January 2020 ProtonVPN has undergone an independent audit by SEC Consult. SEC Consult found some medium and low risk vulnerabilities in ProtonVPN's Windows, Android, and iOS applications, all of which were \"properly fixed\" by ProtonVPN before the reports were published. None of the issues identified would have provided an attacker remote access to your device or traffic. You can view individual reports for each platform at protonvpn.com . Open Source Clients ProtonVPN provides the source code for their desktop and mobile clients in their GitHub organization . Accepts Cash ProtonVPN, in addition to accepting credit/debit cards and PayPal, accepts Bitcoin, and cash/local currency as anonymous forms of payment. WireGuard Support ProtonVPN mostly supports the WireGuard\u00ae protocol. WireGuard is a newer protocol that utilizes state-of-the-art cryptography . Additionally, WireGuard aims to be simpler and more performant. ProtonVPN recommends the use of WireGuard with their service. On ProtonVPN's Windows, macOS, iOS, Android, ChromeOS, and Android TV apps, WireGuard is the default protocol; however, support for the protocol is not present in their Linux app. Remote Port Forwarding ProtonVPN currently only supports remote port forwarding on Windows, which may impact some applications. Especially Peer-to-Peer applications like Torrent clients. Mobile Clients In addition to providing standard OpenVPN configuration files, ProtonVPN has mobile clients for App Store and Google Play allowing for easy connections to their servers. The mobile client on Android is also available in F-Droid , which ensures that it is compiled with reproducible builds . Additional Functionality ProtonVPN have their own servers and datacenters in Switzerland, Iceland and Sweden. They offer adblocking and known malware domains blocking with their DNS service. Additionally, ProtonVPN also offers \"Tor\" servers allowing you to easily connect to onion sites, but we still strongly recommend using the official Tor Browser for this purpose. IVPN \u00b6 Recommendation IVPN is another premium VPN provider, and they have been in operation since 2009. IVPN is based in Gibraltar. Standard USD $60/year - Pro USD $100/year Website 32 Countries IVPN has servers in 32 countries (1). Picking a VPN provider with a server nearest to you will reduce latency of the network traffic you send. This is because of a shorter route (less hops) to the destination. We also think it's better for the security of the VPN provider's private keys if they use dedicated servers , instead of cheaper shared solutions (with other customers) such as virtual private servers . As of 2022/05/17 Independently Audited IVPN has undergone a no-logging audit from Cure53 which concluded in agreement with IVPN's no-logging claim. IVPN has also completed a comprehensive pentest report Cure53 in January 2020. IVPN has also said they plan to have annual reports in the future. Open Source Clients As of Feburary 2020 IVPN applications are now open source . Source code can be obtained from their GitHub organization . Accepts Cash and Monero In addition to accepting credit/debit cards and PayPal, IVPN accepts Bitcoin, Monero and cash/local currency (on annual plans) as anonymous forms of payment. WireGuard Support IVPN supports the WireGuard\u00ae protocol. WireGuard is a newer protocol that utilizes state-of-the-art cryptography . Additionally, WireGuard aims to be simpler and more performant. IVPN recommends the use of WireGuard with their service and, as such, the protocol is the default on all of IVPN's apps. IVPN also offers a WireGuard configuration generator for use with the official WireGuard apps . Remote Port Forwarding Remote port forwarding is possible with a Pro plan. Port forwarding can be activated via the client area. Port forwarding is only available on IVPN when using WireGuard or OpenVPN protocols and is disabled on US servers . Mobile Clients In addition to providing standard OpenVPN configuration files, IVPN has mobile clients for App Store and Google Play allowing for easy connections to their servers. The mobile client on Android is also available in F-Droid , which ensures that it is compiled with reproducible builds . Additional Functionality IVPN clients support two factor authentication (Mullvad and ProtonVPN clients do not). IVPN also provides \" AntiTracker \" functionality, which blocks advertising networks and trackers from the network level. Our Criteria \u00b6 Danger It is important to note that using a VPN provider will not make you anonymous, but it will give you better privacy in certain situations. A VPN is not a tool for illegal activities. Don't rely on a \"no log\" policy. Please note we are not affiliated with any of the providers we recommend. This allows us to provide completely objective recommendations. We have developed a clear set of requirements for any VPN provider wishing to be recommended, including strong encryption, independent security audits, modern technology, and more. We suggest you familiarize yourself with this list before choosing a VPN provider, and conduct your own research to ensure the VPN provider you choose is as trustworthy as possible. Jurisdiction \u00b6 Operating outside the five/nine/fourteen-eyes countries is not a guarantee of privacy necessarily, and there are other factors to consider. However, we believe that avoiding these countries is important if you wish to avoid mass government dragnet surveillance, especially from the United States. Minimum to Qualify: Operating outside the USA or other Five Eyes countries. Best Case: Operating outside the USA or other Fourteen Eyes countries. Operating inside a country with strong consumer protection laws. Technology \u00b6 We require all our recommended VPN providers to provide OpenVPN configuration files to be used in any client. If a VPN provides their own custom client, we require a killswitch to block network data leaks when disconnected. Minimum to Qualify: Support for strong protocols such as WireGuard & OpenVPN. Killswitch built in to clients. Multihop support. Multihopping is important to keep data private in case of a single node compromise. If VPN clients are provided, they should be open source , like the VPN software they generally have built into them. We believe that source code availability provides greater transparency about what your device is actually doing. We like to see these applications available in F-Droid . Best Case: WireGuard and OpenVPN support. Killswitch with highly configurable options (enable/disable on certain networks, on boot, etc.) Easy-to-use VPN clients Supports IPv6 . We expect that servers will allow incoming connections via IPv6 and allow you to access services hosted on IPv6 addresses. Capability of remote port forwarding assists in creating connections when using P2P ( Peer-to-Peer ) filesharing software, Freenet, or hosting a server (e.g., Mumble). Privacy \u00b6 We prefer our recommended providers to collect as little data as possible. Not collecting personal information on registration, and accepting anonymous forms of payment are required. Minimum to Qualify: Monero or cash payment option. No personal information required to register: Only username, password, and email at most. Best Case: Accepts Monero, cash, and other forms of anonymous payment options (gift cards, etc.) No personal information accepted (autogenerated username, no email required, etc.) Security \u00b6 A VPN is pointless if it can't even provide adequate security. We require all our recommended providers to abide by current security standards for their OpenVPN connections. Ideally, they would use more future-proof encryption schemes by default. We also require an independent third-party to audit the provider's security, ideally in a very comprehensive manner and on a repeated (yearly) basis. Minimum to Qualify: Strong Encryption Schemes: OpenVPN with SHA-256 authentication; RSA-2048 or better handshake; AES-256-GCM or AES-256-CBC data encryption. Perfect Forward Secrecy (PFS). Published security audits from a reputable third-party firm. Best Case: Strongest Encryption: RSA-4096. Perfect Forward Secrecy (PFS). Comprehensive published security audits from a reputable third-party firm. Bug-bounty programs and/or a coordinated vulnerability-disclosure process. Trust \u00b6 You wouldn't trust your finances to someone with a fake identity, so why trust them with your internet data? We require our recommended providers to be public about their ownership or leadership. We also would like to see frequent transparency reports, especially in regard to how government requests are handled. Minimum to Qualify: Public-facing leadership or ownership. Best Case: Public-facing leadership. Frequent transparency reports. Marketing \u00b6 With the VPN providers we recommend we like to see responsible marketing. Minimum to Qualify: Must self host analytics (no Google Analytics etc). The provider's site must also comply with DNT (Do Not Track) for people who want to opt-out. Must not have any marketing which is irresponsible: Making guarantees of protecting anonymity 100%. When someone makes a claim that something is 100% it means there is no certainty for failure. We know people can quite easily deanonymize themselves in a number of ways, eg: Reusing personal information eg. (email accounts, unique pseudonyms etc) that they accessed without anonymity software (Tor, VPN etc) Browser fingerprinting Claim that a single circuit VPN is \"more anonymous\" than Tor, which is a circuit of 3 or more hops that regularly changes. Use responsible language, eg it is okay to say that a VPN is \"disconnected\" or \"not connected\", however claiming that someone is \"exposed\", \"vulnerable\" or \"compromised\" is needless use of alarming language that may be incorrect. For example, that person might simply be on another VPN provider's service or using Tor. Best Case: Responsible marketing that is both educational and useful to the consumer could include: An accurate comparison to when Tor or other self-contained networks should be used. Availability of the VPN provider's website over a .onion Hidden Service Additional Functionality \u00b6 While not strictly requirements, there are some factors we looked into when determining which providers to recommend. These include adblocking/tracker-blocking functionality, warrant canaries, multihop connections, excellent customer support, the number of allowed simultaneous connections, etc. VPN Overview \u00b6 Should I use a VPN ? \u00b6 Yes , unless you are already using Tor. A VPN does 2 things: shifting the risks from your Internet Service Provider to itself and hiding your IP from a third party service. VPNs cannot encrypt data outside of the connection between your device and the VPN server. VPN providers can see and modify your traffic the same way your ISP could. And there is no way to verify a VPN provider's \"no logging\" policies in any way. However, they do hide your actual IP from a third party service, provided that there are no IP leaks. They help you blend in with others and mitigate IP based tracking. What about encryption? \u00b6 Encryption offered by VPN providers are between your devices and their servers. It guarantees that this specific link is secure. This is a step up from using unencrypted proxies where an adversary on the network can intercept the communications between your devices and said proxies and modify them. However, encryption between your apps or browsers with the service providers are not handled by this encryption. In order to keep what you actually do on the websites you visit private and secure, you must use HTTPS . This will keep your passwords, session tokens, and queries safe from the VPN provider. Consider enabling \" HTTPS everywhere\" in your browser to mitigate downgrade attacks like SSL Strip . Should I use encrypted DNS with a VPN ? \u00b6 Unless your VPN provider hosts the encrypted DNS servers, no . Using DOH/DOT (or any other form of encrypted DNS ) with third party servers will simply add more entities to trust, and does absolutely nothing to improve your privacy/security. Your VPN provider can still see which websites you visit based on the IP addresses and other methods. Instead of just trusting your VPN provider, you are now trusting both the VPN provider and the DNS provider. A common reason to recommend encrypted DNS is that it helps against DNS spoofing. However, your browser should already be checking for TLS certificates with HTTPS and warn you about it. If you are not using HTTPS , then an adversary can still just modify anything other than your DNS queries and the end result will be little different. Needless to say, you shouldn't use encrypted DNS with Tor . This would direct all of your DNS requests through a single circuit, and would allow the encrypted DNS provider to deanonymize you. Should I use Tor and a VPN ? \u00b6 By using a VPN with Tor, you're creating essentially a permanent entry node, often with a money trail attached. This provides zero additional benefit to you, while increasing the attack surface of your connection dramatically. If you wish to hide your Tor usage from your ISP or your government, Tor has a built-in solution for that: Tor bridges. Read more about Tor bridges and why using a VPN is not necessary . What if I need anonymity? \u00b6 VPNs cannot provide anonymity. Your VPN provider will still see your real IP address, and often has a money trail that can be linked directly back to you. You cannot rely on \"no logging\" policies to protect your data. Use Tor instead. What about VPN providers that provides Tor nodes? \u00b6 Do not use that feature. The point of using Tor is that you do not trust your VPN provider. Currently Tor only supports the TCP protocol. UDP (used in WebRTC for voice and video sharing, the new http3/QUIC protocol, etc), ICMP and other packets will be dropped. To compensate for this, VPN providers typically will route all non TCP packets through their VPN server (your first hop). This is the case with ProtonVPN . Additionally, when using this Tor over VPN setup, you do not have control over other important Tor features such as Isolated Destination Address (using a different Tor circuit for every domain you visit). Thus, this feature should be viewed as a convenient way to access the Tor Network, not to stay annonymous. For true anonimity, use the Tor Browser Bundle, TorSocks, or a Tor gateway. When are VPNs useful? \u00b6 A VPN may still be useful to you in a variety of scenarios, such as: Hiding your traffic from only your Internet Service Provider. Hiding your downloads (such as torrents) from your ISP and anti-piracy organizations. Hiding your IP from third party websites and services, preventing IP based tracking. For use cases like these, or if you have another compelling reason, the VPN providers we listed above are who we think are the most trustworthy. However, using a VPN provider still means you're trusting the provider. In pretty much any other scenario you should be using a secure -by-design tool such as Tor. Sources and Further Reading \u00b6 VPN - a Very Precarious Narrative by Dennis Schubert The self-contained networks recommended by Privacy Guides are able to replace a VPN that allows access to services on local area network Slicing Onions: Part 1 \u2013 Myth-busting Tor by blacklight447 Slicing Onions: Part 2 \u2013 Onion recipes; VPN not required by blacklight447 IVPN Privacy Guides \"Do I need a VPN ?\" , a tool developed by IVPN to challenge aggressive VPN marketing by helping individuals decide if a VPN is right for them. Related VPN information \u00b6 The Trouble with VPN and Privacy Review Sites Proxy.sh VPN Provider Sniffed Server Traffic to Catch Hacker blackVPN announced to delete connection logs after disconnection Don't use LT2P IPSec, use other protocols. Free VPN App Investigation Hidden VPN owners unveiled: 101 VPN products run by just 23 companies This Chinese company is secretly behind 24 popular apps seeking dangerous permissions VPN Related breaches - why external auditing is important \u00b6 \"Zero logs\" VPN exposes millions of logs including user passwords, claims data is anonymous July 2020 NordVPN HTTP POST bug exposed customer information, no authentication required March 2020 Row erupts over who to blame after NordVPN says: One of our servers was hacked via remote management tool October 2019 VPN servers seized by Ukrainian authorities weren't encrypted and allowed authorities to impersonate Windscribe servers and capture and decrypt traffic passing through them July 2021","title":"VPN Services"},{"location":"vpn/#recommended-providers","text":"Criteria Our recommended providers are outside the US, use encryption, accept Monero, support WireGuard & OpenVPN, and have a no logging policy. Read our full list of criteria for more information.","title":"Recommended Providers"},{"location":"vpn/#mullvad","text":"Recommendation Mullvad is a fast and inexpensive VPN with a serious focus on transparency and security. They have been in operation since 2009 . Mullvad is based in Sweden and does not have a free trial. EUR \u20ac60/year Website tor 38 Countries Mullvad has servers in 38 countries (1). Picking a VPN provider with a server nearest to you will reduce latency of the network traffic you send. This is because of a shorter route (less hops) to the destination. We also think it's better for the security of the VPN provider's private keys if they use dedicated servers , instead of cheaper shared solutions (with other customers) such as virtual private servers . As of 2022/05/17 Independently Audited Mullvad's VPN clients have been audited by Cure53 and Assured AB in a pentest report published at cure53.de . The security researchers concluded: Cure53 and Assured AB are happy with the results of the audit and the software leaves an overall positive impression. With security dedication of the in-house team at the Mullvad VPN compound, the testers have no doubts about the project being on the right track from a security standpoint. In 2020 a second audit was announced and the final audit report was made available on Cure53's website: The results of this May-June 2020 project targeting the Mullvad complex are quite positive. [...] The overall application ecosystem used by Mullvad leaves a sound and structured impression. The overall structure of the application makes it easy to roll out patches and fixes in a structured manner. More than anything, the findings spotted by Cure53 showcase the importance of constantly auditing and re-assessing the current leak vectors, in order to always ensure privacy of the end-users. With that being said, Mullvad does a great job protecting the end-user from common PII leaks and privacy related risks. In 2021 an infrastructure audit was announced and the final audit report was made available on Cure53's website. Open Source Clients Mullvad provides the source code for their desktop and mobile clients in their GitHub organization . Accepts Cash and Monero Mullvad, in addition to accepting credit/debit cards and PayPal, accepts Bitcoin, Bitcoin Cash, Monero and cash/local currency as anonymous forms of payment. They also accept Swish and bank wire transfers. WireGuard Support Mullvad supports the WireGuard\u00ae protocol. WireGuard is a newer protocol that utilizes state-of-the-art cryptography . Additionally, WireGuard aims to be simpler and more performant. Mullvad recommends the use of WireGuard with their service. It is the default or only protocol on Mullvad's Android, iOS, macOS, and Linux apps, but on Windows you have to manually enable WireGuard. Mullvad also offers a WireGuard configuration generator for use with the official WireGuard apps . IPv6 Support Mullvad supports the future of networking IPv6 . Their network allows you to access services hosted on IPv6 as opposed to other providers who block IPv6 connections. Remote Port Forwarding Remote port forwarding is allowed for people who make one-time payments, but not allowed for accounts with a recurring/subscription-based payment method. This is to prevent Mullvad from being able to identify you based on your port usage and stored subscription information. See Port forwarding with Mullvad VPN for more information. Mobile Clients Mullvad has published App Store and Google Play clients, both supporting an easy-to use interface as opposed to requiring you to manually configure your WireGuard connection. The mobile client on Android is also available in F-Droid , which ensures that it is compiled with reproducible builds . Additional Functionality Mullvad is very transparent about which nodes they own or rent . They use ShadowSocks in their ShadowSocks + OpenVPN configuration, making them more resistant against firewalls with Deep Packet Inspection trying to block VPNs. Supposedly, China has to use a different method to block ShadowSocks servers . Mullvad's website is also accessible via Tor at o54hon2e2vj6c7m3aqqu6uyece65by3vgoxxhlqlsvkmacw6a7m7kiad.onion .","title":"Mullvad"},{"location":"vpn/#protonvpn","text":"Recommendation ProtonVPN is a strong contender in the VPN space, and they have been in operation since 2016. ProtonVPN is based in Switzerland and offers a limited free pricing tier, as well as premium options. They offer a further 14% discount for buying a 2 year subscription. Free - Basic Plan USD $48/year - Plus Plan USD $96/year Website 63 Countries ProtonVPN has servers in 63 countries (1). Picking a VPN provider with a server nearest to you will reduce latency of the network traffic you send. This is because of a shorter route (less hops) to the destination. We also think it's better for the security of the VPN provider's private keys if they use dedicated servers , instead of cheaper shared solutions (with other customers) such as virtual private servers . As of 2022/05/17 Independently Audited As of January 2020 ProtonVPN has undergone an independent audit by SEC Consult. SEC Consult found some medium and low risk vulnerabilities in ProtonVPN's Windows, Android, and iOS applications, all of which were \"properly fixed\" by ProtonVPN before the reports were published. None of the issues identified would have provided an attacker remote access to your device or traffic. You can view individual reports for each platform at protonvpn.com . Open Source Clients ProtonVPN provides the source code for their desktop and mobile clients in their GitHub organization . Accepts Cash ProtonVPN, in addition to accepting credit/debit cards and PayPal, accepts Bitcoin, and cash/local currency as anonymous forms of payment. WireGuard Support ProtonVPN mostly supports the WireGuard\u00ae protocol. WireGuard is a newer protocol that utilizes state-of-the-art cryptography . Additionally, WireGuard aims to be simpler and more performant. ProtonVPN recommends the use of WireGuard with their service. On ProtonVPN's Windows, macOS, iOS, Android, ChromeOS, and Android TV apps, WireGuard is the default protocol; however, support for the protocol is not present in their Linux app. Remote Port Forwarding ProtonVPN currently only supports remote port forwarding on Windows, which may impact some applications. Especially Peer-to-Peer applications like Torrent clients. Mobile Clients In addition to providing standard OpenVPN configuration files, ProtonVPN has mobile clients for App Store and Google Play allowing for easy connections to their servers. The mobile client on Android is also available in F-Droid , which ensures that it is compiled with reproducible builds . Additional Functionality ProtonVPN have their own servers and datacenters in Switzerland, Iceland and Sweden. They offer adblocking and known malware domains blocking with their DNS service. Additionally, ProtonVPN also offers \"Tor\" servers allowing you to easily connect to onion sites, but we still strongly recommend using the official Tor Browser for this purpose.","title":"ProtonVPN"},{"location":"vpn/#ivpn","text":"Recommendation IVPN is another premium VPN provider, and they have been in operation since 2009. IVPN is based in Gibraltar. Standard USD $60/year - Pro USD $100/year Website 32 Countries IVPN has servers in 32 countries (1). Picking a VPN provider with a server nearest to you will reduce latency of the network traffic you send. This is because of a shorter route (less hops) to the destination. We also think it's better for the security of the VPN provider's private keys if they use dedicated servers , instead of cheaper shared solutions (with other customers) such as virtual private servers . As of 2022/05/17 Independently Audited IVPN has undergone a no-logging audit from Cure53 which concluded in agreement with IVPN's no-logging claim. IVPN has also completed a comprehensive pentest report Cure53 in January 2020. IVPN has also said they plan to have annual reports in the future. Open Source Clients As of Feburary 2020 IVPN applications are now open source . Source code can be obtained from their GitHub organization . Accepts Cash and Monero In addition to accepting credit/debit cards and PayPal, IVPN accepts Bitcoin, Monero and cash/local currency (on annual plans) as anonymous forms of payment. WireGuard Support IVPN supports the WireGuard\u00ae protocol. WireGuard is a newer protocol that utilizes state-of-the-art cryptography . Additionally, WireGuard aims to be simpler and more performant. IVPN recommends the use of WireGuard with their service and, as such, the protocol is the default on all of IVPN's apps. IVPN also offers a WireGuard configuration generator for use with the official WireGuard apps . Remote Port Forwarding Remote port forwarding is possible with a Pro plan. Port forwarding can be activated via the client area. Port forwarding is only available on IVPN when using WireGuard or OpenVPN protocols and is disabled on US servers . Mobile Clients In addition to providing standard OpenVPN configuration files, IVPN has mobile clients for App Store and Google Play allowing for easy connections to their servers. The mobile client on Android is also available in F-Droid , which ensures that it is compiled with reproducible builds . Additional Functionality IVPN clients support two factor authentication (Mullvad and ProtonVPN clients do not). IVPN also provides \" AntiTracker \" functionality, which blocks advertising networks and trackers from the network level.","title":"IVPN"},{"location":"vpn/#our-criteria","text":"Danger It is important to note that using a VPN provider will not make you anonymous, but it will give you better privacy in certain situations. A VPN is not a tool for illegal activities. Don't rely on a \"no log\" policy. Please note we are not affiliated with any of the providers we recommend. This allows us to provide completely objective recommendations. We have developed a clear set of requirements for any VPN provider wishing to be recommended, including strong encryption, independent security audits, modern technology, and more. We suggest you familiarize yourself with this list before choosing a VPN provider, and conduct your own research to ensure the VPN provider you choose is as trustworthy as possible.","title":"Our Criteria"},{"location":"vpn/#jurisdiction","text":"Operating outside the five/nine/fourteen-eyes countries is not a guarantee of privacy necessarily, and there are other factors to consider. However, we believe that avoiding these countries is important if you wish to avoid mass government dragnet surveillance, especially from the United States. Minimum to Qualify: Operating outside the USA or other Five Eyes countries. Best Case: Operating outside the USA or other Fourteen Eyes countries. Operating inside a country with strong consumer protection laws.","title":"Jurisdiction"},{"location":"vpn/#technology","text":"We require all our recommended VPN providers to provide OpenVPN configuration files to be used in any client. If a VPN provides their own custom client, we require a killswitch to block network data leaks when disconnected. Minimum to Qualify: Support for strong protocols such as WireGuard & OpenVPN. Killswitch built in to clients. Multihop support. Multihopping is important to keep data private in case of a single node compromise. If VPN clients are provided, they should be open source , like the VPN software they generally have built into them. We believe that source code availability provides greater transparency about what your device is actually doing. We like to see these applications available in F-Droid . Best Case: WireGuard and OpenVPN support. Killswitch with highly configurable options (enable/disable on certain networks, on boot, etc.) Easy-to-use VPN clients Supports IPv6 . We expect that servers will allow incoming connections via IPv6 and allow you to access services hosted on IPv6 addresses. Capability of remote port forwarding assists in creating connections when using P2P ( Peer-to-Peer ) filesharing software, Freenet, or hosting a server (e.g., Mumble).","title":"Technology"},{"location":"vpn/#privacy","text":"We prefer our recommended providers to collect as little data as possible. Not collecting personal information on registration, and accepting anonymous forms of payment are required. Minimum to Qualify: Monero or cash payment option. No personal information required to register: Only username, password, and email at most. Best Case: Accepts Monero, cash, and other forms of anonymous payment options (gift cards, etc.) No personal information accepted (autogenerated username, no email required, etc.)","title":"Privacy"},{"location":"vpn/#security","text":"A VPN is pointless if it can't even provide adequate security. We require all our recommended providers to abide by current security standards for their OpenVPN connections. Ideally, they would use more future-proof encryption schemes by default. We also require an independent third-party to audit the provider's security, ideally in a very comprehensive manner and on a repeated (yearly) basis. Minimum to Qualify: Strong Encryption Schemes: OpenVPN with SHA-256 authentication; RSA-2048 or better handshake; AES-256-GCM or AES-256-CBC data encryption. Perfect Forward Secrecy (PFS). Published security audits from a reputable third-party firm. Best Case: Strongest Encryption: RSA-4096. Perfect Forward Secrecy (PFS). Comprehensive published security audits from a reputable third-party firm. Bug-bounty programs and/or a coordinated vulnerability-disclosure process.","title":"Security"},{"location":"vpn/#trust","text":"You wouldn't trust your finances to someone with a fake identity, so why trust them with your internet data? We require our recommended providers to be public about their ownership or leadership. We also would like to see frequent transparency reports, especially in regard to how government requests are handled. Minimum to Qualify: Public-facing leadership or ownership. Best Case: Public-facing leadership. Frequent transparency reports.","title":"Trust"},{"location":"vpn/#marketing","text":"With the VPN providers we recommend we like to see responsible marketing. Minimum to Qualify: Must self host analytics (no Google Analytics etc). The provider's site must also comply with DNT (Do Not Track) for people who want to opt-out. Must not have any marketing which is irresponsible: Making guarantees of protecting anonymity 100%. When someone makes a claim that something is 100% it means there is no certainty for failure. We know people can quite easily deanonymize themselves in a number of ways, eg: Reusing personal information eg. (email accounts, unique pseudonyms etc) that they accessed without anonymity software (Tor, VPN etc) Browser fingerprinting Claim that a single circuit VPN is \"more anonymous\" than Tor, which is a circuit of 3 or more hops that regularly changes. Use responsible language, eg it is okay to say that a VPN is \"disconnected\" or \"not connected\", however claiming that someone is \"exposed\", \"vulnerable\" or \"compromised\" is needless use of alarming language that may be incorrect. For example, that person might simply be on another VPN provider's service or using Tor. Best Case: Responsible marketing that is both educational and useful to the consumer could include: An accurate comparison to when Tor or other self-contained networks should be used. Availability of the VPN provider's website over a .onion Hidden Service","title":"Marketing"},{"location":"vpn/#additional-functionality","text":"While not strictly requirements, there are some factors we looked into when determining which providers to recommend. These include adblocking/tracker-blocking functionality, warrant canaries, multihop connections, excellent customer support, the number of allowed simultaneous connections, etc.","title":"Additional Functionality"},{"location":"vpn/#vpn-overview","text":"","title":"VPN Overview"},{"location":"vpn/#should-i-use-a-vpn","text":"Yes , unless you are already using Tor. A VPN does 2 things: shifting the risks from your Internet Service Provider to itself and hiding your IP from a third party service. VPNs cannot encrypt data outside of the connection between your device and the VPN server. VPN providers can see and modify your traffic the same way your ISP could. And there is no way to verify a VPN provider's \"no logging\" policies in any way. However, they do hide your actual IP from a third party service, provided that there are no IP leaks. They help you blend in with others and mitigate IP based tracking.","title":"Should I use a VPN?"},{"location":"vpn/#what-about-encryption","text":"Encryption offered by VPN providers are between your devices and their servers. It guarantees that this specific link is secure. This is a step up from using unencrypted proxies where an adversary on the network can intercept the communications between your devices and said proxies and modify them. However, encryption between your apps or browsers with the service providers are not handled by this encryption. In order to keep what you actually do on the websites you visit private and secure, you must use HTTPS . This will keep your passwords, session tokens, and queries safe from the VPN provider. Consider enabling \" HTTPS everywhere\" in your browser to mitigate downgrade attacks like SSL Strip .","title":"What about encryption?"},{"location":"vpn/#should-i-use-encrypted-dns-with-a-vpn","text":"Unless your VPN provider hosts the encrypted DNS servers, no . Using DOH/DOT (or any other form of encrypted DNS ) with third party servers will simply add more entities to trust, and does absolutely nothing to improve your privacy/security. Your VPN provider can still see which websites you visit based on the IP addresses and other methods. Instead of just trusting your VPN provider, you are now trusting both the VPN provider and the DNS provider. A common reason to recommend encrypted DNS is that it helps against DNS spoofing. However, your browser should already be checking for TLS certificates with HTTPS and warn you about it. If you are not using HTTPS , then an adversary can still just modify anything other than your DNS queries and the end result will be little different. Needless to say, you shouldn't use encrypted DNS with Tor . This would direct all of your DNS requests through a single circuit, and would allow the encrypted DNS provider to deanonymize you.","title":"Should I use encrypted DNS with a VPN?"},{"location":"vpn/#should-i-use-tor-and-a-vpn","text":"By using a VPN with Tor, you're creating essentially a permanent entry node, often with a money trail attached. This provides zero additional benefit to you, while increasing the attack surface of your connection dramatically. If you wish to hide your Tor usage from your ISP or your government, Tor has a built-in solution for that: Tor bridges. Read more about Tor bridges and why using a VPN is not necessary .","title":"Should I use Tor and a VPN?"},{"location":"vpn/#what-if-i-need-anonymity","text":"VPNs cannot provide anonymity. Your VPN provider will still see your real IP address, and often has a money trail that can be linked directly back to you. You cannot rely on \"no logging\" policies to protect your data. Use Tor instead.","title":"What if I need anonymity?"},{"location":"vpn/#what-about-vpn-providers-that-provides-tor-nodes","text":"Do not use that feature. The point of using Tor is that you do not trust your VPN provider. Currently Tor only supports the TCP protocol. UDP (used in WebRTC for voice and video sharing, the new http3/QUIC protocol, etc), ICMP and other packets will be dropped. To compensate for this, VPN providers typically will route all non TCP packets through their VPN server (your first hop). This is the case with ProtonVPN . Additionally, when using this Tor over VPN setup, you do not have control over other important Tor features such as Isolated Destination Address (using a different Tor circuit for every domain you visit). Thus, this feature should be viewed as a convenient way to access the Tor Network, not to stay annonymous. For true anonimity, use the Tor Browser Bundle, TorSocks, or a Tor gateway.","title":"What about VPN providers that provides Tor nodes?"},{"location":"vpn/#when-are-vpns-useful","text":"A VPN may still be useful to you in a variety of scenarios, such as: Hiding your traffic from only your Internet Service Provider. Hiding your downloads (such as torrents) from your ISP and anti-piracy organizations. Hiding your IP from third party websites and services, preventing IP based tracking. For use cases like these, or if you have another compelling reason, the VPN providers we listed above are who we think are the most trustworthy. However, using a VPN provider still means you're trusting the provider. In pretty much any other scenario you should be using a secure -by-design tool such as Tor.","title":"When are VPNs useful?"},{"location":"vpn/#sources-and-further-reading","text":"VPN - a Very Precarious Narrative by Dennis Schubert The self-contained networks recommended by Privacy Guides are able to replace a VPN that allows access to services on local area network Slicing Onions: Part 1 \u2013 Myth-busting Tor by blacklight447 Slicing Onions: Part 2 \u2013 Onion recipes; VPN not required by blacklight447 IVPN Privacy Guides \"Do I need a VPN ?\" , a tool developed by IVPN to challenge aggressive VPN marketing by helping individuals decide if a VPN is right for them.","title":"Sources and Further Reading"},{"location":"vpn/#related-vpn-information","text":"The Trouble with VPN and Privacy Review Sites Proxy.sh VPN Provider Sniffed Server Traffic to Catch Hacker blackVPN announced to delete connection logs after disconnection Don't use LT2P IPSec, use other protocols. Free VPN App Investigation Hidden VPN owners unveiled: 101 VPN products run by just 23 companies This Chinese company is secretly behind 24 popular apps seeking dangerous permissions","title":"Related VPN information"},{"location":"vpn/#vpn-related-breaches-why-external-auditing-is-important","text":"\"Zero logs\" VPN exposes millions of logs including user passwords, claims data is anonymous July 2020 NordVPN HTTP POST bug exposed customer information, no authentication required March 2020 Row erupts over who to blame after NordVPN says: One of our servers was hacked via remote management tool October 2019 VPN servers seized by Ukrainian authorities weren't encrypted and allowed authorities to impersonate Windscribe servers and capture and decrypt traffic passing through them July 2021","title":"VPN Related breaches - why external auditing is important"},{"location":"about/donate/","text":"It takes a lot of people and work to keep Privacy Guides up to date and spreading the word about privacy and mass surveillance. If you like what we do, the best way to help out is by getting involved by editing the site or contributing translations . If you want to support us financially, the most convenient method for us is contributing via Open Collective, a website operated by our fiscal host. Open Collective accepts payments via credit/debit card, PayPal, and bank transfers. Donate on OpenCollective.com Donations made directly to us Open Collective are generally tax-deductible in the US, because our fiscal host (the Open Collective Foundation) is a registered 501(c)3 organization. You will receive a receipt from the Open Collective Foundation after donating. Privacy Guides does not provide financial advice, and you should contact your tax advisor to find out whether this is applicable to you. If you already make use of GitHub sponsorships, you can also sponsor our organization there. Sponsor us on GitHub Backers \u00b6 A special thanks to all those who support our mission! Please note: This section loads a widget directly from Open Collective. This section does not reflect donations made outside of Open Collective, and we have no control over the specific donors featured in this section. How We Use Donations \u00b6 Privacy Guides is a non-profit organization. We use donations for a variety of purposes, including: Domain Registrations We have a few domain names like privacyguides.org which cost us around $10 yearly to maintain their registration. Web Hosting Traffic to this website uses hundreds of gigabytes of data per month, we use a variety of service providers to keep up with this traffic. Online Services We host internet services for testing and showcasing different privacy-products we like and recommend . Some of which are made publicly available for our community's use (SearXNG, Tor, etc.), and some are provided for our team members (email, etc.). Product Purchases We occasionally purchase products and services for the purposes of testing our recommended tools . We are still working with our fiscal host (the Open Collective Foundation) to receive cryptocurrency donations, at the moment the accounting is unfeasible for many smaller transactions, but this should change in the future. In the meantime, if you wish to make a sizable (> $100) cryptocurrency donation please reach out to jonah@privacyguides.org .","title":"Supporting Us"},{"location":"about/donate/#backers","text":"A special thanks to all those who support our mission! Please note: This section loads a widget directly from Open Collective. This section does not reflect donations made outside of Open Collective, and we have no control over the specific donors featured in this section.","title":"Backers"},{"location":"about/donate/#how-we-use-donations","text":"Privacy Guides is a non-profit organization. We use donations for a variety of purposes, including: Domain Registrations We have a few domain names like privacyguides.org which cost us around $10 yearly to maintain their registration. Web Hosting Traffic to this website uses hundreds of gigabytes of data per month, we use a variety of service providers to keep up with this traffic. Online Services We host internet services for testing and showcasing different privacy-products we like and recommend . Some of which are made publicly available for our community's use (SearXNG, Tor, etc.), and some are provided for our team members (email, etc.). Product Purchases We occasionally purchase products and services for the purposes of testing our recommended tools . We are still working with our fiscal host (the Open Collective Foundation) to receive cryptocurrency donations, at the moment the accounting is unfeasible for many smaller transactions, but this should change in the future. In the meantime, if you wish to make a sizable (> $100) cryptocurrency donation please reach out to jonah@privacyguides.org .","title":"How We Use Donations"},{"location":"about/notices/","text":"Legal Disclaimer \u00b6 Privacy Guides is not a law firm. As such, the Privacy Guides website and contributors are not providing legal advice. The material and recommendations in our website and guides do not constitute legal advice nor does contributing to the website or communicating with Privacy Guides or other contributors about our website create an attorney-client relationship. Running this website, like any human endeavor, involves uncertainty and trade-offs. We hope this website helps, but it may include mistakes and can\u2019t address every situation. If you have any questions about your situation, we encourage you to do your own research, seek out other experts, and engage in discussions with the Privacy Guides community. If you have any legal questions, you should consult with your own legal counsel before moving forward. Privacy Guides is an open source project contributed to under licenses that include terms that, for the protection of the website and its contributors, make clear that the Privacy Guides project and website is offered \"as-is\", without warranty, and disclaiming liability for damages resulting from using the website or any recommendations contained within. Privacy Guides does not warrant or make any representations concerning the accuracy, likely results, or reliability of the use of the materials on the website or otherwise relating to such materials on the website or on any third-party sites linked on this site. Privacy Guides additionally does not warrant that this website will be constantly available, or available at all. Licenses \u00b6 Unless otherwise noted, all content on this website is made freely available under the terms of the Creative Commons CC0 1.0 Universal . This does not include third-party code embedded in this repository, or code where a superseding license is otherwise noted. The following are notable examples, but this list may not be all-inclusive: MathJax is licensed under the Apache License 2.0 . Portions of this notice itself were adopted from opensource.guide on GitHub. That resource and this page itself are released under CC-BY-4.0 . This means that you can use the human-readable content in this repository for your own project, per the terms outlined in the CC0 1.0 Universal text. You may not use the Privacy Guides branding in your own project without express approval from this project. Privacy Guides's brand trademarks include the \"Privacy Guides\" wordmark and shield logo. We believe that the logos and other images in assets obtained from third-party providers are either in the public domain or fair use . In a nutshell, legal fair use doctrine allows the use of copyrighted images in order to identify the subject matter for purposes of public comment. However, these logos and other images may still be subject to trademark laws in one or more jurisdictions. Before using this content, please ensure that it is used to identify the entity or organization that owns the trademark and that you have the right to use it under the laws which apply in the circumstances of your intended use. When copying content from this website, you are solely responsible for ensuring that you do not infringe someone else's trademark or copyright. When you contribute to this repository you are doing so under the above licenses. Acceptable Use \u00b6 You may not use this website in any way that causes or may cause damage to the website or impairment of the availability or accessibility of Privacy Guides, or in any way which is unlawful, illegal, fraudulent, harmful, or in connection with any unlawful, illegal, fraudulent, or harmful purpose or activity. You must not conduct any systematic or automated data collection activities on or in relation to this website without express written consent from Aragon Ventures LLC, including: Excessive Automated Scans Denial of Service Attacks Scraping Data Mining 'Framing' (IFrames)","title":"Notices and Disclaimers"},{"location":"about/notices/#legal-disclaimer","text":"Privacy Guides is not a law firm. As such, the Privacy Guides website and contributors are not providing legal advice. The material and recommendations in our website and guides do not constitute legal advice nor does contributing to the website or communicating with Privacy Guides or other contributors about our website create an attorney-client relationship. Running this website, like any human endeavor, involves uncertainty and trade-offs. We hope this website helps, but it may include mistakes and can\u2019t address every situation. If you have any questions about your situation, we encourage you to do your own research, seek out other experts, and engage in discussions with the Privacy Guides community. If you have any legal questions, you should consult with your own legal counsel before moving forward. Privacy Guides is an open source project contributed to under licenses that include terms that, for the protection of the website and its contributors, make clear that the Privacy Guides project and website is offered \"as-is\", without warranty, and disclaiming liability for damages resulting from using the website or any recommendations contained within. Privacy Guides does not warrant or make any representations concerning the accuracy, likely results, or reliability of the use of the materials on the website or otherwise relating to such materials on the website or on any third-party sites linked on this site. Privacy Guides additionally does not warrant that this website will be constantly available, or available at all.","title":"Legal Disclaimer"},{"location":"about/notices/#licenses","text":"Unless otherwise noted, all content on this website is made freely available under the terms of the Creative Commons CC0 1.0 Universal . This does not include third-party code embedded in this repository, or code where a superseding license is otherwise noted. The following are notable examples, but this list may not be all-inclusive: MathJax is licensed under the Apache License 2.0 . Portions of this notice itself were adopted from opensource.guide on GitHub. That resource and this page itself are released under CC-BY-4.0 . This means that you can use the human-readable content in this repository for your own project, per the terms outlined in the CC0 1.0 Universal text. You may not use the Privacy Guides branding in your own project without express approval from this project. Privacy Guides's brand trademarks include the \"Privacy Guides\" wordmark and shield logo. We believe that the logos and other images in assets obtained from third-party providers are either in the public domain or fair use . In a nutshell, legal fair use doctrine allows the use of copyrighted images in order to identify the subject matter for purposes of public comment. However, these logos and other images may still be subject to trademark laws in one or more jurisdictions. Before using this content, please ensure that it is used to identify the entity or organization that owns the trademark and that you have the right to use it under the laws which apply in the circumstances of your intended use. When copying content from this website, you are solely responsible for ensuring that you do not infringe someone else's trademark or copyright. When you contribute to this repository you are doing so under the above licenses.","title":"Licenses"},{"location":"about/notices/#acceptable-use","text":"You may not use this website in any way that causes or may cause damage to the website or impairment of the availability or accessibility of Privacy Guides, or in any way which is unlawful, illegal, fraudulent, harmful, or in connection with any unlawful, illegal, fraudulent, or harmful purpose or activity. You must not conduct any systematic or automated data collection activities on or in relation to this website without express written consent from Aragon Ventures LLC, including: Excessive Automated Scans Denial of Service Attacks Scraping Data Mining 'Framing' (IFrames)","title":"Acceptable Use"},{"location":"about/privacy-policy/","text":"Privacy Guides is a community project operated by a number of active volunteer contributors. The public list of team members can be found on GitHub . Data We Collect From Visitors \u00b6 The privacy of our website visitors is important to us, so we do not track any individual people. As a visitor to our website: No personal information is collected No information such as cookies is stored in the browser No information is shared with, sent to or sold to third-parties No information is shared with advertising companies No information is mined and harvested for personal and behavioral trends No information is monetized You can view the data we collect at stats.privacyguides.net/privacyguides.org . We run a self-hosted installation of Plausible Analytics to collect some anonymous usage data for statistical purposes. The goal is to track overall trends in our website traffic, it is not to track individual visitors. All the data is in aggregate only. No personal data is collected. Data collected includes referral sources, top pages, visit duration, information from the devices (device type, operating system, country and browser) used during the visit and more. You can learn more about how Plausible works and collects information in a privacy-respecting manner here . Data We Collect From Account Holders \u00b6 On some websites and services we provide, many features may require an account. For example, an account may be required to post and reply to topics on a forum platform. To sign up for most accounts, we will collect a name, username, email, and password. In the event a website requires more information than just that data, that will be clearly marked and noted in a separate privacy statement per-site. We use your account data to identify you on the website and to create pages specific to you, such as your profile page. We will also use your account data to publish a public profile for you on our services. We use your email to: Notify you about posts and other activity on the websites or services. Reset your password and help keep your account secure. Contact you in special circumstances related to your account. Contact you about legal requests, such as DMCA takedown requests. On some websites and services you may provide additional information for your account, such as a short biography, avatar, your location, or your birthday. We make that information available to everyone who can access the website or service in question. This information is not required to use any of our services and can be erased at any time. We will store your account data as long as your account remains open. After closing an account, we may retain some or all of your account data in the form of backups or archives for up to 90 days. Contacting Us \u00b6 The Privacy Guides team generally does not have access to personal data outside of limited access granted via some moderation panels. Inquiries regarding your personal information should be sent directly to: Jonah Aragon Services Administrator jonah@privacyguides.org For all other inquiries, you can contact any member of our team. For complaints under GDPR more generally, you may lodge complaints with your local data protection supervisory authorities. About This Policy \u00b6 We will post any new versions of this statement here . We may change how we announce changes in future versions of this document. In the meantime we may update our contact information at any time without announcing a change. Please refer to the Privacy Policy for the latest contact information at any time. A full revision history of this page can be found on GitHub.","title":"Privacy Policy"},{"location":"about/privacy-policy/#data-we-collect-from-visitors","text":"The privacy of our website visitors is important to us, so we do not track any individual people. As a visitor to our website: No personal information is collected No information such as cookies is stored in the browser No information is shared with, sent to or sold to third-parties No information is shared with advertising companies No information is mined and harvested for personal and behavioral trends No information is monetized You can view the data we collect at stats.privacyguides.net/privacyguides.org . We run a self-hosted installation of Plausible Analytics to collect some anonymous usage data for statistical purposes. The goal is to track overall trends in our website traffic, it is not to track individual visitors. All the data is in aggregate only. No personal data is collected. Data collected includes referral sources, top pages, visit duration, information from the devices (device type, operating system, country and browser) used during the visit and more. You can learn more about how Plausible works and collects information in a privacy-respecting manner here .","title":"Data We Collect From Visitors"},{"location":"about/privacy-policy/#data-we-collect-from-account-holders","text":"On some websites and services we provide, many features may require an account. For example, an account may be required to post and reply to topics on a forum platform. To sign up for most accounts, we will collect a name, username, email, and password. In the event a website requires more information than just that data, that will be clearly marked and noted in a separate privacy statement per-site. We use your account data to identify you on the website and to create pages specific to you, such as your profile page. We will also use your account data to publish a public profile for you on our services. We use your email to: Notify you about posts and other activity on the websites or services. Reset your password and help keep your account secure. Contact you in special circumstances related to your account. Contact you about legal requests, such as DMCA takedown requests. On some websites and services you may provide additional information for your account, such as a short biography, avatar, your location, or your birthday. We make that information available to everyone who can access the website or service in question. This information is not required to use any of our services and can be erased at any time. We will store your account data as long as your account remains open. After closing an account, we may retain some or all of your account data in the form of backups or archives for up to 90 days.","title":"Data We Collect From Account Holders"},{"location":"about/privacy-policy/#contacting-us","text":"The Privacy Guides team generally does not have access to personal data outside of limited access granted via some moderation panels. Inquiries regarding your personal information should be sent directly to: Jonah Aragon Services Administrator jonah@privacyguides.org For all other inquiries, you can contact any member of our team. For complaints under GDPR more generally, you may lodge complaints with your local data protection supervisory authorities.","title":"Contacting Us"},{"location":"about/privacy-policy/#about-this-policy","text":"We will post any new versions of this statement here . We may change how we announce changes in future versions of this document. In the meantime we may update our contact information at any time without announcing a change. Please refer to the Privacy Policy for the latest contact information at any time. A full revision history of this page can be found on GitHub.","title":"About This Policy"},{"location":"android/grapheneos-vs-calyxos/","text":"Profiles \u00b6 CalyxOS includes a device controller app so there is no need to install a third party app like Shelter. GrapheneOS extends the user profile feature, allowing you to end a current session. To do this, select End Session which will clear the encryption key from memory. There are plans to add a cross profile notifications system in the future. GrapheneOS plans to introduce nested profile support with better isolation in the future. Sandboxed Google Play vs Privileged microG \u00b6 When Google Play services are used on GrapheneOS, they run as a user app and are contained within a user or work profile. Sandboxed Google Play is confined using the highly restrictive, default untrusted_app domain provided by SELinux . Permissions for apps to use Google Play Services can be revoked at any time. microG is an open-source re-implementation of Google Play Services. This means it needs to be updated every time Android has a major version update (or the Android API changes). It also needs to run in the highly privileged system_app SELinux domain like regular Google Play Services, and it requires an operating system that allows signature spoofing , which allows system apps to insecurely masquerade as other apps. This is less secure than Sandboxed Google Play's approach, which does not need access to sensitive system APIs. When using Sandboxed Play Services, you have the option to reroute location requests to the Play Services API back to the OS location API which uses satellite based location services. With microG, you have the option to either not use a network location backend at all, shift trust to another location backend like Mozilla, or use DejaVu , a location backend that locally collects and saves RF-based location data to an offline database which can be used when GPS is not available. Network location providers like Play Services or Mozilla rely the on the MAC addresses of surrounding WiFi access points and Bluetooth devices being submitted for location approximation. Choosing a network location like Mozilla to use with microG provides little to no privacy benefit over Google because you are still submitting the same data and trusting them to not profile you. Local RF location backends like DejaVu require that the phone has a working GPS first for the local RF data collected to be useful. This makes them ineffective as location providers, as the job of a location provider is to assist location approximation when satellite based services are not working. If your threat model requires protecting your location or the MAC addresses of nearby devices, rerouting location requests to the OS location API is probably the best option. The benefit brought by microG's custom location backend is minimal at best when compared to Sandboxed Play Services. In terms of application compatibility, Sandboxed Google Play outperforms microG due to its support for many services which microG has not yet implemented, like Google Play Games and In-app Billing API . Authentication using FIDO with online services on Android also relies on Play Services, and the feature is not yet implemented in microG. Privileged App Extensions \u00b6 Android 12 comes with special support for seamless app updates with third party app stores . The popular Free and Open Source Software (FOSS) repository F-Droid doesn't implement this feature and requires a privileged extension to be included with the Android distribution in order to have unattended app installation. GrapheneOS does not include F-Droid, because all updates have to be manually installed, which poses a security risk. However, you can use the Neo Store client for F-Droid which does support seamless (background) app updates in Android 12. GrapheneOS officially recommends Sandboxed Google Play instead. Many FOSS Android apps are also in Google Play but sometimes they are not (like NewPipe ). CalyxOS includes the privileged extension , which may lower device security. Seamless app updates should be possible with Aurora Store in Android 12. Additional hardening \u00b6 GrapheneOS improves upon AOSP security with: Hardened WebView: Vanadium WebView requires 64-bit processes on the WebView process and disables legacy 32-bit processes. It uses hardened compiler options such as -fwrapv and -fstack-protector-strong , which can help protect against stack buffer overflows . API s such as the battery status API are disabled for privacy reasons. All system apps on GrapheneOS use the Vanadium WebView which means that apps which use WebView will also benefit from Vanadium's hardening. The Vanadium patch set is a lot more comprehensive than CalyxOS's Chromium patch set which is derived from it. Hardened Kernel: GrapheneOS kernel includes some hardening from the linux-hardened project and the Kernel Self Protection Project (KSPP) . CalyxOS uses the same kernel as regular Android with some minor modifications. Hardened Memory Allocator: GrapheneOS uses the hardened malloc subproject as its memory allocator. This focuses on hardening against memory heap corruption . CalyxOS uses the default AOSP Scudo Malloc , which is generally less effective . Hardened Malloc has uncovered vulnerabilities in AOSP which have been fixed by GrapheneOS such as CVE-2021-0703 . Secure Exec Spawning: GrapheneOS spawns fresh processes as opposed to using the Zygote model used by AOSP and CalyxOS. The Zygote model weakens Address Space Layout Randomization (ASLR) and is considered less secure . Creating fresh processes is safer but will have some performance penalty when launching a new application. These penalties are not really noticeable unless you have an old device with slow storage such as the Pixel 3a/3a XL as it has eMMC . Please note that these are just a few examples and are not an extensive list of GrapheneOS's hardening . For a more complete list, please read GrapheneOS' official documentation .","title":"GrapheneOS vs CalyxOS"},{"location":"android/grapheneos-vs-calyxos/#profiles","text":"CalyxOS includes a device controller app so there is no need to install a third party app like Shelter. GrapheneOS extends the user profile feature, allowing you to end a current session. To do this, select End Session which will clear the encryption key from memory. There are plans to add a cross profile notifications system in the future. GrapheneOS plans to introduce nested profile support with better isolation in the future.","title":"Profiles"},{"location":"android/grapheneos-vs-calyxos/#sandboxed-google-play-vs-privileged-microg","text":"When Google Play services are used on GrapheneOS, they run as a user app and are contained within a user or work profile. Sandboxed Google Play is confined using the highly restrictive, default untrusted_app domain provided by SELinux . Permissions for apps to use Google Play Services can be revoked at any time. microG is an open-source re-implementation of Google Play Services. This means it needs to be updated every time Android has a major version update (or the Android API changes). It also needs to run in the highly privileged system_app SELinux domain like regular Google Play Services, and it requires an operating system that allows signature spoofing , which allows system apps to insecurely masquerade as other apps. This is less secure than Sandboxed Google Play's approach, which does not need access to sensitive system APIs. When using Sandboxed Play Services, you have the option to reroute location requests to the Play Services API back to the OS location API which uses satellite based location services. With microG, you have the option to either not use a network location backend at all, shift trust to another location backend like Mozilla, or use DejaVu , a location backend that locally collects and saves RF-based location data to an offline database which can be used when GPS is not available. Network location providers like Play Services or Mozilla rely the on the MAC addresses of surrounding WiFi access points and Bluetooth devices being submitted for location approximation. Choosing a network location like Mozilla to use with microG provides little to no privacy benefit over Google because you are still submitting the same data and trusting them to not profile you. Local RF location backends like DejaVu require that the phone has a working GPS first for the local RF data collected to be useful. This makes them ineffective as location providers, as the job of a location provider is to assist location approximation when satellite based services are not working. If your threat model requires protecting your location or the MAC addresses of nearby devices, rerouting location requests to the OS location API is probably the best option. The benefit brought by microG's custom location backend is minimal at best when compared to Sandboxed Play Services. In terms of application compatibility, Sandboxed Google Play outperforms microG due to its support for many services which microG has not yet implemented, like Google Play Games and In-app Billing API . Authentication using FIDO with online services on Android also relies on Play Services, and the feature is not yet implemented in microG.","title":"Sandboxed Google Play vs Privileged microG"},{"location":"android/grapheneos-vs-calyxos/#privileged-app-extensions","text":"Android 12 comes with special support for seamless app updates with third party app stores . The popular Free and Open Source Software (FOSS) repository F-Droid doesn't implement this feature and requires a privileged extension to be included with the Android distribution in order to have unattended app installation. GrapheneOS does not include F-Droid, because all updates have to be manually installed, which poses a security risk. However, you can use the Neo Store client for F-Droid which does support seamless (background) app updates in Android 12. GrapheneOS officially recommends Sandboxed Google Play instead. Many FOSS Android apps are also in Google Play but sometimes they are not (like NewPipe ). CalyxOS includes the privileged extension , which may lower device security. Seamless app updates should be possible with Aurora Store in Android 12.","title":"Privileged App Extensions"},{"location":"android/grapheneos-vs-calyxos/#additional-hardening","text":"GrapheneOS improves upon AOSP security with: Hardened WebView: Vanadium WebView requires 64-bit processes on the WebView process and disables legacy 32-bit processes. It uses hardened compiler options such as -fwrapv and -fstack-protector-strong , which can help protect against stack buffer overflows . API s such as the battery status API are disabled for privacy reasons. All system apps on GrapheneOS use the Vanadium WebView which means that apps which use WebView will also benefit from Vanadium's hardening. The Vanadium patch set is a lot more comprehensive than CalyxOS's Chromium patch set which is derived from it. Hardened Kernel: GrapheneOS kernel includes some hardening from the linux-hardened project and the Kernel Self Protection Project (KSPP) . CalyxOS uses the same kernel as regular Android with some minor modifications. Hardened Memory Allocator: GrapheneOS uses the hardened malloc subproject as its memory allocator. This focuses on hardening against memory heap corruption . CalyxOS uses the default AOSP Scudo Malloc , which is generally less effective . Hardened Malloc has uncovered vulnerabilities in AOSP which have been fixed by GrapheneOS such as CVE-2021-0703 . Secure Exec Spawning: GrapheneOS spawns fresh processes as opposed to using the Zygote model used by AOSP and CalyxOS. The Zygote model weakens Address Space Layout Randomization (ASLR) and is considered less secure . Creating fresh processes is safer but will have some performance penalty when launching a new application. These penalties are not really noticeable unless you have an old device with slow storage such as the Pixel 3a/3a XL as it has eMMC . Please note that these are just a few examples and are not an extensive list of GrapheneOS's hardening . For a more complete list, please read GrapheneOS' official documentation .","title":"Additional hardening"},{"location":"android/overview/","text":"Android is a secure operating system that has strong app sandboxing , Verified Boot ( AVB ), and a robust permission control system. Choosing an Android Distribution \u00b6 When you buy an Android phone, the device's default operating system often comes with invasive integration with apps and services that are not part of the Android Open Source Project . An example of such is Google Play Services, which has unrevokable privileges to access your files, contacts storage, call logs, SMS messages, location, camera, microphone, hardware identifiers, and so on. These apps and services increase the attack surface of your device and are the source of various privacy concerns with Android. This problem could be solved by using a custom Android distribution that does not come with such invasive integration. Unfortunately, many custom Android distributions often violate the Android security model by not supporting critical security features such as AVB , rollback protection, firmware updates, and so on. Some distributions also ship userdebug builds which expose root via ADB and require more permissive SELinux policies to accomodate debugging features, resulting in a further increased attack surface and weakened security model. Ideally, when choosing a custom Android distribution, you should make sure that it upholds the Android security model. At the very least, the distribution should have production builds, support for AVB , rollback protection, timely firmware and operating system updates, and SELinux in enforcing mode . All of our recommended Android distributions satisfy these criteria. Our Android System Recommendations Avoid Rooting \u00b6 Rooting Android phones can decrease security significantly as it weakens the complete Android security model . This can decrease privacy should there be an exploit that is assisted by the decreased security. Common rooting methods involve directly tampering with the boot partition, making it impossible to perform successful Verified Boot. Apps that require root will also modify the system partition meaning that Verified Boot would have to remain disabled. Having root exposed directly in the user interface also increases the attack surface of your device and may assist in privilege escalation vulnerabilities and SELinux policy bypasses. Adblockers which modify the hosts file (AdAway) and firewalls (AFWall+) which require root access persistently are dangerous and should not be used. They are also not the correct way to solve their intended purposes. For Adblocking we suggest encrypted DNS or VPN server blocking solutions instead. RethinkDNS, TrackerControl and AdAway in non-root mode will take up the VPN slot (by using a local loopback VPN ) preventing you from using privacy enhancing services such as Orbot or a real VPN server. AFWall+ works based on the packet filtering approach and may be bypassable in some situations. We do not believe that the security sacrifices made by rooting a phone are worth the questionable privacy benefits of those apps. Verified Boot \u00b6 Verified Boot is an important part of the Android security model. It provides protection against evil maid attacks, malware persistence, and ensures security updates cannot be downgraded with rollback protection . Android 10 and above has moved away from full-disk encryption to more flexible file-based encryption . Your data is encrypted using unique encryption keys, and the operating system files are left unencrypted. Verified Boot ensures the integrity of the operating system files, thereby preventing an adversary with physical access from tampering or installing malware on the device. In the unlikely case that malware is able to exploit other parts of the system and gain higher privileged access, Verified Boot will prevent and revert changes to the system partition upon rebooting device. Unfortunately, OEMs are only obliged to support Verified Boot on their stock Android distribution. Only a few OEMs such as Google support custom AVB key enrollment on their devices. Additionally, some AOSP derivatives such as LineageOS or /e/ OS do not support Verified Boot even on hardware with Verified Boot support for third party operating systems. We recommend that you check for support before purchasing a new device. AOSP derivatives which do not support Verified Boot are not recommended. Firmware Updates \u00b6 Firmware updates are critical for maintaining security and without them your device cannot be secure. OEMs have support agreements with their partners to provide the closed source components for a limited support period. These are detailed in the monthly Android Security Bulletins . As the components of the phone such as the processor and radio technologies rely on closed source components, the updates must be provided by the respective manufacturers. Therefore it is important that you purchase a device within an active support cycle. Qualcomm and Samsung support their devices for 4 years, while cheaper products often have shorter support cycles. With the introduction of the Pixel 6 , Google now makes their own SoC and they will provide a minimum of 5 years of support. EOL devices which are no longer supported by the SoC manufacturer cannot receive firmware updates from OEM vendors or after market Android distributors. This means that security issues with those devices will remain unfixed. Android Versions \u00b6 It's important to not use an end-of-life version of Android. Newer versions of Android not only receive security updates for the operating system but also important privacy enhancing updates too. For example, prior to Android 10 , any apps with the READ_PHONE_STATE permission could access sensitive and unique serial numbers of your phone such as IMEI , MEID , your SIM card's IMSI , whereas now they must be system apps to do so. System apps are only provided by the OEM or Android distribution. Android Permissions \u00b6 Permissions on Android grant you control over what apps are allowed to access. Google regularly makes improvements on the permission system in each successive version. All apps you install are strictly sandboxed , therefore there is no need to install any antivirus apps. The savings you make from not purchasing or subscribing to security apps is better spent on paying for a supported device in the future. Should you want to run an app that you're unsure about, consider using a user or work profile . User Profiles \u00b6 Multiple user profiles can be found in Settings \u2192 System \u2192 Multiple users and are the simplest way to isolate in Android. With user profiles, you can impose restrictions on a specific profile, such as: making calls, using SMS , or installing apps on the device. Each profile is encrypted using its own encryption key and cannot access the data of any other profiles. Even the device owner cannot view the data of other profiles without knowing their password. Multiple user profiles is a more secure method of isolation. Work Profile \u00b6 Work Profiles are another way to isolate individual apps and may be more convenient than separate user profiles. A device controller such as Shelter is required, unless you're using CalyxOS which includes one. The work profile is dependent on a device controller to function. Features such as File Shuttle and contact search blocking or any kind of isolation features must be implemented by the controller. You must also fully trust the device controller app, as it has full access to your data inside of the work profile. This method is generally less secure than a secondary user profile; however, it does allow you the convenience of running apps in both the work and personal profiles simultaneously. VPN Killswitch \u00b6 Android 7 and above supports a VPN killswitch and it is available without the need to install third party apps. This feature can prevent leaks if the VPN is disconnected. It can be found in ( Settings \u2192 Network & internet \u2192 VPN \u2192 \u2192 Block connections without VPN ). Global Toggles \u00b6 Modern Android devices have global toggles for disabling Bluetooth and location services. Android 12 introduced toggles for the camera and microphone. When not in use, we recommend disabling these features. Apps cannot use disabled features (even if granted individual permission) until re-enabled. Google \u00b6 If you are using a device with Google services, either your stock operating system or an operating system that safely sandboxes Google Play Services like GrapheneOS, there are a number of additional changes you can make to improve your privacy. We still recommend avoiding Google services entirely, or limiting Google Play services to a specific user/work profile by combining a device controller like Shelter with GrapheneOS's Sandboxed Google Play. Advanced Protection Program \u00b6 If you have a Google account we suggest enrolling in the Advanced Protection Program . It is available at no cost to anyone with two or more hardware security keys with FIDO support. The Advanced Protection Program provides enhanced threat monitoring and enables: Stricter two factor authentication; e.g. that FIDO must be used and disallows the use of SMS OTPs , TOTP , and OAuth Only Google and verified third party apps can access account data Scanning of incoming emails on Gmail accounts for phishing attempts Stricter safe browser scanning with Google Chrome Stricter recovery process for accounts with lost credentials If you use non-sandboxed Google Play Services (common on stock operating systems), the Advanced Protection Program also comes with additional benefits such as: Not allowing app installation outside of the Google Play Store, the OS vendor's app store, or via adb Mandatory automatic device scanning with Play Protect Warning you about unverified applications Google Play System Updates \u00b6 In the past, Android security updates had to be shipped by the operating system vendor. Android has become more modular beginning with Android 10, and Google can push security updates for some system components via the privileged Play Services. If you have an EOL device shipped with Android 10 or above and are unable to run any of our recommended operating systems on your device, you are likely going to be better off sticking with your OEM Android installation (as opposed to an operating system not listed here such as LineageOS or /e/ OS ). This will allow you to receive some security fixes from Google, while not violating the Android security model by using an insecure Android derivative and increasing your attack surface . We would still recommend upgrading to a supported device as soon as possible. Advertising ID \u00b6 All devices with Google Play Services installed automatically generate an advertising ID used for targeted advertising. Disable this feature to limit the data collected about you. On Android distributions with Sandboxed Google Play , go to Settings \u2192 Apps \u2192 Sandboxed Google Play \u2192 Google Settings \u2192 Ads , and select Delete advertising ID . On Android distributions with privileged Google Play Services (such as stock OSes), the setting may be in one of several locations. Check Settings \u2192 Google \u2192 Ads Settings \u2192 Privacy \u2192 Ads You will either be given the option to delete your advertising ID or to Opt out of interest-based ads , this varies between OEM distributions of Android. If presented with the option to delete the advertising ID that is preferred. If not, then make sure to opt out and reset your advertising ID. SafetyNet and Play Integrity API \u00b6 SafetyNet and the Play Integrity APIs are generally used for banking apps . Many banking apps will work fine in GrapheneOS with sandboxed Play services, however some non-financal apps have their own crude anti-tampering mechanisms which might fail. GrapheneOS passes the basicIntegrity check, but not the certification check ctsProfileMatch . Devices with Android 8 or later have hardware attestation support which cannot be bypassed without leaked keys or serious vulnerabilities. As for Google Wallet, we don't recommend this due to their privacy policy , which states you must opt-out if you don't want your credit rating and personal information shared with affiliate marketing services.","title":"Android Overview"},{"location":"android/overview/#choosing-an-android-distribution","text":"When you buy an Android phone, the device's default operating system often comes with invasive integration with apps and services that are not part of the Android Open Source Project . An example of such is Google Play Services, which has unrevokable privileges to access your files, contacts storage, call logs, SMS messages, location, camera, microphone, hardware identifiers, and so on. These apps and services increase the attack surface of your device and are the source of various privacy concerns with Android. This problem could be solved by using a custom Android distribution that does not come with such invasive integration. Unfortunately, many custom Android distributions often violate the Android security model by not supporting critical security features such as AVB , rollback protection, firmware updates, and so on. Some distributions also ship userdebug builds which expose root via ADB and require more permissive SELinux policies to accomodate debugging features, resulting in a further increased attack surface and weakened security model. Ideally, when choosing a custom Android distribution, you should make sure that it upholds the Android security model. At the very least, the distribution should have production builds, support for AVB , rollback protection, timely firmware and operating system updates, and SELinux in enforcing mode . All of our recommended Android distributions satisfy these criteria. Our Android System Recommendations","title":"Choosing an Android Distribution"},{"location":"android/overview/#avoid-rooting","text":"Rooting Android phones can decrease security significantly as it weakens the complete Android security model . This can decrease privacy should there be an exploit that is assisted by the decreased security. Common rooting methods involve directly tampering with the boot partition, making it impossible to perform successful Verified Boot. Apps that require root will also modify the system partition meaning that Verified Boot would have to remain disabled. Having root exposed directly in the user interface also increases the attack surface of your device and may assist in privilege escalation vulnerabilities and SELinux policy bypasses. Adblockers which modify the hosts file (AdAway) and firewalls (AFWall+) which require root access persistently are dangerous and should not be used. They are also not the correct way to solve their intended purposes. For Adblocking we suggest encrypted DNS or VPN server blocking solutions instead. RethinkDNS, TrackerControl and AdAway in non-root mode will take up the VPN slot (by using a local loopback VPN ) preventing you from using privacy enhancing services such as Orbot or a real VPN server. AFWall+ works based on the packet filtering approach and may be bypassable in some situations. We do not believe that the security sacrifices made by rooting a phone are worth the questionable privacy benefits of those apps.","title":"Avoid Rooting"},{"location":"android/overview/#verified-boot","text":"Verified Boot is an important part of the Android security model. It provides protection against evil maid attacks, malware persistence, and ensures security updates cannot be downgraded with rollback protection . Android 10 and above has moved away from full-disk encryption to more flexible file-based encryption . Your data is encrypted using unique encryption keys, and the operating system files are left unencrypted. Verified Boot ensures the integrity of the operating system files, thereby preventing an adversary with physical access from tampering or installing malware on the device. In the unlikely case that malware is able to exploit other parts of the system and gain higher privileged access, Verified Boot will prevent and revert changes to the system partition upon rebooting device. Unfortunately, OEMs are only obliged to support Verified Boot on their stock Android distribution. Only a few OEMs such as Google support custom AVB key enrollment on their devices. Additionally, some AOSP derivatives such as LineageOS or /e/ OS do not support Verified Boot even on hardware with Verified Boot support for third party operating systems. We recommend that you check for support before purchasing a new device. AOSP derivatives which do not support Verified Boot are not recommended.","title":"Verified Boot"},{"location":"android/overview/#firmware-updates","text":"Firmware updates are critical for maintaining security and without them your device cannot be secure. OEMs have support agreements with their partners to provide the closed source components for a limited support period. These are detailed in the monthly Android Security Bulletins . As the components of the phone such as the processor and radio technologies rely on closed source components, the updates must be provided by the respective manufacturers. Therefore it is important that you purchase a device within an active support cycle. Qualcomm and Samsung support their devices for 4 years, while cheaper products often have shorter support cycles. With the introduction of the Pixel 6 , Google now makes their own SoC and they will provide a minimum of 5 years of support. EOL devices which are no longer supported by the SoC manufacturer cannot receive firmware updates from OEM vendors or after market Android distributors. This means that security issues with those devices will remain unfixed.","title":"Firmware Updates"},{"location":"android/overview/#android-versions","text":"It's important to not use an end-of-life version of Android. Newer versions of Android not only receive security updates for the operating system but also important privacy enhancing updates too. For example, prior to Android 10 , any apps with the READ_PHONE_STATE permission could access sensitive and unique serial numbers of your phone such as IMEI , MEID , your SIM card's IMSI , whereas now they must be system apps to do so. System apps are only provided by the OEM or Android distribution.","title":"Android Versions"},{"location":"android/overview/#android-permissions","text":"Permissions on Android grant you control over what apps are allowed to access. Google regularly makes improvements on the permission system in each successive version. All apps you install are strictly sandboxed , therefore there is no need to install any antivirus apps. The savings you make from not purchasing or subscribing to security apps is better spent on paying for a supported device in the future. Should you want to run an app that you're unsure about, consider using a user or work profile .","title":"Android Permissions"},{"location":"android/overview/#user-profiles","text":"Multiple user profiles can be found in Settings \u2192 System \u2192 Multiple users and are the simplest way to isolate in Android. With user profiles, you can impose restrictions on a specific profile, such as: making calls, using SMS , or installing apps on the device. Each profile is encrypted using its own encryption key and cannot access the data of any other profiles. Even the device owner cannot view the data of other profiles without knowing their password. Multiple user profiles is a more secure method of isolation.","title":"User Profiles"},{"location":"android/overview/#work-profile","text":"Work Profiles are another way to isolate individual apps and may be more convenient than separate user profiles. A device controller such as Shelter is required, unless you're using CalyxOS which includes one. The work profile is dependent on a device controller to function. Features such as File Shuttle and contact search blocking or any kind of isolation features must be implemented by the controller. You must also fully trust the device controller app, as it has full access to your data inside of the work profile. This method is generally less secure than a secondary user profile; however, it does allow you the convenience of running apps in both the work and personal profiles simultaneously.","title":"Work Profile"},{"location":"android/overview/#vpn-killswitch","text":"Android 7 and above supports a VPN killswitch and it is available without the need to install third party apps. This feature can prevent leaks if the VPN is disconnected. It can be found in ( Settings \u2192 Network & internet \u2192 VPN \u2192 \u2192 Block connections without VPN ).","title":"VPN Killswitch"},{"location":"android/overview/#global-toggles","text":"Modern Android devices have global toggles for disabling Bluetooth and location services. Android 12 introduced toggles for the camera and microphone. When not in use, we recommend disabling these features. Apps cannot use disabled features (even if granted individual permission) until re-enabled.","title":"Global Toggles"},{"location":"android/overview/#google","text":"If you are using a device with Google services, either your stock operating system or an operating system that safely sandboxes Google Play Services like GrapheneOS, there are a number of additional changes you can make to improve your privacy. We still recommend avoiding Google services entirely, or limiting Google Play services to a specific user/work profile by combining a device controller like Shelter with GrapheneOS's Sandboxed Google Play.","title":"Google"},{"location":"android/overview/#advanced-protection-program","text":"If you have a Google account we suggest enrolling in the Advanced Protection Program . It is available at no cost to anyone with two or more hardware security keys with FIDO support. The Advanced Protection Program provides enhanced threat monitoring and enables: Stricter two factor authentication; e.g. that FIDO must be used and disallows the use of SMS OTPs , TOTP , and OAuth Only Google and verified third party apps can access account data Scanning of incoming emails on Gmail accounts for phishing attempts Stricter safe browser scanning with Google Chrome Stricter recovery process for accounts with lost credentials If you use non-sandboxed Google Play Services (common on stock operating systems), the Advanced Protection Program also comes with additional benefits such as: Not allowing app installation outside of the Google Play Store, the OS vendor's app store, or via adb Mandatory automatic device scanning with Play Protect Warning you about unverified applications","title":"Advanced Protection Program"},{"location":"android/overview/#google-play-system-updates","text":"In the past, Android security updates had to be shipped by the operating system vendor. Android has become more modular beginning with Android 10, and Google can push security updates for some system components via the privileged Play Services. If you have an EOL device shipped with Android 10 or above and are unable to run any of our recommended operating systems on your device, you are likely going to be better off sticking with your OEM Android installation (as opposed to an operating system not listed here such as LineageOS or /e/ OS ). This will allow you to receive some security fixes from Google, while not violating the Android security model by using an insecure Android derivative and increasing your attack surface . We would still recommend upgrading to a supported device as soon as possible.","title":"Google Play System Updates"},{"location":"android/overview/#advertising-id","text":"All devices with Google Play Services installed automatically generate an advertising ID used for targeted advertising. Disable this feature to limit the data collected about you. On Android distributions with Sandboxed Google Play , go to Settings \u2192 Apps \u2192 Sandboxed Google Play \u2192 Google Settings \u2192 Ads , and select Delete advertising ID . On Android distributions with privileged Google Play Services (such as stock OSes), the setting may be in one of several locations. Check Settings \u2192 Google \u2192 Ads Settings \u2192 Privacy \u2192 Ads You will either be given the option to delete your advertising ID or to Opt out of interest-based ads , this varies between OEM distributions of Android. If presented with the option to delete the advertising ID that is preferred. If not, then make sure to opt out and reset your advertising ID.","title":"Advertising ID"},{"location":"android/overview/#safetynet-and-play-integrity-api","text":"SafetyNet and the Play Integrity APIs are generally used for banking apps . Many banking apps will work fine in GrapheneOS with sandboxed Play services, however some non-financal apps have their own crude anti-tampering mechanisms which might fail. GrapheneOS passes the basicIntegrity check, but not the certification check ctsProfileMatch . Devices with Android 8 or later have hardware attestation support which cannot be bypassed without leaked keys or serious vulnerabilities. As for Google Wallet, we don't recommend this due to their privacy policy , which states you must opt-out if you don't want your credit rating and personal information shared with affiliate marketing services.","title":"SafetyNet and Play Integrity API"},{"location":"basics/account-deletion/","text":"Over time, it can be easy to accumulate a number of online accounts, many of which you may no longer use. Deleting these unused accounts is an important step in reclaiming your privacy, as dormant accounts are vulnerable to data breaches. A data breach is when a service's security is compromised and protected information is viewed, transmitted, or stolen by unauthorized actors. Data breaches are unfortunately all too common these days, and so practicing good digital hygiene is the best way to minimize the impact they have on your life. The goal of this guide then is to help navigate you through the irksome process of account deletion, often made difficult by deceptive design , for the betterment of your online presence. Finding Old Accounts \u00b6 Password Manager \u00b6 If you have a password manager that you've used for your entire digital life, this part will be very easy. Oftentimes, they include built-in functionality for detecting if your credentials were exposed in a data breach\u2014such as Bitwarden's Data Breach Report . Even if you haven't explicitly used a password manager before, there's a chance you've used the one in your browser or your phone without even realizing it. For example: Firefox Password Manager , Google Password Manager and Edge Password Manager . Desktop platforms also often have a password manager which may help you recover passwords you've forgotten about: Windows Credential Manager macOS Passwords iOS Passwords Linux, Gnome Keyring, which can be accessed through Seahorse , or KDE Wallet Manager Email \u00b6 If you didn't use a password manager in the past or you think you have accounts that were never added to your password manager, another option is to search the email account(s) that you believe you signed up on. On your email client, search for keywords such as \"verify\" or \"welcome.\" Almost every time you make an online account, the service will send a verification link or an introductory message to your email. This can be a good way to find old, forgotten accounts. Deleting Old Accounts \u00b6 Log In \u00b6 In order to delete your old accounts, you'll need to first make sure you can log in to them. Again, if the account was in your password manager, this step is easy. If not, you can try to guess your password. Failing that, there are typically options to regain access to your account, commonly available through a \"forgot password\" link on the login page. It may also be possible that accounts you've abandoned have already been deleted\u2014sometimes services prune all old accounts. When attempting to regain access, if the site returns an error message saying that email is not associated with an account, or you never receive a reset link after multiple attempts, then you do not have an account under that email address and should try a different one. If you can't figure out which email address you used, or you no longer have access to that email, you can try contacting the service's customer support. Unfortunately there is no guarantee that you will be able to reclaim access your account. GDPR ( EEA residents only) \u00b6 Residents of the EEA have additional rights regarding data erasure specified in Article 17 of the GDPR . If it's applicable to you, read the privacy policy for any given service to find information on how to exercise your right to erasure. Reading the privacy policy can prove important, as some services have a \"Delete Account\" option that only disables your account and for real deletion you have to take additional action. Sometimes actual deletion may involve filling out surveys, emailing the data protection officer of the service, or even proving your residence in the EEA . If you plan to go this way, do not overwrite account information\u2014your identity as an EEA resident may be required. Note that the location of the service does not matter; GDPR applies to anyone serving European users. If the service does not respect your right to erasure, you can contact your national Data Protection Authority and you may be entitled to monetary compensation. Overwriting Account information \u00b6 In some situations where you plan to abandon an account, it may make sense to overwrite the account information with fake data. Once you've made sure you can log in, change all the information in your account to falsified information. The reason for this is that many sites will retain information you previously had even after account deletion. The hope is that they will overwrite the previous information with the newest data you entered. However, there is no guarantee that there won't be backups with the prior information. For the account email, either create a new alternate email account via your provider of choice or create an alias using an email aliasing service . You can then delete your alternate email address once you are done. We recommend against using temporary email providers, as oftentimes it is possible to reactivate temporary emails. Delete \u00b6 You can check JustDeleteMe for instructions on deleting the account for a specific service. Some sites will graciously have a \"Delete Account\" option, while others will go as far as to force you to speak with a support agent. The deletion process can vary from site to site, with account deletion being impossible on some. For services that don't allow account deletion, the best thing to do is falsify all your information as previously mentioned and strengthen account security. To do so, enable MFA and any extra security features offered. As well, change the password to a randomly-generated one that is the maximum allowed size (a password manager can be useful for this). If you're satisfied that all information you care about is removed, you can safely forget about this account. If not, it might be a good idea to keep the credentials stored with your other passwords and occasionally re-login to reset the password. Even when you are able to delete an account, there is no guarantee that all your information will be removed. In fact, some companies are required by law to keep certain information, particularly when related to financial transactions. It's mostly out of your control what happens to your data when it comes to websites and cloud services. Avoid New Accounts \u00b6 As the old saying goes, \"an ounce of prevention is worth a pound of cure.\" Whenever you feel tempted to sign up for a new account, ask yourself \"Do I really need this? Can I accomplish what I need to without an account?\" It can often be much harder to delete an account than to create one. And even after deleting or changing the info on your account, there might be a cached version from a third party\u2014like the Internet Archive . Avoid the temptation when you're able to\u2014your future self will thank you!","title":"Account Deletion"},{"location":"basics/account-deletion/#finding-old-accounts","text":"","title":"Finding Old Accounts"},{"location":"basics/account-deletion/#password-manager","text":"If you have a password manager that you've used for your entire digital life, this part will be very easy. Oftentimes, they include built-in functionality for detecting if your credentials were exposed in a data breach\u2014such as Bitwarden's Data Breach Report . Even if you haven't explicitly used a password manager before, there's a chance you've used the one in your browser or your phone without even realizing it. For example: Firefox Password Manager , Google Password Manager and Edge Password Manager . Desktop platforms also often have a password manager which may help you recover passwords you've forgotten about: Windows Credential Manager macOS Passwords iOS Passwords Linux, Gnome Keyring, which can be accessed through Seahorse , or KDE Wallet Manager","title":"Password Manager"},{"location":"basics/account-deletion/#email","text":"If you didn't use a password manager in the past or you think you have accounts that were never added to your password manager, another option is to search the email account(s) that you believe you signed up on. On your email client, search for keywords such as \"verify\" or \"welcome.\" Almost every time you make an online account, the service will send a verification link or an introductory message to your email. This can be a good way to find old, forgotten accounts.","title":"Email"},{"location":"basics/account-deletion/#deleting-old-accounts","text":"","title":"Deleting Old Accounts"},{"location":"basics/account-deletion/#log-in","text":"In order to delete your old accounts, you'll need to first make sure you can log in to them. Again, if the account was in your password manager, this step is easy. If not, you can try to guess your password. Failing that, there are typically options to regain access to your account, commonly available through a \"forgot password\" link on the login page. It may also be possible that accounts you've abandoned have already been deleted\u2014sometimes services prune all old accounts. When attempting to regain access, if the site returns an error message saying that email is not associated with an account, or you never receive a reset link after multiple attempts, then you do not have an account under that email address and should try a different one. If you can't figure out which email address you used, or you no longer have access to that email, you can try contacting the service's customer support. Unfortunately there is no guarantee that you will be able to reclaim access your account.","title":"Log In"},{"location":"basics/account-deletion/#gdpr-eea-residents-only","text":"Residents of the EEA have additional rights regarding data erasure specified in Article 17 of the GDPR . If it's applicable to you, read the privacy policy for any given service to find information on how to exercise your right to erasure. Reading the privacy policy can prove important, as some services have a \"Delete Account\" option that only disables your account and for real deletion you have to take additional action. Sometimes actual deletion may involve filling out surveys, emailing the data protection officer of the service, or even proving your residence in the EEA . If you plan to go this way, do not overwrite account information\u2014your identity as an EEA resident may be required. Note that the location of the service does not matter; GDPR applies to anyone serving European users. If the service does not respect your right to erasure, you can contact your national Data Protection Authority and you may be entitled to monetary compensation.","title":"GDPR (EEA residents only)"},{"location":"basics/account-deletion/#overwriting-account-information","text":"In some situations where you plan to abandon an account, it may make sense to overwrite the account information with fake data. Once you've made sure you can log in, change all the information in your account to falsified information. The reason for this is that many sites will retain information you previously had even after account deletion. The hope is that they will overwrite the previous information with the newest data you entered. However, there is no guarantee that there won't be backups with the prior information. For the account email, either create a new alternate email account via your provider of choice or create an alias using an email aliasing service . You can then delete your alternate email address once you are done. We recommend against using temporary email providers, as oftentimes it is possible to reactivate temporary emails.","title":"Overwriting Account information"},{"location":"basics/account-deletion/#delete","text":"You can check JustDeleteMe for instructions on deleting the account for a specific service. Some sites will graciously have a \"Delete Account\" option, while others will go as far as to force you to speak with a support agent. The deletion process can vary from site to site, with account deletion being impossible on some. For services that don't allow account deletion, the best thing to do is falsify all your information as previously mentioned and strengthen account security. To do so, enable MFA and any extra security features offered. As well, change the password to a randomly-generated one that is the maximum allowed size (a password manager can be useful for this). If you're satisfied that all information you care about is removed, you can safely forget about this account. If not, it might be a good idea to keep the credentials stored with your other passwords and occasionally re-login to reset the password. Even when you are able to delete an account, there is no guarantee that all your information will be removed. In fact, some companies are required by law to keep certain information, particularly when related to financial transactions. It's mostly out of your control what happens to your data when it comes to websites and cloud services.","title":"Delete"},{"location":"basics/account-deletion/#avoid-new-accounts","text":"As the old saying goes, \"an ounce of prevention is worth a pound of cure.\" Whenever you feel tempted to sign up for a new account, ask yourself \"Do I really need this? Can I accomplish what I need to without an account?\" It can often be much harder to delete an account than to create one. And even after deleting or changing the info on your account, there might be a cached version from a third party\u2014like the Internet Archive . Avoid the temptation when you're able to\u2014your future self will thank you!","title":"Avoid New Accounts"},{"location":"basics/dns/","text":"The Domain Name System is the 'phonebook of the Internet'. DNS translates domain names to IP addresses so browsers and other services can load Internet resources, through a decentralized network of servers. What is DNS ? \u00b6 When you visit a website, a numerical address is returned. For example, when you visit privacyguides.org , the address 192.98.54.105 is returned. DNS has existed since the early days of the Internet. DNS requests made to and from DNS servers are not generally encrypted. In a residential setting, a customer is given servers by the ISP via DHCP . Unencrypted DNS requests are able to be easily surveilled and modified in transit. In some parts of the world, ISPs are ordered to do primitive DNS filtering . When you request the IP address of a domain that is blocked, the server may not respond or may respond with a different IP address. As the DNS protocol is not encrypted, the ISP (or any network operator) can use DPI to monitor requests. ISPs can also block requests based on common characteristics, regardless of which DNS server is used. Unencrypted DNS always uses port 53 and always uses UDP . Below, we discuss and provide a tutorial to prove what an outside observer may see using regular unencrypted DNS and encrypted DNS . Unencrypted DNS \u00b6 Using tshark (part of the Wireshark project) we can monitor and record internet packet flow. This command records packets that meet the rules specified: tshark -w /tmp/dns.pcap udp port 53 and host 1 .1.1.1 or host 8 .8.8.8 We can then use dig (Linux, MacOS etc) or nslookup (Windows) to send the DNS lookup to both servers. Software such as web browsers do these lookups automatically, unless they are configured to use encrypted DNS . Linux, macOS Windows dig +noall +answer privacyguides.org @1.1.1.1 dig +noall +answer privacyguides.org @8.8.8.8 nslookup privacyguides.org 1.1.1.1 nslookup privacyguides.org 8.8.8.8 Next, we want to analyse the results: Wireshark tshark wireshark -r /tmp/dns.pcap tshark -r /tmp/dns.pcap If you run the Wireshark command above, the top pane shows the \" frames \", and the bottom pane shows all the data about the selected frame. Enterprise filtering and monitoring solutions (such as those purchased by governments) can do the process automatically, without human interaction, and can aggregate those frames to produce statistical data useful to the network observer. No. Time Source Destination Protocol Length Info 1 0.000000 192.0.2.1 1.1.1.1 DNS 104 Standard query 0x58ba A privacyguides.org OPT 2 0.293395 1.1.1.1 192.0.2.1 DNS 108 Standard query response 0x58ba A privacyguides.org A 198.98.54.105 OPT 3 1.682109 192.0.2.1 8.8.8.8 DNS 104 Standard query 0xf1a9 A privacyguides.org OPT 4 2.154698 8.8.8.8 192.0.2.1 DNS 108 Standard query response 0xf1a9 A privacyguides.org A 198.98.54.105 OPT An observer could modify any of these packets. What is \"encrypted DNS \"? \u00b6 Encrypted DNS can refer to one of a number of protocols, the most common ones being: DNSCrypt \u00b6 DNSCrypt was one of the first methods of encrypting DNS queries. DNSCrypt operates on port 443 and works with both the TCP or UDP transport protocols. DNSCrypt has never been submitted to the Internet Engineering Task Force (IETF) nor has it gone through the Request for Comments (RFC) process, so it has not been used widely outside of a few implementations . As a result, it has been largely replaced by the more popular DNS over HTTPS . DNS over TLS ( DoT ) \u00b6 DNS over TLS is another method for encrypting DNS communication that is defined in RFC 7858 . Support was first implemented in Android 9, iOS 14, and on Linux in systemd-resolved in version 237. Preference in the industry has been moving away from DoT to DoH in recent years, as DoT is a complex protocol and has varying compliance to the RFC across the implementations that exist. DoT also operates on a dedicated port 853 which can be blocked easily by restrictive firewalls. DNS over HTTPS ( DoH ) \u00b6 DNS over HTTPS as defined in RFC 8484 packages queries in the HTTP /2 protocol and provides security with HTTPS . Support was first added in web browsers such as Firefox 60 and Chrome 83. Native implementation of DoH showed up in iOS 14, macOS 11, Microsoft Windows, and Android 13 (however it won't be enabled by default ). General Linux desktop support is waiting on the systemd implementation so installing third party software is still required . What can an outside party see? \u00b6 In this example we will record what happens when we make a DoH request: First, start tshark : tshark -w /tmp/dns_doh.pcap -f \"tcp port https and host 1.1.1.1\" Second, make a request with curl : curl -vI --doh-url https://1.1.1.1/dns-query https://privacyguides.org After making the request, we can stop the packet capture with CTRL + C . Analyse the results in Wireshark: wireshark -r /tmp/dns_doh.pcap We can see the connection establishment and TLS handshake that occurs with any encrypted connection. When looking at the \"application data\" packets that follow, none of them contain the domain we requested or the IP address returned. Why shouldn't I use encrypted DNS ? \u00b6 In locations where there is internet filtering (or censorship), visiting forbidden resources may have its own consequences which you should consider in your threat model . We do not suggest the use of encrypted DNS for this purpose. Use Tor or a VPN instead. If you're using a VPN , you should use your VPN 's DNS servers. When using a VPN , you are already trusting them with all your network activity. When we do a DNS lookup, it's generally because we want to access a resource. Below, we will discuss some of the methods that may disclose your browsing activities even when using encrypted DNS : IP Address \u00b6 The simplest way to determine browsing activity might be to look at the IP addresses your devices are accessing. For example, if the observer knows that privacyguides.org is at 198.98.54.105 , and your device is requesting data from 198.98.54.105 , there is a good chance you're visiting Privacy Guides. This method is only useful when the IP address belongs to a server that only hosts few websites. It's also not very useful if the site is hosted on a shared platform, (e.g. Github Pages, Cloudflare Pages, Netlify, WordPress, Blogger, etc). It also isn't very useful if the server is hosted behind a reverse proxy , which is very common on the modern Internet. Server Name Indication ( SNI ) \u00b6 Server Name Indication is typically used when a IP address hosts many websites. This could be a service like Cloudflare, or some other Denial-of-service attack protection. Start capturing again with tshark . We've added a filter with our IP address so you don't capture many packets: tshark -w /tmp/pg.pcap port 443 and host 198 .98.54.105 Then we visit https://privacyguides.org . After visiting the website, we want to stop the packet capture with CTRL + C . Next we want to analyze the results: wireshark -r /tmp/pg.pcap We will see the connection establishment, followed by the TLS handshake for the Privacy Guides website. Around frame 5. you'll see a \"Client Hello\". Expand the triangle \u25b8 next to each field: \u25b8 Transport Layer Security \u25b8 TLSv1.3 Record Layer: Handshake Protocol: Client Hello \u25b8 Handshake Protocol: Client Hello \u25b8 Extension: server_name (len=22) \u25b8 Server Name Indication extension We can see the SNI value which discloses the website we are visiting. The tshark command can give you the value directly for all packets containing a SNI value: tshark -r /tmp/pg.pcap -Tfields -Y tls.handshake.extensions_server_name -e tls.handshake.extensions_server_name This means even if we are using \"Encrypted DNS \" servers, the domain will likely be disclosed through SNI . The TLS v1.3 protocol brings with it Encrypted Client Hello , which prevents this kind of leak. Governments, in particular China and Russia , have either already started blocking it or expressed a desire to do so. Recently, Russia has started blocking foreign websites that use the HTTP /3 standard. This is because the QUIC protocol that is a part of HTTP /3 requires that ClientHello also be encrypted. Online Certificate Status Protocol ( OCSP ) \u00b6 Another way your browser can disclose your browsing activities is with the Online Certificate Status Protocol . When visiting a HTTPS website, the browser might check to see if the website's certificate has been revoked. This is generally done through the HTTP protocol, meaning it is not encrypted. The OCSP request contains the certificate \" serial number \", which is unique. It is sent to the \" OCSP responder\" in order to check its status. We can simulate what a browser would do using the openssl command. Get the server certificate and use sed to keep just the important part and write it out to a file: openssl s_client -connect privacyguides.org:443 < /dev/null 2 > & 1 | sed -n '/^-*BEGIN/,/^-*END/p' > /tmp/pg_server.cert Get the intermediate certificate. Certificate Authorities (CA) normally don't sign a certificate directly; they use what is known as an \"intermediate\" certificate. openssl s_client -showcerts -connect privacyguides.org:443 < /dev/null 2 > & 1 | sed -n '/^-*BEGIN/,/^-*END/p' > /tmp/pg_and_intermediate.cert The first certificate in pg_and_intermediate.cert is actually the server certificate from step 1. We can use sed again to delete until the first instance of END: sed -n '/^-*END CERTIFICATE-*$/!d;:a n;p;ba' \\ /tmp/pg_and_intermediate.cert > /tmp/intermediate_chain.cert Get the OCSP responder for the server certificate: openssl x509 -noout -ocsp_uri -in /tmp/pg_server.cert Our certificate shows the Lets Encrypt certificate responder. If we want to see all the details of the certificate we can use: openssl x509 -text -noout -in /tmp/pg_server.cert Start the packet capture: tshark -w /tmp/pg_ocsp.pcap -f \"tcp port http\" Make the OCSP request: openssl ocsp -issuer /tmp/intermediate_chain.cert \\ -cert /tmp/pg_server.cert \\ -text \\ -url http://r3.o.lencr.org Open the capture: wireshark -r /tmp/pg_ocsp.pcap There will be two packets with the \" OCSP \" protocol; a \"Request\" and a \"Response\". For the \"Request\" we can see the \"serial number\" by expanding the triangle \u25b8 next to each field: \u25b8 Online Certificate Status Protocol \u25b8 tbsRequest \u25b8 requestList: 1 item \u25b8 Request \u25b8 reqCert serialNumber For the \"Response\" we can also see the \"serial number\": \u25b8 Online Certificate Status Protocol \u25b8 responseBytes \u25b8 BasicOCSPResponse \u25b8 tbsResponseData \u25b8 responses: 1 item \u25b8 SingleResponse \u25b8 certID serialNumber Or use tshark to filter the packets for the Serial Number: tshark -r /tmp/pg_ocsp.pcap -Tfields -Y ocsp.serialNumber -e ocsp.serialNumber If the network observer has the public certificate, which is publicly available, they can match the serial number with that certificate and therefore determine the site you're visiting from that. The process can be automated and can associate IP addresses with serial numbers. It is also possible to check Certificate Transparency logs for the serial number. Should I use encrypted DNS ? \u00b6 We made this flow chart to describe when you should use encrypted DNS : graph TB Start[Start] --> anonymous{Trying to be<br> anonymous?} anonymous--> | Yes | tor(Use Tor) anonymous --> | No | censorship{Avoiding<br> censorship?} censorship --> | Yes | vpnOrTor(Use<br> VPN or Tor) censorship --> | No | privacy{Want privacy<br> from ISP?} privacy --> | Yes | vpnOrTor privacy --> | No | obnoxious{ISP makes<br> obnoxious<br> redirects?} obnoxious --> | Yes | encryptedDNS(Use<br> encrypted DNS<br> with 3rd party) obnoxious --> | No | ispDNS{Does ISP support<br> encrypted DNS?} ispDNS --> | Yes | useISP(Use<br> encrypted DNS<br> with ISP) ispDNS --> | No | nothing(Do nothing) Encrypted DNS with a 3rd party should only be used to get around redirects and basic DNS blocking when you can be sure there won't be any consequences or you're interested in a provider that does some rudimentary filtering. List of recommended DNS servers What is DNSSEC ? \u00b6 Domain Name System Security Extensions ( DNSSEC ) is a feature of DNS that authenticates responses to domain name lookups. It does not provide privacy protections for those lookups, but rather prevents attackers from manipulating or poisoning the responses to DNS requests. In other words, DNSSEC digitally signs data to help ensure its validity. In order to ensure a secure lookup, the signing occurs at every level in the DNS lookup process. As a result, all answers from DNS can be trusted. The DNSSEC signing process is similar to someone signing a legal document with a pen; that person signs with a unique signature that no one else can create, and a court expert can look at that signature and verify that the document was signed by that person. These digital signatures ensure that data has not been tampered with. DNSSEC implements a hierarchical digital signing policy across all layers of DNS . For example, in the case of a privacyguides.org lookup, a root DNS server would sign a key for the .org nameserver, and the .org nameserver would then sign a key for privacyguides.org \u2019s authoritative nameserver. Adapted from DNS Security Extensions ( DNSSEC ) overview by Google and DNSSEC : An Introduction by Cloudflare, both licensed under CC BY 4.0 . What is QNAME minimization? \u00b6 A QNAME is a \"qualified name\", for example privacyguides.org . QNAME minimisation reduces the amount of information sent from the DNS server to the authoritative name server . Instead of sending the whole domain privacyguides.org , QNAME minimization means the DNS server will ask for all the records that end in .org . Further technical description is defined in RFC 7816 . What is EDNS Client Subnet ( ECS )? \u00b6 The EDNS Client Subnet is a method for a recursive DNS resolver to specify a subnetwork for the host or client which is making the DNS query. It's intended to \"speed up\" delivery of data by giving the client an answer that belongs to a server that is close to them such as a content delivery network , which are often used in video streaming and serving JavaScript web apps. This feature does come at a privacy cost, as it tells the DNS server some information about the client's location.","title":"Introduction to DNS"},{"location":"basics/dns/#what-is-dns","text":"When you visit a website, a numerical address is returned. For example, when you visit privacyguides.org , the address 192.98.54.105 is returned. DNS has existed since the early days of the Internet. DNS requests made to and from DNS servers are not generally encrypted. In a residential setting, a customer is given servers by the ISP via DHCP . Unencrypted DNS requests are able to be easily surveilled and modified in transit. In some parts of the world, ISPs are ordered to do primitive DNS filtering . When you request the IP address of a domain that is blocked, the server may not respond or may respond with a different IP address. As the DNS protocol is not encrypted, the ISP (or any network operator) can use DPI to monitor requests. ISPs can also block requests based on common characteristics, regardless of which DNS server is used. Unencrypted DNS always uses port 53 and always uses UDP . Below, we discuss and provide a tutorial to prove what an outside observer may see using regular unencrypted DNS and encrypted DNS .","title":"What is DNS?"},{"location":"basics/dns/#unencrypted-dns","text":"Using tshark (part of the Wireshark project) we can monitor and record internet packet flow. This command records packets that meet the rules specified: tshark -w /tmp/dns.pcap udp port 53 and host 1 .1.1.1 or host 8 .8.8.8 We can then use dig (Linux, MacOS etc) or nslookup (Windows) to send the DNS lookup to both servers. Software such as web browsers do these lookups automatically, unless they are configured to use encrypted DNS . Linux, macOS Windows dig +noall +answer privacyguides.org @1.1.1.1 dig +noall +answer privacyguides.org @8.8.8.8 nslookup privacyguides.org 1.1.1.1 nslookup privacyguides.org 8.8.8.8 Next, we want to analyse the results: Wireshark tshark wireshark -r /tmp/dns.pcap tshark -r /tmp/dns.pcap If you run the Wireshark command above, the top pane shows the \" frames \", and the bottom pane shows all the data about the selected frame. Enterprise filtering and monitoring solutions (such as those purchased by governments) can do the process automatically, without human interaction, and can aggregate those frames to produce statistical data useful to the network observer. No. Time Source Destination Protocol Length Info 1 0.000000 192.0.2.1 1.1.1.1 DNS 104 Standard query 0x58ba A privacyguides.org OPT 2 0.293395 1.1.1.1 192.0.2.1 DNS 108 Standard query response 0x58ba A privacyguides.org A 198.98.54.105 OPT 3 1.682109 192.0.2.1 8.8.8.8 DNS 104 Standard query 0xf1a9 A privacyguides.org OPT 4 2.154698 8.8.8.8 192.0.2.1 DNS 108 Standard query response 0xf1a9 A privacyguides.org A 198.98.54.105 OPT An observer could modify any of these packets.","title":"Unencrypted DNS"},{"location":"basics/dns/#what-is-encrypted-dns","text":"Encrypted DNS can refer to one of a number of protocols, the most common ones being:","title":"What is \"encrypted DNS\"?"},{"location":"basics/dns/#dnscrypt","text":"DNSCrypt was one of the first methods of encrypting DNS queries. DNSCrypt operates on port 443 and works with both the TCP or UDP transport protocols. DNSCrypt has never been submitted to the Internet Engineering Task Force (IETF) nor has it gone through the Request for Comments (RFC) process, so it has not been used widely outside of a few implementations . As a result, it has been largely replaced by the more popular DNS over HTTPS .","title":"DNSCrypt"},{"location":"basics/dns/#dns-over-tls-dot","text":"DNS over TLS is another method for encrypting DNS communication that is defined in RFC 7858 . Support was first implemented in Android 9, iOS 14, and on Linux in systemd-resolved in version 237. Preference in the industry has been moving away from DoT to DoH in recent years, as DoT is a complex protocol and has varying compliance to the RFC across the implementations that exist. DoT also operates on a dedicated port 853 which can be blocked easily by restrictive firewalls.","title":"DNS over TLS (DoT)"},{"location":"basics/dns/#dns-over-https-doh","text":"DNS over HTTPS as defined in RFC 8484 packages queries in the HTTP /2 protocol and provides security with HTTPS . Support was first added in web browsers such as Firefox 60 and Chrome 83. Native implementation of DoH showed up in iOS 14, macOS 11, Microsoft Windows, and Android 13 (however it won't be enabled by default ). General Linux desktop support is waiting on the systemd implementation so installing third party software is still required .","title":"DNS over HTTPS (DoH)"},{"location":"basics/dns/#what-can-an-outside-party-see","text":"In this example we will record what happens when we make a DoH request: First, start tshark : tshark -w /tmp/dns_doh.pcap -f \"tcp port https and host 1.1.1.1\" Second, make a request with curl : curl -vI --doh-url https://1.1.1.1/dns-query https://privacyguides.org After making the request, we can stop the packet capture with CTRL + C . Analyse the results in Wireshark: wireshark -r /tmp/dns_doh.pcap We can see the connection establishment and TLS handshake that occurs with any encrypted connection. When looking at the \"application data\" packets that follow, none of them contain the domain we requested or the IP address returned.","title":"What can an outside party see?"},{"location":"basics/dns/#why-shouldnt-i-use-encrypted-dns","text":"In locations where there is internet filtering (or censorship), visiting forbidden resources may have its own consequences which you should consider in your threat model . We do not suggest the use of encrypted DNS for this purpose. Use Tor or a VPN instead. If you're using a VPN , you should use your VPN 's DNS servers. When using a VPN , you are already trusting them with all your network activity. When we do a DNS lookup, it's generally because we want to access a resource. Below, we will discuss some of the methods that may disclose your browsing activities even when using encrypted DNS :","title":"Why shouldn't I use encrypted DNS?"},{"location":"basics/dns/#ip-address","text":"The simplest way to determine browsing activity might be to look at the IP addresses your devices are accessing. For example, if the observer knows that privacyguides.org is at 198.98.54.105 , and your device is requesting data from 198.98.54.105 , there is a good chance you're visiting Privacy Guides. This method is only useful when the IP address belongs to a server that only hosts few websites. It's also not very useful if the site is hosted on a shared platform, (e.g. Github Pages, Cloudflare Pages, Netlify, WordPress, Blogger, etc). It also isn't very useful if the server is hosted behind a reverse proxy , which is very common on the modern Internet.","title":"IP Address"},{"location":"basics/dns/#server-name-indication-sni","text":"Server Name Indication is typically used when a IP address hosts many websites. This could be a service like Cloudflare, or some other Denial-of-service attack protection. Start capturing again with tshark . We've added a filter with our IP address so you don't capture many packets: tshark -w /tmp/pg.pcap port 443 and host 198 .98.54.105 Then we visit https://privacyguides.org . After visiting the website, we want to stop the packet capture with CTRL + C . Next we want to analyze the results: wireshark -r /tmp/pg.pcap We will see the connection establishment, followed by the TLS handshake for the Privacy Guides website. Around frame 5. you'll see a \"Client Hello\". Expand the triangle \u25b8 next to each field: \u25b8 Transport Layer Security \u25b8 TLSv1.3 Record Layer: Handshake Protocol: Client Hello \u25b8 Handshake Protocol: Client Hello \u25b8 Extension: server_name (len=22) \u25b8 Server Name Indication extension We can see the SNI value which discloses the website we are visiting. The tshark command can give you the value directly for all packets containing a SNI value: tshark -r /tmp/pg.pcap -Tfields -Y tls.handshake.extensions_server_name -e tls.handshake.extensions_server_name This means even if we are using \"Encrypted DNS \" servers, the domain will likely be disclosed through SNI . The TLS v1.3 protocol brings with it Encrypted Client Hello , which prevents this kind of leak. Governments, in particular China and Russia , have either already started blocking it or expressed a desire to do so. Recently, Russia has started blocking foreign websites that use the HTTP /3 standard. This is because the QUIC protocol that is a part of HTTP /3 requires that ClientHello also be encrypted.","title":"Server Name Indication (SNI)"},{"location":"basics/dns/#online-certificate-status-protocol-ocsp","text":"Another way your browser can disclose your browsing activities is with the Online Certificate Status Protocol . When visiting a HTTPS website, the browser might check to see if the website's certificate has been revoked. This is generally done through the HTTP protocol, meaning it is not encrypted. The OCSP request contains the certificate \" serial number \", which is unique. It is sent to the \" OCSP responder\" in order to check its status. We can simulate what a browser would do using the openssl command. Get the server certificate and use sed to keep just the important part and write it out to a file: openssl s_client -connect privacyguides.org:443 < /dev/null 2 > & 1 | sed -n '/^-*BEGIN/,/^-*END/p' > /tmp/pg_server.cert Get the intermediate certificate. Certificate Authorities (CA) normally don't sign a certificate directly; they use what is known as an \"intermediate\" certificate. openssl s_client -showcerts -connect privacyguides.org:443 < /dev/null 2 > & 1 | sed -n '/^-*BEGIN/,/^-*END/p' > /tmp/pg_and_intermediate.cert The first certificate in pg_and_intermediate.cert is actually the server certificate from step 1. We can use sed again to delete until the first instance of END: sed -n '/^-*END CERTIFICATE-*$/!d;:a n;p;ba' \\ /tmp/pg_and_intermediate.cert > /tmp/intermediate_chain.cert Get the OCSP responder for the server certificate: openssl x509 -noout -ocsp_uri -in /tmp/pg_server.cert Our certificate shows the Lets Encrypt certificate responder. If we want to see all the details of the certificate we can use: openssl x509 -text -noout -in /tmp/pg_server.cert Start the packet capture: tshark -w /tmp/pg_ocsp.pcap -f \"tcp port http\" Make the OCSP request: openssl ocsp -issuer /tmp/intermediate_chain.cert \\ -cert /tmp/pg_server.cert \\ -text \\ -url http://r3.o.lencr.org Open the capture: wireshark -r /tmp/pg_ocsp.pcap There will be two packets with the \" OCSP \" protocol; a \"Request\" and a \"Response\". For the \"Request\" we can see the \"serial number\" by expanding the triangle \u25b8 next to each field: \u25b8 Online Certificate Status Protocol \u25b8 tbsRequest \u25b8 requestList: 1 item \u25b8 Request \u25b8 reqCert serialNumber For the \"Response\" we can also see the \"serial number\": \u25b8 Online Certificate Status Protocol \u25b8 responseBytes \u25b8 BasicOCSPResponse \u25b8 tbsResponseData \u25b8 responses: 1 item \u25b8 SingleResponse \u25b8 certID serialNumber Or use tshark to filter the packets for the Serial Number: tshark -r /tmp/pg_ocsp.pcap -Tfields -Y ocsp.serialNumber -e ocsp.serialNumber If the network observer has the public certificate, which is publicly available, they can match the serial number with that certificate and therefore determine the site you're visiting from that. The process can be automated and can associate IP addresses with serial numbers. It is also possible to check Certificate Transparency logs for the serial number.","title":"Online Certificate Status Protocol (OCSP)"},{"location":"basics/dns/#should-i-use-encrypted-dns","text":"We made this flow chart to describe when you should use encrypted DNS : graph TB Start[Start] --> anonymous{Trying to be<br> anonymous?} anonymous--> | Yes | tor(Use Tor) anonymous --> | No | censorship{Avoiding<br> censorship?} censorship --> | Yes | vpnOrTor(Use<br> VPN or Tor) censorship --> | No | privacy{Want privacy<br> from ISP?} privacy --> | Yes | vpnOrTor privacy --> | No | obnoxious{ISP makes<br> obnoxious<br> redirects?} obnoxious --> | Yes | encryptedDNS(Use<br> encrypted DNS<br> with 3rd party) obnoxious --> | No | ispDNS{Does ISP support<br> encrypted DNS?} ispDNS --> | Yes | useISP(Use<br> encrypted DNS<br> with ISP) ispDNS --> | No | nothing(Do nothing) Encrypted DNS with a 3rd party should only be used to get around redirects and basic DNS blocking when you can be sure there won't be any consequences or you're interested in a provider that does some rudimentary filtering. List of recommended DNS servers","title":"Should I use encrypted DNS?"},{"location":"basics/dns/#what-is-dnssec","text":"Domain Name System Security Extensions ( DNSSEC ) is a feature of DNS that authenticates responses to domain name lookups. It does not provide privacy protections for those lookups, but rather prevents attackers from manipulating or poisoning the responses to DNS requests. In other words, DNSSEC digitally signs data to help ensure its validity. In order to ensure a secure lookup, the signing occurs at every level in the DNS lookup process. As a result, all answers from DNS can be trusted. The DNSSEC signing process is similar to someone signing a legal document with a pen; that person signs with a unique signature that no one else can create, and a court expert can look at that signature and verify that the document was signed by that person. These digital signatures ensure that data has not been tampered with. DNSSEC implements a hierarchical digital signing policy across all layers of DNS . For example, in the case of a privacyguides.org lookup, a root DNS server would sign a key for the .org nameserver, and the .org nameserver would then sign a key for privacyguides.org \u2019s authoritative nameserver. Adapted from DNS Security Extensions ( DNSSEC ) overview by Google and DNSSEC : An Introduction by Cloudflare, both licensed under CC BY 4.0 .","title":"What is DNSSEC?"},{"location":"basics/dns/#what-is-qname-minimization","text":"A QNAME is a \"qualified name\", for example privacyguides.org . QNAME minimisation reduces the amount of information sent from the DNS server to the authoritative name server . Instead of sending the whole domain privacyguides.org , QNAME minimization means the DNS server will ask for all the records that end in .org . Further technical description is defined in RFC 7816 .","title":"What is QNAME minimization?"},{"location":"basics/dns/#what-is-edns-client-subnet-ecs","text":"The EDNS Client Subnet is a method for a recursive DNS resolver to specify a subnetwork for the host or client which is making the DNS query. It's intended to \"speed up\" delivery of data by giving the client an answer that belongs to a server that is close to them such as a content delivery network , which are often used in video streaming and serving JavaScript web apps. This feature does come at a privacy cost, as it tells the DNS server some information about the client's location.","title":"What is EDNS Client Subnet (ECS)?"},{"location":"basics/multi-factor-authentication/","text":"Multi-factor authentication is a security mechanism that requires additional steps beyond entering your username (or email) and password. The most common method is time limited codes you might receive from SMS or an app. Normally, if a hacker (or adversary) is able to figure out your password then they\u2019d gain access to the account that password belongs to. An account with MFA forces the hacker to have both the password (something you know ) and a device that you own (something you have ), like your phone. MFA methods vary in security, but are based on the premise that the more difficult it is for an attacker to gain access to your MFA method, the better. Examples of MFA methods (from weakest to strongest) include SMS , Email codes, app push notifications, TOTP , Yubico OTP , and FIDO . MFA Method Comparison \u00b6 SMS or Email MFA \u00b6 Receiving OTP codes via SMS or email are one of the weaker ways to secure your accounts with MFA . Obtaining a code by email or SMS takes away from the \"something you have \" idea, because there are a variety of ways a hacker could take over your phone number or gain access to your email without having physical access to any of your devices at all. If an unauthorized person gained access to your email, they would be able to use that access to both reset your password and receive the authentication code, giving them full access to your account. Push Notifications \u00b6 Push notification MFA takes the form of a message being sent to an app on your phone asking you to confirm new account logins. This method is a lot better than SMS or email, since an attacker typically wouldn't be able to get these push notifications without having an already logged-in device, which means they would need to compromise one of your other devices first. We all make mistakes, and there is the risk that you might accept the login attempt by accident. Push notification login authorizations are typically sent to all your devices at once, widening the availability of the MFA code if you have many devices. The security of push notification MFA is dependent on both the quality of the app, the server component and the trust of the developer who produces it. Installing an app may also require you to accept invasive privileges that grant access to other data on your device. An individual app also requires that you have a specific app for each service which may not require a password to open, unlike a good TOTP generator app. Time-based One-time Password ( TOTP ) \u00b6 TOTP is one of the most common forms of MFA available. When you set up TOTP you are generally required to scan a QR Code which establishes a \" shared secret \" with the service that you intend to use. The shared secret is secured inside of the authenticator app's data, and is sometimes protected by a password. The time-limited code is then derived from the shared secret and the current time. As the code is only valid for a short time, without access to the shared secret an adversary cannot generate new codes. If you have a hardware security key with TOTP support (such as a YubiKey with Yubico Authenticator ), we recommend that you store your \"shared secrets\" on the hardware. Hardware such as the YubiKey was developed with the intention of making the \"shared secret\" difficult to extract and copy. A YubiKey is also not connected to the Internet, unlike a phone with a TOTP app. Unlike WebAuthn , TOTP offers no protection against phishing or reuse attacks. If an adversary obtains a valid code from you they may use it as many times as they like until it expires (generally 60 seconds). An adversary could set up a website to imitate an official service in an attempt to trick you into giving out your username, password and current TOTP code. If the adversary then uses those recorded credentials they may be able to log into the real service and hijack the account. Although not perfect, TOTP is secure enough for most people, and when hardware security keys are not supported authenticator apps are still a good option. Hardware security keys \u00b6 The YubiKey stores data on a tamper-resistant solid-state chip which is impossible to access non-destructively without a expensive processes and a forensics laboratory. These keys are generally multi-function and provide a number of methods to authenticate. Below are the most common ones. Yubico OTP \u00b6 Yubico OTP is an authentication protocol typically implemented in hardware security keys. When you decide to use Yubico OTP , the key will generate a public ID, private ID, and a Secret Key which is then uploaded to the Yubico OTP server. When logging into a website, all you need to do is to physically touch the security key. The security key will emulate a keyboard and print out a one-time password into the password field. The service will then forward the one-time password to the Yubico OTP server for validation. A counter is incremented both on the key and Yubico's validation server. The OTP can only only be used once, and when a successful authentication occurs the counter is increased which prevents reuse of the OTP . Yubico provides a detailed document about the process. There are some benefits and disadvantages to using Yubico OTP when compared to TOTP . The Yubico validation server is a cloud based service, and you're placing trust in Yubico that they are storing data securely and not profiling you. The public ID associated with Yubico OTP is reused on every website and could be another avenue for third parties to profile you. Like TOTP , Yubico OTP does not provide phishing resistance. If your threat model requires you to have different identities on different websites, do not use Yubico OTP with the same hardware security key across those websites as public ID is unique to each security key. FIDO (Fast IDentity Online) \u00b6 FIDO includes a number of standards, first there was U2F and then later FIDO2 which includes the web standard WebAuthn . U2F and FIDO2 refer to the Client to Authenticator Protocol , which is the protocol between the security key and the computer, such as a laptop or phone. It complements WebAuthn which is the component used to authenticate with the website (the \"Relying Party\") you're trying to log in on. WebAuthn is the most secure and private form of second factor authentication. While the authentication experience is similar to Yubico OTP , the key does not print out a one-time password and validate with a third party server. Instead it uses public key cryptography for authentication. When you create an account the public key is sent to the service, then when you log in, the service will require you to \"sign\" some data with your private key. The benefit of this is that no password data is ever stored by the service, so there is nothing for an adversary to steal. This presentation discusses the history of password authentication, the pitfalls (such as password reuse), and discussion of FIDO2 and WebAuthn standards. FIDO2 and WebAuthn have superior security and privacy properties when compared to any MFA methods. Typically for web services it is used with WebAuthn which is a part of the W3C recommendations . It uses public key authentication and is more secure than shared secrets used in Yubico OTP and TOTP methods, as it includes the origin name (usually, the domain name) during authentication. Attestation is provided to protect you from phishing attacks, as it helps you to determine that you are using the authentic service and not a fake copy. Unlike Yubico OTP , WebAuthn does not use any public ID, so the key is not identifiable across different websites. It also does not use any third party cloud server for authentication. All communication is completed between the key and the website you are logging into. FIDO also uses a counter which is incremented upon use in order to prevent session reuse and cloned keys. If a website or service supports WebAuthn for the authentication, it is highly recommended that you use it over any other form of MFA . General Recommendations \u00b6 We have these general recommendations: Which Method Should I Use? \u00b6 When configuring your MFA method, keep in mind that it is only as secure as your weakest authentication method you use. This means it is important that you only use the best MFA method available. For instance, if you are already using TOTP , you should disable email and SMS MFA . If you are already using FIDO2/WebAuthn, you should not be using Yubico OTP or TOTP on your account. Backups \u00b6 You should always have backups for your MFA method. Hardware security keys can get lost, stolen, or simply stop working over time. It is recommended that you have a pair of hardware security keys with the same access to your accounts instead of just one. When using TOTP with an authenticator app, be sure to back up your recovery keys or the app itself, or copy the \"shared secrets\" to another instance of the app on a different phone or to an encrypted container (e.g VeraCrypt ). Initial Set Up \u00b6 When buying a security key, it is important that you change the default credentials, set up password protection for the key, and enable touch confirmation if your key supports it. Products such as the YubiKey) have multiple interfaces with separate credentials for each one of them, so you should go over each interface and set up protection as well. Email and SMS \u00b6 If you have to use email for MFA , make sure that the email account itself is secured with a proper MFA method. If you use SMS MFA , use a carrier who will not switch your phone number to a new SIM card without account access, or use a dedicated VoIP number from a provider with similar security to avoid a SIM swap attack . MFA tools we recommend More Places to Set Up MFA \u00b6 Beyond just securing your website logins, multi-factor authentication can be used to secure your local logins, SSH keys or even password databases as well. Windows \u00b6 Yubico has a dedicated Credential Provider that adds Challenge-Response authentication for the username + password login flow for local Windows accounts. If you have a YubiKey with Challenge-Response authentication support, take a look at the Yubico Login for Windows Configuration Guide , which will allow you to set up MFA on your Windows computer. macOS \u00b6 macOS has native support for authentication with smart cards (PIV). If you have a smartcard or a hardware security key that supports the PIV interface such as the YubiKey, we recommend that you follow your smartcard/hardware security vendor's documentation and set up second factor authentication for your macOS computer. Yubico have a guide Using Your YubiKey as a Smart Card in macOS which can help you set up your YubiKey on macOS. After your smartcard/security key is set up, we recommend running this command in the Terminal: sudo defaults write /Library/Preferences/com.apple.loginwindow DisableFDEAutoLogin -bool YES The command will prevent an adversary from bypassing MFA when the computer boots. Linux \u00b6 Warning If the hostname of your system changes (such as due to DHCP), you would be unable to login. It is vital that you set up a proper hostname for your computer before following this guide. The pam_u2f module on Linux can provide two factor authentication for logging in on most popular Linux distributions. If you have a hardware security key that supports U2F , you can set up MFA authentication for your login. Yubico has a guide Ubuntu Linux Login Guide - U2F which should work on any distribution. The package manager commands\u2014such as apt-get \u2014and package names may however differ. This guide does not apply to Qubes OS . Qubes OS \u00b6 Qubes OS has support for Challenge-Response authentication with YubiKeys. If you have a YubiKey with Challenge-Response authentication support, take a look at the Qubes OS YubiKey documentation if you want to set up MFA on Qubes OS . SSH \u00b6 Hardware Security Keys \u00b6 SSH MFA could be set up using multiple different authentication methods that are popular with hardware security keys. We recommend that you check out Yubico's documentation on how to set this up. Time-based One-time Password ( TOTP ) \u00b6 SSH MFA can also be set up using TOTP . DigitalOcean has provided a tutorial How To Set Up Multi-Factor Authentication for SSH on Ubuntu 20.04 . Most things should be the same regardless of distribution, however the package manager commands\u2014such as apt-get \u2014and package names may differ. KeePass (and KeePassXC) \u00b6 KeePass and KeePassXC databases can be secured using Challenge-Response or HOTP as a second factor authentication. Yubico has provided a document for KeePass Using Your YubiKey with KeePass and there is also one on the KeePassXC website.","title":"Multi-factor Authentication"},{"location":"basics/multi-factor-authentication/#mfa-method-comparison","text":"","title":"MFA Method Comparison"},{"location":"basics/multi-factor-authentication/#sms-or-email-mfa","text":"Receiving OTP codes via SMS or email are one of the weaker ways to secure your accounts with MFA . Obtaining a code by email or SMS takes away from the \"something you have \" idea, because there are a variety of ways a hacker could take over your phone number or gain access to your email without having physical access to any of your devices at all. If an unauthorized person gained access to your email, they would be able to use that access to both reset your password and receive the authentication code, giving them full access to your account.","title":"SMS or Email MFA"},{"location":"basics/multi-factor-authentication/#push-notifications","text":"Push notification MFA takes the form of a message being sent to an app on your phone asking you to confirm new account logins. This method is a lot better than SMS or email, since an attacker typically wouldn't be able to get these push notifications without having an already logged-in device, which means they would need to compromise one of your other devices first. We all make mistakes, and there is the risk that you might accept the login attempt by accident. Push notification login authorizations are typically sent to all your devices at once, widening the availability of the MFA code if you have many devices. The security of push notification MFA is dependent on both the quality of the app, the server component and the trust of the developer who produces it. Installing an app may also require you to accept invasive privileges that grant access to other data on your device. An individual app also requires that you have a specific app for each service which may not require a password to open, unlike a good TOTP generator app.","title":"Push Notifications"},{"location":"basics/multi-factor-authentication/#time-based-one-time-password-totp","text":"TOTP is one of the most common forms of MFA available. When you set up TOTP you are generally required to scan a QR Code which establishes a \" shared secret \" with the service that you intend to use. The shared secret is secured inside of the authenticator app's data, and is sometimes protected by a password. The time-limited code is then derived from the shared secret and the current time. As the code is only valid for a short time, without access to the shared secret an adversary cannot generate new codes. If you have a hardware security key with TOTP support (such as a YubiKey with Yubico Authenticator ), we recommend that you store your \"shared secrets\" on the hardware. Hardware such as the YubiKey was developed with the intention of making the \"shared secret\" difficult to extract and copy. A YubiKey is also not connected to the Internet, unlike a phone with a TOTP app. Unlike WebAuthn , TOTP offers no protection against phishing or reuse attacks. If an adversary obtains a valid code from you they may use it as many times as they like until it expires (generally 60 seconds). An adversary could set up a website to imitate an official service in an attempt to trick you into giving out your username, password and current TOTP code. If the adversary then uses those recorded credentials they may be able to log into the real service and hijack the account. Although not perfect, TOTP is secure enough for most people, and when hardware security keys are not supported authenticator apps are still a good option.","title":"Time-based One-time Password (TOTP)"},{"location":"basics/multi-factor-authentication/#hardware-security-keys","text":"The YubiKey stores data on a tamper-resistant solid-state chip which is impossible to access non-destructively without a expensive processes and a forensics laboratory. These keys are generally multi-function and provide a number of methods to authenticate. Below are the most common ones.","title":"Hardware security keys"},{"location":"basics/multi-factor-authentication/#yubico-otp","text":"Yubico OTP is an authentication protocol typically implemented in hardware security keys. When you decide to use Yubico OTP , the key will generate a public ID, private ID, and a Secret Key which is then uploaded to the Yubico OTP server. When logging into a website, all you need to do is to physically touch the security key. The security key will emulate a keyboard and print out a one-time password into the password field. The service will then forward the one-time password to the Yubico OTP server for validation. A counter is incremented both on the key and Yubico's validation server. The OTP can only only be used once, and when a successful authentication occurs the counter is increased which prevents reuse of the OTP . Yubico provides a detailed document about the process. There are some benefits and disadvantages to using Yubico OTP when compared to TOTP . The Yubico validation server is a cloud based service, and you're placing trust in Yubico that they are storing data securely and not profiling you. The public ID associated with Yubico OTP is reused on every website and could be another avenue for third parties to profile you. Like TOTP , Yubico OTP does not provide phishing resistance. If your threat model requires you to have different identities on different websites, do not use Yubico OTP with the same hardware security key across those websites as public ID is unique to each security key.","title":"Yubico OTP"},{"location":"basics/multi-factor-authentication/#fido-fast-identity-online","text":"FIDO includes a number of standards, first there was U2F and then later FIDO2 which includes the web standard WebAuthn . U2F and FIDO2 refer to the Client to Authenticator Protocol , which is the protocol between the security key and the computer, such as a laptop or phone. It complements WebAuthn which is the component used to authenticate with the website (the \"Relying Party\") you're trying to log in on. WebAuthn is the most secure and private form of second factor authentication. While the authentication experience is similar to Yubico OTP , the key does not print out a one-time password and validate with a third party server. Instead it uses public key cryptography for authentication. When you create an account the public key is sent to the service, then when you log in, the service will require you to \"sign\" some data with your private key. The benefit of this is that no password data is ever stored by the service, so there is nothing for an adversary to steal. This presentation discusses the history of password authentication, the pitfalls (such as password reuse), and discussion of FIDO2 and WebAuthn standards. FIDO2 and WebAuthn have superior security and privacy properties when compared to any MFA methods. Typically for web services it is used with WebAuthn which is a part of the W3C recommendations . It uses public key authentication and is more secure than shared secrets used in Yubico OTP and TOTP methods, as it includes the origin name (usually, the domain name) during authentication. Attestation is provided to protect you from phishing attacks, as it helps you to determine that you are using the authentic service and not a fake copy. Unlike Yubico OTP , WebAuthn does not use any public ID, so the key is not identifiable across different websites. It also does not use any third party cloud server for authentication. All communication is completed between the key and the website you are logging into. FIDO also uses a counter which is incremented upon use in order to prevent session reuse and cloned keys. If a website or service supports WebAuthn for the authentication, it is highly recommended that you use it over any other form of MFA .","title":"FIDO (Fast IDentity Online)"},{"location":"basics/multi-factor-authentication/#general-recommendations","text":"We have these general recommendations:","title":"General Recommendations"},{"location":"basics/multi-factor-authentication/#which-method-should-i-use","text":"When configuring your MFA method, keep in mind that it is only as secure as your weakest authentication method you use. This means it is important that you only use the best MFA method available. For instance, if you are already using TOTP , you should disable email and SMS MFA . If you are already using FIDO2/WebAuthn, you should not be using Yubico OTP or TOTP on your account.","title":"Which Method Should I Use?"},{"location":"basics/multi-factor-authentication/#backups","text":"You should always have backups for your MFA method. Hardware security keys can get lost, stolen, or simply stop working over time. It is recommended that you have a pair of hardware security keys with the same access to your accounts instead of just one. When using TOTP with an authenticator app, be sure to back up your recovery keys or the app itself, or copy the \"shared secrets\" to another instance of the app on a different phone or to an encrypted container (e.g VeraCrypt ).","title":"Backups"},{"location":"basics/multi-factor-authentication/#initial-set-up","text":"When buying a security key, it is important that you change the default credentials, set up password protection for the key, and enable touch confirmation if your key supports it. Products such as the YubiKey) have multiple interfaces with separate credentials for each one of them, so you should go over each interface and set up protection as well.","title":"Initial Set Up"},{"location":"basics/multi-factor-authentication/#email-and-sms","text":"If you have to use email for MFA , make sure that the email account itself is secured with a proper MFA method. If you use SMS MFA , use a carrier who will not switch your phone number to a new SIM card without account access, or use a dedicated VoIP number from a provider with similar security to avoid a SIM swap attack . MFA tools we recommend","title":"Email and SMS"},{"location":"basics/multi-factor-authentication/#more-places-to-set-up-mfa","text":"Beyond just securing your website logins, multi-factor authentication can be used to secure your local logins, SSH keys or even password databases as well.","title":"More Places to Set Up MFA"},{"location":"basics/multi-factor-authentication/#windows","text":"Yubico has a dedicated Credential Provider that adds Challenge-Response authentication for the username + password login flow for local Windows accounts. If you have a YubiKey with Challenge-Response authentication support, take a look at the Yubico Login for Windows Configuration Guide , which will allow you to set up MFA on your Windows computer.","title":"Windows"},{"location":"basics/multi-factor-authentication/#macos","text":"macOS has native support for authentication with smart cards (PIV). If you have a smartcard or a hardware security key that supports the PIV interface such as the YubiKey, we recommend that you follow your smartcard/hardware security vendor's documentation and set up second factor authentication for your macOS computer. Yubico have a guide Using Your YubiKey as a Smart Card in macOS which can help you set up your YubiKey on macOS. After your smartcard/security key is set up, we recommend running this command in the Terminal: sudo defaults write /Library/Preferences/com.apple.loginwindow DisableFDEAutoLogin -bool YES The command will prevent an adversary from bypassing MFA when the computer boots.","title":"macOS"},{"location":"basics/multi-factor-authentication/#linux","text":"Warning If the hostname of your system changes (such as due to DHCP), you would be unable to login. It is vital that you set up a proper hostname for your computer before following this guide. The pam_u2f module on Linux can provide two factor authentication for logging in on most popular Linux distributions. If you have a hardware security key that supports U2F , you can set up MFA authentication for your login. Yubico has a guide Ubuntu Linux Login Guide - U2F which should work on any distribution. The package manager commands\u2014such as apt-get \u2014and package names may however differ. This guide does not apply to Qubes OS .","title":"Linux"},{"location":"basics/multi-factor-authentication/#qubes-os","text":"Qubes OS has support for Challenge-Response authentication with YubiKeys. If you have a YubiKey with Challenge-Response authentication support, take a look at the Qubes OS YubiKey documentation if you want to set up MFA on Qubes OS .","title":"Qubes OS"},{"location":"basics/multi-factor-authentication/#ssh","text":"","title":"SSH"},{"location":"basics/multi-factor-authentication/#hardware-security-keys_1","text":"SSH MFA could be set up using multiple different authentication methods that are popular with hardware security keys. We recommend that you check out Yubico's documentation on how to set this up.","title":"Hardware Security Keys"},{"location":"basics/multi-factor-authentication/#time-based-one-time-password-totp_1","text":"SSH MFA can also be set up using TOTP . DigitalOcean has provided a tutorial How To Set Up Multi-Factor Authentication for SSH on Ubuntu 20.04 . Most things should be the same regardless of distribution, however the package manager commands\u2014such as apt-get \u2014and package names may differ.","title":"Time-based One-time Password (TOTP)"},{"location":"basics/multi-factor-authentication/#keepass-and-keepassxc","text":"KeePass and KeePassXC databases can be secured using Challenge-Response or HOTP as a second factor authentication. Yubico has provided a document for KeePass Using Your YubiKey with KeePass and there is also one on the KeePassXC website.","title":"KeePass (and KeePassXC)"},{"location":"basics/threat-modeling/","text":"Balancing security, privacy, and usability is one of the first and most difficult tasks you'll face on your privacy journey. Everything is a trade-off: The more secure something is, the more restricting or inconvenient it generally is, et cetera. Often people find that the problem with the tools they see recommended is they're just too hard to start using! If you wanted to use the most secure tools available, you'd have to sacrifice a lot of usability. And even then, nothing is ever fully secure. There's high security, but never full security. That's why threat models are important. So, what are these threat models anyways? A threat model is a list of the most probable threats to your security/privacy endeavors. Since it's impossible to protect yourself against every attack(er), you should focus on the most probable threats. In computer security, a threat is a potential event that could undermine your efforts to stay private and secure. By focusing on the threats that matter to you, this narrows down your thinking about the protection you need, so you can choose the tools that are right for the job. Examples of threat models \u00b6 An investigative journalist's threat model might be (protecting themselves against) a foreign government. A company's manager's threat model might be (protecting themselves against) a hacker hired by competition to do corporate espionage. The average citizen's threat model might be (hiding their data from) large tech corporations. Creating your threat model \u00b6 To identify what could happen to the things you value and determine from whom you need to protect them, you want to answer these five questions: What do I want to protect? Who do I want to protect it from? How likely is it that I will need to protect it? How bad are the consequences if I fail? How much trouble am I willing to go through to try to prevent potential consequences? Example: Protecting your belongings \u00b6 To demonstrate how these questions work, let's build a plan to keep your house and possessions safe. What do you want to protect? (Or, what do you have that is worth protecting? ) \u00b6 Your assets might include jewelry, electronics, important documents, or photos. Who do you want to protect it from? \u00b6 Your adversaries might include burglars, roommates, or guests. How likely is it that you will need to protect it? \u00b6 Does your neighborhood have a history of burglaries? How trustworthy are your roommates/guests? What are the capabilities of your adversaries? What are the risks you should consider? How bad are the consequences if you fail? \u00b6 Do you have anything in your house that you cannot replace? Do you have the time or money to replace these things? Do you have insurance that covers goods stolen from your home? How much trouble are you willing to go through to prevent these consequences? \u00b6 Are you willing to buy a safe for sensitive documents? Can you afford to buy a high-quality lock? Do you have time to open a security box at your local bank and keep your valuables there? Only once you have asked yourself these questions will you be in a position to assess what measures to take. If your possessions are valuable, but the probability of a break-in is low, then you may not want to invest too much money in a lock. But, if the probability of a break-in is high, you'll want to get the best lock on the market, and consider adding a security system. Making a security plan will help you to understand the threats that are unique to you and to evaluate your assets, your adversaries, and your adversaries' capabilities, along with the likelihood of risks you face. Now, let's take a closer look at the questions in our list: What do I want to protect? \u00b6 An \u201casset\u201d is something you value and want to protect. In the context of digital security, an asset is usually some kind of information. For example, your emails, contact lists, instant messages, location, and files are all possible assets. Your devices themselves may also be assets. Make a list of your assets: data that you keep, where it's kept, who has access to it, and what stops others from accessing it. Who do I want to protect it from? \u00b6 To answer this question, it's important to identify who might want to target you or your information. A person or entity that poses a threat to your assets is an \u201cadversary.\u201d Examples of potential adversaries are your boss, your former partner, your business competition, your government, or a hacker on a public network. Make a list of your adversaries, or those who might want to get ahold of your assets. Your list may include individuals, a government agency, or corporations. Depending on who your adversaries are, under some circumstances this list might be something you want to destroy after you're done security planning. How likely is it that I will need to protect it? \u00b6 Risk is the likelihood that a particular threat against a particular asset will actually occur. It goes hand-in-hand with capability. While your mobile phone provider has the capability to access all of your data, the risk of them posting your private data online to harm your reputation is low. It is important to distinguish between what might happen and the probability it may happen. For instance, there is a threat that your building might collapse, but the risk of this happening is far greater in San Francisco (where earthquakes are common) than in Stockholm (where they are not). Assessing risks is both a personal and a subjective process. Many people find certain threats unacceptable no matter the likelihood they will occur because the mere presence of the threat at any likelihood is not worth the cost. In other cases, people disregard high risks because they don't view the threat as a problem. Write down which threats you are going to take seriously, and which may be too rare or too harmless (or too difficult to combat) to worry about. How bad are the consequences if I fail? \u00b6 There are many ways that an adversary could gain access to your data. For example, an adversary can read your private communications as they pass through the network, or they can delete or corrupt your data. The motives of adversaries differ widely, as do their tactics. A government trying to prevent the spread of a video showing police violence may be content to simply delete or reduce the availability of that video. In contrast, a political opponent may wish to gain access to secret content and publish that content without you knowing. Security planning involves understanding how bad the consequences could be if an adversary successfully gains access to one of your assets. To determine this, you should consider the capability of your adversary. For example, your mobile phone provider has access to all your phone records. A hacker on an open Wi-Fi network can access your unencrypted communications. Your government might have stronger capabilities. Write down what your adversary might want to do with your private data. How much trouble am I willing to go through to try to prevent potential consequences? \u00b6 There is no perfect option for security. Not everyone has the same priorities, concerns, or access to resources. Your risk assessment will allow you to plan the right strategy for you, balancing convenience, cost, and privacy. For example, an attorney representing a client in a national security case may be willing to go to greater lengths to protect communications about that case, such as using encrypted email, than a mother who regularly emails her daughter funny cat videos. Write down what options you have available to you to help mitigate your unique threats. Note if you have any financial constraints, technical constraints, or social constraints. Further reading Wikipedia: Threat model Sources EFF Surveillance Self Defense: Your Security Plan","title":"Threat Modeling"},{"location":"basics/threat-modeling/#examples-of-threat-models","text":"An investigative journalist's threat model might be (protecting themselves against) a foreign government. A company's manager's threat model might be (protecting themselves against) a hacker hired by competition to do corporate espionage. The average citizen's threat model might be (hiding their data from) large tech corporations.","title":"Examples of threat models"},{"location":"basics/threat-modeling/#creating-your-threat-model","text":"To identify what could happen to the things you value and determine from whom you need to protect them, you want to answer these five questions: What do I want to protect? Who do I want to protect it from? How likely is it that I will need to protect it? How bad are the consequences if I fail? How much trouble am I willing to go through to try to prevent potential consequences?","title":"Creating your threat model"},{"location":"basics/threat-modeling/#example-protecting-your-belongings","text":"To demonstrate how these questions work, let's build a plan to keep your house and possessions safe.","title":"Example: Protecting your belongings"},{"location":"basics/threat-modeling/#what-do-you-want-to-protect-or-what-do-you-have-that-is-worth-protecting","text":"Your assets might include jewelry, electronics, important documents, or photos.","title":"What do you want to protect? (Or, what do you have that is worth protecting?)"},{"location":"basics/threat-modeling/#who-do-you-want-to-protect-it-from","text":"Your adversaries might include burglars, roommates, or guests.","title":"Who do you want to protect it from?"},{"location":"basics/threat-modeling/#how-likely-is-it-that-you-will-need-to-protect-it","text":"Does your neighborhood have a history of burglaries? How trustworthy are your roommates/guests? What are the capabilities of your adversaries? What are the risks you should consider?","title":"How likely is it that you will need to protect it?"},{"location":"basics/threat-modeling/#how-bad-are-the-consequences-if-you-fail","text":"Do you have anything in your house that you cannot replace? Do you have the time or money to replace these things? Do you have insurance that covers goods stolen from your home?","title":"How bad are the consequences if you fail?"},{"location":"basics/threat-modeling/#how-much-trouble-are-you-willing-to-go-through-to-prevent-these-consequences","text":"Are you willing to buy a safe for sensitive documents? Can you afford to buy a high-quality lock? Do you have time to open a security box at your local bank and keep your valuables there? Only once you have asked yourself these questions will you be in a position to assess what measures to take. If your possessions are valuable, but the probability of a break-in is low, then you may not want to invest too much money in a lock. But, if the probability of a break-in is high, you'll want to get the best lock on the market, and consider adding a security system. Making a security plan will help you to understand the threats that are unique to you and to evaluate your assets, your adversaries, and your adversaries' capabilities, along with the likelihood of risks you face. Now, let's take a closer look at the questions in our list:","title":"How much trouble are you willing to go through to prevent these consequences?"},{"location":"basics/threat-modeling/#what-do-i-want-to-protect","text":"An \u201casset\u201d is something you value and want to protect. In the context of digital security, an asset is usually some kind of information. For example, your emails, contact lists, instant messages, location, and files are all possible assets. Your devices themselves may also be assets. Make a list of your assets: data that you keep, where it's kept, who has access to it, and what stops others from accessing it.","title":"What do I want to protect?"},{"location":"basics/threat-modeling/#who-do-i-want-to-protect-it-from","text":"To answer this question, it's important to identify who might want to target you or your information. A person or entity that poses a threat to your assets is an \u201cadversary.\u201d Examples of potential adversaries are your boss, your former partner, your business competition, your government, or a hacker on a public network. Make a list of your adversaries, or those who might want to get ahold of your assets. Your list may include individuals, a government agency, or corporations. Depending on who your adversaries are, under some circumstances this list might be something you want to destroy after you're done security planning.","title":"Who do I want to protect it from?"},{"location":"basics/threat-modeling/#how-likely-is-it-that-i-will-need-to-protect-it","text":"Risk is the likelihood that a particular threat against a particular asset will actually occur. It goes hand-in-hand with capability. While your mobile phone provider has the capability to access all of your data, the risk of them posting your private data online to harm your reputation is low. It is important to distinguish between what might happen and the probability it may happen. For instance, there is a threat that your building might collapse, but the risk of this happening is far greater in San Francisco (where earthquakes are common) than in Stockholm (where they are not). Assessing risks is both a personal and a subjective process. Many people find certain threats unacceptable no matter the likelihood they will occur because the mere presence of the threat at any likelihood is not worth the cost. In other cases, people disregard high risks because they don't view the threat as a problem. Write down which threats you are going to take seriously, and which may be too rare or too harmless (or too difficult to combat) to worry about.","title":"How likely is it that I will need to protect it?"},{"location":"basics/threat-modeling/#how-bad-are-the-consequences-if-i-fail","text":"There are many ways that an adversary could gain access to your data. For example, an adversary can read your private communications as they pass through the network, or they can delete or corrupt your data. The motives of adversaries differ widely, as do their tactics. A government trying to prevent the spread of a video showing police violence may be content to simply delete or reduce the availability of that video. In contrast, a political opponent may wish to gain access to secret content and publish that content without you knowing. Security planning involves understanding how bad the consequences could be if an adversary successfully gains access to one of your assets. To determine this, you should consider the capability of your adversary. For example, your mobile phone provider has access to all your phone records. A hacker on an open Wi-Fi network can access your unencrypted communications. Your government might have stronger capabilities. Write down what your adversary might want to do with your private data.","title":"How bad are the consequences if I fail?"},{"location":"basics/threat-modeling/#how-much-trouble-am-i-willing-to-go-through-to-try-to-prevent-potential-consequences","text":"There is no perfect option for security. Not everyone has the same priorities, concerns, or access to resources. Your risk assessment will allow you to plan the right strategy for you, balancing convenience, cost, and privacy. For example, an attorney representing a client in a national security case may be willing to go to greater lengths to protect communications about that case, such as using encrypted email, than a mother who regularly emails her daughter funny cat videos. Write down what options you have available to you to help mitigate your unique threats. Note if you have any financial constraints, technical constraints, or social constraints.","title":"How much trouble am I willing to go through to try to prevent potential consequences?"},{"location":"english/vol1/","text":"I \u00b6 I am a teacher, I am a student, I am not interested I don't want to learn piano, I want to learn music, I want to become a doctor I want to be with my parents, I trust my self, I can learn english I want to learn hindi also, I am a very confident boy You \u00b6 You are awesome, Are you a teacher?, Will you come with me, Yes i will come with you Will you do a favor for me, Are you interested, How are you, How about you, You may go. Can you come?, You are late, You seem busy, It's up to you, Are you excited?, I agree with you. We \u00b6 We are at mumbai, We are going to london, We are fortunate to meet you We are going to come with you, Where are we?, When can we eat?, We must keep calm. Where should we go?, Where will we meet?, We will do our best, We want a new carpet. They \u00b6 They are my neighbours, Are they coming, Are they friends?, They are in class. What are they doing?, When will they arrive?, They will agree on that Do they take care of the dog?, They were watching television, Every time they talk, they argue. He \u00b6 He is smart, He is my friend, Is he coming with us, Is he Interested He's studying, What did he say?, Does he live here?, He is very honest Do as he tells you, He is about my age, Whose friend is he?, He's a late bloomer. She \u00b6 She is a beautiful woman, She wants to come with us, She doesn't want to come Who is she?, She knows me, She went out, She went home, Is she at home? Is she married?, What did she say?, She decided to go, When was she born? It \u00b6 It doesn't mean that i am going to work with you, It's my job This is it, Turn it off, Play it cool, Take it easy, Don't touch it It's too large, Leave it to me, I don't need it, What time is it? Me \u00b6 Can you come with me, Will you work with me, It's on me Let me pay, Look at me, Leave me alone, Give me a break! He made me a suit, Tell me the truth, Send me a postcard Us \u00b6 Will you share few moments with us, Are you going to come with us Can you work with us, All of us were silent, She taught us singing Try us again next Monday, One of us will have to go","title":"Vol-1"},{"location":"english/vol1/#i","text":"I am a teacher, I am a student, I am not interested I don't want to learn piano, I want to learn music, I want to become a doctor I want to be with my parents, I trust my self, I can learn english I want to learn hindi also, I am a very confident boy","title":"I"},{"location":"english/vol1/#you","text":"You are awesome, Are you a teacher?, Will you come with me, Yes i will come with you Will you do a favor for me, Are you interested, How are you, How about you, You may go. Can you come?, You are late, You seem busy, It's up to you, Are you excited?, I agree with you.","title":"You"},{"location":"english/vol1/#we","text":"We are at mumbai, We are going to london, We are fortunate to meet you We are going to come with you, Where are we?, When can we eat?, We must keep calm. Where should we go?, Where will we meet?, We will do our best, We want a new carpet.","title":"We"},{"location":"english/vol1/#they","text":"They are my neighbours, Are they coming, Are they friends?, They are in class. What are they doing?, When will they arrive?, They will agree on that Do they take care of the dog?, They were watching television, Every time they talk, they argue.","title":"They"},{"location":"english/vol1/#he","text":"He is smart, He is my friend, Is he coming with us, Is he Interested He's studying, What did he say?, Does he live here?, He is very honest Do as he tells you, He is about my age, Whose friend is he?, He's a late bloomer.","title":"He"},{"location":"english/vol1/#she","text":"She is a beautiful woman, She wants to come with us, She doesn't want to come Who is she?, She knows me, She went out, She went home, Is she at home? Is she married?, What did she say?, She decided to go, When was she born?","title":"She"},{"location":"english/vol1/#it","text":"It doesn't mean that i am going to work with you, It's my job This is it, Turn it off, Play it cool, Take it easy, Don't touch it It's too large, Leave it to me, I don't need it, What time is it?","title":"It"},{"location":"english/vol1/#me","text":"Can you come with me, Will you work with me, It's on me Let me pay, Look at me, Leave me alone, Give me a break! He made me a suit, Tell me the truth, Send me a postcard","title":"Me"},{"location":"english/vol1/#us","text":"Will you share few moments with us, Are you going to come with us Can you work with us, All of us were silent, She taught us singing Try us again next Monday, One of us will have to go","title":"Us"},{"location":"english/vol2/","text":"Am, Is, Are --> used in presentence Am, Is --> Singular Are --> Plural Am \u00b6 We use \"Am\" only with I like \"I am\". (Name, Age, Profession, Quality, Relation) I am Divijesh, I am 30 years old, I am a singer, I am genius, I am son of Srinu. I am the only son of Srinu, I am sure, Am I making sense?, He is stronger than I am. I am thinking of going abroad, I'll show you that I am right, I am in London. Is \u00b6 We use \"Is\" with (He, She, It, Any name). (Name, Age, Profession, Quality, Relation) She is Radha, She is 10 years old, She is a student, She is good at studies She is a sister of Ravi, Is it free?, Is that it?, Whose is this? Is she married?, Dinner is ready, How is your dad?, The light is on. Everything is ready, Where is your room?, My stomach is full. Are \u00b6 We use \"Are\" with (They, We, You, Any plural(Boys, Parents, Friends, siblings)) They are my friends, We are going to delhi, You are late, Lemons are sour They are pretty, How are you, Tom?, My parents are old, Where are you from? Are you able to swim?, Where are my glasses?, What are the symptoms? What are you looking at?, All the seats are booked, There are no comments yet.","title":"Vol-2"},{"location":"english/vol2/#am","text":"We use \"Am\" only with I like \"I am\". (Name, Age, Profession, Quality, Relation) I am Divijesh, I am 30 years old, I am a singer, I am genius, I am son of Srinu. I am the only son of Srinu, I am sure, Am I making sense?, He is stronger than I am. I am thinking of going abroad, I'll show you that I am right, I am in London.","title":"Am"},{"location":"english/vol2/#is","text":"We use \"Is\" with (He, She, It, Any name). (Name, Age, Profession, Quality, Relation) She is Radha, She is 10 years old, She is a student, She is good at studies She is a sister of Ravi, Is it free?, Is that it?, Whose is this? Is she married?, Dinner is ready, How is your dad?, The light is on. Everything is ready, Where is your room?, My stomach is full.","title":"Is"},{"location":"english/vol2/#are","text":"We use \"Are\" with (They, We, You, Any plural(Boys, Parents, Friends, siblings)) They are my friends, We are going to delhi, You are late, Lemons are sour They are pretty, How are you, Tom?, My parents are old, Where are you from? Are you able to swim?, Where are my glasses?, What are the symptoms? What are you looking at?, All the seats are booked, There are no comments yet.","title":"Are"},{"location":"english/vol3/","text":"The right usage of Am - Is - Are Subject Verb Compliment/Object Singular I am a teacher I am not a teacher He is a teacher He is not a teacher She is a teacher She is not a teacher Divi is a teacher Divi is not a teacher It is a good book It is not a good book That is a good book That is not a good book This is a good book This is not a good book Subject Verb Compliment/Object Plural We are in the meeting We are not in the meeting You(Singular/Plural) are in the meeting You are not in the meeting They are in the meeting They are not in the meeting All members are in the meeting All members are not in the meeting These are fresh fruits These are not fresh fruits Those are fresh fruits Those are not fresh fruits All fruits are in the tiffin box All fruits are not in the tiffin box Queations related Is = He, She, Name, It, That, This Are = We, You, They, These, Those, All Subject Verb Compliment/Object Am i a teacher? Am i not a teacher? Is he a teacher? Is he not a teacher? Is she a teacher? Is she not a teacher? Is divi a teacher? Is divi not a teacher? Is it a good book? Is it not a good book? Is that a good book? Is that not a good book? Is this a good book? Is this not a good book? Plural Are we in the meeting? Are we not in the meeting? Are you(Singular/Plural) in the meeting? Are you not in the meeting? Are they in the meeting? Are they not in the meeting? Are all members in the meeting? Are all members not in the meeting? Are these fresh fruits? Are these not fresh fruits? Are those fresh fruits? Are those not fresh fruits? Are all treats in the box? Are all treats not in the box?","title":"Vol-3"},{"location":"english/vol4/","text":"The Right Usage of Was & Were They were used only in Pastense Was = I, He, She, Name, It, That, This --> Singular Were = We, You, They, These, Those, All --> Plural Singular I was a Teacher I was not a Teacher He was a Teacher He was not a Teacher She was a Teacher She was not a Teacher It was a good book It was not a good book That was a good book That was not a good book This was a good book This was not a good book Plural We were in the meeting We were not in the meeting You were in the meeting You were not in the meeting They were in the meeting They were not in the meeting All members were in the meeting All members were not in the meeting These were fresh fruits These were not fresh fruits Those were fresh fruits Those were not fresh fruits All Biscuits were in the tiffin box All Biscuits were not in the tiffin box Questions Singular Was i a teacher? Was he a teacher? Was she a teacher? Was ram a teacher? Was i not a teacher? Was he not a teacher? Was she not a teacher? Was ram not a teacher? Was it a good book? Was that a good book? Was this a good book? Was it not a good book? Was that not a good book? Was this not a good book? Plural Were we in the meeting? Were you in the meeting? Were they in the meeting? Were all members in the meeting? Were we not in the meeting? Were you not in the meeting? Were they not in the meeting? Were all members not in the meeting? Were these fresh fruits? Were those fresh fruits? Were all biscuits in the tiffin box? Were these not fresh fruits? Were those not fresh fruits? Were all biscuits not in the tiffin box?","title":"Vol-4"},{"location":"linux/acl/","text":"Access control lists (ACLs) provide a finer-grained access control mechanism than these traditional Linux access permissions. Link1 Link2","title":"Access control lists (ACLs)"},{"location":"linux/cron/","text":"cron \u00b6 Cron is a utility program that lets users input commands for scheduling tasks repeatedly at a specific time. Tasks scheduled in cron are called cron jobs. Users can determine what kind of task they want to automate and when it should be executed. Cron is a daemon \u2013 a background process executing non-interactive jobs. In Windows, you might be familiar with background processes such as Services that work similarly to the cron daemon. Link Link2 anacron \u00b6 Anacron is used to run commands periodically with a frequency defined in days. It works a little different from cron; assumes that a machine will not be powered on all the time. It is appropriate for running daily, weekly, and monthly scheduled jobs normally run by cron, on machines that will not run 24-7 such as laptops and desktops machines. Link Link2 Link3 at \u00b6 at command is a command-line utility that is used to schedule a command to be executed at a particular time in the future. Jobs created with at command are executed only once. Link Link2 systemd timers \u00b6 Video Video2 Link Link systemd-tmpfiles \u00b6 Link Video","title":"Cron Jobs"},{"location":"linux/cron/#cron","text":"Cron is a utility program that lets users input commands for scheduling tasks repeatedly at a specific time. Tasks scheduled in cron are called cron jobs. Users can determine what kind of task they want to automate and when it should be executed. Cron is a daemon \u2013 a background process executing non-interactive jobs. In Windows, you might be familiar with background processes such as Services that work similarly to the cron daemon. Link Link2","title":"cron"},{"location":"linux/cron/#anacron","text":"Anacron is used to run commands periodically with a frequency defined in days. It works a little different from cron; assumes that a machine will not be powered on all the time. It is appropriate for running daily, weekly, and monthly scheduled jobs normally run by cron, on machines that will not run 24-7 such as laptops and desktops machines. Link Link2 Link3","title":"anacron"},{"location":"linux/cron/#at","text":"at command is a command-line utility that is used to schedule a command to be executed at a particular time in the future. Jobs created with at command are executed only once. Link Link2","title":"at"},{"location":"linux/cron/#systemd-timers","text":"Video Video2 Link Link","title":"systemd timers"},{"location":"linux/cron/#systemd-tmpfiles","text":"Link Video","title":"systemd-tmpfiles"},{"location":"linux/disk/","text":"Storage Management \u00b6 Video fdisk \u00b6 Link Link1 Video gdisk \u00b6 Video parted \u00b6 Video","title":"Disk Management"},{"location":"linux/disk/#storage-management","text":"Video","title":"Storage Management"},{"location":"linux/disk/#fdisk","text":"Link Link1 Video","title":"fdisk"},{"location":"linux/disk/#gdisk","text":"Video","title":"gdisk"},{"location":"linux/disk/#parted","text":"Video","title":"parted"},{"location":"linux/logs/","text":"rsyslog server and client \u00b6 Video Video1 logrotate \u00b6 Video","title":"Logs"},{"location":"linux/logs/#rsyslog-server-and-client","text":"Video Video1","title":"rsyslog server and client"},{"location":"linux/logs/#logrotate","text":"Video","title":"logrotate"},{"location":"linux/nano/","text":"GNU nano is an easy to use command line text editor for Unix and Linux operating systems. It includes all the basic functionality you\u2019d expect from a regular text editor, like syntax highlighting, multiple buffers, search and replace with regular expression support, spellchecking, UTF-8 encoding, and more. At the bottom of the window, there is a list of the most basic command shortcuts to use with the nano editor. All commands are prefixed with either ^ or M character. The caret symbol (^) represents the Ctrl key. For example, the ^J commands mean to press the Ctrl and J keys at the same time. The letter M represents the Alt key. To start nano in very specific line number: nano +16 textfile To start nano in view only mode: nano -v textfile Cheat Sheet \u00b6 Ctrl+g Help Ctrl+o Save file Ctrl+x Exit Ctrl+w Search text Ctrl+k Cut text Ctrl+u Paste text Ctrl+_ Goto specific line Number Ctrl+r insert existing file Alt+a Alt+^ Select text or Mark set and copy text Ctrl+u To paste data which you copied Alt+\\ Move to Top of File Alt+/ Move to bottom of File Ctrl+Shift+v To paste text from Outside Shift+\u2192 To select text Alt+u Undo changes Alt+e Redo changes Ctrl+a Move to the beginning of a line Ctrl+e move to the end of a line Ctrl+y Start of file Ctrl+v End of file Ctr+\\ Search and replace Alt+del Delete current line List Commands \u00b6 You can get a list of all commands by typing Ctrl+g. Editing Files \u00b6 To move the cursor to a specific line and character number, use the Ctrl+_ command. Searching and Replacing \u00b6 To search for a text, press Ctrl+w, type in the search term, and press Enter. The cursor will move to the first match. To move to the next match, press Alt+w. If you want to search and replace, press Ctrl+. Enter the search term and the text to be replaced with. The editor will move to the first match and ask you whether to replace it. After hitting Y or N it will move to the next match. Pressing A will replace all matches. Copy Cut and Paste \u00b6 To select text, move the cursor to the beginning of the text and press Alt+a. This will set a selection mark. Move the cursor to the end of the text you want to select using the arrow keys. The selected text will be highlighted. If you want to cancel the selection press Ctrl+6. Copy the selected text to the clipboard using the Alt+6 command. Ctrl+k will cut the selected text. If you want to cut whole lines, simply move the cursor to the line and press Ctrl+k. You can cut multiple lines by hitting Ctrl+k several times. To paste the text move the cursor to where you want to put the text and press Ctrl+u Saving and Exiting \u00b6 To save the changes you\u2019ve made to the file, press Ctrl+o. If the file doesn\u2019t already exist, it will be created once you save it. To exit nano press Ctrl+x. If there are unsaved changes, you\u2019ll be asked whether you want to save the changes.","title":"Nano"},{"location":"linux/nano/#cheat-sheet","text":"Ctrl+g Help Ctrl+o Save file Ctrl+x Exit Ctrl+w Search text Ctrl+k Cut text Ctrl+u Paste text Ctrl+_ Goto specific line Number Ctrl+r insert existing file Alt+a Alt+^ Select text or Mark set and copy text Ctrl+u To paste data which you copied Alt+\\ Move to Top of File Alt+/ Move to bottom of File Ctrl+Shift+v To paste text from Outside Shift+\u2192 To select text Alt+u Undo changes Alt+e Redo changes Ctrl+a Move to the beginning of a line Ctrl+e move to the end of a line Ctrl+y Start of file Ctrl+v End of file Ctr+\\ Search and replace Alt+del Delete current line","title":"Cheat Sheet"},{"location":"linux/nano/#list-commands","text":"You can get a list of all commands by typing Ctrl+g.","title":"List Commands"},{"location":"linux/nano/#editing-files","text":"To move the cursor to a specific line and character number, use the Ctrl+_ command.","title":"Editing Files"},{"location":"linux/nano/#searching-and-replacing","text":"To search for a text, press Ctrl+w, type in the search term, and press Enter. The cursor will move to the first match. To move to the next match, press Alt+w. If you want to search and replace, press Ctrl+. Enter the search term and the text to be replaced with. The editor will move to the first match and ask you whether to replace it. After hitting Y or N it will move to the next match. Pressing A will replace all matches.","title":"Searching and Replacing"},{"location":"linux/nano/#copy-cut-and-paste","text":"To select text, move the cursor to the beginning of the text and press Alt+a. This will set a selection mark. Move the cursor to the end of the text you want to select using the arrow keys. The selected text will be highlighted. If you want to cancel the selection press Ctrl+6. Copy the selected text to the clipboard using the Alt+6 command. Ctrl+k will cut the selected text. If you want to cut whole lines, simply move the cursor to the line and press Ctrl+k. You can cut multiple lines by hitting Ctrl+k several times. To paste the text move the cursor to where you want to put the text and press Ctrl+u","title":"Copy Cut and Paste"},{"location":"linux/nano/#saving-and-exiting","text":"To save the changes you\u2019ve made to the file, press Ctrl+o. If the file doesn\u2019t already exist, it will be created once you save it. To exit nano press Ctrl+x. If there are unsaved changes, you\u2019ll be asked whether you want to save the changes.","title":"Saving and Exiting"},{"location":"linux/network/","text":"ip Command \u00b6 Link nmcli Command \u00b6 Link NIC Teaming Teaming Network Bridge Network Bridge2 nslookup dig nmtui command \u00b6 Link ss command \u00b6 Link","title":"Networking"},{"location":"linux/network/#ip-command","text":"Link","title":"ip Command"},{"location":"linux/network/#nmcli-command","text":"Link NIC Teaming Teaming Network Bridge Network Bridge2 nslookup dig","title":"nmcli Command"},{"location":"linux/network/#nmtui-command","text":"Link","title":"nmtui command"},{"location":"linux/network/#ss-command","text":"Link","title":"ss command"},{"location":"linux/process/","text":"A process in Linux is nothing but a program in execution. It\u2019s a running instance of a program. Any command that you execute starts a process. Link Link1 ps command \u00b6 Link Link1 top command \u00b6 Link Link1 Link2 Link3 load average \u00b6 Link watch command \u00b6 Link Link2 lscpu command \u00b6 Link kill command \u00b6 Link Link1 signals \u00b6 Link nice renice \u00b6 Link Link tuned \u00b6 Link","title":"Process Management"},{"location":"linux/process/#ps-command","text":"Link Link1","title":"ps command"},{"location":"linux/process/#top-command","text":"Link Link1 Link2 Link3","title":"top command"},{"location":"linux/process/#load-average","text":"Link","title":"load average"},{"location":"linux/process/#watch-command","text":"Link Link2","title":"watch command"},{"location":"linux/process/#lscpu-command","text":"Link","title":"lscpu command"},{"location":"linux/process/#kill-command","text":"Link Link1","title":"kill command"},{"location":"linux/process/#signals","text":"Link","title":"signals"},{"location":"linux/process/#nice-renice","text":"Link Link","title":"nice renice"},{"location":"linux/process/#tuned","text":"Link","title":"tuned"},{"location":"linux/rhcsa/","text":"RHCSA Notes \u00b6 Which \u00b6 which command in Linux is a command which is used to locate the executable file associated with the given command by searching it in the path environment variable. It has 3 return status as follows: 0 : If all specified commands are found and executable. 1 : If one or more specified commands is nonexistent or not executable. 2 : If an invalid option is specified. echo $? exit code to show errors for last command if error output 1 if no error output 0 Locate \u00b6 The locate command finds files in Linux using the file name. locate is used for obtaining instantaneous results, and it is an essential utility when speed is a priority. install mlocate package. locate mysql | less Print the number of matched files locate -c mysql Limit the number of search results locate git -n 10 To ignore case sensitivity using the -i option locate -i git Search for a File with an Exact Name locate -r mysql$ Tee \u00b6 It is like T junction or pipe tee is used to save to a file compulsory Save output to out.txt and send to input of wc simultaneously ls -l | tee out.txt | wc To display output to terminal ls -l | tee out.txt Pass output to wc command ls -l | tee out.txt | wc > wc.txt ls -l | tee out.txt | wc | tee wc.txt Xargs \u00b6 To Convert output stream into command line arguments Read filenames from test.txt and remove every file cat test.txt | xargs rm Read filenames from test.txt and display file contents to terminal cat test.txt | xargs cat Find \u00b6 The find command is used to search and locate the list of files and directories based on conditions you specify for files that match the arguments. Link Tar \u00b6 The Linux \u201ctar\u201d stands for tape archive, which is used by a large number of Linux/Unix system administrators to deal with tape drives backup. Link xz \u00b6 xz is a new general-purpose, command line data compression utility, similar to gzip and bzip2. It can be used to compress or decompress a file according to the selected operation mode. It supports various formats to compress or decompress files. link Links \u00b6 Links are a very handy way to create a shortcut to an original directory. In Linux there are two different types of links: Hard links Symbolic links link Inode \u00b6 Linux must allocate an index node (inode) for every file and directory in the filesystem. Inodes do not store actual data. Instead, they store the metadata where you can find the storage blocks of each file\u2019s data. link Cut \u00b6 The cut command in UNIX is a command for cutting out the sections from each line of files and writing the result to standard output. It can be used to cut parts of a line by byte position, character and field. Display specific character: cut -c 8 test.txt Display range of characters: cut -c 4-8 test.txt Display 5 character to last character: cut -c 5- test.txt Display 1 to specified character: cut -c -3 test.txt Display 3 to 5 and 7 to 10 characters: cut -c 3-5,7-10 test.txt Display specific column data: -d -- delimiter ignore pipe symbol, by default TAB. -f -- field we get 3 column data. cut -d \"|\" -f 3 test.txt Display range of columns like 2 to 4: cut -d \"|\" -f 2-4 test.txt Display 2 to last column: cut -d \"|\" -f 2- text.txt Display 1 to specified column: cut -d \"|\" -f -3 text.txt Display 1,3,5 columns: cut -d \"|\" -f 1,3,5 text.txt Display all columns except 3 and 5: use --complement option cut -d \"|\" --complement -f 3,5 text.txt 3 to 5 columns: cut -d \"|\" --complement -f 3-5 text.txt Tr \u00b6 Stands for translate or delete. Search and replace a to A character: echo \"this is a line\" | tr 'a' 'A' echo \"this is a line\" | tr 'aeiou' 'AEIOU' Delete specified characters: echo \"this is a line\" | tr -d 'aeiou' Remove repeated characters in word: echo \"thiiis iis aaa linee\" | tr -s 'aeiou' Regular Expressions \u00b6 By using wild card characters, we can build regular expressions. \"*\" --> represents zero or more characters, i.e any number of characters. \"?\" --> represents only one character \"[]\" --> range of characters \"[abc]\" --> a or b or c (we have to take only one character a or b or c) \"[!abc]\" --> except a,b,c. any character \"[a-z]\" --> any lower case alphabet symbol \"[A-Z]\" --> any upper case alphabet symbol \"[a-zA-z]\" --> any alphabet symbol either lower or upper \"[0-9]\" --> any digit 0 to 9 \"[a-zA-z0-9]\" --> any alphanumeric character \"[!a-zA-z0-9]\" --> Except any alphanumeric character (special symbol) \"[[:lower:]]\" --> Any lower case alphabet symbol \"[[:upper:]]\" --> Any upper case alphabet symbol \"[[:alpha:]]\" --> Any alphabet symbol \"[[:digit:]]\" --> Any digit from 0 to 9 \"[[:alnum:]]\" --> This is the same as \u2018[0-9A-Za-z]\u2019 \"[![:digit:]]\" --> Any character except digit \"{ }\" --> List of files with comma seperator. \"{a..z}\" --> a to z files touch {a..d}.java --> create a,b,c,d files To list out all files where file name starts with a or b or c ls [a-c]* --> a.txt, b.txt, c.java List first one uppercase alpha, second digit, third lowercase alpha ls [[:upper:]][[:digit:]][[:lower:]] --> A7b W4u Z6k List all files starts with special symbol ls [![:alnum:]]* --> %abc.txt List all files .java or .py extension ls {*.java,*.py} --> b.java, c.java, j.py, k.py Remove all files start with a or b or c and ends with e or t rm [abc]*[et] --> a.txt and b.txt will be removed List files begin with upper and has letter d in 3rd char, ends with lowercase [[:upper:]]?d*[[:lower]] Password authentication \u00b6 Password authentication for aws instance not keybased vi /etc/ssh/sshd_config PasswordAuthentication yes systemctl restart sshd visudo for sudo access in /etc/sudoers file without password username All=(ALL) NOPASSWD: ALL To check memory: free - h /etc/hosts \u00b6 All operating systems with network support have a hosts file to translate hostnames to IP addresses. Whenever you open a website by typing its hostname, your system will read through the hosts file to check for the corresponding IP and then open it. The hosts file is a simple text file located in the etc folder on Linux and Mac OS (/etc/hosts). Whenever you type an address, your system will check the hosts file for its presence; if it is present there, you will be directed to the corresponding IP. If the hostname is not defined in the hosts file, your system will check the DNS server of your internet to look up for the corresponding IP and redirect you accordingly. Why Edit /etc/hosts file? By editing the hosts files, you can achieve the following things: Block a website: You can block a website by redirecting it to the IP of your localhost or the default route. For example, if we want to block google.com, we can add the following text to our file: 127.0.0.1 www.google.com or 0.0.0.0 www.google.com Now when you try to open www.google.com from your browser, you will see an error. Access Remote Computer Through an Alias: Suppose we have a server located at a local network that we want to access. We usually have to type the server\u2019s IP to access it unless it has been defined on our local DNS. One way to avoid typing the IP, again and again, is to assign an alias to the server in the hosts file as follows: 192.168.1.10 myserver The IP corresponds to the location of the server we want to access and myserver is the new alias we want to use. Sometimes you may need to restart the web browser to apply changes. Findmnt \u00b6 The more common command to check mounted file systems on linux is the mount command which is used to not only list mounted devices, but also mount and unmount them as and when needed. The findmnt command shows details like the device name, mount directory, mount options and the file system type. List the file systems: findmnt Output in list format: findmnt - l df style output: findmnt - D Read file systems from fstab: findmnt - s Filter filesystems by type: findmnt - t ext4 Search by source device: findmnt -S /dev/sda1 Search by mount point: findmnt -T / To run previous command: !f To list environment variables: env Grep \u00b6 The grep filter searches a file for a particular pattern of characters, and displays all lines that contain that pattern. The pattern that is searched in the file is referred to as the regular expression (grep stands for global search for regular expression and print out). Search any line that contains the word in filename on Linux: grep 'word' filename Perform a case-insensitive search for the word \u2018bar\u2019 in Linux and Unix: grep -i 'bar' file1 Look for all files in the current directory and in all of its subdirectories in Linux for the word \u2018httpd\u2019: grep -R 'httpd' . Search and display the total number of times that the string \u2018nixcraft\u2019 appears in a file named frontpage.md: grep -c 'nixcraft' frontpage.md Use grep to search words only: You can force the grep command to select only those lines containing matches that form whole words grep -w \"boo\" file Output with the number of the line in the text file: grep -n 'root' /etc/passwd Force grep invert match: For example print all line that do not contain the word start root grep -v '^root' /etc/passwd Display lines before and after the match: Want to see the lines before your matches grep -B 3 'root' /etc/passwd display the lines after your matches grep -A 3 'root' /etc/passwd prints the searched line and 3 lines after and before the result grep -C 3 'root' /etc/passwd Display the file names that matches the pattern: grep -l \"unix\" * Displaying only the matched pattern: By default, grep displays the entire line which has the matched string. We can make the grep to display only the matched string by using the -o option. grep -o \"unix\" geekfile.txt Matching the lines that start with a string: The ^ regular expression pattern specifies the start of a line. grep \"^unix\" geekfile.txt Matching the lines that end with a string: The $ regular expression pattern specifies the end of a line. grep \"os$\" geekfile.txt Specifies multiple contents with -e option: grep \u2013e \"Agarwal\" \u2013e \"divi\" \u2013e \"jesh\" geekfile.txt Takes patterns from file, one per line using option -f: grep \u2013f pattern.txt geekfile.txt To search for string in directory recursive ignore errors: sudo grep - R anon / etc / 2 > / dev / null To find files: sudo grep - Rl anon / etc / 2 > / dev / null Egrep \u00b6 The egrep command searches for a text pattern, using extended regular expressions to perform the match. Running egrep is equivalent to running grep with the -E option. Grep can understand some patterns but not all patterns. Display all lines start with 'D' grep '^D' text Display all lines end with 'D' grep 'D$' text Search for vowels in file grep '[aeiou]' text Search for other than vowels in file grep '[^aeiou]' text Search for multiple patterns grep -e 'hyd' -e 'ban' text or egrep '(hyd|ban)' text Fgrep \u00b6 Fixed strings grep cannot understand patterns, it can understand only strings. To search fast we use grep and performance wise. grep -F Some words are there in file.txt search those in demo.txt. fgrep -f file.txt demo.txt Shuffling \u00b6 shuf -i 1-100 -n 1 8 touch pot/dir$(shuf -i 1-100 -n 1)/divi.txt find pot -type f -name 'divi.txt' move find result to desktop find pot -type f -name 'divi.txt' -exec mv {} ~/Desktop \\; Remove all files in pot but not dirs find pot -type f -name '*.txt' -exec rm {} \\;","title":"Tritree"},{"location":"linux/rhcsa/#rhcsa-notes","text":"","title":"RHCSA Notes"},{"location":"linux/rhcsa/#which","text":"which command in Linux is a command which is used to locate the executable file associated with the given command by searching it in the path environment variable. It has 3 return status as follows: 0 : If all specified commands are found and executable. 1 : If one or more specified commands is nonexistent or not executable. 2 : If an invalid option is specified. echo $? exit code to show errors for last command if error output 1 if no error output 0","title":"Which"},{"location":"linux/rhcsa/#locate","text":"The locate command finds files in Linux using the file name. locate is used for obtaining instantaneous results, and it is an essential utility when speed is a priority. install mlocate package. locate mysql | less Print the number of matched files locate -c mysql Limit the number of search results locate git -n 10 To ignore case sensitivity using the -i option locate -i git Search for a File with an Exact Name locate -r mysql$","title":"Locate"},{"location":"linux/rhcsa/#tee","text":"It is like T junction or pipe tee is used to save to a file compulsory Save output to out.txt and send to input of wc simultaneously ls -l | tee out.txt | wc To display output to terminal ls -l | tee out.txt Pass output to wc command ls -l | tee out.txt | wc > wc.txt ls -l | tee out.txt | wc | tee wc.txt","title":"Tee"},{"location":"linux/rhcsa/#xargs","text":"To Convert output stream into command line arguments Read filenames from test.txt and remove every file cat test.txt | xargs rm Read filenames from test.txt and display file contents to terminal cat test.txt | xargs cat","title":"Xargs"},{"location":"linux/rhcsa/#find","text":"The find command is used to search and locate the list of files and directories based on conditions you specify for files that match the arguments. Link","title":"Find"},{"location":"linux/rhcsa/#tar","text":"The Linux \u201ctar\u201d stands for tape archive, which is used by a large number of Linux/Unix system administrators to deal with tape drives backup. Link","title":"Tar"},{"location":"linux/rhcsa/#xz","text":"xz is a new general-purpose, command line data compression utility, similar to gzip and bzip2. It can be used to compress or decompress a file according to the selected operation mode. It supports various formats to compress or decompress files. link","title":"xz"},{"location":"linux/rhcsa/#links","text":"Links are a very handy way to create a shortcut to an original directory. In Linux there are two different types of links: Hard links Symbolic links link","title":"Links"},{"location":"linux/rhcsa/#inode","text":"Linux must allocate an index node (inode) for every file and directory in the filesystem. Inodes do not store actual data. Instead, they store the metadata where you can find the storage blocks of each file\u2019s data. link","title":"Inode"},{"location":"linux/rhcsa/#cut","text":"The cut command in UNIX is a command for cutting out the sections from each line of files and writing the result to standard output. It can be used to cut parts of a line by byte position, character and field. Display specific character: cut -c 8 test.txt Display range of characters: cut -c 4-8 test.txt Display 5 character to last character: cut -c 5- test.txt Display 1 to specified character: cut -c -3 test.txt Display 3 to 5 and 7 to 10 characters: cut -c 3-5,7-10 test.txt Display specific column data: -d -- delimiter ignore pipe symbol, by default TAB. -f -- field we get 3 column data. cut -d \"|\" -f 3 test.txt Display range of columns like 2 to 4: cut -d \"|\" -f 2-4 test.txt Display 2 to last column: cut -d \"|\" -f 2- text.txt Display 1 to specified column: cut -d \"|\" -f -3 text.txt Display 1,3,5 columns: cut -d \"|\" -f 1,3,5 text.txt Display all columns except 3 and 5: use --complement option cut -d \"|\" --complement -f 3,5 text.txt 3 to 5 columns: cut -d \"|\" --complement -f 3-5 text.txt","title":"Cut"},{"location":"linux/rhcsa/#tr","text":"Stands for translate or delete. Search and replace a to A character: echo \"this is a line\" | tr 'a' 'A' echo \"this is a line\" | tr 'aeiou' 'AEIOU' Delete specified characters: echo \"this is a line\" | tr -d 'aeiou' Remove repeated characters in word: echo \"thiiis iis aaa linee\" | tr -s 'aeiou'","title":"Tr"},{"location":"linux/rhcsa/#regular-expressions","text":"By using wild card characters, we can build regular expressions. \"*\" --> represents zero or more characters, i.e any number of characters. \"?\" --> represents only one character \"[]\" --> range of characters \"[abc]\" --> a or b or c (we have to take only one character a or b or c) \"[!abc]\" --> except a,b,c. any character \"[a-z]\" --> any lower case alphabet symbol \"[A-Z]\" --> any upper case alphabet symbol \"[a-zA-z]\" --> any alphabet symbol either lower or upper \"[0-9]\" --> any digit 0 to 9 \"[a-zA-z0-9]\" --> any alphanumeric character \"[!a-zA-z0-9]\" --> Except any alphanumeric character (special symbol) \"[[:lower:]]\" --> Any lower case alphabet symbol \"[[:upper:]]\" --> Any upper case alphabet symbol \"[[:alpha:]]\" --> Any alphabet symbol \"[[:digit:]]\" --> Any digit from 0 to 9 \"[[:alnum:]]\" --> This is the same as \u2018[0-9A-Za-z]\u2019 \"[![:digit:]]\" --> Any character except digit \"{ }\" --> List of files with comma seperator. \"{a..z}\" --> a to z files touch {a..d}.java --> create a,b,c,d files To list out all files where file name starts with a or b or c ls [a-c]* --> a.txt, b.txt, c.java List first one uppercase alpha, second digit, third lowercase alpha ls [[:upper:]][[:digit:]][[:lower:]] --> A7b W4u Z6k List all files starts with special symbol ls [![:alnum:]]* --> %abc.txt List all files .java or .py extension ls {*.java,*.py} --> b.java, c.java, j.py, k.py Remove all files start with a or b or c and ends with e or t rm [abc]*[et] --> a.txt and b.txt will be removed List files begin with upper and has letter d in 3rd char, ends with lowercase [[:upper:]]?d*[[:lower]]","title":"Regular Expressions"},{"location":"linux/rhcsa/#password-authentication","text":"Password authentication for aws instance not keybased vi /etc/ssh/sshd_config PasswordAuthentication yes systemctl restart sshd visudo for sudo access in /etc/sudoers file without password username All=(ALL) NOPASSWD: ALL To check memory: free - h","title":"Password authentication"},{"location":"linux/rhcsa/#etchosts","text":"All operating systems with network support have a hosts file to translate hostnames to IP addresses. Whenever you open a website by typing its hostname, your system will read through the hosts file to check for the corresponding IP and then open it. The hosts file is a simple text file located in the etc folder on Linux and Mac OS (/etc/hosts). Whenever you type an address, your system will check the hosts file for its presence; if it is present there, you will be directed to the corresponding IP. If the hostname is not defined in the hosts file, your system will check the DNS server of your internet to look up for the corresponding IP and redirect you accordingly. Why Edit /etc/hosts file? By editing the hosts files, you can achieve the following things: Block a website: You can block a website by redirecting it to the IP of your localhost or the default route. For example, if we want to block google.com, we can add the following text to our file: 127.0.0.1 www.google.com or 0.0.0.0 www.google.com Now when you try to open www.google.com from your browser, you will see an error. Access Remote Computer Through an Alias: Suppose we have a server located at a local network that we want to access. We usually have to type the server\u2019s IP to access it unless it has been defined on our local DNS. One way to avoid typing the IP, again and again, is to assign an alias to the server in the hosts file as follows: 192.168.1.10 myserver The IP corresponds to the location of the server we want to access and myserver is the new alias we want to use. Sometimes you may need to restart the web browser to apply changes.","title":"/etc/hosts"},{"location":"linux/rhcsa/#findmnt","text":"The more common command to check mounted file systems on linux is the mount command which is used to not only list mounted devices, but also mount and unmount them as and when needed. The findmnt command shows details like the device name, mount directory, mount options and the file system type. List the file systems: findmnt Output in list format: findmnt - l df style output: findmnt - D Read file systems from fstab: findmnt - s Filter filesystems by type: findmnt - t ext4 Search by source device: findmnt -S /dev/sda1 Search by mount point: findmnt -T / To run previous command: !f To list environment variables: env","title":"Findmnt"},{"location":"linux/rhcsa/#grep","text":"The grep filter searches a file for a particular pattern of characters, and displays all lines that contain that pattern. The pattern that is searched in the file is referred to as the regular expression (grep stands for global search for regular expression and print out). Search any line that contains the word in filename on Linux: grep 'word' filename Perform a case-insensitive search for the word \u2018bar\u2019 in Linux and Unix: grep -i 'bar' file1 Look for all files in the current directory and in all of its subdirectories in Linux for the word \u2018httpd\u2019: grep -R 'httpd' . Search and display the total number of times that the string \u2018nixcraft\u2019 appears in a file named frontpage.md: grep -c 'nixcraft' frontpage.md Use grep to search words only: You can force the grep command to select only those lines containing matches that form whole words grep -w \"boo\" file Output with the number of the line in the text file: grep -n 'root' /etc/passwd Force grep invert match: For example print all line that do not contain the word start root grep -v '^root' /etc/passwd Display lines before and after the match: Want to see the lines before your matches grep -B 3 'root' /etc/passwd display the lines after your matches grep -A 3 'root' /etc/passwd prints the searched line and 3 lines after and before the result grep -C 3 'root' /etc/passwd Display the file names that matches the pattern: grep -l \"unix\" * Displaying only the matched pattern: By default, grep displays the entire line which has the matched string. We can make the grep to display only the matched string by using the -o option. grep -o \"unix\" geekfile.txt Matching the lines that start with a string: The ^ regular expression pattern specifies the start of a line. grep \"^unix\" geekfile.txt Matching the lines that end with a string: The $ regular expression pattern specifies the end of a line. grep \"os$\" geekfile.txt Specifies multiple contents with -e option: grep \u2013e \"Agarwal\" \u2013e \"divi\" \u2013e \"jesh\" geekfile.txt Takes patterns from file, one per line using option -f: grep \u2013f pattern.txt geekfile.txt To search for string in directory recursive ignore errors: sudo grep - R anon / etc / 2 > / dev / null To find files: sudo grep - Rl anon / etc / 2 > / dev / null","title":"Grep"},{"location":"linux/rhcsa/#egrep","text":"The egrep command searches for a text pattern, using extended regular expressions to perform the match. Running egrep is equivalent to running grep with the -E option. Grep can understand some patterns but not all patterns. Display all lines start with 'D' grep '^D' text Display all lines end with 'D' grep 'D$' text Search for vowels in file grep '[aeiou]' text Search for other than vowels in file grep '[^aeiou]' text Search for multiple patterns grep -e 'hyd' -e 'ban' text or egrep '(hyd|ban)' text","title":"Egrep"},{"location":"linux/rhcsa/#fgrep","text":"Fixed strings grep cannot understand patterns, it can understand only strings. To search fast we use grep and performance wise. grep -F Some words are there in file.txt search those in demo.txt. fgrep -f file.txt demo.txt","title":"Fgrep"},{"location":"linux/rhcsa/#shuffling","text":"shuf -i 1-100 -n 1 8 touch pot/dir$(shuf -i 1-100 -n 1)/divi.txt find pot -type f -name 'divi.txt' move find result to desktop find pot -type f -name 'divi.txt' -exec mv {} ~/Desktop \\; Remove all files in pot but not dirs find pot -type f -name '*.txt' -exec rm {} \\;","title":"Shuffling"},{"location":"linux/software/","text":"rpm \u00b6 The RPM Package Manager (RPM) is a powerful package management system used by Red Hat Linux and its derivatives such as CentOS and Fedora. RPM also refers to the rpm command and .rpm file format. An RPM Package consists of an archive of files and metadata including information such as dependencies and install location. Link0 Link1 Link2 Link3 Link4 yum Configuration \u00b6 Link Link2 local yum repo \u00b6 Link Link yum \u00b6 Link CheatSheet Link dnf \u00b6 Link Link1 Application Stream and Modules \u00b6 Link Link1 Subscription Manager \u00b6 Link Link","title":"Software Management"},{"location":"linux/software/#rpm","text":"The RPM Package Manager (RPM) is a powerful package management system used by Red Hat Linux and its derivatives such as CentOS and Fedora. RPM also refers to the rpm command and .rpm file format. An RPM Package consists of an archive of files and metadata including information such as dependencies and install location. Link0 Link1 Link2 Link3 Link4","title":"rpm"},{"location":"linux/software/#yum-configuration","text":"Link Link2","title":"yum Configuration"},{"location":"linux/software/#local-yum-repo","text":"Link Link","title":"local yum repo"},{"location":"linux/software/#yum","text":"Link CheatSheet Link","title":"yum"},{"location":"linux/software/#dnf","text":"Link Link1","title":"dnf"},{"location":"linux/software/#application-stream-and-modules","text":"Link Link1","title":"Application Stream and Modules"},{"location":"linux/software/#subscription-manager","text":"Link Link","title":"Subscription Manager"},{"location":"linux/ssh/","text":"SSH (short for Secure Shell) is a network protocol that provides a secure way for two computers to connect remotely. SSH employs encryption to ensure that hackers cannot interpret the traffic between two connected devices. Ssh essentials Secure ssh server Basic ssh commands Ssh tutorial Ssh tutorial1 Ssh tutorial2 YoutubeLink OpenSSH is remote management tool, that gives you access to run commands on another machine Developed by OpenBSD project It's a suite of utilities, the most important of which are the server and client components You should have ssh client already installed, this ssh client will give ability to connect to a romote server but having ssh client doesn't give permission to outside of your network connect to your machine. Ssh client allows to connect to other servers but doesn't let anyone connect to you Check if ssh is installed which ssh","title":"OpenSSH"},{"location":"linux/systemd/","text":"Systemd is a collection of system management daemons, utilities, and libraries which serves as a replacement of System V init daemon. Systemd functions as central management and configuration platform for UNIX like system. Systemd is a system that is designed specifically for the Linux kernel. It replaces the sysvinit process to become the first process with PID = 1, which gets executed in user space during the Linux start-up process. systemctl \u00b6 Link Link","title":"Systemd Management"},{"location":"linux/systemd/#systemctl","text":"Link Link","title":"systemctl"},{"location":"linux/user/","text":"A user is an entity, in a Linux operating system, that can manipulate files and perform several other operations. Each user is assigned an ID that is unique for each user in the operating system. After installation of the operating system, the ID 0 is assigned to the root user and the IDs 1 to 999 (both inclusive) are assigned to the system users and hence the ids for local user begins from 1000 onwards. In a single directory, we can create 60,000 users. Now we will discuss the important commands to manage users in Linux. To list out all the users in Linux, use the awk command with -F option. Here, we are accessing a file and printing only first column with the help of print $1 and awk. awk -F ':' '{ print $1}' /etc/passwd Using id command, you can get the ID of any username. id username Useradd \u00b6 Reference: Link Reference1: Link1 The command to add a user sudo useradd username Add description/comment to a user account. sudo useradd -c \"John Wise\" john Set the home directory for the specified user sudo useradd -d /mnt/home/john For instance some of parameters to add a new user useradd -g tech -G apple,linux -s /bin/zsh -c \"James Adem\" adem -g: Allows you to set the primary group of a user. The user will be added to a group by default if you don't add one during the creation process. -G: Adds the user to multiple groups. -s: Sets Zsh as the default shell for the user You can also view/modify the default settings using the useradd command. useradd -D -b Modifies the default home directory (/home) for new user accounts. -g Modifies the default new user primary group (username) with another default group. -s Replaces the default /bin/bash shell with another default shell. -e Modifies the default expiration date to disable a user account in YYYY-MM-DD format. -f Allows to set inactive days before the account is disabled and after password expiration For instance useradd -D -b /home/new -s /bin/sh User with Account Expiry Date useradd -e 2024 -03-27 divi Create a User with Password Expiry Date We will set an account password expiry date i.e. 45 days on a user \u2018mansi\u2018 using \u2018-e\u2018 and \u2018-f\u2018 options. useradd -e 2024 -04-27 -f 45 mansi Create user with specific UID and GID useradd -u 1000 -g 500 divi Usermod \u00b6 Reference: Link Reference1: Link1 To change the user ID for a user. sudo usermod -u 1982 test Modify the group ID of a user. This command can change the group ID of a user and hence it can even be used to move a user to an already existing group. sudo usermod -g 1005 test Change the user login name sudo usermod -l new_login_name old_login_name Command to change the home directory usermod -d new_home_directory_path username To include adem in the sales group You'll need to use the -aG flag as a simple -G flag will remove the user from the previously added supplementary groups usermod -aG sales adem Passwd \u00b6 Reference: Link Reference1: Link1 Referenc2: Link2 Using passwd command to assign a password to a user. passwd username Accessing a user configuration file. cat /etc/passwd username:password:UID:GID:comment:home:shell Userdel \u00b6 Reference: Link Reference1: Link1 Make sure that the user is not part of a group. If the user is part of a group then it will not be deleted directly, hence we will have to first remove him from the group and then we can delete him. userdel -r username Groupadd \u00b6 Reference: Link Reference1: Link1 Groupmod \u00b6 Reference: Link Groupdel \u00b6 Reference: Link Chmod \u00b6 Reference: Link Reference1: Link1 Chown \u00b6 Reference: Link Reference1: Link1 Chgrp \u00b6 Reference: Link Chroot \u00b6 Reference: Link Chage \u00b6 Reference: Link Reference1: Link1 Password aging \u00b6 Reference: Link Umask \u00b6 Reference: Link Reference1: Link1 Special permissions \u00b6 Reference: Link Reference1: Link1 Reference2: Link2","title":"User Management"},{"location":"linux/user/#useradd","text":"Reference: Link Reference1: Link1 The command to add a user sudo useradd username Add description/comment to a user account. sudo useradd -c \"John Wise\" john Set the home directory for the specified user sudo useradd -d /mnt/home/john For instance some of parameters to add a new user useradd -g tech -G apple,linux -s /bin/zsh -c \"James Adem\" adem -g: Allows you to set the primary group of a user. The user will be added to a group by default if you don't add one during the creation process. -G: Adds the user to multiple groups. -s: Sets Zsh as the default shell for the user You can also view/modify the default settings using the useradd command. useradd -D -b Modifies the default home directory (/home) for new user accounts. -g Modifies the default new user primary group (username) with another default group. -s Replaces the default /bin/bash shell with another default shell. -e Modifies the default expiration date to disable a user account in YYYY-MM-DD format. -f Allows to set inactive days before the account is disabled and after password expiration For instance useradd -D -b /home/new -s /bin/sh User with Account Expiry Date useradd -e 2024 -03-27 divi Create a User with Password Expiry Date We will set an account password expiry date i.e. 45 days on a user \u2018mansi\u2018 using \u2018-e\u2018 and \u2018-f\u2018 options. useradd -e 2024 -04-27 -f 45 mansi Create user with specific UID and GID useradd -u 1000 -g 500 divi","title":"Useradd"},{"location":"linux/user/#usermod","text":"Reference: Link Reference1: Link1 To change the user ID for a user. sudo usermod -u 1982 test Modify the group ID of a user. This command can change the group ID of a user and hence it can even be used to move a user to an already existing group. sudo usermod -g 1005 test Change the user login name sudo usermod -l new_login_name old_login_name Command to change the home directory usermod -d new_home_directory_path username To include adem in the sales group You'll need to use the -aG flag as a simple -G flag will remove the user from the previously added supplementary groups usermod -aG sales adem","title":"Usermod"},{"location":"linux/user/#passwd","text":"Reference: Link Reference1: Link1 Referenc2: Link2 Using passwd command to assign a password to a user. passwd username Accessing a user configuration file. cat /etc/passwd username:password:UID:GID:comment:home:shell","title":"Passwd"},{"location":"linux/user/#userdel","text":"Reference: Link Reference1: Link1 Make sure that the user is not part of a group. If the user is part of a group then it will not be deleted directly, hence we will have to first remove him from the group and then we can delete him. userdel -r username","title":"Userdel"},{"location":"linux/user/#groupadd","text":"Reference: Link Reference1: Link1","title":"Groupadd"},{"location":"linux/user/#groupmod","text":"Reference: Link","title":"Groupmod"},{"location":"linux/user/#groupdel","text":"Reference: Link","title":"Groupdel"},{"location":"linux/user/#chmod","text":"Reference: Link Reference1: Link1","title":"Chmod"},{"location":"linux/user/#chown","text":"Reference: Link Reference1: Link1","title":"Chown"},{"location":"linux/user/#chgrp","text":"Reference: Link","title":"Chgrp"},{"location":"linux/user/#chroot","text":"Reference: Link","title":"Chroot"},{"location":"linux/user/#chage","text":"Reference: Link Reference1: Link1","title":"Chage"},{"location":"linux/user/#password-aging","text":"Reference: Link","title":"Password aging"},{"location":"linux/user/#umask","text":"Reference: Link Reference1: Link1","title":"Umask"},{"location":"linux/user/#special-permissions","text":"Reference: Link Reference1: Link1 Reference2: Link2","title":"Special permissions"},{"location":"linux/vi/","text":"Vim is a very powerful editor that has many commands, too many to explain in a tutor such as this. This tutor is designed to describe enough of the commands that you will be able to easily use Vim as an all-purpose editor. Exiting Vim \u00b6 Press the Esc key (to make sure you are in Normal mode). Type :q! Enter This exits the editor, DISCARDING any changes you have made. Text Editing - Deletion \u00b6 Press x to delete the character under the cursor. Text Editing - Insertion \u00b6 Press i to insert text. Text Editing - Appending \u00b6 Press A to append text. It moves to end of line in insert mode. Save and Quit \u00b6 Use :wq to save a file and exit. Deletion Commands \u00b6 Type dw to delete a word. Type d$ to delete to the end of the line. Operators and Motion \u00b6 Many commands that change text are made from an operator and a motion. The format for a delete command with the d delete operator is as follows: d and motion d - is the delete operator. motion - is what the operator will operate on (listed below). A short list of motions: w - until the start of the next word, EXCLUDING its first character. e - to the end of the current word, INCLUDING the last character. $ - to the end of the line, INCLUDING the last character. de - will delete from the cursor to the end of the word. Using a Count for Motion: Typing a number before a motion repeats it that many times. 2w to move the cursor two words forward. 3e to move the cursor to the end of the third word forward. 0 (zero) to move to the start of the line. Using a Count to Delete More: Typing a number with an operator repeats it that many times. d number motion Type d2w or 2dw to delete two words. Operating on Line: Type dd to delete a whole line. Type 2dd to delete two lines. Undo \u00b6 Press u to undo the last commands, U to fix a whole line. Now type CTRL-R (keeping CTRL key pressed while hitting R) a few times to redo the commands (undo the undo's). Delete Summary \u00b6 To delete from the cursor up to the next word type: dw To delete from the cursor up to the end of the word type: de To delete from the cursor to the end of a line type: d$ To delete a whole line type: dd Put Command \u00b6 Type dd to delete the line and store it in a Vim register. Type p to put previously deleted text after the cursor. Replace Command \u00b6 Type rx to replace the character at the cursor with x . Another way to replace Type a capital R to replace more than one character. Replace mode is like Insert mode, but every typed character deletes an existing character. Change Operator \u00b6 To change until the end of a word, type ce . Type ce and the correct word. cc does the same for the whole line. The change operator works in the same way as delete. The format is: c [number] motion The motions are the same, such as w (word) and $ (end of line). Cursor Location and File Status \u00b6 Type CTRL-G to show your location in the file and the file status. Press G to move you to the bottom of the file. Type gg to move you to the start of the file. Type the number of the line you were on and then G, ex. 34G Search Command \u00b6 Type / followed by a phrase to search for the phrase. To search for the same phrase again, simply type n . To search for the same phrase in the opposite direction, type N . To search for a phrase in the backward direction, use ? instead of / . To go back to where you came from press CTRL-O (Keep Ctrl down while pressing the letter o). Repeat to go back further. CTRL-I goes forward. Matching Parentheses Search \u00b6 Type % to find a matching ),], or } . The cursor will move to the matching parenthesis or bracket. Substitute Command \u00b6 Type :s/old/new/g to substitute 'new' for 'old'. Type :s/thee/the Enter . Note that this command only changes the first occurrence of \"thee\" in the line. Now type :s/thee/the/g . Adding the g flag means to substitute globally in the line, change all occurrences of \"thee\" in the line. To change every occurrence of a character string between two lines, Type :#,#s/old/new/g where #,# are the line numbers of the range of lines where the substitution is to be done. Type :%s/old/new/g to change every occurrence in the whole file. Type :%s/old/new/gc to find every occurrence in the whole file, with a prompt whether to substitute or not. Execute External Command \u00b6 Type :! followed by an external command to execute that command. :!ls :!pwd for example. Writing Files \u00b6 To save the changes made to the text, type :w FILENAME Now remove the file by typing (Windows) :!del TEST or (Unix): :!rm TEST Selecting Text to Write \u00b6 To save part of the file, type v motion :w FILENAME Press v and move the cursor to the fifth item below. Notice that the text is highlighted. Press the : character. At the bottom of the screen :'<,'> will appear. Type w TEST , where TEST is a filename that does not exist yet. Verify that you see :'<,'>w TEST before you press Enter Retrieving and Merging Files \u00b6 To insert the contents of a file, type :r FILENAME You can also read the output of an external command. For example, :r !ls reads the output of the ls command and puts it below the cursor. :r FILENAME retrieves disk file FILENAME and puts it below the cursor position. :r !dir reads the output of the dir command and puts it below the cursor position. Open Command \u00b6 Type o to open a line below the cursor and place you in Insert mode. To open up a line ABOVE the cursor, simply type a capital O Append Command \u00b6 Type a to insert text AFTER the cursor. Use e to move to the next incomplete word. a, i and A all go to the same Insert mode, the only difference is where the characters are inserted. Copy and Paste \u00b6 Use the y operator to copy text and p to paste it. You can also use y as an operator: yw yanks one word, yy yanks the whole line, then p puts that line. Set Option \u00b6 Set an option so a search or substitute ignores case. Typing \":set xxx\" sets the option \"xxx\". Some options are: 'ic' 'ignorecase' ignore upper/lower case when searching 'is' 'incsearch' show partial matches for a search phrase 'hls' 'hlsearch' highlight all matching phrases, You can either use the long or the short option name. Prepend \"no\" to switch an option off. :set noic Getting Help \u00b6 :help w :help c_CTRL-D :help insert-index :help user-manual Type CTRL-W CTRL-W to jump from one window to another. Type :q Enter to close the help window. Completion \u00b6 Command line completion with CTRL-D and Tab Type the start of a command :e CTRL-D and Vim will show a list of commands that start with \"e\". Comment multiple lines \u00b6 Press the Ctrl + V keys to enable visual mode. Select all the lines you wish to comment out. With the target lines selected, press Shift + I to enter insert mode. We need to insert the pound (#) symbol. Finally, press the ESC key, and Vim will comment out all the selected lines. Notes \u00b6 :e! -- Discard unsavedchanges in file. :sh -- Switch to shell temporary, copy something. ctrl+d return to vi file. X -- Remove left side chars. D -- Remove everything from cursor right side. dG -- Remove everything below d1G -- Remove everything above :set nu -- Set numbers :set nonu -- Remove numbers :11,15d -- Remove everything between 11 to 15 G -- last line 1G -- first line 60G -- to go to line L -- last line of display H -- top line of display M -- middle line cc -- Remove line and insert C -- Remove everything from cursor right side and insert. J -- Join 2 lines :1,5 co 9 -- after 9 th line 1 to 5 lines copied :4 m 2 -- after 2nd line 4 line will be moved. shift + o -- new line on top of cursor. :set ic -- ignore case sensitive :set noic -- case sensitive","title":"Vim"},{"location":"linux/vi/#exiting-vim","text":"Press the Esc key (to make sure you are in Normal mode). Type :q! Enter This exits the editor, DISCARDING any changes you have made.","title":"Exiting Vim"},{"location":"linux/vi/#text-editing-deletion","text":"Press x to delete the character under the cursor.","title":"Text Editing - Deletion"},{"location":"linux/vi/#text-editing-insertion","text":"Press i to insert text.","title":"Text Editing - Insertion"},{"location":"linux/vi/#text-editing-appending","text":"Press A to append text. It moves to end of line in insert mode.","title":"Text Editing - Appending"},{"location":"linux/vi/#save-and-quit","text":"Use :wq to save a file and exit.","title":"Save and Quit"},{"location":"linux/vi/#deletion-commands","text":"Type dw to delete a word. Type d$ to delete to the end of the line.","title":"Deletion Commands"},{"location":"linux/vi/#operators-and-motion","text":"Many commands that change text are made from an operator and a motion. The format for a delete command with the d delete operator is as follows: d and motion d - is the delete operator. motion - is what the operator will operate on (listed below). A short list of motions: w - until the start of the next word, EXCLUDING its first character. e - to the end of the current word, INCLUDING the last character. $ - to the end of the line, INCLUDING the last character. de - will delete from the cursor to the end of the word. Using a Count for Motion: Typing a number before a motion repeats it that many times. 2w to move the cursor two words forward. 3e to move the cursor to the end of the third word forward. 0 (zero) to move to the start of the line. Using a Count to Delete More: Typing a number with an operator repeats it that many times. d number motion Type d2w or 2dw to delete two words. Operating on Line: Type dd to delete a whole line. Type 2dd to delete two lines.","title":"Operators and Motion"},{"location":"linux/vi/#undo","text":"Press u to undo the last commands, U to fix a whole line. Now type CTRL-R (keeping CTRL key pressed while hitting R) a few times to redo the commands (undo the undo's).","title":"Undo"},{"location":"linux/vi/#delete-summary","text":"To delete from the cursor up to the next word type: dw To delete from the cursor up to the end of the word type: de To delete from the cursor to the end of a line type: d$ To delete a whole line type: dd","title":"Delete Summary"},{"location":"linux/vi/#put-command","text":"Type dd to delete the line and store it in a Vim register. Type p to put previously deleted text after the cursor.","title":"Put Command"},{"location":"linux/vi/#replace-command","text":"Type rx to replace the character at the cursor with x . Another way to replace Type a capital R to replace more than one character. Replace mode is like Insert mode, but every typed character deletes an existing character.","title":"Replace Command"},{"location":"linux/vi/#change-operator","text":"To change until the end of a word, type ce . Type ce and the correct word. cc does the same for the whole line. The change operator works in the same way as delete. The format is: c [number] motion The motions are the same, such as w (word) and $ (end of line).","title":"Change Operator"},{"location":"linux/vi/#cursor-location-and-file-status","text":"Type CTRL-G to show your location in the file and the file status. Press G to move you to the bottom of the file. Type gg to move you to the start of the file. Type the number of the line you were on and then G, ex. 34G","title":"Cursor Location and File Status"},{"location":"linux/vi/#search-command","text":"Type / followed by a phrase to search for the phrase. To search for the same phrase again, simply type n . To search for the same phrase in the opposite direction, type N . To search for a phrase in the backward direction, use ? instead of / . To go back to where you came from press CTRL-O (Keep Ctrl down while pressing the letter o). Repeat to go back further. CTRL-I goes forward.","title":"Search Command"},{"location":"linux/vi/#matching-parentheses-search","text":"Type % to find a matching ),], or } . The cursor will move to the matching parenthesis or bracket.","title":"Matching Parentheses Search"},{"location":"linux/vi/#substitute-command","text":"Type :s/old/new/g to substitute 'new' for 'old'. Type :s/thee/the Enter . Note that this command only changes the first occurrence of \"thee\" in the line. Now type :s/thee/the/g . Adding the g flag means to substitute globally in the line, change all occurrences of \"thee\" in the line. To change every occurrence of a character string between two lines, Type :#,#s/old/new/g where #,# are the line numbers of the range of lines where the substitution is to be done. Type :%s/old/new/g to change every occurrence in the whole file. Type :%s/old/new/gc to find every occurrence in the whole file, with a prompt whether to substitute or not.","title":"Substitute Command"},{"location":"linux/vi/#execute-external-command","text":"Type :! followed by an external command to execute that command. :!ls :!pwd for example.","title":"Execute External Command"},{"location":"linux/vi/#writing-files","text":"To save the changes made to the text, type :w FILENAME Now remove the file by typing (Windows) :!del TEST or (Unix): :!rm TEST","title":"Writing Files"},{"location":"linux/vi/#selecting-text-to-write","text":"To save part of the file, type v motion :w FILENAME Press v and move the cursor to the fifth item below. Notice that the text is highlighted. Press the : character. At the bottom of the screen :'<,'> will appear. Type w TEST , where TEST is a filename that does not exist yet. Verify that you see :'<,'>w TEST before you press Enter","title":"Selecting Text to Write"},{"location":"linux/vi/#retrieving-and-merging-files","text":"To insert the contents of a file, type :r FILENAME You can also read the output of an external command. For example, :r !ls reads the output of the ls command and puts it below the cursor. :r FILENAME retrieves disk file FILENAME and puts it below the cursor position. :r !dir reads the output of the dir command and puts it below the cursor position.","title":"Retrieving and Merging Files"},{"location":"linux/vi/#open-command","text":"Type o to open a line below the cursor and place you in Insert mode. To open up a line ABOVE the cursor, simply type a capital O","title":"Open Command"},{"location":"linux/vi/#append-command","text":"Type a to insert text AFTER the cursor. Use e to move to the next incomplete word. a, i and A all go to the same Insert mode, the only difference is where the characters are inserted.","title":"Append Command"},{"location":"linux/vi/#copy-and-paste","text":"Use the y operator to copy text and p to paste it. You can also use y as an operator: yw yanks one word, yy yanks the whole line, then p puts that line.","title":"Copy and Paste"},{"location":"linux/vi/#set-option","text":"Set an option so a search or substitute ignores case. Typing \":set xxx\" sets the option \"xxx\". Some options are: 'ic' 'ignorecase' ignore upper/lower case when searching 'is' 'incsearch' show partial matches for a search phrase 'hls' 'hlsearch' highlight all matching phrases, You can either use the long or the short option name. Prepend \"no\" to switch an option off. :set noic","title":"Set Option"},{"location":"linux/vi/#getting-help","text":":help w :help c_CTRL-D :help insert-index :help user-manual Type CTRL-W CTRL-W to jump from one window to another. Type :q Enter to close the help window.","title":"Getting Help"},{"location":"linux/vi/#completion","text":"Command line completion with CTRL-D and Tab Type the start of a command :e CTRL-D and Vim will show a list of commands that start with \"e\".","title":"Completion"},{"location":"linux/vi/#comment-multiple-lines","text":"Press the Ctrl + V keys to enable visual mode. Select all the lines you wish to comment out. With the target lines selected, press Shift + I to enter insert mode. We need to insert the pound (#) symbol. Finally, press the ESC key, and Vim will comment out all the selected lines.","title":"Comment multiple lines"},{"location":"linux/vi/#notes","text":":e! -- Discard unsavedchanges in file. :sh -- Switch to shell temporary, copy something. ctrl+d return to vi file. X -- Remove left side chars. D -- Remove everything from cursor right side. dG -- Remove everything below d1G -- Remove everything above :set nu -- Set numbers :set nonu -- Remove numbers :11,15d -- Remove everything between 11 to 15 G -- last line 1G -- first line 60G -- to go to line L -- last line of display H -- top line of display M -- middle line cc -- Remove line and insert C -- Remove everything from cursor right side and insert. J -- Join 2 lines :1,5 co 9 -- after 9 th line 1 to 5 lines copied :4 m 2 -- after 2nd line 4 line will be moved. shift + o -- new line on top of cursor. :set ic -- ignore case sensitive :set noic -- case sensitive","title":"Notes"},{"location":"linux-desktop/hardening/","text":"There are a number of procedures you can follow to make your Linux desktop system more secure, some more advanced than others. We cover some general techniques here. Firewalls \u00b6 A firewall may be used to secure connections to your system. If you\u2019re on a public network, the necessity of this may be greater than if you\u2019re on a local trusted network that you control. We would generally recommend that you block incoming connections only, unless you\u2019re using an application firewall such as OpenSnitch or Portmaster . Red Hat distributions (such as Fedora) are typically configured through firewalld . Red Hat has plenty of documentation regarding this topic. There is also the Uncomplicated Firewall which can be used as an alternative. Consider blocking all ports which are not well known or \u201cprivileged ports\u201d. That is, ports from 1025 up to 65535. Block both TCP and UDP after the operating system is installed. If you use Fedora, consider removing the whitelist for for smb -client and mdns services if you do not use them. All these firewalls use the Netfilter framework and therefore cannot protect against malicious programs running on the system. A malicious program could insert its own rules. If you are using Flatpak packages, you can revoke their network socket access using Flatseal and prevent those applications from accessing your network. This permission is not bypassable. If you are using non-classic Snap packages on a system with proper snap confinement support (with both AppArmor and cgroups v1 present), you can use the Snap Store to revoke network permission as well. This is also not bypassable. Kernel hardening \u00b6 There are some additional kernel hardening options such as configuring sysctl keys and kernel command-line parameters which are described in the following pages. We don\u2019t recommend you change these options unless you learn about what they do. Recommended sysctl settings Recommended boot parameters Additional recommendations to reduce the kernel's attack surface Note that setting kernel.unprivileged_userns_clone=0 will stop Flatpak, Snap (that depend on browser-sandbox), Electron based AppImages, Podman, Docker, and LXC containers from working. Do not set this flag if you are using container products. Linux-Hardened \u00b6 Some distributions like Arch Linux have the linux-hardened , kernel package. It includes hardening patches and more security-conscious defaults. Linux-Hardened has kernel.unprivileged_userns_clone=0 disabled by default. See the warning above about how this might impact you. Simultaneous multithreading (SMT) \u00b6 SMT has been the cause of numerous hardware vulnerabilities, and subsequent patches for those vulnerabilities often come with performance penalties that negate most of the performance gain given by SMT. If you followed the \u201ckernel hardening\u201d section above, some kernel parameters already disable SMT. If the option is available to you, we recommend that you disable it in your firmware as well. Hardened memory allocator \u00b6 The hardened memory allocator from GrapheneOS can be used on Linux distributions. It is available by default on Whonix and is available as an AUR package on Arch based distributions. If you are using the AUR package, consider setting up LD_PRELOAD as described in the Arch Wiki . Umask \u00b6 If you are not using openSUSE, consider changing the default umask for both regular user accounts and root to 077. Changing umask to 077 can break snapper on openSUSE and is not recommended. Mountpoint hardening \u00b6 Consider adding the following options nodev , noexec , and nosuid to mountpoints which do not need them. Typically, these could be applied to /boot , /boot/efi , /home , /root , and /var . If you use Toolbox , /var/log/journal must not have any of those options. If you are on Arch Linux, do not apply noexec to /var/tmp . Linux Pluggable Authentication Modules (PAM) \u00b6 There is also further hardening to PAM to secure authentication to your system. This guide has some tips on this. On Red Hat distributions you can use authselect to configure this e.g.: sudo authselect select <profile_id, default: sssd> with-faillock without-nullok with-pamaccess On systems where pam_faillock is not available, consider using pam_tally2 instead. USB port protection \u00b6 To better protect your USB ports from attacks such as BadUSB we recommend USBGuard . USBGuard has documentation as does the Arch Wiki . Another alternative option if you\u2019re using the linux-hardened is the deny_new_usb sysctl. See Preventing USB Attacks with linux-hardened . Secure Boot \u00b6 Secure Boot can be used to secure the boot process by preventing the loading of unsigned UEFI drivers or boot loaders . Some guidance for this is provided in this physical security guide and this verified boot guide . For further resources on Secure Boot we suggest taking a look at the following for instructional advice: The Archwiki\u2019s Secure Boot article. There are two main methods, the first is to use a shim , the second more complete way is to use your own keys . For background of how Secure Boot works on Linux: The Strange State of Authenticated Boot and Disk Encryption on Generic Linux Distributions Rod Smith\u2019s Managing EFI Boot Loaders for Linux Dealing with Secure Boot Controlling Secure Boot One of the problems with Secure Boot particularly on Linux is that only the chainloader (shim), the boot loader (GRUB), and the kernel are verified and that\u2019s where verification stops. The initramfs is often left unverified, unencrypted, and open up the window for an evil maid attack. There are a few things that can be done to reduce risk such as: Creating an EFI Boot Stub that contains the kernel , initramfs and microcode . This EFI stub can then be signed. If you use dracut this can easily be done with the --uefi-stub switch or the uefi_stub config option. Encrypting the boot partition . However, this has its own issues, the first being that GRUB only supports LUKS1 and not the newer default LUKS2 scheme. As the bootloader runs in protected mode and the encryption module lacks SSE acceleration the boot process will take minutes to complete. Using TPM to perform a measured boot . After setting up Secure Boot it is crucial that you set a \u201cfirmware password\u201d (also called a \u201csupervisor password, \u201cBIOS password\u201d or \u201cUEFI password\u201d), otherwise an adversary can simply disable Secure Boot. These recommendations can make you a little more resistant to evil maid attacks, but they not good as a proper verified boot process such as that found on Android , ChromeOS or Windows .","title":"System Hardening"},{"location":"linux-desktop/hardening/#firewalls","text":"A firewall may be used to secure connections to your system. If you\u2019re on a public network, the necessity of this may be greater than if you\u2019re on a local trusted network that you control. We would generally recommend that you block incoming connections only, unless you\u2019re using an application firewall such as OpenSnitch or Portmaster . Red Hat distributions (such as Fedora) are typically configured through firewalld . Red Hat has plenty of documentation regarding this topic. There is also the Uncomplicated Firewall which can be used as an alternative. Consider blocking all ports which are not well known or \u201cprivileged ports\u201d. That is, ports from 1025 up to 65535. Block both TCP and UDP after the operating system is installed. If you use Fedora, consider removing the whitelist for for smb -client and mdns services if you do not use them. All these firewalls use the Netfilter framework and therefore cannot protect against malicious programs running on the system. A malicious program could insert its own rules. If you are using Flatpak packages, you can revoke their network socket access using Flatseal and prevent those applications from accessing your network. This permission is not bypassable. If you are using non-classic Snap packages on a system with proper snap confinement support (with both AppArmor and cgroups v1 present), you can use the Snap Store to revoke network permission as well. This is also not bypassable.","title":"Firewalls"},{"location":"linux-desktop/hardening/#kernel-hardening","text":"There are some additional kernel hardening options such as configuring sysctl keys and kernel command-line parameters which are described in the following pages. We don\u2019t recommend you change these options unless you learn about what they do. Recommended sysctl settings Recommended boot parameters Additional recommendations to reduce the kernel's attack surface Note that setting kernel.unprivileged_userns_clone=0 will stop Flatpak, Snap (that depend on browser-sandbox), Electron based AppImages, Podman, Docker, and LXC containers from working. Do not set this flag if you are using container products.","title":"Kernel hardening"},{"location":"linux-desktop/hardening/#linux-hardened","text":"Some distributions like Arch Linux have the linux-hardened , kernel package. It includes hardening patches and more security-conscious defaults. Linux-Hardened has kernel.unprivileged_userns_clone=0 disabled by default. See the warning above about how this might impact you.","title":"Linux-Hardened"},{"location":"linux-desktop/hardening/#simultaneous-multithreading-smt","text":"SMT has been the cause of numerous hardware vulnerabilities, and subsequent patches for those vulnerabilities often come with performance penalties that negate most of the performance gain given by SMT. If you followed the \u201ckernel hardening\u201d section above, some kernel parameters already disable SMT. If the option is available to you, we recommend that you disable it in your firmware as well.","title":"Simultaneous multithreading (SMT)"},{"location":"linux-desktop/hardening/#hardened-memory-allocator","text":"The hardened memory allocator from GrapheneOS can be used on Linux distributions. It is available by default on Whonix and is available as an AUR package on Arch based distributions. If you are using the AUR package, consider setting up LD_PRELOAD as described in the Arch Wiki .","title":"Hardened memory allocator"},{"location":"linux-desktop/hardening/#umask","text":"If you are not using openSUSE, consider changing the default umask for both regular user accounts and root to 077. Changing umask to 077 can break snapper on openSUSE and is not recommended.","title":"Umask"},{"location":"linux-desktop/hardening/#mountpoint-hardening","text":"Consider adding the following options nodev , noexec , and nosuid to mountpoints which do not need them. Typically, these could be applied to /boot , /boot/efi , /home , /root , and /var . If you use Toolbox , /var/log/journal must not have any of those options. If you are on Arch Linux, do not apply noexec to /var/tmp .","title":"Mountpoint hardening"},{"location":"linux-desktop/hardening/#linux-pluggable-authentication-modules-pam","text":"There is also further hardening to PAM to secure authentication to your system. This guide has some tips on this. On Red Hat distributions you can use authselect to configure this e.g.: sudo authselect select <profile_id, default: sssd> with-faillock without-nullok with-pamaccess On systems where pam_faillock is not available, consider using pam_tally2 instead.","title":"Linux Pluggable Authentication Modules (PAM)"},{"location":"linux-desktop/hardening/#usb-port-protection","text":"To better protect your USB ports from attacks such as BadUSB we recommend USBGuard . USBGuard has documentation as does the Arch Wiki . Another alternative option if you\u2019re using the linux-hardened is the deny_new_usb sysctl. See Preventing USB Attacks with linux-hardened .","title":"USB port protection"},{"location":"linux-desktop/hardening/#secure-boot","text":"Secure Boot can be used to secure the boot process by preventing the loading of unsigned UEFI drivers or boot loaders . Some guidance for this is provided in this physical security guide and this verified boot guide . For further resources on Secure Boot we suggest taking a look at the following for instructional advice: The Archwiki\u2019s Secure Boot article. There are two main methods, the first is to use a shim , the second more complete way is to use your own keys . For background of how Secure Boot works on Linux: The Strange State of Authenticated Boot and Disk Encryption on Generic Linux Distributions Rod Smith\u2019s Managing EFI Boot Loaders for Linux Dealing with Secure Boot Controlling Secure Boot One of the problems with Secure Boot particularly on Linux is that only the chainloader (shim), the boot loader (GRUB), and the kernel are verified and that\u2019s where verification stops. The initramfs is often left unverified, unencrypted, and open up the window for an evil maid attack. There are a few things that can be done to reduce risk such as: Creating an EFI Boot Stub that contains the kernel , initramfs and microcode . This EFI stub can then be signed. If you use dracut this can easily be done with the --uefi-stub switch or the uefi_stub config option. Encrypting the boot partition . However, this has its own issues, the first being that GRUB only supports LUKS1 and not the newer default LUKS2 scheme. As the bootloader runs in protected mode and the encryption module lacks SSE acceleration the boot process will take minutes to complete. Using TPM to perform a measured boot . After setting up Secure Boot it is crucial that you set a \u201cfirmware password\u201d (also called a \u201csupervisor password, \u201cBIOS password\u201d or \u201cUEFI password\u201d), otherwise an adversary can simply disable Secure Boot. These recommendations can make you a little more resistant to evil maid attacks, but they not good as a proper verified boot process such as that found on Android , ChromeOS or Windows .","title":"Secure Boot"},{"location":"linux-desktop/overview/","text":"It is often believed that open source software is inherently secure because the source code is available. There is an expectation that community verification occurs regularly; however, this isn\u2019t always the case . It does depend on a number of factors, such as project activity, developer experience, level of rigour applied to code reviews , and how often attention is given to specific parts of the codebase that may go untouched for years. At the moment, desktop GNU/Linux does have some areas that could be better improved when compared to their proprietary counterparts, e.g: A verified boot chain, unlike Apple\u2019s Secure Boot (with Secure Enclave ), Android\u2019s Verified Boot or Microsoft Windows\u2019s boot process with TPM . These features and hardware technologies can all help prevent persistent tampering by malware or evil maid attacks Strong sandboxing solution such as that found in macOS , ChromeOS , and Android . Commonly used Linux sandboxing solutions such as Flatpak and Firejail still have a long way to go Strong exploit mitigations Despite these drawbacks, desktop GNU/Linux distributions are great if you want to: Avoid telemetry that often comes with proprietary operating systems Maintain software freedom Have purpose built systems such as Whonix or Tails Our website generally uses the term \u201cLinux\u201d to describe desktop GNU/Linux distributions. Other operating systems which also use the Linux kernel such as ChromeOS, Android, and Qubes OS are not discussed here. Our Linux Recommendations Release cycle \u00b6 We highly recommend that you choose distributions which stay close to the stable upstream software releases, often referred to as rolling release distributions. This is because frozen release cycle distributions often don\u2019t update package versions and fall behind on security updates. For frozen distributions, package maintainers are expected to backport patches to fix vulnerabilities (Debian is one such example ) rather than bump the software to the \u201cnext version\u201d released by the upstream developer. Some security fixes do not receive a CVE (particularly less popular software) at all and therefore do not make it into the distribution with this patching model. As a result minor security fixes are sometimes held back until the next major release. We don\u2019t believe holding packages back and applying interim patches is a good idea, as it diverges from the way the developer might have intended the software to work. Richard Brown has a presentation about this: Traditional vs Atomic updates \u00b6 Traditionally, Linux distributions update by sequentially updating the desired packages. Traditional updates such as those used in Fedora, Arch Linux, and Debian based distributions can be less reliable if an error occurs while updating. Atomic updating distributions apply updates in full or not at all. Typically, transactional update systems are also atomic. A transactional update system creates a snapshot that is made before and after an update is applied. If an update fails at any time (perhaps due to a power failure), the update can be easily rolled back to a \u201clast known good state\u201d. The Atomic update method is used for immutable distributions like Silverblue, Tumbleweed, and NixOS and can achieve reliability with this model. Adam \u0160amal\u00edk provided a presentation on how rpm-ostree works with Silverblue: \u201cSecurity-focused\u201d distributions \u00b6 There is often some confusion about \u201csecurity-focused\u201d distributions and \u201cpentesting\u201d distributions. A quick search for \u201cthe most secure Linux distribution\u201d will often give results like Kali Linux, Black Arch, and Parrot OS . These distributions are offensive penetration testing distributions that bundle tools for testing other systems. They don\u2019t include any \u201cextra security\u201d or defensive mitigations intended for regular use. Arch-based distributions \u00b6 Arch based distributions are not recommended for those new to Linux, regardless of the distribution. Arch does not have an distribution update mechanism for the underlying software choices. As a result you have to stay aware with current trends and adopt technologies as they supersede older practices on your own. For a secure system, you are also expected to have sufficient Linux knowledge to properly set up security for their system such as adopting a mandatory access control system, setting up kernel module blacklists, hardening boot parameters, manipulating sysctl parameters, and knowing what components they need such as Polkit . Anyone using the Arch User Repository (AUR) , must be comfortable in auditing PKGBUILDs that they install from that service. AUR packages are community-produced content and are not vetted in any way, and therefore are vulnerable to software supply chain attacks, which has in fact happened in the past . AUR should always be used sparingly and often there is a lot of bad advice on various pages which direct people to blindly use AUR helpers without sufficient warning. Similar warnings apply to using third party Personal Package Archives (PPAs) on Debian based distributions or Community Projects (COPR) on Fedora. If you are experienced with Linux and wish to use an Arch-based distribution, we only recommend Arch Linux proper, not any of its derivatives. We recommend against these two Arch derivatives specifically: Manjaro : This distribution holds packages back for 2 weeks to make sure that their own changes don\u2019t break, not to make sure that upstream is stable. When AUR packages are used, they are often built against the latest libraries from Arch\u2019s repositories. Garuda : They use Chaotic-AUR which automatically and blindly compiles packages from the AUR. There is no verification process to make sure that the AUR packages don\u2019t suffer from supply chain attacks. Linux-libre kernel and \u201cLibre\u201d distributions \u00b6 We strongly recommend against using the Linux-libre kernel, since it removes security mitigations and suppresses kernel warnings about vulnerable microcode for ideological reasons.","title":"Linux Overview"},{"location":"linux-desktop/overview/#release-cycle","text":"We highly recommend that you choose distributions which stay close to the stable upstream software releases, often referred to as rolling release distributions. This is because frozen release cycle distributions often don\u2019t update package versions and fall behind on security updates. For frozen distributions, package maintainers are expected to backport patches to fix vulnerabilities (Debian is one such example ) rather than bump the software to the \u201cnext version\u201d released by the upstream developer. Some security fixes do not receive a CVE (particularly less popular software) at all and therefore do not make it into the distribution with this patching model. As a result minor security fixes are sometimes held back until the next major release. We don\u2019t believe holding packages back and applying interim patches is a good idea, as it diverges from the way the developer might have intended the software to work. Richard Brown has a presentation about this:","title":"Release cycle"},{"location":"linux-desktop/overview/#traditional-vs-atomic-updates","text":"Traditionally, Linux distributions update by sequentially updating the desired packages. Traditional updates such as those used in Fedora, Arch Linux, and Debian based distributions can be less reliable if an error occurs while updating. Atomic updating distributions apply updates in full or not at all. Typically, transactional update systems are also atomic. A transactional update system creates a snapshot that is made before and after an update is applied. If an update fails at any time (perhaps due to a power failure), the update can be easily rolled back to a \u201clast known good state\u201d. The Atomic update method is used for immutable distributions like Silverblue, Tumbleweed, and NixOS and can achieve reliability with this model. Adam \u0160amal\u00edk provided a presentation on how rpm-ostree works with Silverblue:","title":"Traditional vs Atomic updates"},{"location":"linux-desktop/overview/#security-focused-distributions","text":"There is often some confusion about \u201csecurity-focused\u201d distributions and \u201cpentesting\u201d distributions. A quick search for \u201cthe most secure Linux distribution\u201d will often give results like Kali Linux, Black Arch, and Parrot OS . These distributions are offensive penetration testing distributions that bundle tools for testing other systems. They don\u2019t include any \u201cextra security\u201d or defensive mitigations intended for regular use.","title":"\u201cSecurity-focused\u201d distributions"},{"location":"linux-desktop/overview/#arch-based-distributions","text":"Arch based distributions are not recommended for those new to Linux, regardless of the distribution. Arch does not have an distribution update mechanism for the underlying software choices. As a result you have to stay aware with current trends and adopt technologies as they supersede older practices on your own. For a secure system, you are also expected to have sufficient Linux knowledge to properly set up security for their system such as adopting a mandatory access control system, setting up kernel module blacklists, hardening boot parameters, manipulating sysctl parameters, and knowing what components they need such as Polkit . Anyone using the Arch User Repository (AUR) , must be comfortable in auditing PKGBUILDs that they install from that service. AUR packages are community-produced content and are not vetted in any way, and therefore are vulnerable to software supply chain attacks, which has in fact happened in the past . AUR should always be used sparingly and often there is a lot of bad advice on various pages which direct people to blindly use AUR helpers without sufficient warning. Similar warnings apply to using third party Personal Package Archives (PPAs) on Debian based distributions or Community Projects (COPR) on Fedora. If you are experienced with Linux and wish to use an Arch-based distribution, we only recommend Arch Linux proper, not any of its derivatives. We recommend against these two Arch derivatives specifically: Manjaro : This distribution holds packages back for 2 weeks to make sure that their own changes don\u2019t break, not to make sure that upstream is stable. When AUR packages are used, they are often built against the latest libraries from Arch\u2019s repositories. Garuda : They use Chaotic-AUR which automatically and blindly compiles packages from the AUR. There is no verification process to make sure that the AUR packages don\u2019t suffer from supply chain attacks.","title":"Arch-based distributions"},{"location":"linux-desktop/overview/#linux-libre-kernel-and-libre-distributions","text":"We strongly recommend against using the Linux-libre kernel, since it removes security mitigations and suppresses kernel warnings about vulnerable microcode for ideological reasons.","title":"Linux-libre kernel and \u201cLibre\u201d distributions"},{"location":"linux-desktop/sandboxing/","text":"Some sandboxing solutions for desktop Linux distributions do exist, however they are not as strict as those found in macOS or ChromeOS. Applications installed from the package manager ( dnf , apt , etc.) typically have no sandboxing or confinement whatsoever. Below are a few projects that aim to solve this problem: Flatpak \u00b6 Flatpak aims to be a universal package manager for Linux. One of its main goals is to provide a universal package format which can be used in most Linux distributions. It provides some permission control . It has been pointed out that Flatpak sandboxing could be improved as particular Flatpaks often have greater permission than required. There does seem to be some agreement that this is the case. You can restrict applications further by issuing Flatpak overrides . This can be done with the command-line or by using Flatseal . Some sample overrides are provided by tommytran732 and rusty-snake . We generally recommend revoking access to: the Network ( share=network ) socket (internet access) the PulseAudio socket (for both audio in and out), device=all (access to all devices including the camera) org.freedesktop.secrets dbus (access to secrets stored on your keychain) for applications which do not need it If an application works natively with Wayland (and not running through the XWayland compatibility layer), consider revoking its access to the X11 ( socket=x11 ) and Inter-process communications (IPC) socket ( share=ipc ) as well. We also recommend restricting broad filesystem permissions such as filesystem=home and filesystem=host which should be revoked and replaced with just the directories that the app needs to access. Some applications like VLC implement the Portals API , which allows a file manager to pass files to the Flatpak application (e.g. VLC) without specific filesystem access privileges. VLC is only able to access the specific file that you want to open, rather than requiring privileges to particular locations. Hard-coded access to some kernel interfaces like /sys and /proc and weak seccomp filters unfortunately cannot be secured with Flatpak. Firejail \u00b6 Firejail is another method of sandboxing. As it is a large setuid binary, it has a large attack surface which may assist in privilege escalation . This post from a Whonix security researcher provides additional details on how Firejail can worsen the security of your device. Mandatory Access Control \u00b6 Mandatory access control systems require policy files in order to force constraints on the system. The two main control systems are SELinux (used on Android and Fedora) and AppArmor . Fedora includes SELinux preconfigured with some policies that will confine system daemons (background processes). We don\u2019t recommend disabling SELinux . openSUSE gives the choice of AppArmor or SELinux during the installation process. We recommend sticking to the default for each variant (AppArmor for Tumbleweed and SELinux for MicroOS ). openSUSE\u2019s SELinux policies are derived from Fedora. Arch and Arch-based operating systems often do not come with a mandatory access control system and that must be configured manually for either AppArmor or SELinux . Linux desktops don't usually include individual app confinement rules, unlike Android which sandboxes every application installed. Making your own policies/profiles \u00b6 You can make your own AppArmor profiles, SELinux policies, Bubblewrap profiles, and seccomp blacklist to have better confinement of applications. This is an advanced and sometimes tedious task, so we won\u2019t go into detail about how to do it here, but we do have a few projects that you could use as reference. Whonix\u2019s AppArmor Everything Krathalan\u2019s AppArmor profiles noatsecure\u2019s SELinux templates Seirdy\u2019s Bubblewrap scripts Securing Linux containers \u00b6 If you\u2019re running a server you may have heard of Linux Containers, Docker, or Podman which refer to a kind of OS -level virtualization . Containers are more common in server and development environments where individual apps are built to operate independently. Docker is one of the most common container solutions. It does not run a proper sandbox, and this means that there is a large kernel attack surface . The daemon controls everything and typically runs as root. If it crashes for some reason, all the containers will crash too. The gVisor runtime which implements an application level kernel can help limit the number of syscalls an application can make and can help isolate it from the host\u2019s kernel . Red Hat develops Podman and secures it with SELinux to isolate containers from each other. One of the notable differences between Docker and Podman is that Docker requires root while Podman can run with rootless containers that are also daemonless , meaning if one crashes they don\u2019t all come down. Another option is Kata containers , where virtual machines masquerade as containers. Each Kata container has its own Linux kernel and is isolated from the host. These container technologies can be useful for those who may want to run certain web app software on their local area network (LAN) such as Vaultwarden or images provided by linuxserver.io to increase privacy by decreasing dependence on various web services.","title":"Application Sandboxing"},{"location":"linux-desktop/sandboxing/#flatpak","text":"Flatpak aims to be a universal package manager for Linux. One of its main goals is to provide a universal package format which can be used in most Linux distributions. It provides some permission control . It has been pointed out that Flatpak sandboxing could be improved as particular Flatpaks often have greater permission than required. There does seem to be some agreement that this is the case. You can restrict applications further by issuing Flatpak overrides . This can be done with the command-line or by using Flatseal . Some sample overrides are provided by tommytran732 and rusty-snake . We generally recommend revoking access to: the Network ( share=network ) socket (internet access) the PulseAudio socket (for both audio in and out), device=all (access to all devices including the camera) org.freedesktop.secrets dbus (access to secrets stored on your keychain) for applications which do not need it If an application works natively with Wayland (and not running through the XWayland compatibility layer), consider revoking its access to the X11 ( socket=x11 ) and Inter-process communications (IPC) socket ( share=ipc ) as well. We also recommend restricting broad filesystem permissions such as filesystem=home and filesystem=host which should be revoked and replaced with just the directories that the app needs to access. Some applications like VLC implement the Portals API , which allows a file manager to pass files to the Flatpak application (e.g. VLC) without specific filesystem access privileges. VLC is only able to access the specific file that you want to open, rather than requiring privileges to particular locations. Hard-coded access to some kernel interfaces like /sys and /proc and weak seccomp filters unfortunately cannot be secured with Flatpak.","title":"Flatpak"},{"location":"linux-desktop/sandboxing/#firejail","text":"Firejail is another method of sandboxing. As it is a large setuid binary, it has a large attack surface which may assist in privilege escalation . This post from a Whonix security researcher provides additional details on how Firejail can worsen the security of your device.","title":"Firejail"},{"location":"linux-desktop/sandboxing/#mandatory-access-control","text":"Mandatory access control systems require policy files in order to force constraints on the system. The two main control systems are SELinux (used on Android and Fedora) and AppArmor . Fedora includes SELinux preconfigured with some policies that will confine system daemons (background processes). We don\u2019t recommend disabling SELinux . openSUSE gives the choice of AppArmor or SELinux during the installation process. We recommend sticking to the default for each variant (AppArmor for Tumbleweed and SELinux for MicroOS ). openSUSE\u2019s SELinux policies are derived from Fedora. Arch and Arch-based operating systems often do not come with a mandatory access control system and that must be configured manually for either AppArmor or SELinux . Linux desktops don't usually include individual app confinement rules, unlike Android which sandboxes every application installed.","title":"Mandatory Access Control"},{"location":"linux-desktop/sandboxing/#making-your-own-policiesprofiles","text":"You can make your own AppArmor profiles, SELinux policies, Bubblewrap profiles, and seccomp blacklist to have better confinement of applications. This is an advanced and sometimes tedious task, so we won\u2019t go into detail about how to do it here, but we do have a few projects that you could use as reference. Whonix\u2019s AppArmor Everything Krathalan\u2019s AppArmor profiles noatsecure\u2019s SELinux templates Seirdy\u2019s Bubblewrap scripts","title":"Making your own policies/profiles"},{"location":"linux-desktop/sandboxing/#securing-linux-containers","text":"If you\u2019re running a server you may have heard of Linux Containers, Docker, or Podman which refer to a kind of OS -level virtualization . Containers are more common in server and development environments where individual apps are built to operate independently. Docker is one of the most common container solutions. It does not run a proper sandbox, and this means that there is a large kernel attack surface . The daemon controls everything and typically runs as root. If it crashes for some reason, all the containers will crash too. The gVisor runtime which implements an application level kernel can help limit the number of syscalls an application can make and can help isolate it from the host\u2019s kernel . Red Hat develops Podman and secures it with SELinux to isolate containers from each other. One of the notable differences between Docker and Podman is that Docker requires root while Podman can run with rootless containers that are also daemonless , meaning if one crashes they don\u2019t all come down. Another option is Kata containers , where virtual machines masquerade as containers. Each Kata container has its own Linux kernel and is isolated from the host. These container technologies can be useful for those who may want to run certain web app software on their local area network (LAN) such as Vaultwarden or images provided by linuxserver.io to increase privacy by decreasing dependence on various web services.","title":"Securing Linux containers"},{"location":"redhat/access/","text":"INTRODUCTION TO THE BASH SHELL \u00b6 A command line is a text-based interface which can be used to input instructions to a computer system. The Linux command line is provided by a program called the shell. Various options for the shell program have been developed over the years, and different users can be configured to use different shells. Most users, however, stick with the current default. The default shell for users in Red Hat Enterprise Linux is the GNU Bourne-Again Shell (bash) . Bash is an improved version of one of the most successful shells used on UNIX-like systems, the Bourne Shell (sh) . When a shell is used interactively, it displays a string when it is waiting for a command from the user. This is called the shell prompt. When a regular user starts a shell, the default prompt ends with a $ character, as shown below. [ user@host ~ ] $ The $ character is replaced by a # character if the shell is running as the superuser, root. This makes it more obvious that it is a superuser shell, which helps to avoid accidents and mistakes which can affect the whole system. The superuser shell prompt is shown below. [ root@host ~ ] # Using bash to execute commands can be powerful. The bash shell provides a scripting language that can support automation of tasks. The shell has additional capabilities that can simplify or make possible operations that are hard to accomplish efficiently with graphical tools. NOTE The bash shell is similar in concept to the command-line interpreter found in recent versions of Microsoft Windows, cmd.exe, although bash has a more sophisticated scripting language. It is also similar to Windows PowerShell in Windows 7 and Windows Server 2008 R2 and later. Administrators using the Apple Mac who use the Terminal utility may be pleased to note that bash is the default shell in macOS. SHELL BASICS \u00b6 Commands entered at the shell prompt have three basic parts: Command to run Options to adjust the behavior of the command Arguments, which are typically targets of the command The command is the name of the program to run. It may be followed by one or more options, which adjust the behavior of the command or what it will do. Options normally start with one or two dashes (-a or --all, for example) to distinguish them from arguments. Commands may also be followed by one or more arguments, which often indicate a target that the command should operate upon. For example, the command usermod -L user01 has a command (usermod), an option (-L), and an argument (user01). The effect of this command is to lock the password of the user01 user account. LOGGING IN TO A LOCAL COMPUTER \u00b6 To run the shell, you need to log in to the computer on a terminal. A terminal is a text-based interface used to enter commands into and print output from a computer system. There are several ways to do this. The computer might have a hardware keyboard and display for input and output directly connected to it. This is the Linux machine's physical console. The physical console supports multiple virtual consoles, which can run separate terminals. Each virtual console supports an independent login session. You can switch between them by pressing Ctrl+Alt and a function key (F1 through F6) at the same time. Most of these virtual consoles run a terminal providing a text login prompt, and if you enter your username and password correctly, you will log in and get a shell prompt. The computer might provide a graphical login prompt on one of the virtual consoles. You can use this to log in to a graphical environment. The graphical environment also runs on a virtual console. To get a shell prompt you must start a terminal program in the graphical environment. The shell prompt is provided in an application window of your graphical terminal program. NOTE Many system administrators choose not to run a graphical environment on their servers. This allows resources which would be used by the graphical environment to be used by the server's services instead. In Red Hat Enterprise Linux 8, if the graphical environment is available, the login screen will run on the first virtual console, called tty1 . Five additional text login prompts are available on virtual consoles two through six. If you log in using the graphical login screen, your graphical environment will start on the first virtual console that is not currently being used by a login session. Normally, your graphical session will replace the login prompt on the second virtual console ( tty2 ). However, if that console is in use by an active text login session (not just a login prompt), the next free virtual console is used instead. The graphical login screen continues to run on the first virtual console ( tty1 ). If you are already logged in to a graphical session, and log in as another user on the graphical login screen or use the Switch User menu item to switch users in the graphical environment without logging out, another graphical environment will be started for that user on the next free virtual console. When you log out of a graphical environment, it will exit and the physical console will automatically switch back to the graphical login screen on the first virtual console. NOTE In Red Hat Enterprise Linux 6 and 7, the graphical login screen runs on the first virtual console, but when you log in your initial graphical environment replaces the login screen on the first virtual console instead of starting on a new virtual console. In Red Hat Enterprise Linux 5 and earlier, the first six virtual consoles always provided text login prompts. If the graphical environment is running, it is on virtual console seven (accessed through Ctrl+Alt+F7 ). A headless server does not have a keyboard and display permanently connected to it. A data center may be filled with many racks of headless servers, and not providing each with a keyboard and display saves space and expense. To allow administrators to log in, a headless server might have a login prompt provided by its serial console, running on a serial port which is connected to a networked console server for remote access to the serial console. The serial console would normally be used to fix the server if its own network card became misconfigured and logging in over its own network connection became impossible. Most of the time, however, headless servers are accessed by other means over the network. LOGGING IN OVER THE NETWORK \u00b6 Linux users and administrators often need to get shell access to a remote system by connecting to it over the network. In a modern computing environment, many headless servers are actually virtual machines or are running as public or private cloud instances. These systems are not physical and do not have real hardware consoles. They might not even provide access to their (simulated) physical console or serial console. In Linux, the most common way to get a shell prompt on a remote system is to use Secure Shell (SSH). Most Linux systems (including Red Hat Enterprise Linux) and macOS provide the OpenSSH command-line program ssh for this purpose. In this example, a user with a shell prompt on the machine host uses ssh to log in to the remote Linux system remotehost as the user remoteuser: [ user@host ~ ] $ ssh remoteuser@remotehost remoteuser@remotehost ' s password: password [ remoteuser@remotehost ~ ] $ The ssh command encrypts the connection to secure the communication against eavesdropping or hijacking of the passwords and content. Some systems (such as new cloud instances) do not allow users to use a password to log in with ssh for tighter security. An alternative way to authenticate to a remote machine without entering a password is through public key authentication . With this authentication method, users have a special identity file containing a private key, which is equivalent to a password, and which they keep secret. Their account on the server is configured with a matching public key, which does not have to be secret. When logging in, users can configure ssh to provide the private key and if their matching public key is installed in that account on that remote server, it will log them in without asking for a password. In the next example, a user with a shell prompt on the machine host logs in to remotehost as remoteuser using ssh , using public key authentication. The -i option is used to specify the user's private key file, which is mylab.pem. The matching public key is already set up as an authorized key in the remoteuser account. [ user@host ~ ] $ ssh -i mylab.pem remoteuser@remotehost [ remoteuser@remotehost ~ ] $ For this to work, the private key file must be readable only by the user that owns the file. In the preceding example, where the private key is in the mylab.pem file, the command chmod 600 mylab.pem could be used to ensure this. How to set file permissions is discussed in more detail in a later chapter. Users might also have private keys configured that are tried automatically, but that discussion is beyond the scope of this section. The References at the end of this section contain links to more information on this topic. NOTE The first time you log in to a new machine, you will be prompted with a warning from ssh that it cannot establish the authenticity of the host: [ user@host ~ ] $ ssh -i mylab.pem remoteuser@remotehost The authenticity of host 'remotehost (192.0.2.42)' can ' t be established. ECDSA key fingerprint is 47 :bf:82:cd:fa:68:06:ee:d8:83:03:1a:bb:29:14:a3. Are you sure you want to continue connecting ( yes/no ) ? yes [ remoteuser@remotehost ~ ] $ Each time you connect to a remote host with ssh, the remote host sends ssh its host key to authenticate itself and to help set up encrypted communication. The ssh command compares that against a list of saved host keys to make sure it has not changed. If the host key has changed, this might indicate that someone is trying to pretend to be that host to hijack the connection which is also known as man-in-the- middle attack. In SSH, host keys protect against man-in-the-middle attacks, these host keys are unique for each server, and they need to be changed periodically and whenever a compromise is suspected. You will get this warning if your local machine does not have a host key saved for the remote host. If you enter yes, the host key that the remote host sent will be accepted and saved for future reference. Login will continue, and you should not see this message again when connecting to this host. If you enter no, the host key will be rejected and the connection closed. If the local machine does have a host key saved and it does not match the one actually sent by the remote host, the connection will automatically be closed with a warning. LOGGING OUT \u00b6 When you are finished using the shell and want to quit, you can choose one of several ways to end the session. You can enter the exit command to terminate the current shell session. Alternatively, finish a session by pressing Ctrl+D . The following is an example of a user logging out of an SSH session: [ remoteuser@remotehost ~ ] $ exit logout Connection to remotehost closed. [ user@host ~ ] $ EXECUTING COMMANDS USING THE BASH SHELL \u00b6 BASIC COMMAND SYNTAX \u00b6 The GNU Bourne-Again Shell ( bash ) is a program that interprets commands typed in by the user. Each string typed into the shell can have up to three parts: the command, options (which usually begin with a - or --), and arguments. Each word typed into the shell is separated from each other with spaces. Commands are the names of programs that are installed on the system. Each command has its own options and arguments. When you are ready to execute a command, press the Enter key. Type each command on a separate line. The command output is displayed before the next shell prompt appears. [ user@host ] $ whoami user [ user@host ] $ If you want to type more than one command on a single line, use the semicolon (;) as a command separator. A semicolon is a member of a class of characters called metacharacters that have special meanings for bash . In this case the output of both commands will be displayed before the next shell prompt appears. The following example shows how to combine two commands (command1 and command2) on the command line. [ user@host ] $ command1 ; command2 EXAMPLES OF SIMPLE COMMANDS \u00b6 The date command displays the current date and time. It can also be used by the superuser to set the system clock. An argument that begins with a plus sign (+) specifies a format string for the date command. [ user@host ~ ] $ date Sat Jan 26 08 :13:50 IST 2019 [ user@host ~ ] $ date +%R 08 :13 [ user@host ~ ] $ date +%x 01 /26/2019 The passwd command changes a user's own password. The original password for the account must be specified before a change is allowed. By default, passwd is configured to require a strong password, consisting of lowercase letters, uppercase letters, numbers, and symbols, and is not based on a dictionary word. The superuser can use the passwd command to change other users' passwords. [ user@host ~ ] $ passwd Changing password for user user. Current password: old_password New password: new_password Retype new password: new_password passwd: all authentication tokens updated successfully. Linux does not require file name extensions to classify files by type. The file command scans the beginning of a file's contents and displays what type it is. The files to be classified are passed as arguments to the command. [ user@host ~ ] $ file /etc/passwd /etc/passwd: ASCII text [ user@host ~ ] $ file /bin/passwd /bin/passwd: setuid ELF 64 -bit LSB shared object, x86-64, version 1 ( SYSV ) , dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3 .2.0, BuildID [ sha1 ]= a3637110e27e9a48dced9f38b4ae43388d32d0e4, stripped [ user@host ~ ] $ file /home /home: directory VIEWING THE CONTENTS OF FILES \u00b6 One of the most simple and frequently used commands in Linux is cat . The cat command allows you to create single or multiple files, view the contents of files, concatenate the contents from multiple files, and redirect contents of the file to a terminal or files. The example shows how to view the contents of the /etc/passwd file. [ user@host ~ ] $ cat /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin ...output omitted... Use the following command to display the contents of multiple files. [ user@host ~ ] $ cat file1 file2 Hello World!! Introduction to Linux commands. Some files are very long and can take up more room to display than that provided by the terminal. The cat command does not display the contents of a file as pages. The less command displays one page of a file at a time and lets you scroll at your leisure. The less command allows you to page forward and backward through files that are longer than can fit on one terminal window. Use the UpArrow key and the DownArrow key to scroll up and down. Press Q to exit the command. The head and tail commands display the beginning and end of a file, respectively. By default these commands display 10 lines of the file, but they both have a -n option that allows a different number of lines to be specified. The file to display is passed as an argument to these commands. [ user@host ~ ] $ head /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin [ user@host ~ ] $ tail -n 3 /etc/passwd gdm:x:42:42::/var/lib/gdm:/sbin/nologin gnome-initial-setup:x:977:977::/run/gnome-initial-setup/:/sbin/nologin avahi:x:70:70:Avahi mDNS/DNS-SD Stack:/var/run/avahi-daemon:/sbin/nologin The wc command counts lines, words, and characters in a file. It takes a -l, -w, or -c option to [ user@host ~ ] $ wc /etc/passwd 45 102 2480 /etc/passwd [ user@host ~ ] $ wc -l /etc/passwd ; wc -l /etc/group 45 /etc/passwd 70 /etc/group [ user@host ~ ] $ wc -c /etc/group /etc/hosts 966 /etc/group 516 /etc/hosts 1482 total CONTINUING A LONG COMMAND ON ANOTHER LINE \u00b6 Commands that support many options and arguments can quickly grow quite long and are automatically scrolled by the Bash shell. As soon as the cursor reaches the right margin of the window, the command continues on the next line. To make the readability of the command easier, you can break it up so that if fits on more than one line. To do this, add a backslash character () as the last character on the line. This tells the shell to ignore the newline character and treat the next line as if it were part of the current line. The Bash shell will start the next line with the continuation prompt, usually a greater-than character (>), which indicates that the line is a continuation of the previous line. You can do this more than once. [ user@host ] $ head -n 3 \\ > /usr/share/dict/words \\ > /usr/share/dict/linux.words == > /usr/share/dict/words < == 1080 10 -point 10th == > /usr/share/dict/linux.words < == 1080 10 -point 10th [ user@host ~ ] $ COMMAND HISTORY \u00b6 The history command displays a list of previously executed commands prefixed with a command number. The exclamation point character (!) is a metacharacter that is used to expand previous commands without having to retype them. The !number command expands to the command matching the number specified. The !string command expands to the most recent command that begins with the string specified. [ user@host ~ ] $ history ...output omitted... 23 clear 24 who 25 pwd 26 ls /etc 27 uptime 28 ls -l 29 date 30 history [ user@host ~ ] $ !ls ls -l total 0 drwxr-xr-x. 2 user user 6 Mar 29 21 :16 Desktop ...output omitted... [ user@host ~ ] $ !26 ls /etc abrt hosts pulse adjtime hosts.allow purple aliases hosts.deny qemu-ga ...output omitted... The arrow keys can be used to navigate through previous commands in the shell's history. UpArrow edits the previous command in the history list. DownArrow edits the next command in the history list. LeftArrow and RightArrow move the cursor left and right in the current command from the history list, so that you can edit it before running it. You can use either the Esc+ . or Alt+ . key combination to insert the last word of the previous command at the cursor's current location. Repeated use of the key combination will replace that text with the last word of even earlier commands in the history. The Alt+. key combination is particularly convenient because you can hold down Alt and press . repeatedly to easily go through earlier and earlier commands. EDITING THE COMMAND LINE \u00b6 When used interactively, bash has a command-line editing feature. This allows the user to use text editor commands to move around within and modify the current command being typed. Using the arrow keys to move within the current command and to step through the command history was introduced earlier in this session. More powerful editing commands are introduced in the following table. Useful Command-line Editing Shortcuts SHORTCUT DESCRIPTION Ctrl+A Jump to the beginning of the command line. Ctrl+E Jump to the end of the command line. Ctrl+U Clear from the cursor to the beginning of the command line. Ctrl+K Clear from the cursor to the end of the command line. Ctrl+Left Arrow Jump to the beginning of the previous word on the command line. Ctrl+Right Arrow Jump to the end of the next word on the command line. Ctrl+R Search the history list of commands for a pattern. There are several other command-line editing commands available, but these are the most useful commands for new users. The other commands can be found in the bash(1) man page. ACCESSING THE COMMAND LINE \u00b6 Use the date command to display the current time and date. [ student@workstation ~ ] $ date Thu Jan 22 10 :13:04 PDT 2019 Display the current time in 12-hour clock time (for example, 11:42:11 AM). Hint: The format string that displays that output is %r. Use the +%r argument with the date command to display the current time in 12-hour clock time. [ student@workstation ~ ] $ date +%r 10 :14:07 AM What kind of file is /home/student/zcat? Is it readable by humans? Use the file command to determine its file type. [ student@workstation ~ ] $ file zcat zcat: POSIX shell script, ASCII text executable Use the wc command and Bash shortcuts to display the size of zcat. The wc command can be used to display the number of lines, words, and bytes in the zcat script. Instead of retyping the file name, use the Bash history shortcut Esc+. (the keys Esc and . pressed at the same time) to reuse the argument from the previous command. [ student@workstation ~ ] $ wc Esc+. [ student@workstation ~ ] $ wc zcat Display the first 10 lines of zcat. The head command displays the beginning of the file. Try using the Esc+. shortcut again. [ student@workstation ~ ] $ head Esc+. [ student@workstation ~ ] $ head zcat #!/bin/sh # Uncompress files to standard output. # Copyright (C) 2007, 2010-2018 Free Software Foundation, Inc. # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 3 of the License, or # (at your option) any later version. Display the last 10 lines of the zcat file. Use the tail command to display the last 10 lines of the zcat file. [ student@workstation ~ ] $ tail Esc+. [ student@workstation ~ ] $ tail zcat With no FILE, or when FILE is -, read standard input. Report bugs to <bug-gzip@gnu.org>. \" case $1 in --help) printf '%s\\n' \" $usage \" || exit 1;; --version) printf '%s\\n' \" $version \" || exit 1;; esac exec gzip -cd \" $@ \" Repeat the previous command exactly with three or fewer keystrokes. Repeat the previous command exactly. Either press the UpArrow key once to scroll back through the command history one command and then press Enter (uses two keystrokes), or enter the shortcut command !! and then press Enter (uses three keystrokes) to run the most recent command in the command history . (Try both.) [ student@workstation ] $ !! tail zcat With no FILE, or when FILE is -, read standard input. Report bugs to <bug-gzip@gnu.org>. \" case $1 in --help) printf '%s\\n' \" $usage \" || exit 1;; --version) printf '%s\\n' \" $version \" || exit 1;; esac exec gzip -cd \" $@ \" Repeat the previous command, but use the -n 20 option to display the last 20 lines in the file. Use command-line editing to accomplish this with a minimal number of keystrokes. UpArrow displays the previous command. Ctrl+A makes the cursor jump to the beginning of the line. Ctrl+RightArrow jumps to the next word, then add the -n 20 option and hit Enter to execute the command. [ student@workstation ~ ] $ tail -n 20 zcat -l, --list list compressed file contents -q, --quiet suppress all warnings -r, --recursive operate recursively on directories -S, --suffix = SUF use suffix SUF on compressed files --synchronous synchronous output ( safer if system crashes, but slower ) -t, --test test compressed file integrity -v, --verbose verbose mode --help display this help and exit --version display version information and exit With no FILE, or when FILE is -, read standard input. Report bugs to <bug-gzip@gnu.org>. \" case $1 in --help) printf '%s\\n' \" $usage \" || exit 1; exit;; --version) printf '%s\\n' \" $version \" || exit 1; exit;; esac exec gzip -cd \" $@ \" Use the shell history to run the date +%r command again. Use the history command to display the list of previous commands and to identify the specific date command to be executed. Use !number to run the command, where number is the command number to use from the output of the history command. Note that your shell history may be different from the following example. Determine the command number to use based on the output of your own history command. [ student@workstation ~ ] $ history 1 date 2 date +%r 3 file zcat 4 wc zcat 5 head zcat 6 tail zcat 7 tail -n 20 zcat 8 history [ student@workstation ~ ] $ !2 date +%r 10 :49:56 AM SUMMARY \u00b6 In this chapter, you learned: The Bash shell is a command interpreter that prompts interactive users to specify Linux commands. Many commands have a --help option that displays a usage message or screen. Using workspaces makes it easier to organize multiple application windows. The Activities button located at the upper-left corner of the top bar provides an overview mode that helps a user organize windows and start applications. The file command scans the beginning of a file's contents and displays what type it is. The head and tail commands display the beginning and end of a file, respectively. You can use Tab completion to complete file names when typing them as arguments to commands.","title":"Accessing The Command Line"},{"location":"redhat/access/#introduction-to-the-bash-shell","text":"A command line is a text-based interface which can be used to input instructions to a computer system. The Linux command line is provided by a program called the shell. Various options for the shell program have been developed over the years, and different users can be configured to use different shells. Most users, however, stick with the current default. The default shell for users in Red Hat Enterprise Linux is the GNU Bourne-Again Shell (bash) . Bash is an improved version of one of the most successful shells used on UNIX-like systems, the Bourne Shell (sh) . When a shell is used interactively, it displays a string when it is waiting for a command from the user. This is called the shell prompt. When a regular user starts a shell, the default prompt ends with a $ character, as shown below. [ user@host ~ ] $ The $ character is replaced by a # character if the shell is running as the superuser, root. This makes it more obvious that it is a superuser shell, which helps to avoid accidents and mistakes which can affect the whole system. The superuser shell prompt is shown below. [ root@host ~ ] # Using bash to execute commands can be powerful. The bash shell provides a scripting language that can support automation of tasks. The shell has additional capabilities that can simplify or make possible operations that are hard to accomplish efficiently with graphical tools. NOTE The bash shell is similar in concept to the command-line interpreter found in recent versions of Microsoft Windows, cmd.exe, although bash has a more sophisticated scripting language. It is also similar to Windows PowerShell in Windows 7 and Windows Server 2008 R2 and later. Administrators using the Apple Mac who use the Terminal utility may be pleased to note that bash is the default shell in macOS.","title":"INTRODUCTION TO THE BASH SHELL"},{"location":"redhat/access/#shell-basics","text":"Commands entered at the shell prompt have three basic parts: Command to run Options to adjust the behavior of the command Arguments, which are typically targets of the command The command is the name of the program to run. It may be followed by one or more options, which adjust the behavior of the command or what it will do. Options normally start with one or two dashes (-a or --all, for example) to distinguish them from arguments. Commands may also be followed by one or more arguments, which often indicate a target that the command should operate upon. For example, the command usermod -L user01 has a command (usermod), an option (-L), and an argument (user01). The effect of this command is to lock the password of the user01 user account.","title":"SHELL BASICS"},{"location":"redhat/access/#logging-in-to-a-local-computer","text":"To run the shell, you need to log in to the computer on a terminal. A terminal is a text-based interface used to enter commands into and print output from a computer system. There are several ways to do this. The computer might have a hardware keyboard and display for input and output directly connected to it. This is the Linux machine's physical console. The physical console supports multiple virtual consoles, which can run separate terminals. Each virtual console supports an independent login session. You can switch between them by pressing Ctrl+Alt and a function key (F1 through F6) at the same time. Most of these virtual consoles run a terminal providing a text login prompt, and if you enter your username and password correctly, you will log in and get a shell prompt. The computer might provide a graphical login prompt on one of the virtual consoles. You can use this to log in to a graphical environment. The graphical environment also runs on a virtual console. To get a shell prompt you must start a terminal program in the graphical environment. The shell prompt is provided in an application window of your graphical terminal program. NOTE Many system administrators choose not to run a graphical environment on their servers. This allows resources which would be used by the graphical environment to be used by the server's services instead. In Red Hat Enterprise Linux 8, if the graphical environment is available, the login screen will run on the first virtual console, called tty1 . Five additional text login prompts are available on virtual consoles two through six. If you log in using the graphical login screen, your graphical environment will start on the first virtual console that is not currently being used by a login session. Normally, your graphical session will replace the login prompt on the second virtual console ( tty2 ). However, if that console is in use by an active text login session (not just a login prompt), the next free virtual console is used instead. The graphical login screen continues to run on the first virtual console ( tty1 ). If you are already logged in to a graphical session, and log in as another user on the graphical login screen or use the Switch User menu item to switch users in the graphical environment without logging out, another graphical environment will be started for that user on the next free virtual console. When you log out of a graphical environment, it will exit and the physical console will automatically switch back to the graphical login screen on the first virtual console. NOTE In Red Hat Enterprise Linux 6 and 7, the graphical login screen runs on the first virtual console, but when you log in your initial graphical environment replaces the login screen on the first virtual console instead of starting on a new virtual console. In Red Hat Enterprise Linux 5 and earlier, the first six virtual consoles always provided text login prompts. If the graphical environment is running, it is on virtual console seven (accessed through Ctrl+Alt+F7 ). A headless server does not have a keyboard and display permanently connected to it. A data center may be filled with many racks of headless servers, and not providing each with a keyboard and display saves space and expense. To allow administrators to log in, a headless server might have a login prompt provided by its serial console, running on a serial port which is connected to a networked console server for remote access to the serial console. The serial console would normally be used to fix the server if its own network card became misconfigured and logging in over its own network connection became impossible. Most of the time, however, headless servers are accessed by other means over the network.","title":"LOGGING IN TO A LOCAL COMPUTER"},{"location":"redhat/access/#logging-in-over-the-network","text":"Linux users and administrators often need to get shell access to a remote system by connecting to it over the network. In a modern computing environment, many headless servers are actually virtual machines or are running as public or private cloud instances. These systems are not physical and do not have real hardware consoles. They might not even provide access to their (simulated) physical console or serial console. In Linux, the most common way to get a shell prompt on a remote system is to use Secure Shell (SSH). Most Linux systems (including Red Hat Enterprise Linux) and macOS provide the OpenSSH command-line program ssh for this purpose. In this example, a user with a shell prompt on the machine host uses ssh to log in to the remote Linux system remotehost as the user remoteuser: [ user@host ~ ] $ ssh remoteuser@remotehost remoteuser@remotehost ' s password: password [ remoteuser@remotehost ~ ] $ The ssh command encrypts the connection to secure the communication against eavesdropping or hijacking of the passwords and content. Some systems (such as new cloud instances) do not allow users to use a password to log in with ssh for tighter security. An alternative way to authenticate to a remote machine without entering a password is through public key authentication . With this authentication method, users have a special identity file containing a private key, which is equivalent to a password, and which they keep secret. Their account on the server is configured with a matching public key, which does not have to be secret. When logging in, users can configure ssh to provide the private key and if their matching public key is installed in that account on that remote server, it will log them in without asking for a password. In the next example, a user with a shell prompt on the machine host logs in to remotehost as remoteuser using ssh , using public key authentication. The -i option is used to specify the user's private key file, which is mylab.pem. The matching public key is already set up as an authorized key in the remoteuser account. [ user@host ~ ] $ ssh -i mylab.pem remoteuser@remotehost [ remoteuser@remotehost ~ ] $ For this to work, the private key file must be readable only by the user that owns the file. In the preceding example, where the private key is in the mylab.pem file, the command chmod 600 mylab.pem could be used to ensure this. How to set file permissions is discussed in more detail in a later chapter. Users might also have private keys configured that are tried automatically, but that discussion is beyond the scope of this section. The References at the end of this section contain links to more information on this topic. NOTE The first time you log in to a new machine, you will be prompted with a warning from ssh that it cannot establish the authenticity of the host: [ user@host ~ ] $ ssh -i mylab.pem remoteuser@remotehost The authenticity of host 'remotehost (192.0.2.42)' can ' t be established. ECDSA key fingerprint is 47 :bf:82:cd:fa:68:06:ee:d8:83:03:1a:bb:29:14:a3. Are you sure you want to continue connecting ( yes/no ) ? yes [ remoteuser@remotehost ~ ] $ Each time you connect to a remote host with ssh, the remote host sends ssh its host key to authenticate itself and to help set up encrypted communication. The ssh command compares that against a list of saved host keys to make sure it has not changed. If the host key has changed, this might indicate that someone is trying to pretend to be that host to hijack the connection which is also known as man-in-the- middle attack. In SSH, host keys protect against man-in-the-middle attacks, these host keys are unique for each server, and they need to be changed periodically and whenever a compromise is suspected. You will get this warning if your local machine does not have a host key saved for the remote host. If you enter yes, the host key that the remote host sent will be accepted and saved for future reference. Login will continue, and you should not see this message again when connecting to this host. If you enter no, the host key will be rejected and the connection closed. If the local machine does have a host key saved and it does not match the one actually sent by the remote host, the connection will automatically be closed with a warning.","title":"LOGGING IN OVER THE NETWORK"},{"location":"redhat/access/#logging-out","text":"When you are finished using the shell and want to quit, you can choose one of several ways to end the session. You can enter the exit command to terminate the current shell session. Alternatively, finish a session by pressing Ctrl+D . The following is an example of a user logging out of an SSH session: [ remoteuser@remotehost ~ ] $ exit logout Connection to remotehost closed. [ user@host ~ ] $","title":"LOGGING OUT"},{"location":"redhat/access/#executing-commands-using-the-bash-shell","text":"","title":"EXECUTING COMMANDS USING THE BASH SHELL"},{"location":"redhat/access/#basic-command-syntax","text":"The GNU Bourne-Again Shell ( bash ) is a program that interprets commands typed in by the user. Each string typed into the shell can have up to three parts: the command, options (which usually begin with a - or --), and arguments. Each word typed into the shell is separated from each other with spaces. Commands are the names of programs that are installed on the system. Each command has its own options and arguments. When you are ready to execute a command, press the Enter key. Type each command on a separate line. The command output is displayed before the next shell prompt appears. [ user@host ] $ whoami user [ user@host ] $ If you want to type more than one command on a single line, use the semicolon (;) as a command separator. A semicolon is a member of a class of characters called metacharacters that have special meanings for bash . In this case the output of both commands will be displayed before the next shell prompt appears. The following example shows how to combine two commands (command1 and command2) on the command line. [ user@host ] $ command1 ; command2","title":"BASIC COMMAND SYNTAX"},{"location":"redhat/access/#examples-of-simple-commands","text":"The date command displays the current date and time. It can also be used by the superuser to set the system clock. An argument that begins with a plus sign (+) specifies a format string for the date command. [ user@host ~ ] $ date Sat Jan 26 08 :13:50 IST 2019 [ user@host ~ ] $ date +%R 08 :13 [ user@host ~ ] $ date +%x 01 /26/2019 The passwd command changes a user's own password. The original password for the account must be specified before a change is allowed. By default, passwd is configured to require a strong password, consisting of lowercase letters, uppercase letters, numbers, and symbols, and is not based on a dictionary word. The superuser can use the passwd command to change other users' passwords. [ user@host ~ ] $ passwd Changing password for user user. Current password: old_password New password: new_password Retype new password: new_password passwd: all authentication tokens updated successfully. Linux does not require file name extensions to classify files by type. The file command scans the beginning of a file's contents and displays what type it is. The files to be classified are passed as arguments to the command. [ user@host ~ ] $ file /etc/passwd /etc/passwd: ASCII text [ user@host ~ ] $ file /bin/passwd /bin/passwd: setuid ELF 64 -bit LSB shared object, x86-64, version 1 ( SYSV ) , dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3 .2.0, BuildID [ sha1 ]= a3637110e27e9a48dced9f38b4ae43388d32d0e4, stripped [ user@host ~ ] $ file /home /home: directory","title":"EXAMPLES OF SIMPLE COMMANDS"},{"location":"redhat/access/#viewing-the-contents-of-files","text":"One of the most simple and frequently used commands in Linux is cat . The cat command allows you to create single or multiple files, view the contents of files, concatenate the contents from multiple files, and redirect contents of the file to a terminal or files. The example shows how to view the contents of the /etc/passwd file. [ user@host ~ ] $ cat /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin ...output omitted... Use the following command to display the contents of multiple files. [ user@host ~ ] $ cat file1 file2 Hello World!! Introduction to Linux commands. Some files are very long and can take up more room to display than that provided by the terminal. The cat command does not display the contents of a file as pages. The less command displays one page of a file at a time and lets you scroll at your leisure. The less command allows you to page forward and backward through files that are longer than can fit on one terminal window. Use the UpArrow key and the DownArrow key to scroll up and down. Press Q to exit the command. The head and tail commands display the beginning and end of a file, respectively. By default these commands display 10 lines of the file, but they both have a -n option that allows a different number of lines to be specified. The file to display is passed as an argument to these commands. [ user@host ~ ] $ head /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin [ user@host ~ ] $ tail -n 3 /etc/passwd gdm:x:42:42::/var/lib/gdm:/sbin/nologin gnome-initial-setup:x:977:977::/run/gnome-initial-setup/:/sbin/nologin avahi:x:70:70:Avahi mDNS/DNS-SD Stack:/var/run/avahi-daemon:/sbin/nologin The wc command counts lines, words, and characters in a file. It takes a -l, -w, or -c option to [ user@host ~ ] $ wc /etc/passwd 45 102 2480 /etc/passwd [ user@host ~ ] $ wc -l /etc/passwd ; wc -l /etc/group 45 /etc/passwd 70 /etc/group [ user@host ~ ] $ wc -c /etc/group /etc/hosts 966 /etc/group 516 /etc/hosts 1482 total","title":"VIEWING THE CONTENTS OF FILES"},{"location":"redhat/access/#continuing-a-long-command-on-another-line","text":"Commands that support many options and arguments can quickly grow quite long and are automatically scrolled by the Bash shell. As soon as the cursor reaches the right margin of the window, the command continues on the next line. To make the readability of the command easier, you can break it up so that if fits on more than one line. To do this, add a backslash character () as the last character on the line. This tells the shell to ignore the newline character and treat the next line as if it were part of the current line. The Bash shell will start the next line with the continuation prompt, usually a greater-than character (>), which indicates that the line is a continuation of the previous line. You can do this more than once. [ user@host ] $ head -n 3 \\ > /usr/share/dict/words \\ > /usr/share/dict/linux.words == > /usr/share/dict/words < == 1080 10 -point 10th == > /usr/share/dict/linux.words < == 1080 10 -point 10th [ user@host ~ ] $","title":"CONTINUING A LONG COMMAND ON ANOTHER LINE"},{"location":"redhat/access/#command-history","text":"The history command displays a list of previously executed commands prefixed with a command number. The exclamation point character (!) is a metacharacter that is used to expand previous commands without having to retype them. The !number command expands to the command matching the number specified. The !string command expands to the most recent command that begins with the string specified. [ user@host ~ ] $ history ...output omitted... 23 clear 24 who 25 pwd 26 ls /etc 27 uptime 28 ls -l 29 date 30 history [ user@host ~ ] $ !ls ls -l total 0 drwxr-xr-x. 2 user user 6 Mar 29 21 :16 Desktop ...output omitted... [ user@host ~ ] $ !26 ls /etc abrt hosts pulse adjtime hosts.allow purple aliases hosts.deny qemu-ga ...output omitted... The arrow keys can be used to navigate through previous commands in the shell's history. UpArrow edits the previous command in the history list. DownArrow edits the next command in the history list. LeftArrow and RightArrow move the cursor left and right in the current command from the history list, so that you can edit it before running it. You can use either the Esc+ . or Alt+ . key combination to insert the last word of the previous command at the cursor's current location. Repeated use of the key combination will replace that text with the last word of even earlier commands in the history. The Alt+. key combination is particularly convenient because you can hold down Alt and press . repeatedly to easily go through earlier and earlier commands.","title":"COMMAND HISTORY"},{"location":"redhat/access/#editing-the-command-line","text":"When used interactively, bash has a command-line editing feature. This allows the user to use text editor commands to move around within and modify the current command being typed. Using the arrow keys to move within the current command and to step through the command history was introduced earlier in this session. More powerful editing commands are introduced in the following table. Useful Command-line Editing Shortcuts SHORTCUT DESCRIPTION Ctrl+A Jump to the beginning of the command line. Ctrl+E Jump to the end of the command line. Ctrl+U Clear from the cursor to the beginning of the command line. Ctrl+K Clear from the cursor to the end of the command line. Ctrl+Left Arrow Jump to the beginning of the previous word on the command line. Ctrl+Right Arrow Jump to the end of the next word on the command line. Ctrl+R Search the history list of commands for a pattern. There are several other command-line editing commands available, but these are the most useful commands for new users. The other commands can be found in the bash(1) man page.","title":"EDITING THE COMMAND LINE"},{"location":"redhat/access/#accessing-the-command-line","text":"Use the date command to display the current time and date. [ student@workstation ~ ] $ date Thu Jan 22 10 :13:04 PDT 2019 Display the current time in 12-hour clock time (for example, 11:42:11 AM). Hint: The format string that displays that output is %r. Use the +%r argument with the date command to display the current time in 12-hour clock time. [ student@workstation ~ ] $ date +%r 10 :14:07 AM What kind of file is /home/student/zcat? Is it readable by humans? Use the file command to determine its file type. [ student@workstation ~ ] $ file zcat zcat: POSIX shell script, ASCII text executable Use the wc command and Bash shortcuts to display the size of zcat. The wc command can be used to display the number of lines, words, and bytes in the zcat script. Instead of retyping the file name, use the Bash history shortcut Esc+. (the keys Esc and . pressed at the same time) to reuse the argument from the previous command. [ student@workstation ~ ] $ wc Esc+. [ student@workstation ~ ] $ wc zcat Display the first 10 lines of zcat. The head command displays the beginning of the file. Try using the Esc+. shortcut again. [ student@workstation ~ ] $ head Esc+. [ student@workstation ~ ] $ head zcat #!/bin/sh # Uncompress files to standard output. # Copyright (C) 2007, 2010-2018 Free Software Foundation, Inc. # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 3 of the License, or # (at your option) any later version. Display the last 10 lines of the zcat file. Use the tail command to display the last 10 lines of the zcat file. [ student@workstation ~ ] $ tail Esc+. [ student@workstation ~ ] $ tail zcat With no FILE, or when FILE is -, read standard input. Report bugs to <bug-gzip@gnu.org>. \" case $1 in --help) printf '%s\\n' \" $usage \" || exit 1;; --version) printf '%s\\n' \" $version \" || exit 1;; esac exec gzip -cd \" $@ \" Repeat the previous command exactly with three or fewer keystrokes. Repeat the previous command exactly. Either press the UpArrow key once to scroll back through the command history one command and then press Enter (uses two keystrokes), or enter the shortcut command !! and then press Enter (uses three keystrokes) to run the most recent command in the command history . (Try both.) [ student@workstation ] $ !! tail zcat With no FILE, or when FILE is -, read standard input. Report bugs to <bug-gzip@gnu.org>. \" case $1 in --help) printf '%s\\n' \" $usage \" || exit 1;; --version) printf '%s\\n' \" $version \" || exit 1;; esac exec gzip -cd \" $@ \" Repeat the previous command, but use the -n 20 option to display the last 20 lines in the file. Use command-line editing to accomplish this with a minimal number of keystrokes. UpArrow displays the previous command. Ctrl+A makes the cursor jump to the beginning of the line. Ctrl+RightArrow jumps to the next word, then add the -n 20 option and hit Enter to execute the command. [ student@workstation ~ ] $ tail -n 20 zcat -l, --list list compressed file contents -q, --quiet suppress all warnings -r, --recursive operate recursively on directories -S, --suffix = SUF use suffix SUF on compressed files --synchronous synchronous output ( safer if system crashes, but slower ) -t, --test test compressed file integrity -v, --verbose verbose mode --help display this help and exit --version display version information and exit With no FILE, or when FILE is -, read standard input. Report bugs to <bug-gzip@gnu.org>. \" case $1 in --help) printf '%s\\n' \" $usage \" || exit 1; exit;; --version) printf '%s\\n' \" $version \" || exit 1; exit;; esac exec gzip -cd \" $@ \" Use the shell history to run the date +%r command again. Use the history command to display the list of previous commands and to identify the specific date command to be executed. Use !number to run the command, where number is the command number to use from the output of the history command. Note that your shell history may be different from the following example. Determine the command number to use based on the output of your own history command. [ student@workstation ~ ] $ history 1 date 2 date +%r 3 file zcat 4 wc zcat 5 head zcat 6 tail zcat 7 tail -n 20 zcat 8 history [ student@workstation ~ ] $ !2 date +%r 10 :49:56 AM","title":"ACCESSING THE COMMAND LINE"},{"location":"redhat/access/#summary","text":"In this chapter, you learned: The Bash shell is a command interpreter that prompts interactive users to specify Linux commands. Many commands have a --help option that displays a usage message or screen. Using workspaces makes it easier to organize multiple application windows. The Activities button located at the upper-left corner of the top bar provides an overview mode that helps a user organize windows and start applications. The file command scans the beginning of a file's contents and displays what type it is. The head and tail commands display the beginning and end of a file, respectively. You can use Tab completion to complete file names when typing them as arguments to commands.","title":"SUMMARY"},{"location":"redhat/control/","text":"INTERPRETING LINUX FILE SYSTEM PERMISSIONS \u00b6 LINUX FILE-SYSTEM PERMISSIONS \u00b6 File permissions control access to files. The Linux file permissions system is simple but flexible, which makes it easy to understand and apply, yet still able to handle most normal permission cases easily. Files have three categories of user to which permissions apply. The file is owned by a user, normally the one who created the file. The file is also owned by a single group, usually the primary group of the user who created the file, but this can be changed. Different permissions can be set for the owning user, the owning group, and for all other users on the system that are not the user or a member of the owning group. The most specific permissions take precedence. User permissions override group permissions, which override other permissions. In Figure, joshua is a member of the groups joshua and web, and allison is a member of allison, wheel, and web. When joshua and allison need to collaborate, the files should be associated with the group web and group permissions should allow the desired access. Three categories of permissions apply: read, write, and execute. The following table explains how these permissions affect access to files and directories. Effects of Permissions on Files and Directories PERMISSION EFFECT ON FILES EFFECT ON DIRECTORIES r (read) Contents of the file can be read. Contents of the directory (the filenames) can be listed. w (write) Contents of the file can be changed. Any file in the directory can be created or deleted. x (execute) Files can be executed as commands. Contents of the directory can be accessed. (You can change into the directory, read information about its files, and access its files if the files'permissions allow it.) Note that users normally have both read and execute permissions on read-only directories so that they can list the directory and have full read-only access to its contents. If a user only has read access on a directory, the names of the files in it can be listed, but no other information, including permissions or time stamps, are available, nor can they be accessed. If a user only has execute access on a directory, they cannot list the names of the files in the directory, but if they already know the name of a file that they have permission to read, then they can access the contents of that file by explicitly specifying the file name. A file may be removed by anyone who has write permission to the directory in which the file resides, regardless of the ownership or permissions on the file itself. This can be overridden with a special permission, the sticky bit , discussed later in this chapter. NOTE Linux file permissions work differently than the permissions system used by the NTFS file system for Microsoft Windows. On Linux, permissions apply only to the file or directory on which they are set. That is, permissions on a directory are not inherited automatically by the subdirectories and files within it. However, permissions on a directory can block access to the contents of the directory depending on how restrictive they are. The read permission on a directory in Linux is roughly equivalent to List folder contents in Windows. The write permission on a directory in Linux is equivalent to Modify in Windows; it implies the ability to delete files and subdirectories. In Linux, if write and the sticky bit are both set on a directory, then only the user that owns a file or subdirectory in the directory may delete it, which is close to the behavior of the Windows Write permission. The root user on Linux has the equivalent of the Windows Full Control permission on all files. However, root may still have access restricted by the system's SELinux policy and the security context of the process and files in question. SELinux will be discussed in a later course. VIEWING FILE AND DIRECTORY PERMISSIONS AND OWNERSHIP \u00b6 The -l option of the ls command shows more detailed information about file permissions and ownership: [ user@host~ ] $ ls -l test -rw-rw-r--. 1 student student 0 Feb 8 17 :36 test You can use the -d option to to show detailed information about a directory itself, and not its contents. [ user@host ~ ] $ ls -ld /home drwxr-xr-x. 5 root root 4096 Jan 31 22 :00 /home The first character of the long listing is the file type. You interpret it like this: - is a regular file. d is a directory. l is a soft link. Other characters represent hardware devices (b and c) or other special-purpose files (p and s). The next nine characters are the file permissions. These are in three sets of three characters: permissions that apply to the user that owns the file, the group that owns the file, and all other users. If the set shows rwx , that category has all three permissions, read, write, and execute. If a letter has been replaced by -, then that category does not have that permission. After the link count, the first name specifies the user that owns the file, and the second name the group that owns the file. So in the example above, the permissions for user student are specified by the first set of three characters. User student has read and write on test, but not execute. Group student is specified by the second set of three characters: it also has read and write on test, but not execute. Any other user's permissions are specified by the third set of three characters: they only have read permission on test. The most specific set of permissions apply. So if user student has different permissions than group student, and user student is also a member of that group, then the user permissions will be the ones that apply. EXAMPLES OF PERMISSION EFFECTS \u00b6 The following examples will help illustrate how file permissions interact. For these examples, we have four users with the following group memberships: USER GROUP MEMBERSHIPS operator1 operator1, consultant1 database1 database1, consultant1 database2 database2, operator2 contractor1 contractor1, operator2 Those users will be working with files in the dir directory. This is a long listing of the files in that directory: [ database1@host dir ] $ ls -la total 24 drwxrwxr-x. 2 database1 consultant1 4096 Apr 4 10 :23 . drwxr-xr-x. 10 root root 4096 Apr 1 17 :34 .. -rw-rw-r--. 1 operator1 operator1 1024 Apr 4 11 :02 lfile1 -rw-r--rw-. 1 operator1 consultant1 3144 Apr 4 11 :02 lfile2 -rw-rw-r--. 1 database1 consultant1 10234 Apr 4 10 :14 rfile1 -rw-r-----. 1 database1 consultant1 2048 Apr 4 10 :18 rfile2 The -a option shows the permissions of hidden files, including the special files used to represent the directory and its parent. In this example, . reflects the permissions of dir itself, and .. the permissions of its parent directory. What are the permissions of rfile1 ? The user that owns the file (database1) has read and write but not execute. The group that owns the file (consultant1) has read and write but not execute. All other users have read but not write or execute. The following table explores some of the effects of this set of permissions for these users: EFFECT WHY IS THIS TRUE? The user operator1 can change the contents of rfile1 . User operator1 is a member of the consultant1 group, and that group has both read and write permissions on rfile1 . The user database1 can view and modify the contents of rfile2 . User database1 owns the file and has both read and write access to rfile2 . The user operator1 can view but not modify the contents of rfile2 (without deleting it and recreating it). User operator1 is a member of the consultant1 group, and that group only has read access to rfile2 . The users database2 and contractor1 do not have any access to the contents of rfile2 . other permissions apply to users database2 and contractor1, and those permissions do not include read or write permission. operator1 is the only user who can change the contents of lfile1 (without deleting it and recreating it). User and group operator1 have write permission on the file, other users do not. But the only member of group operator1 is user operator1. The user database2 can change the contents of lfile2 . User database2 is not the user that owns the file and is not in group consultant1, so other permissions apply. Those grant write permission. The user database1 can view the contents of lfile2 , but cannot modify the contents of lfile2 (without deleting it and recreating it). User database1 is a member of the group consultant1, and that group only has read permissions on lfile2 . Even though other has write permission, the group permissions take precedence. The user database1 can delete lfile1 and lfile2 . User database1 has write permissions on the directory containing both files (shown by .), and therefore can delete any file in that directory. This is true even if database1 does not have write permission on the file itself. MANAGING FILE SYSTEM PERMISSIONS FROM THE COMMAND LINE \u00b6 CHANGING FILE AND DIRECTORY PERMISSIONS \u00b6 The command used to change permissions from the command line is chmod , which means \"change mode\" (permissions are also called the mode of a file). The chmod command takes a permission instruction followed by a list of files or directories to change. The permission instruction can be issued either symbolically (the symbolic method) or numerically (the numeric method). Changing Permissions with the Symbolic Method chmod WhoWhatWhich file|directory Who is u, g, o, a (for user, group, other, all) What is +, -, = (for add, remove, set exactly) Which is r, w, x (for read, write, execute) The symbolic method of changing file permissions uses letters to represent the different groups of permissions: u for user, g for group, o for other, and a for all. With the symbolic method, it is not necessary to set a complete new group of permissions. Instead, you can change one or more of the existing permissions. Use + or - to add or remove permissions, respectively, or use = to replace the entire set for a group of permissions. The permissions themselves are represented by a single letter: r for read, w for write, and x for execute. When using chmod to change permissions with the symbolic method, using a capital X as the permission flag will add execute permission only if the file is a directory or already has execute set for user, group, or other. NOTE The chmod command supports the -R option to recursively set permissions on the files in an entire directory tree. When using the -R option, it can be useful to set permissions symbolically using the X option. This allows the execute (search) permission to be set on directories so that their contents can be accessed, without changing permissions on most files. Be cautious with the X option, however, because if a file has any execute permission set, X will set the specified execute permission on that file as well. For example, the following command recursively sets read and write access on demodir and all its children for their group owner, but only applies group execute permissions to directories and files that already have execute set for user, group, or other. [ root@host opt ] # chmod -R g+rwX demodir Examples Remove read and write permission for group and other on file1: [ user@host ~ ] $ chmod go-rw file1 Add execute permission for everyone on file2: [ user@host ~ ] $ chmod a+x file2 Changing Permissions with the Numeric Method In the example below the # character represents a digit. chmod ### file|directory Each digit represents permissions for an access level: user, group, other. The digit is calculated by adding together numbers for each permission you want to add, 4 for read, 2 for write, and 1 for execute. Using the numeric method, permissions are represented by a 3-digit (or 4-digit, when setting advanced permissions) octal number. A single octal digit can represent any single value from 0-7. In the 3-digit octal (numeric) representation of permissions, each digit stands for one access level, from left to right: user, group, and other. To determine each digit: Start with 0. If the read permission should be present for this access level, add 4. If the write permission should be present, add 2. If the execute permission should be present, add 1. Examine the permissions -rwxr-x---. For the user, rwx is calculated as 4+2+1=7. For the group, r-x is calculated as 4+0+1=5, and for other users, --- is represented with 0. Putting these three together, the numeric representation of those permissions is 750. This calculation can also be performed in the opposite direction. Look at the permissions 640. For the user permissions, 6 represents read (4) and write (2), which displays as rw-. For the group part, 4 only includes read (4) and displays as r--. The 0 for other provides no permissions (---) and the final set of symbolic permissions for this file is -rw-r-----. Experienced administrators often use numeric permissions because they are shorter to type and pronounce, while still giving full control over all permissions. Examples Set read and write permissions for user, read permission for group and other, on samplefile: [ user@host ~ ] $ chmod 644 samplefile Set read, write, and execute permissions for user, read and execute permissions for group, and no permission for other on sampledir : [ user@host ~ ] $ chmod 750 sampledir CHANGING FILE AND DIRECTORY USER OR GROUP OWNERSHIP \u00b6 A newly created file is owned by the user who creates that file. By default, new files have a group ownership that is the primary group of the user creating the file. In Red Hat Enterprise Linux, a user's primary group is usually a private group with only that user as a member. To grant access to a file based on group membership, the group that owns the file may need to be changed. Only root can change the user that owns a file. Group ownership, however, can be set by root or by the file's owner. root can grant file ownership to any group, but regular users can make a group the owner of a file only if they are a member of that group. File ownership can be changed with the chown (change owner) command. For example, to grant ownership of the test_file file to the student user, use the following command: [ root@host ~ ] # chown student test_file chown can be used with the -R option to recursively change the ownership of an entire directory tree. The following command grants ownership of test_dir and all files and subdirectories within it to student: [ root@host ~ ] # chown -R student test_dir The chown command can also be used to change group ownership of a file by preceding the group name with a colon (:). For example, the following command changes the group test_dir to admins: [ root@host ~ ] # chown :admins test_dir The chown command can also be used to change both owner and group at the same time by using the owner:group syntax. For example, to change the ownership of test_dir to visitor and the group to guests, use the following command: [ root@host ~ ] # chown visitor:guests test_dir Instead of using chown , some users change the group ownership by using the chgrp command. This command works just like chown , except that it is only used to change group ownership and the colon (:) before the group name is not required. IMPORTANT You may encounter examples of chown commands using an alternative syntax that separates owner and group with a period instead of a colon: [ root@host ~ ] # chown owner.group filename You should not use this syntax. Always use a colon. A period is a valid character in a user name, but a colon is not. If the user enoch.root, the user enoch, and the group root exist on the system, the result of chown enoch.root filename will be to have filename owned by the user enoch.root. You may have been trying to set the file ownership to the user enoch and group root. This can be confusing. If you always use the chown colon syntax when setting the user and group at the same time, the results are always easy to predict. MANAGING DEFAULT PERMISSIONS AND FILE ACCESS \u00b6 SPECIAL PERMISSIONS \u00b6 Special permissions constitute a fourth permission type in addition to the basic user, group, and other types. As the name implies, these permissions provide additional access-related features over and above what the basic permission types allow. This section details the impact of special permissions, summarized in the table below. Effects of Special Permissions on Files and Directories SPECIAL PERMISSION EFFECT ON FILES EFFECT ON DIRECTORIES u+s (suid) File executes as the user that owns the file, not the user that ran the file. No effect. g+s (sgid) File executes as the group that owns the file. Files newly created in the directory have their group owner set to match the group owner of the directory. o+t (sticky) No effect. Users with write access to the directory can only remove files that they own; they cannot remove or force saves to files owned by other users. The setuid permission on an executable file means that commands run as the user owning the file, not as the user that ran the command. One example is the passwd command: [ user@host ~ ] $ ls -l /usr/bin/passwd -rwsr-xr-x. 1 root root 35504 Jul 16 2010 /usr/bin/passwd In a long listing, you can identify the setuid permissions by a lowercase s where you would normally expect the x (owner execute permissions) to be. If the owner does not have execute permissions, this is replaced by an uppercase S. The special permission setgid on a directory means that files created in the directory inherit their group ownership from the directory, rather than inheriting it from the creating user. This is commonly used on group collaborative directories to automatically change a file from the default private group to the shared group, or if files in a directory should be always owned by a specific group. An example of this is the /run/log/journal directory: [ user@host ~ ] $ ls -ld /run/log/journal drwxr-sr-x. 3 root systemd-journal 60 May 18 09 :15 /run/log/journal If setgid is set on an executable file, commands run as the group that owns that file, not as the user that ran the command, in a similar way to setuid works. One example is the locate command: [ user@host ~ ] $ ls -ld /usr/bin/locate -rwx--s--x. 1 root slocate 47128 Aug 12 17 :17 /usr/bin/locate In a long listing, you can identify the setgid permissions by a lowercase s where you would normally expect the x (group execute permissions) to be. If the group does not have execute permissions, this is replaced by an uppercase S. Lastly, the sticky bit for a directory sets a special restriction on deletion of files. Only the owner of the file (and root) can delete files within the directory. An example is /tmp: [ user@host ~ ] $ ls -ld /tmp drwxrwxrwt. 39 root root 4096 Feb 8 20 :52 /tmp In a long listing, you can identify the sticky permissions by a lowercase t where you would normally expect the x (other execute permissions) to be. If other does not have execute permissions, this is replaced by an uppercase T. Setting Special Permissions Symbolically: setuid = u+s; setgid = g+s; sticky = o+t Numerically (fourth preceding digit): setuid = 4; setgid = 2; sticky = 1 Examples Add the setgid bit on directory: [ user@host ~ ] # chmod g+s directory Set the setgid bit and add read/write/execute permissions for user and group, with no access for others, on directory: [ user@host ~ ] # chmod 2770 directory DEFAULT FILE PERMISSIONS \u00b6 When you create a new file or directory, it is assigned initial permissions. There are two things that affect these initial permissions. The first is whether you are creating a regular file or a directory. The second is the current umask . If you create a new directory, the operating system starts by assigning it octal permissions 0777 ( drwxrwxrwx ). If you create a new regular file, the operating system assignes it octal permissions 0666 ( -rw-rw-rw- ). You always have to explicitly add execute permission to a regular file. This makes it harder for an attacker to compromise a network service so that it creates a new file and immediately executes it as a program. However, the shell session will also set a umask to further restrict the permissions that are initially set. This is an octal bitmask used to clear the permissions of new files and directories created by a process. If a bit is set in the umask, then the corresponding permission is cleared on new files. For example, the umask 0002 clears the write bit for other users. The leading zeros indicate the special, user, and group permissions are not cleared. A umask of 0077 clears all the group and other permissions of newly created files. The umask command without arguments will display the current value of the shell's umask: [ user@host ~ ] $ umask 0002 Use the umask command with a single numeric argument to change the umask of the current shell. The numeric argument should be an octal value corresponding to the new umask value. You can omit any leading zeros in the umask. The system's default umask values for Bash shell users are defined in the /etc/profile and / etc/bashrc files. Users can override the system defaults in the .bash_profile and .bashrc files in their home directories. umask Example The following example explains how the umask affects the permissions of files and directories. Look at the default umask permissions for both files and directories in the current shell. The owner and group both have read and write permission on files, and other is set to read. The owner and group both have read, write, and execute permissions on directories. The only permission for other is read. [ user@host ~ ] $ umask 0002 [ user@host ~ ] $ touch default [ user@host ~ ] $ ls -l default.txt -rw-rw-r--. 1 user user 0 May 9 01 :54 default.txt [ user@host ~ ] $ mkdir default [ user@host ~ ] $ ls -ld default drwxrwxr-x. 2 user user 0 May 9 01 :54 default By setting the umask value to 0, the file permissions for other change from read to read and write. The directory permissions for other changes from read and execute to read, write, and execute. [ user@host ~ ] $ umask 0 [ user@host ~ ] $ touch zero.txt [ user@host ~ ] $ ls -l zero.txt -rw-rw-rw-. 1 user user 0 May 9 01 :54 zero.txt [ user@host ~ ] $ mkdir zero [ user@host ~ ] $ ls -ld zero drwxrwxrwx. 2 user user 0 May 9 01 :54 zero To mask all file and directory permissions for other, set the umask value to 007. [ user@host ~ ] $ umask 007 [ user@host ~ ] $ touch seven.txt [ user@host ~ ] $ ls -l seven.txt -rw-rw----. 1 user user 0 May 9 01 :55 seven.txt [ user@host ~ ] $ mkdir seven [ user@host ~ ] $ ls -ld seven drwxrwx---. 2 user user 0 May 9 01 :54 seven A umask of 027 ensures that new files have read and write permissions for user and read permission for group. New directories have read and write access for group and no permissions for other. [ user@host ~ ] $ umask 027 [ user@host ~ ] $ touch two-seven.txt [ user@host ~ ] $ ls -l two-seven.txt -rw-r-----. 1 user user 0 May 9 01 :55 two-seven.txt [ user@host ~ ] $ mkdir two-seven [ user@host ~ ] $ ls -ld two-seven drwxr-x---. 2 user user 0 May 9 01 :54 two-seven The default umask for users is set by the shell startup scripts. By default, if your account's UID is 200 or more and your username and primary group name are the same, you will be assigned a umask of 002. Otherwise, your umask will be 022. As root, you can change this by adding a shell startup script named /etc/profile.d/local- umask.sh that looks something like the output in this example: [ root@host ~ ] # cat /etc/profile.d/local-umask.sh # Overrides default umask configuration if [ $UID -gt 199 ] && [ \"`id -gn`\" = \"`id -un`\" ] ; then umask 007 else umask 022 fi The preceding example will set the umask to 007 for users with a UID greater than 199 and with a username and primary group name that match, and to 022 for everyone else. If you just wanted to set the umask for everyone to 022, you could create that file with just the following content: # Overrides default umask configuration umask 022 To ensure that global umask changes take effect you must log out of the shell and log back in. Until that time the umask configured in the current shell is still in effect. SUMMARY \u00b6 In this chapter, you learned: Files have three categories to which permissions apply. A file is owned by a user, a single group, and other users. The most specific permission applies. User permissions override group permissions and group permissions override other permissions. The ls command with the -l option expands the file listing to include both the file permissions and ownership. The chmod command changes file permissions from the command line. There are two methods to represent permissions, symbolic (letters) and numeric (digits). The chown command changes file ownership. The -R option recursively changes the ownership of a directory tree. The umask command without arguments displays the current umask value of the shell. Every process on the system has a umask. The default umask values for Bash are defined in the /etc/ profile and /etc/bashrc files.","title":"Controlling Access To Files"},{"location":"redhat/control/#interpreting-linux-file-system-permissions","text":"","title":"INTERPRETING LINUX FILE SYSTEM PERMISSIONS"},{"location":"redhat/control/#linux-file-system-permissions","text":"File permissions control access to files. The Linux file permissions system is simple but flexible, which makes it easy to understand and apply, yet still able to handle most normal permission cases easily. Files have three categories of user to which permissions apply. The file is owned by a user, normally the one who created the file. The file is also owned by a single group, usually the primary group of the user who created the file, but this can be changed. Different permissions can be set for the owning user, the owning group, and for all other users on the system that are not the user or a member of the owning group. The most specific permissions take precedence. User permissions override group permissions, which override other permissions. In Figure, joshua is a member of the groups joshua and web, and allison is a member of allison, wheel, and web. When joshua and allison need to collaborate, the files should be associated with the group web and group permissions should allow the desired access. Three categories of permissions apply: read, write, and execute. The following table explains how these permissions affect access to files and directories. Effects of Permissions on Files and Directories PERMISSION EFFECT ON FILES EFFECT ON DIRECTORIES r (read) Contents of the file can be read. Contents of the directory (the filenames) can be listed. w (write) Contents of the file can be changed. Any file in the directory can be created or deleted. x (execute) Files can be executed as commands. Contents of the directory can be accessed. (You can change into the directory, read information about its files, and access its files if the files'permissions allow it.) Note that users normally have both read and execute permissions on read-only directories so that they can list the directory and have full read-only access to its contents. If a user only has read access on a directory, the names of the files in it can be listed, but no other information, including permissions or time stamps, are available, nor can they be accessed. If a user only has execute access on a directory, they cannot list the names of the files in the directory, but if they already know the name of a file that they have permission to read, then they can access the contents of that file by explicitly specifying the file name. A file may be removed by anyone who has write permission to the directory in which the file resides, regardless of the ownership or permissions on the file itself. This can be overridden with a special permission, the sticky bit , discussed later in this chapter. NOTE Linux file permissions work differently than the permissions system used by the NTFS file system for Microsoft Windows. On Linux, permissions apply only to the file or directory on which they are set. That is, permissions on a directory are not inherited automatically by the subdirectories and files within it. However, permissions on a directory can block access to the contents of the directory depending on how restrictive they are. The read permission on a directory in Linux is roughly equivalent to List folder contents in Windows. The write permission on a directory in Linux is equivalent to Modify in Windows; it implies the ability to delete files and subdirectories. In Linux, if write and the sticky bit are both set on a directory, then only the user that owns a file or subdirectory in the directory may delete it, which is close to the behavior of the Windows Write permission. The root user on Linux has the equivalent of the Windows Full Control permission on all files. However, root may still have access restricted by the system's SELinux policy and the security context of the process and files in question. SELinux will be discussed in a later course.","title":"LINUX FILE-SYSTEM PERMISSIONS"},{"location":"redhat/control/#viewing-file-and-directory-permissions-and-ownership","text":"The -l option of the ls command shows more detailed information about file permissions and ownership: [ user@host~ ] $ ls -l test -rw-rw-r--. 1 student student 0 Feb 8 17 :36 test You can use the -d option to to show detailed information about a directory itself, and not its contents. [ user@host ~ ] $ ls -ld /home drwxr-xr-x. 5 root root 4096 Jan 31 22 :00 /home The first character of the long listing is the file type. You interpret it like this: - is a regular file. d is a directory. l is a soft link. Other characters represent hardware devices (b and c) or other special-purpose files (p and s). The next nine characters are the file permissions. These are in three sets of three characters: permissions that apply to the user that owns the file, the group that owns the file, and all other users. If the set shows rwx , that category has all three permissions, read, write, and execute. If a letter has been replaced by -, then that category does not have that permission. After the link count, the first name specifies the user that owns the file, and the second name the group that owns the file. So in the example above, the permissions for user student are specified by the first set of three characters. User student has read and write on test, but not execute. Group student is specified by the second set of three characters: it also has read and write on test, but not execute. Any other user's permissions are specified by the third set of three characters: they only have read permission on test. The most specific set of permissions apply. So if user student has different permissions than group student, and user student is also a member of that group, then the user permissions will be the ones that apply.","title":"VIEWING FILE AND DIRECTORY PERMISSIONS AND OWNERSHIP"},{"location":"redhat/control/#examples-of-permission-effects","text":"The following examples will help illustrate how file permissions interact. For these examples, we have four users with the following group memberships: USER GROUP MEMBERSHIPS operator1 operator1, consultant1 database1 database1, consultant1 database2 database2, operator2 contractor1 contractor1, operator2 Those users will be working with files in the dir directory. This is a long listing of the files in that directory: [ database1@host dir ] $ ls -la total 24 drwxrwxr-x. 2 database1 consultant1 4096 Apr 4 10 :23 . drwxr-xr-x. 10 root root 4096 Apr 1 17 :34 .. -rw-rw-r--. 1 operator1 operator1 1024 Apr 4 11 :02 lfile1 -rw-r--rw-. 1 operator1 consultant1 3144 Apr 4 11 :02 lfile2 -rw-rw-r--. 1 database1 consultant1 10234 Apr 4 10 :14 rfile1 -rw-r-----. 1 database1 consultant1 2048 Apr 4 10 :18 rfile2 The -a option shows the permissions of hidden files, including the special files used to represent the directory and its parent. In this example, . reflects the permissions of dir itself, and .. the permissions of its parent directory. What are the permissions of rfile1 ? The user that owns the file (database1) has read and write but not execute. The group that owns the file (consultant1) has read and write but not execute. All other users have read but not write or execute. The following table explores some of the effects of this set of permissions for these users: EFFECT WHY IS THIS TRUE? The user operator1 can change the contents of rfile1 . User operator1 is a member of the consultant1 group, and that group has both read and write permissions on rfile1 . The user database1 can view and modify the contents of rfile2 . User database1 owns the file and has both read and write access to rfile2 . The user operator1 can view but not modify the contents of rfile2 (without deleting it and recreating it). User operator1 is a member of the consultant1 group, and that group only has read access to rfile2 . The users database2 and contractor1 do not have any access to the contents of rfile2 . other permissions apply to users database2 and contractor1, and those permissions do not include read or write permission. operator1 is the only user who can change the contents of lfile1 (without deleting it and recreating it). User and group operator1 have write permission on the file, other users do not. But the only member of group operator1 is user operator1. The user database2 can change the contents of lfile2 . User database2 is not the user that owns the file and is not in group consultant1, so other permissions apply. Those grant write permission. The user database1 can view the contents of lfile2 , but cannot modify the contents of lfile2 (without deleting it and recreating it). User database1 is a member of the group consultant1, and that group only has read permissions on lfile2 . Even though other has write permission, the group permissions take precedence. The user database1 can delete lfile1 and lfile2 . User database1 has write permissions on the directory containing both files (shown by .), and therefore can delete any file in that directory. This is true even if database1 does not have write permission on the file itself.","title":"EXAMPLES OF PERMISSION EFFECTS"},{"location":"redhat/control/#managing-file-system-permissions-from-the-command-line","text":"","title":"MANAGING FILE SYSTEM PERMISSIONS FROM THE COMMAND LINE"},{"location":"redhat/control/#changing-file-and-directory-permissions","text":"The command used to change permissions from the command line is chmod , which means \"change mode\" (permissions are also called the mode of a file). The chmod command takes a permission instruction followed by a list of files or directories to change. The permission instruction can be issued either symbolically (the symbolic method) or numerically (the numeric method). Changing Permissions with the Symbolic Method chmod WhoWhatWhich file|directory Who is u, g, o, a (for user, group, other, all) What is +, -, = (for add, remove, set exactly) Which is r, w, x (for read, write, execute) The symbolic method of changing file permissions uses letters to represent the different groups of permissions: u for user, g for group, o for other, and a for all. With the symbolic method, it is not necessary to set a complete new group of permissions. Instead, you can change one or more of the existing permissions. Use + or - to add or remove permissions, respectively, or use = to replace the entire set for a group of permissions. The permissions themselves are represented by a single letter: r for read, w for write, and x for execute. When using chmod to change permissions with the symbolic method, using a capital X as the permission flag will add execute permission only if the file is a directory or already has execute set for user, group, or other. NOTE The chmod command supports the -R option to recursively set permissions on the files in an entire directory tree. When using the -R option, it can be useful to set permissions symbolically using the X option. This allows the execute (search) permission to be set on directories so that their contents can be accessed, without changing permissions on most files. Be cautious with the X option, however, because if a file has any execute permission set, X will set the specified execute permission on that file as well. For example, the following command recursively sets read and write access on demodir and all its children for their group owner, but only applies group execute permissions to directories and files that already have execute set for user, group, or other. [ root@host opt ] # chmod -R g+rwX demodir Examples Remove read and write permission for group and other on file1: [ user@host ~ ] $ chmod go-rw file1 Add execute permission for everyone on file2: [ user@host ~ ] $ chmod a+x file2 Changing Permissions with the Numeric Method In the example below the # character represents a digit. chmod ### file|directory Each digit represents permissions for an access level: user, group, other. The digit is calculated by adding together numbers for each permission you want to add, 4 for read, 2 for write, and 1 for execute. Using the numeric method, permissions are represented by a 3-digit (or 4-digit, when setting advanced permissions) octal number. A single octal digit can represent any single value from 0-7. In the 3-digit octal (numeric) representation of permissions, each digit stands for one access level, from left to right: user, group, and other. To determine each digit: Start with 0. If the read permission should be present for this access level, add 4. If the write permission should be present, add 2. If the execute permission should be present, add 1. Examine the permissions -rwxr-x---. For the user, rwx is calculated as 4+2+1=7. For the group, r-x is calculated as 4+0+1=5, and for other users, --- is represented with 0. Putting these three together, the numeric representation of those permissions is 750. This calculation can also be performed in the opposite direction. Look at the permissions 640. For the user permissions, 6 represents read (4) and write (2), which displays as rw-. For the group part, 4 only includes read (4) and displays as r--. The 0 for other provides no permissions (---) and the final set of symbolic permissions for this file is -rw-r-----. Experienced administrators often use numeric permissions because they are shorter to type and pronounce, while still giving full control over all permissions. Examples Set read and write permissions for user, read permission for group and other, on samplefile: [ user@host ~ ] $ chmod 644 samplefile Set read, write, and execute permissions for user, read and execute permissions for group, and no permission for other on sampledir : [ user@host ~ ] $ chmod 750 sampledir","title":"CHANGING FILE AND DIRECTORY PERMISSIONS"},{"location":"redhat/control/#changing-file-and-directory-user-or-group-ownership","text":"A newly created file is owned by the user who creates that file. By default, new files have a group ownership that is the primary group of the user creating the file. In Red Hat Enterprise Linux, a user's primary group is usually a private group with only that user as a member. To grant access to a file based on group membership, the group that owns the file may need to be changed. Only root can change the user that owns a file. Group ownership, however, can be set by root or by the file's owner. root can grant file ownership to any group, but regular users can make a group the owner of a file only if they are a member of that group. File ownership can be changed with the chown (change owner) command. For example, to grant ownership of the test_file file to the student user, use the following command: [ root@host ~ ] # chown student test_file chown can be used with the -R option to recursively change the ownership of an entire directory tree. The following command grants ownership of test_dir and all files and subdirectories within it to student: [ root@host ~ ] # chown -R student test_dir The chown command can also be used to change group ownership of a file by preceding the group name with a colon (:). For example, the following command changes the group test_dir to admins: [ root@host ~ ] # chown :admins test_dir The chown command can also be used to change both owner and group at the same time by using the owner:group syntax. For example, to change the ownership of test_dir to visitor and the group to guests, use the following command: [ root@host ~ ] # chown visitor:guests test_dir Instead of using chown , some users change the group ownership by using the chgrp command. This command works just like chown , except that it is only used to change group ownership and the colon (:) before the group name is not required. IMPORTANT You may encounter examples of chown commands using an alternative syntax that separates owner and group with a period instead of a colon: [ root@host ~ ] # chown owner.group filename You should not use this syntax. Always use a colon. A period is a valid character in a user name, but a colon is not. If the user enoch.root, the user enoch, and the group root exist on the system, the result of chown enoch.root filename will be to have filename owned by the user enoch.root. You may have been trying to set the file ownership to the user enoch and group root. This can be confusing. If you always use the chown colon syntax when setting the user and group at the same time, the results are always easy to predict.","title":"CHANGING FILE AND DIRECTORY USER OR GROUP OWNERSHIP"},{"location":"redhat/control/#managing-default-permissions-and-file-access","text":"","title":"MANAGING DEFAULT PERMISSIONS AND FILE ACCESS"},{"location":"redhat/control/#special-permissions","text":"Special permissions constitute a fourth permission type in addition to the basic user, group, and other types. As the name implies, these permissions provide additional access-related features over and above what the basic permission types allow. This section details the impact of special permissions, summarized in the table below. Effects of Special Permissions on Files and Directories SPECIAL PERMISSION EFFECT ON FILES EFFECT ON DIRECTORIES u+s (suid) File executes as the user that owns the file, not the user that ran the file. No effect. g+s (sgid) File executes as the group that owns the file. Files newly created in the directory have their group owner set to match the group owner of the directory. o+t (sticky) No effect. Users with write access to the directory can only remove files that they own; they cannot remove or force saves to files owned by other users. The setuid permission on an executable file means that commands run as the user owning the file, not as the user that ran the command. One example is the passwd command: [ user@host ~ ] $ ls -l /usr/bin/passwd -rwsr-xr-x. 1 root root 35504 Jul 16 2010 /usr/bin/passwd In a long listing, you can identify the setuid permissions by a lowercase s where you would normally expect the x (owner execute permissions) to be. If the owner does not have execute permissions, this is replaced by an uppercase S. The special permission setgid on a directory means that files created in the directory inherit their group ownership from the directory, rather than inheriting it from the creating user. This is commonly used on group collaborative directories to automatically change a file from the default private group to the shared group, or if files in a directory should be always owned by a specific group. An example of this is the /run/log/journal directory: [ user@host ~ ] $ ls -ld /run/log/journal drwxr-sr-x. 3 root systemd-journal 60 May 18 09 :15 /run/log/journal If setgid is set on an executable file, commands run as the group that owns that file, not as the user that ran the command, in a similar way to setuid works. One example is the locate command: [ user@host ~ ] $ ls -ld /usr/bin/locate -rwx--s--x. 1 root slocate 47128 Aug 12 17 :17 /usr/bin/locate In a long listing, you can identify the setgid permissions by a lowercase s where you would normally expect the x (group execute permissions) to be. If the group does not have execute permissions, this is replaced by an uppercase S. Lastly, the sticky bit for a directory sets a special restriction on deletion of files. Only the owner of the file (and root) can delete files within the directory. An example is /tmp: [ user@host ~ ] $ ls -ld /tmp drwxrwxrwt. 39 root root 4096 Feb 8 20 :52 /tmp In a long listing, you can identify the sticky permissions by a lowercase t where you would normally expect the x (other execute permissions) to be. If other does not have execute permissions, this is replaced by an uppercase T. Setting Special Permissions Symbolically: setuid = u+s; setgid = g+s; sticky = o+t Numerically (fourth preceding digit): setuid = 4; setgid = 2; sticky = 1 Examples Add the setgid bit on directory: [ user@host ~ ] # chmod g+s directory Set the setgid bit and add read/write/execute permissions for user and group, with no access for others, on directory: [ user@host ~ ] # chmod 2770 directory","title":"SPECIAL PERMISSIONS"},{"location":"redhat/control/#default-file-permissions","text":"When you create a new file or directory, it is assigned initial permissions. There are two things that affect these initial permissions. The first is whether you are creating a regular file or a directory. The second is the current umask . If you create a new directory, the operating system starts by assigning it octal permissions 0777 ( drwxrwxrwx ). If you create a new regular file, the operating system assignes it octal permissions 0666 ( -rw-rw-rw- ). You always have to explicitly add execute permission to a regular file. This makes it harder for an attacker to compromise a network service so that it creates a new file and immediately executes it as a program. However, the shell session will also set a umask to further restrict the permissions that are initially set. This is an octal bitmask used to clear the permissions of new files and directories created by a process. If a bit is set in the umask, then the corresponding permission is cleared on new files. For example, the umask 0002 clears the write bit for other users. The leading zeros indicate the special, user, and group permissions are not cleared. A umask of 0077 clears all the group and other permissions of newly created files. The umask command without arguments will display the current value of the shell's umask: [ user@host ~ ] $ umask 0002 Use the umask command with a single numeric argument to change the umask of the current shell. The numeric argument should be an octal value corresponding to the new umask value. You can omit any leading zeros in the umask. The system's default umask values for Bash shell users are defined in the /etc/profile and / etc/bashrc files. Users can override the system defaults in the .bash_profile and .bashrc files in their home directories. umask Example The following example explains how the umask affects the permissions of files and directories. Look at the default umask permissions for both files and directories in the current shell. The owner and group both have read and write permission on files, and other is set to read. The owner and group both have read, write, and execute permissions on directories. The only permission for other is read. [ user@host ~ ] $ umask 0002 [ user@host ~ ] $ touch default [ user@host ~ ] $ ls -l default.txt -rw-rw-r--. 1 user user 0 May 9 01 :54 default.txt [ user@host ~ ] $ mkdir default [ user@host ~ ] $ ls -ld default drwxrwxr-x. 2 user user 0 May 9 01 :54 default By setting the umask value to 0, the file permissions for other change from read to read and write. The directory permissions for other changes from read and execute to read, write, and execute. [ user@host ~ ] $ umask 0 [ user@host ~ ] $ touch zero.txt [ user@host ~ ] $ ls -l zero.txt -rw-rw-rw-. 1 user user 0 May 9 01 :54 zero.txt [ user@host ~ ] $ mkdir zero [ user@host ~ ] $ ls -ld zero drwxrwxrwx. 2 user user 0 May 9 01 :54 zero To mask all file and directory permissions for other, set the umask value to 007. [ user@host ~ ] $ umask 007 [ user@host ~ ] $ touch seven.txt [ user@host ~ ] $ ls -l seven.txt -rw-rw----. 1 user user 0 May 9 01 :55 seven.txt [ user@host ~ ] $ mkdir seven [ user@host ~ ] $ ls -ld seven drwxrwx---. 2 user user 0 May 9 01 :54 seven A umask of 027 ensures that new files have read and write permissions for user and read permission for group. New directories have read and write access for group and no permissions for other. [ user@host ~ ] $ umask 027 [ user@host ~ ] $ touch two-seven.txt [ user@host ~ ] $ ls -l two-seven.txt -rw-r-----. 1 user user 0 May 9 01 :55 two-seven.txt [ user@host ~ ] $ mkdir two-seven [ user@host ~ ] $ ls -ld two-seven drwxr-x---. 2 user user 0 May 9 01 :54 two-seven The default umask for users is set by the shell startup scripts. By default, if your account's UID is 200 or more and your username and primary group name are the same, you will be assigned a umask of 002. Otherwise, your umask will be 022. As root, you can change this by adding a shell startup script named /etc/profile.d/local- umask.sh that looks something like the output in this example: [ root@host ~ ] # cat /etc/profile.d/local-umask.sh # Overrides default umask configuration if [ $UID -gt 199 ] && [ \"`id -gn`\" = \"`id -un`\" ] ; then umask 007 else umask 022 fi The preceding example will set the umask to 007 for users with a UID greater than 199 and with a username and primary group name that match, and to 022 for everyone else. If you just wanted to set the umask for everyone to 022, you could create that file with just the following content: # Overrides default umask configuration umask 022 To ensure that global umask changes take effect you must log out of the shell and log back in. Until that time the umask configured in the current shell is still in effect.","title":"DEFAULT FILE PERMISSIONS"},{"location":"redhat/control/#summary","text":"In this chapter, you learned: Files have three categories to which permissions apply. A file is owned by a user, a single group, and other users. The most specific permission applies. User permissions override group permissions and group permissions override other permissions. The ls command with the -l option expands the file listing to include both the file permissions and ownership. The chmod command changes file permissions from the command line. There are two methods to represent permissions, symbolic (letters) and numeric (digits). The chown command changes file ownership. The -R option recursively changes the ownership of a directory tree. The umask command without arguments displays the current umask value of the shell. Every process on the system has a umask. The default umask values for Bash are defined in the /etc/ profile and /etc/bashrc files.","title":"SUMMARY"},{"location":"redhat/edit/","text":"REDIRECTING OUTPUT TO A FILE OR PROGRAM \u00b6 STANDARD INPUT, STANDARD OUTPUT, AND STANDARD ERROR \u00b6 A running program, or process , needs to read input from somewhere and write output to somewhere. A command run from the shell prompt normally reads its input from the keyboard and sends its output to its terminal window. A process uses numbered channels called file descriptors to get input and send output. All processes start with at least three file descriptors. Standard input (channel 0) reads input from the keyboard. Standard output (channel 1) sends normal output to the terminal. Standard error (channel 2) sends error messages to the terminal. If a program opens separate connections to other files, it may use higher-numbered file descriptors. Channels (File Descriptors) NUMBER CHANNEL NAME DESCRIPTION DEFAULT CONNECTION USAGE 0 stdin Standard input Keyboard read only 1 stdout Standard output Terminal write only 2 stderr Standard error Terminal write only 3+ filename Other files none read and/or write REDIRECTING OUTPUT TO A FILE \u00b6 I/O redirection changes how the process gets its input or output. Instead of getting input from the keyboard, or sending output and errors to the terminal, the process reads from or writes to files. Redirection lets you save messages to a file that are normally sent to the terminal window. Alternatively, you can use redirection to discard output or errors, so they are not displayed on the terminal or saved. Redirecting stdout suppresses process output from appearing on the terminal. As seen in the following table, redirecting only stdout does not suppress stderr error messages from displaying on the terminal. If the file does not exist, it will be created. If the file does exist and the redirection is not one that appends to the file, the file's contents will be overwritten. If you want to discard messages, the special file /dev/null quietly discards channel output redirected to it and is always an empty file. USAGE EXPLANATION > file redirect stdout to overwrite a file >> file redirect stdout to append to a file 2> file redirect stderr to overwrite a file 2> /dev/null stderr error messages by redirecting to /dev/null > file 2>&1 redirect stdout and stderr to overwrite the same file &> file redirect stdout and stderr to overwrite the same file >> file 2>&1 redirect stdout and stderr to append to the same file &>> file redirect stdout and stderr to append to the same file IMPORTANT The order of redirection operations is important. The following sequence redirects standard output to file and then redirects standard error to the same place as standard output (file). > file 2>&1 However, the next sequence does redirection in the opposite order. This redirects standard error to the default place for standard output (the terminal window, so no change) and then redirects only standard output to file. 2>&1 > file Because of this, some people prefer to use the merging redirection operators: &>file instead of >file 2>&1 &>>file instead of >>file 2>&1(in Bash 4 / RHEL 6 and later) However, other system administrators and programmers who also use other shells related to bash (known as Bourne-compatible shells) for scripting commands think that the newer merging redirection operators should be avoided, because they are not standardized or implemented in all of those shells and have other limitations. The authors of this course take a neutral stance on this topic, and both syntaxes are likely to be encountered in the field. Examples for Output Redirection Many routine administration tasks are simplified by using redirection. Use the previous table to assist while considering the following examples: Save a time stamp for later reference. [ user@host ~ ] $ date > /tmp/saved-timestamp Copy the last 100 lines from a log file to another file. [ user@host ~ ] $ tail -n 100 /var/log/dmesg > /tmp/last-100-boot-messages Concatenate four files into one. [ user@host ~ ] $ cat file1 file2 file3 file4 > /tmp/all-four-in-one List the home directory's hidden and regular file names into a file. [ user@host ~ ] $ ls -a > /tmp/my-file-names Append output to an existing file. [ user@host ~ ] $ echo \"new line of information\" >> /tmp/many-lines-of-information [ user@host ~ ] $ diff previous-file current-file >> /tmp/tracking-changes-made The next few commands generate error messages because some system directories are inaccessible to normal users. Observe as the error messages are redirected. Redirect errors to a file while viewing normal command output on the terminal. [user@host ~]$ find /etc -name passwd 2> /tmp/errors Save process output and error messages to separate files. [ user@host ~ ] $ find /etc -name passwd > /tmp/output 2 > /tmp/errors Ignore and discard error messages. [ user@host ~ ] $ find /etc -name passwd > /tmp/output 2 > /dev/null Store output and generated errors together. [ user@host ~ ] $ find /etc -name passwd & > /tmp/save-both Append output and generated errors to an existing file. [ user@host ~ ] $ find /etc -name passwd >> /tmp/save-both 2 > & 1 CONSTRUCTING PIPELINES \u00b6 A pipeline is a sequence of one or more commands separated by the pipe character (|). A pipe connects the standard output of the first command to the standard input of the next command. Pipelines allow the output of a process to be manipulated and formatted by other processes before it is output to the terminal. One useful mental image is to imagine that data is \"flowing\" through the pipeline from one process to another, being altered slightly by each command in the pipeline through which it flows. NOTE Pipelines and I/O redirection both manipulate standard output and standard input. Redirection sends standard output to files or gets standard input from files. Pipes send the standard output from one process to the standard input of another process. Pipeline Examples This example takes the output of the ls command and uses less to display it on the terminal one screen at a time. [ user@host ~ ] $ ls -l /usr/bin | less The output of the ls command is piped to wc -l , which counts the number of lines received from ls and prints that to the terminal. [ user@host ~ ] $ ls | wc -l In this pipeline, head will output the first 10 lines of output from ls -t , with the final result redirected to a file. [ user@host ~ ] $ ls -t | head -n 10 > /tmp/ten-last-changed-files Pipelines, Redirection, and the tee Command When redirection is combined with a pipeline, the shell sets up the entire pipeline first, then it redirects input/output. If output redirection is used in the middle of a pipeline, the output will go to the file and not to the next command in the pipeline. In this example, the output of the ls command goes to the file, and less displays nothing on the terminal. [ user@host ~ ] $ ls > /tmp/saved-output | less The tee command overcomes this limitation. In a pipeline, tee copies its standard input to its standard output and also redirects its standard output to the files named as arguments to the command. If you imagine data as water flowing through a pipeline, tee can be visualized as a \"T\" joint in the pipe which directs output in two directions. Pipeline Examples Using the tee Command This example redirects the output of the ls command to the file and passes it to less to be displayed on the terminal one screen at a time. [ user@host ~ ] $ ls -l | tee /tmp/saved-output | less If tee is used at the end of a pipeline, then the final output of a command can be saved and output to the terminal at the same time. [ user@host ~ ] $ ls -t | head -n 10 | tee /tmp/ten-last-changed-files IMPORTANT Standard error can be redirected through a pipe, but the merging redirection operators ( &> and &>> ) cannot be used to do this. The following is the correct way to redirect both standard output and standard error through a pipe: [ user@host ~ ] $ find -name / passwd 2 > & 1 | less EDITING TEXT FILES FROM THE SHELL PROMPT \u00b6 EDITING FILES WITH VIM \u00b6 A key design principle of Linux is that information and configuration settings are commonly stored in text-based files. These files can be structured in various ways, as lists of settings, in INI-like formats, as structured XML or YAML, and so on. However, the advantage of text files is that they can be viewed and edited using any simple text editor. Vim is an improved version of the vi editor distributed with Linux and UNIX systems. Vim is highly configurable and efficient for practiced users, including such features as split screen editing, color formatting, and highlighting for editing text. Why Learn Vim? You should know how to use at least one text editor that can be used from a text-only shell prompt. If you do, you can edit text-based configuration files from a terminal window, or from remote logins through ssh or the Web Console. Then you do not need access to a graphical desktop in order to edit files on a server, and in fact that server might not need to run a graphical desktop environment at all. But then, why learn Vim instead of other possible options? The key reason is that Vim is almost always installed on a server, if any text editor is present. This is because vi was specified by the POSIX standard that Linux and many other UNIX-like operating systems comply with in large part. In addition, Vim is often used as the vi implementation on other common operating systems or distributions. For example, macOS currently includes a lightweight installation of Vim by default. So Vim skills learned for Linux might also help you get things done elsewhere. Starting Vim Vim may be installed in Red Hat Enterprise Linux in two different ways. This can affect the features and Vim commands available to you. Your server might only have the vim-minimal package installed. This is a very lightweight installation that includes only the core feature set and the basic vi command. In this case, you can open a file for editing with vi filename , and all the core features discussed in this section will be available to you. Alternatively, your server might have the vim-enhanced package installed. This provides a much more comprehensive set of features, an on-line help system, and a tutorial program. In order to start Vim in this enhanced mode, you use the vim command. [ user@host ~ ] $ vim filename Either way, the core features that we will discuss in this section will work with both commands. NOTE If vim-enhanced is installed, regular users will have a shell alias set so that if they run the vi command, they will automatically get the vim command instead. This does not apply to root and other users with UIDs below 200 (which are used by system services). If you are editing files as the root user and you expect vi to run in enhanced mode, this can be a surprise. Likewise, if vim-enhanced is installed and a regular user wants the simple vi for some reason, they might need to use \\vi to override the alias temporarily. Advanced users can use \\vi --version and vim --version to compare the feature sets of the two commands. Vim Operating Modes An unusual characteristic of Vim is that it has several modes of operation, including command mode, extended command mode, edit mode , and visual mode . Depending on the mode, you may be issuing commands, editing text, or working with blocks of text. As a new Vim user, you should always be aware of your current mode as keystrokes have different effects in different modes. When you first open Vim, it starts in command mode, which is used for navigation, cut and paste, and other text manipulation. Enter each of the other modes with single character keystrokes to access specific editing functionality: An i keystroke enters insert mode, where all text typed becomes file content. Pressing Esc returns to command mode. A v keystroke enters visual mode, where multiple characters may be selected for text manipulation. Use Shift+V for multiline and Ctrl+V for block selection. The same keystroke used to enter visual mode ( v, Shift+V or Ctrl+V ) is used to exit. The : keystroke begins extended command mode for tasks such as writing the file (to save it), and quitting the Vim editor. NOTE If you are not sure what mode Vim is in, you can try pressing Esc a few times to get back into command mode. Pressing Esc in command mode is harmless, so a few extra key presses are okay. The Minimum, Basic Vim Workflow Vim has efficient, coordinated keystrokes for advanced editing tasks. Although considered useful with practice, Vim's capabilities can overwhelm new users. The i key puts Vim into insert mode. All text entered after this is treated as file contents until you exit insert mode. The Esc key exits insert mode and returns Vim to command mode. The u key will undo the most recent edit. Press the x key to delete a single character. The :w command writes (saves) the file and remains in command mode for more editing. The :wq command writes (saves) the file and quits Vim. The :q! command quits Vim, discarding all file changes since the last write. The Vim user must learn these commands to accomplish any editing task. Rearranging Existing Text In Vim, copy and paste is known as yank and put, using command characters Y and P . Begin by positioning the cursor on the first character to be selected, and then enter visual mode. Use the arrow keys to expand the visual selection. When ready, press y to yank the selection into memory. Position the cursor at the new location, and then press p to put the selection at the cursor. Visual Mode in Vim Visual mode is a great way to highlight and manipulate text. There are three keystrokes: Character mode: v Line mode: Shift+V Block mode: Ctrl+V Character mode highlights sentences in a block of text. The word VISUAL will appear at the bottom of the screen. Press v to enter visual character mode. Shift+V enters line mode. VISUAL LINE will appear at the bottom of the screen. Visual block mode is perfect for manipulating data files. From the cursor, press the Ctrl+V to enter visual block. VISUAL BLOCK will appear at the bottom of the screen. Use the arrow keys to highlight the section to change. NOTE Vim has a lot of capabilities, but you should master the basic workflow first. You do not need to quickly understand the entire editor and its capabilities. Get comfortable with those basics through practice and then you can expand your Vim vocabulary by learning additional Vim commands (keystrokes). The exercise for this section will introduce you to the vimtutor command. This tutorial, which ships with vim-enhanced, is an excellent way to learn the core functionality of Vim. CHANGING THE SHELL ENVIRONMENT \u00b6 USING SHELL VARIABLES \u00b6 The Bash shell allows you to set shell variables that you can use to help run commands or to modify the behavior of the shell. You can also export shell variables as environment variables, which are automatically copied to programs run from that shell when they start. You can use variables to help make it easier to run a command with a long argument, or to apply a common setting to commands run from that shell. Shell variables are unique to a particular shell session. If you have two terminal windows open, or two independent login sessions to the same remote server, you are running two shells. Each shell has its own set of values for its shell variables. Assigning Values to Variables Assign a value to a shell variable using the following syntax: VARIABLENAME=value Variable names can contain uppercase or lowercase letters, digits, and the underscore character (_). For example, the following commands set shell variables: [ user@host ~ ] $ COUNT = 40 [ user@host ~ ] $ first_name = John [ user@host ~ ] $ file1 = /tmp/abc [ user@host ~ ] $ _ID = RH123 Remember, this change only affects the shell in which you run the command, not any other shells you may be running on that server. You can use the set command to list all shell variables that are currently set. (It also lists all shell functions, which you can ignore.) This list is long enough that you may want to pipe the output into the less command so that you can view it one page at a time. [ user@host ~ ] $ set | less BASH = /usr/bin/bash BASHOPTS = checkwinsize:cmdhist:complete_fullquote:expand_aliases:extglob:extquote: force_fignore:histappend:interactive_comments:progcomp:promptvars:sourcepath BASHRCSOURCED = Y ...output omitted... Retrieving Values with Variable Expansion You can use variable expansion to refer to the value of a variable that you have set. To do this, precede the name of the variable with a dollar sign ($). In the following example, the echo command prints out the rest of the command line entered, but after variable expansion is performed. For example, the following command sets the variable COUNT to 40. [ user@host ~ ] $ COUNT = 40 If you enter the command echo COUNT, it will print out the string COUNT. [ user@host ~ ] $ echo COUNT COUNT But if you enter the command echo $COUNT , it will print out the value of the variable COUNT. [ user@host ~ ] $ echo $COUNT 40 A more practical example might be to use a variable to refer to a long file name for multiple commands. [ user@host ~ ] $ file1 = /tmp/tmp.z9pXW0HqcC [ user@host ~ ] $ ls -l $file1 -rw-------. 1 student student 1452 Jan 22 14 :39 /tmp/tmp.z9pXW0HqcC [ user@host ~ ] $ rm $file1 [ user@host ~ ] $ ls -l $file1 total 0 IMPORTANT If there are any trailing characters adjacent to the variable name, you might need to protect the variable name with curly braces. You can always use curly braces in variable expansion, but you will also see many examples in which they are not needed and are omitted. In the following example, the first echo command tries to expand the nonexistent variable COUNTx, which does not cause an error but instead returns nothing. [ user@host ~ ] $ echo Repeat $COUNTx Repeat [ user@host ~ ] $ echo Repeat ${ COUNT } x Repeat 40x Configuring Bash with Shell Variables Some shell variables are set when Bash starts but can be modified to adjust the shell's behavior. For example, two shell variables that affect the shell history and the history command are HISTFILE and HISTFILESIZE. If HISTFILE is set, it specifies the location of a file to save the shell history in when it exits. By default this is the user's ~/.bash_history file. The HISTFILESIZE variable specifies how many commands should be saved in that file from the history. Another example is PS1, which is a shell variable that controls the appearance of the shell prompt. If you change this value, it will change the appearance of your shell prompt. A number of special character expansions supported by the prompt are listed in the \"PROMPTING\" section of the bash(1) man page. [ user@host ~ ] $ PS1 = \"bash\\$ \" bash$ PS1 = \"[\\u@\\h \\W]\\$ \" [ user@host ~ ] $ Two items to note about the above example: first, because the value set by PS1 is a prompt, it is virtually always desirable to end the prompt with a trailing space. Second, whenever the value of a variable contains some form of space, including a space, a tab, or a return, the value must be surrounded by quotes, either single or double; this is not optional. Unexpected results will occur if the quotes are omitted. Examine the PS1 example above and note that it conforms to both the recommendation (trailing space) and the rule (quotes). CONFIGURING PROGRAMS WITH ENVIRONMENT VARIABLES \u00b6 The shell provides an environment to the programs you run from that shell. Among other things, this environment includes information on the current working directory on the file system, the command-line options passed to the program, and the values of environment variables . The programs may use these environment variables to change their behavior or their default settings. Shell variables that are not environment variables can only be used by the shell. Environment variables can be used by the shell and by programs run from that shell. NOTE HISTFILE, HISTFILESIZE, and PS1, learned in the previous section, do not need to be exported as environment variables because they are only used by the shell itself, not by the programs that you run from the shell. You can make any variable defined in the shell into an environment variable by marking it for export with the export command. [ user@host ~ ] $ EDITOR = vim [ user@host ~ ] $ export EDITOR You can set and export a variable in one step: [ user@host ~ ] $ export EDITOR = vim Applications and sessions use these variables to determine their behavior. For example, the shell automatically sets the HOME variable to the file name of the user's home directory when it starts. This can be used to help programs determine where to save files. Another example is LANG, which sets the locale. This adjusts the preferred language for program output; the character set; the formatting of dates, numbers, and currency; and the sort order for programs. If it is set to en_US.UTF-8 , the locale will use US English with UTF-8 Unicode character encoding. If it is set to something else, for example fr_FR.UTF-8 , it will use French UTF-8 Unicode encoding. [ user@host ~ ] $ date Tue Jan 22 16 :37:45 CST 2019 [ user@host ~ ] $ export LANG = fr_FR.UTF-8 [ user@host ~ ] $ date mar. janv. 22 16 :38:14 CST 2019 Another important environment variable is PATH. The PATH variable contains a list of colon- separated directories that contain programs: [ user@host ~ ] $ echo $PATH /home/user/.local/bin:/home/user/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/ bin:/usr/local/sbin:/usr/sbin When you run a command such as ls , the shell looks for the executable file ls in each of those directories in order, and runs the first matching file it finds. (On a typical system, this is /usr/ bin/ls.) You can easily add additional directories to the end of your PATH. For example, perhaps you have executable programs or scripts that you want to run like regular commands in /home/user/sbin . You can add /home/user/sbin to the end of your PATH for the current session like this: [ user@host ~ ] $ export PATH = ${ PATH } :/home/user/sbin To list all the environment variables for a particular shell, run the env command: [ user@host ~ ] $ env ...output omitted... LANG = en_US.UTF-8 HISTCONTROL = ignoredups HOSTNAME = host.example.com XDG_SESSION_ID = 4 ...output omitted... Setting the Default Text Editor The EDITOR environment variable specifies the program you want to use as your default text editor for command-line programs. Many programs use vi or vim if it is not specified, but you can override this preference if required: [ user@host ~ ] $ export EDITOR = nano IMPORTANT By convention, environment variables and shell variables that are automatically set by the shell have names that use all uppercase characters. If you are setting your own variables, you may want to use names made up of lowercase characters to help avoid naming collisions. SETTING VARIABLES AUTOMATICALLY \u00b6 If you want to set shell or environment variables automatically when your shell starts, you can edit the Bash startup scripts. When Bash starts, several text files containing shell commands are run which initialize the shell environment. The exact scripts that run depend on how the shell was started, whether it is an interactive login shell, an interactive non-login shell, or a shell script. Assuming the default /etc/profile , /etc/bashrc , and ~/.bash_profile files, if you want to make a change to your user account that affects all your interactive shell prompts at startup, edit your ~/.bashrc file. For example, you could set that account's default editor to nano by editing the file to read: # .bashrc # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific environment PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\" export PATH # User specific aliases and functions export EDITOR=nano NOTE The best way to adjust settings that affect all user accounts is by adding a file with a name ending in .sh containing the changes to the /etc/profile.d directory. To do this, you need to be logged in as the root user. UNSETTING AND UNEXPORTING VARIABLES \u00b6 To unset and unexport a variable entirely, use the unset command: [ user@host ~ ] $ echo $file1 /tmp/tmp.z9pXW0HqcC [ user@host ~ ] $ unset file1 [ user@host ~ ] $ echo $file1 [ user@host ~ ] $ To unexport a variable without unsetting it, use the export -n command: [ user@host ~ ] $ export -n PS1 SUMMARY \u00b6 In this chapter, you learned: Running programs, or processes, have three standard communication channels, standard input, standard output, and standard error. You can use I/O redirection to read standard input from a file or write the output or errors from a process to a file. Pipelines can be used to connect standard output from one process to standard input of another process, and can be used to format output or build complex commands. You should know how to use at least one command-line text editor, and Vim is generally installed. Shell variables can help you run commands and are unique to a particular shell session. Environment variables can help you configure the behavior of the shell or the processes it starts.","title":"Creating, Viewing, And Editing Text Files"},{"location":"redhat/edit/#redirecting-output-to-a-file-or-program","text":"","title":"REDIRECTING OUTPUT TO A FILE OR PROGRAM"},{"location":"redhat/edit/#standard-input-standard-output-and-standard-error","text":"A running program, or process , needs to read input from somewhere and write output to somewhere. A command run from the shell prompt normally reads its input from the keyboard and sends its output to its terminal window. A process uses numbered channels called file descriptors to get input and send output. All processes start with at least three file descriptors. Standard input (channel 0) reads input from the keyboard. Standard output (channel 1) sends normal output to the terminal. Standard error (channel 2) sends error messages to the terminal. If a program opens separate connections to other files, it may use higher-numbered file descriptors. Channels (File Descriptors) NUMBER CHANNEL NAME DESCRIPTION DEFAULT CONNECTION USAGE 0 stdin Standard input Keyboard read only 1 stdout Standard output Terminal write only 2 stderr Standard error Terminal write only 3+ filename Other files none read and/or write","title":"STANDARD INPUT, STANDARD OUTPUT, AND STANDARD ERROR"},{"location":"redhat/edit/#redirecting-output-to-a-file","text":"I/O redirection changes how the process gets its input or output. Instead of getting input from the keyboard, or sending output and errors to the terminal, the process reads from or writes to files. Redirection lets you save messages to a file that are normally sent to the terminal window. Alternatively, you can use redirection to discard output or errors, so they are not displayed on the terminal or saved. Redirecting stdout suppresses process output from appearing on the terminal. As seen in the following table, redirecting only stdout does not suppress stderr error messages from displaying on the terminal. If the file does not exist, it will be created. If the file does exist and the redirection is not one that appends to the file, the file's contents will be overwritten. If you want to discard messages, the special file /dev/null quietly discards channel output redirected to it and is always an empty file. USAGE EXPLANATION > file redirect stdout to overwrite a file >> file redirect stdout to append to a file 2> file redirect stderr to overwrite a file 2> /dev/null stderr error messages by redirecting to /dev/null > file 2>&1 redirect stdout and stderr to overwrite the same file &> file redirect stdout and stderr to overwrite the same file >> file 2>&1 redirect stdout and stderr to append to the same file &>> file redirect stdout and stderr to append to the same file IMPORTANT The order of redirection operations is important. The following sequence redirects standard output to file and then redirects standard error to the same place as standard output (file). > file 2>&1 However, the next sequence does redirection in the opposite order. This redirects standard error to the default place for standard output (the terminal window, so no change) and then redirects only standard output to file. 2>&1 > file Because of this, some people prefer to use the merging redirection operators: &>file instead of >file 2>&1 &>>file instead of >>file 2>&1(in Bash 4 / RHEL 6 and later) However, other system administrators and programmers who also use other shells related to bash (known as Bourne-compatible shells) for scripting commands think that the newer merging redirection operators should be avoided, because they are not standardized or implemented in all of those shells and have other limitations. The authors of this course take a neutral stance on this topic, and both syntaxes are likely to be encountered in the field. Examples for Output Redirection Many routine administration tasks are simplified by using redirection. Use the previous table to assist while considering the following examples: Save a time stamp for later reference. [ user@host ~ ] $ date > /tmp/saved-timestamp Copy the last 100 lines from a log file to another file. [ user@host ~ ] $ tail -n 100 /var/log/dmesg > /tmp/last-100-boot-messages Concatenate four files into one. [ user@host ~ ] $ cat file1 file2 file3 file4 > /tmp/all-four-in-one List the home directory's hidden and regular file names into a file. [ user@host ~ ] $ ls -a > /tmp/my-file-names Append output to an existing file. [ user@host ~ ] $ echo \"new line of information\" >> /tmp/many-lines-of-information [ user@host ~ ] $ diff previous-file current-file >> /tmp/tracking-changes-made The next few commands generate error messages because some system directories are inaccessible to normal users. Observe as the error messages are redirected. Redirect errors to a file while viewing normal command output on the terminal. [user@host ~]$ find /etc -name passwd 2> /tmp/errors Save process output and error messages to separate files. [ user@host ~ ] $ find /etc -name passwd > /tmp/output 2 > /tmp/errors Ignore and discard error messages. [ user@host ~ ] $ find /etc -name passwd > /tmp/output 2 > /dev/null Store output and generated errors together. [ user@host ~ ] $ find /etc -name passwd & > /tmp/save-both Append output and generated errors to an existing file. [ user@host ~ ] $ find /etc -name passwd >> /tmp/save-both 2 > & 1","title":"REDIRECTING OUTPUT TO A FILE"},{"location":"redhat/edit/#constructing-pipelines","text":"A pipeline is a sequence of one or more commands separated by the pipe character (|). A pipe connects the standard output of the first command to the standard input of the next command. Pipelines allow the output of a process to be manipulated and formatted by other processes before it is output to the terminal. One useful mental image is to imagine that data is \"flowing\" through the pipeline from one process to another, being altered slightly by each command in the pipeline through which it flows. NOTE Pipelines and I/O redirection both manipulate standard output and standard input. Redirection sends standard output to files or gets standard input from files. Pipes send the standard output from one process to the standard input of another process. Pipeline Examples This example takes the output of the ls command and uses less to display it on the terminal one screen at a time. [ user@host ~ ] $ ls -l /usr/bin | less The output of the ls command is piped to wc -l , which counts the number of lines received from ls and prints that to the terminal. [ user@host ~ ] $ ls | wc -l In this pipeline, head will output the first 10 lines of output from ls -t , with the final result redirected to a file. [ user@host ~ ] $ ls -t | head -n 10 > /tmp/ten-last-changed-files Pipelines, Redirection, and the tee Command When redirection is combined with a pipeline, the shell sets up the entire pipeline first, then it redirects input/output. If output redirection is used in the middle of a pipeline, the output will go to the file and not to the next command in the pipeline. In this example, the output of the ls command goes to the file, and less displays nothing on the terminal. [ user@host ~ ] $ ls > /tmp/saved-output | less The tee command overcomes this limitation. In a pipeline, tee copies its standard input to its standard output and also redirects its standard output to the files named as arguments to the command. If you imagine data as water flowing through a pipeline, tee can be visualized as a \"T\" joint in the pipe which directs output in two directions. Pipeline Examples Using the tee Command This example redirects the output of the ls command to the file and passes it to less to be displayed on the terminal one screen at a time. [ user@host ~ ] $ ls -l | tee /tmp/saved-output | less If tee is used at the end of a pipeline, then the final output of a command can be saved and output to the terminal at the same time. [ user@host ~ ] $ ls -t | head -n 10 | tee /tmp/ten-last-changed-files IMPORTANT Standard error can be redirected through a pipe, but the merging redirection operators ( &> and &>> ) cannot be used to do this. The following is the correct way to redirect both standard output and standard error through a pipe: [ user@host ~ ] $ find -name / passwd 2 > & 1 | less","title":"CONSTRUCTING PIPELINES"},{"location":"redhat/edit/#editing-text-files-from-the-shell-prompt","text":"","title":"EDITING TEXT FILES FROM THE SHELL PROMPT"},{"location":"redhat/edit/#editing-files-with-vim","text":"A key design principle of Linux is that information and configuration settings are commonly stored in text-based files. These files can be structured in various ways, as lists of settings, in INI-like formats, as structured XML or YAML, and so on. However, the advantage of text files is that they can be viewed and edited using any simple text editor. Vim is an improved version of the vi editor distributed with Linux and UNIX systems. Vim is highly configurable and efficient for practiced users, including such features as split screen editing, color formatting, and highlighting for editing text. Why Learn Vim? You should know how to use at least one text editor that can be used from a text-only shell prompt. If you do, you can edit text-based configuration files from a terminal window, or from remote logins through ssh or the Web Console. Then you do not need access to a graphical desktop in order to edit files on a server, and in fact that server might not need to run a graphical desktop environment at all. But then, why learn Vim instead of other possible options? The key reason is that Vim is almost always installed on a server, if any text editor is present. This is because vi was specified by the POSIX standard that Linux and many other UNIX-like operating systems comply with in large part. In addition, Vim is often used as the vi implementation on other common operating systems or distributions. For example, macOS currently includes a lightweight installation of Vim by default. So Vim skills learned for Linux might also help you get things done elsewhere. Starting Vim Vim may be installed in Red Hat Enterprise Linux in two different ways. This can affect the features and Vim commands available to you. Your server might only have the vim-minimal package installed. This is a very lightweight installation that includes only the core feature set and the basic vi command. In this case, you can open a file for editing with vi filename , and all the core features discussed in this section will be available to you. Alternatively, your server might have the vim-enhanced package installed. This provides a much more comprehensive set of features, an on-line help system, and a tutorial program. In order to start Vim in this enhanced mode, you use the vim command. [ user@host ~ ] $ vim filename Either way, the core features that we will discuss in this section will work with both commands. NOTE If vim-enhanced is installed, regular users will have a shell alias set so that if they run the vi command, they will automatically get the vim command instead. This does not apply to root and other users with UIDs below 200 (which are used by system services). If you are editing files as the root user and you expect vi to run in enhanced mode, this can be a surprise. Likewise, if vim-enhanced is installed and a regular user wants the simple vi for some reason, they might need to use \\vi to override the alias temporarily. Advanced users can use \\vi --version and vim --version to compare the feature sets of the two commands. Vim Operating Modes An unusual characteristic of Vim is that it has several modes of operation, including command mode, extended command mode, edit mode , and visual mode . Depending on the mode, you may be issuing commands, editing text, or working with blocks of text. As a new Vim user, you should always be aware of your current mode as keystrokes have different effects in different modes. When you first open Vim, it starts in command mode, which is used for navigation, cut and paste, and other text manipulation. Enter each of the other modes with single character keystrokes to access specific editing functionality: An i keystroke enters insert mode, where all text typed becomes file content. Pressing Esc returns to command mode. A v keystroke enters visual mode, where multiple characters may be selected for text manipulation. Use Shift+V for multiline and Ctrl+V for block selection. The same keystroke used to enter visual mode ( v, Shift+V or Ctrl+V ) is used to exit. The : keystroke begins extended command mode for tasks such as writing the file (to save it), and quitting the Vim editor. NOTE If you are not sure what mode Vim is in, you can try pressing Esc a few times to get back into command mode. Pressing Esc in command mode is harmless, so a few extra key presses are okay. The Minimum, Basic Vim Workflow Vim has efficient, coordinated keystrokes for advanced editing tasks. Although considered useful with practice, Vim's capabilities can overwhelm new users. The i key puts Vim into insert mode. All text entered after this is treated as file contents until you exit insert mode. The Esc key exits insert mode and returns Vim to command mode. The u key will undo the most recent edit. Press the x key to delete a single character. The :w command writes (saves) the file and remains in command mode for more editing. The :wq command writes (saves) the file and quits Vim. The :q! command quits Vim, discarding all file changes since the last write. The Vim user must learn these commands to accomplish any editing task. Rearranging Existing Text In Vim, copy and paste is known as yank and put, using command characters Y and P . Begin by positioning the cursor on the first character to be selected, and then enter visual mode. Use the arrow keys to expand the visual selection. When ready, press y to yank the selection into memory. Position the cursor at the new location, and then press p to put the selection at the cursor. Visual Mode in Vim Visual mode is a great way to highlight and manipulate text. There are three keystrokes: Character mode: v Line mode: Shift+V Block mode: Ctrl+V Character mode highlights sentences in a block of text. The word VISUAL will appear at the bottom of the screen. Press v to enter visual character mode. Shift+V enters line mode. VISUAL LINE will appear at the bottom of the screen. Visual block mode is perfect for manipulating data files. From the cursor, press the Ctrl+V to enter visual block. VISUAL BLOCK will appear at the bottom of the screen. Use the arrow keys to highlight the section to change. NOTE Vim has a lot of capabilities, but you should master the basic workflow first. You do not need to quickly understand the entire editor and its capabilities. Get comfortable with those basics through practice and then you can expand your Vim vocabulary by learning additional Vim commands (keystrokes). The exercise for this section will introduce you to the vimtutor command. This tutorial, which ships with vim-enhanced, is an excellent way to learn the core functionality of Vim.","title":"EDITING FILES WITH VIM"},{"location":"redhat/edit/#changing-the-shell-environment","text":"","title":"CHANGING THE SHELL ENVIRONMENT"},{"location":"redhat/edit/#using-shell-variables","text":"The Bash shell allows you to set shell variables that you can use to help run commands or to modify the behavior of the shell. You can also export shell variables as environment variables, which are automatically copied to programs run from that shell when they start. You can use variables to help make it easier to run a command with a long argument, or to apply a common setting to commands run from that shell. Shell variables are unique to a particular shell session. If you have two terminal windows open, or two independent login sessions to the same remote server, you are running two shells. Each shell has its own set of values for its shell variables. Assigning Values to Variables Assign a value to a shell variable using the following syntax: VARIABLENAME=value Variable names can contain uppercase or lowercase letters, digits, and the underscore character (_). For example, the following commands set shell variables: [ user@host ~ ] $ COUNT = 40 [ user@host ~ ] $ first_name = John [ user@host ~ ] $ file1 = /tmp/abc [ user@host ~ ] $ _ID = RH123 Remember, this change only affects the shell in which you run the command, not any other shells you may be running on that server. You can use the set command to list all shell variables that are currently set. (It also lists all shell functions, which you can ignore.) This list is long enough that you may want to pipe the output into the less command so that you can view it one page at a time. [ user@host ~ ] $ set | less BASH = /usr/bin/bash BASHOPTS = checkwinsize:cmdhist:complete_fullquote:expand_aliases:extglob:extquote: force_fignore:histappend:interactive_comments:progcomp:promptvars:sourcepath BASHRCSOURCED = Y ...output omitted... Retrieving Values with Variable Expansion You can use variable expansion to refer to the value of a variable that you have set. To do this, precede the name of the variable with a dollar sign ($). In the following example, the echo command prints out the rest of the command line entered, but after variable expansion is performed. For example, the following command sets the variable COUNT to 40. [ user@host ~ ] $ COUNT = 40 If you enter the command echo COUNT, it will print out the string COUNT. [ user@host ~ ] $ echo COUNT COUNT But if you enter the command echo $COUNT , it will print out the value of the variable COUNT. [ user@host ~ ] $ echo $COUNT 40 A more practical example might be to use a variable to refer to a long file name for multiple commands. [ user@host ~ ] $ file1 = /tmp/tmp.z9pXW0HqcC [ user@host ~ ] $ ls -l $file1 -rw-------. 1 student student 1452 Jan 22 14 :39 /tmp/tmp.z9pXW0HqcC [ user@host ~ ] $ rm $file1 [ user@host ~ ] $ ls -l $file1 total 0 IMPORTANT If there are any trailing characters adjacent to the variable name, you might need to protect the variable name with curly braces. You can always use curly braces in variable expansion, but you will also see many examples in which they are not needed and are omitted. In the following example, the first echo command tries to expand the nonexistent variable COUNTx, which does not cause an error but instead returns nothing. [ user@host ~ ] $ echo Repeat $COUNTx Repeat [ user@host ~ ] $ echo Repeat ${ COUNT } x Repeat 40x Configuring Bash with Shell Variables Some shell variables are set when Bash starts but can be modified to adjust the shell's behavior. For example, two shell variables that affect the shell history and the history command are HISTFILE and HISTFILESIZE. If HISTFILE is set, it specifies the location of a file to save the shell history in when it exits. By default this is the user's ~/.bash_history file. The HISTFILESIZE variable specifies how many commands should be saved in that file from the history. Another example is PS1, which is a shell variable that controls the appearance of the shell prompt. If you change this value, it will change the appearance of your shell prompt. A number of special character expansions supported by the prompt are listed in the \"PROMPTING\" section of the bash(1) man page. [ user@host ~ ] $ PS1 = \"bash\\$ \" bash$ PS1 = \"[\\u@\\h \\W]\\$ \" [ user@host ~ ] $ Two items to note about the above example: first, because the value set by PS1 is a prompt, it is virtually always desirable to end the prompt with a trailing space. Second, whenever the value of a variable contains some form of space, including a space, a tab, or a return, the value must be surrounded by quotes, either single or double; this is not optional. Unexpected results will occur if the quotes are omitted. Examine the PS1 example above and note that it conforms to both the recommendation (trailing space) and the rule (quotes).","title":"USING SHELL VARIABLES"},{"location":"redhat/edit/#configuring-programs-with-environment-variables","text":"The shell provides an environment to the programs you run from that shell. Among other things, this environment includes information on the current working directory on the file system, the command-line options passed to the program, and the values of environment variables . The programs may use these environment variables to change their behavior or their default settings. Shell variables that are not environment variables can only be used by the shell. Environment variables can be used by the shell and by programs run from that shell. NOTE HISTFILE, HISTFILESIZE, and PS1, learned in the previous section, do not need to be exported as environment variables because they are only used by the shell itself, not by the programs that you run from the shell. You can make any variable defined in the shell into an environment variable by marking it for export with the export command. [ user@host ~ ] $ EDITOR = vim [ user@host ~ ] $ export EDITOR You can set and export a variable in one step: [ user@host ~ ] $ export EDITOR = vim Applications and sessions use these variables to determine their behavior. For example, the shell automatically sets the HOME variable to the file name of the user's home directory when it starts. This can be used to help programs determine where to save files. Another example is LANG, which sets the locale. This adjusts the preferred language for program output; the character set; the formatting of dates, numbers, and currency; and the sort order for programs. If it is set to en_US.UTF-8 , the locale will use US English with UTF-8 Unicode character encoding. If it is set to something else, for example fr_FR.UTF-8 , it will use French UTF-8 Unicode encoding. [ user@host ~ ] $ date Tue Jan 22 16 :37:45 CST 2019 [ user@host ~ ] $ export LANG = fr_FR.UTF-8 [ user@host ~ ] $ date mar. janv. 22 16 :38:14 CST 2019 Another important environment variable is PATH. The PATH variable contains a list of colon- separated directories that contain programs: [ user@host ~ ] $ echo $PATH /home/user/.local/bin:/home/user/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/ bin:/usr/local/sbin:/usr/sbin When you run a command such as ls , the shell looks for the executable file ls in each of those directories in order, and runs the first matching file it finds. (On a typical system, this is /usr/ bin/ls.) You can easily add additional directories to the end of your PATH. For example, perhaps you have executable programs or scripts that you want to run like regular commands in /home/user/sbin . You can add /home/user/sbin to the end of your PATH for the current session like this: [ user@host ~ ] $ export PATH = ${ PATH } :/home/user/sbin To list all the environment variables for a particular shell, run the env command: [ user@host ~ ] $ env ...output omitted... LANG = en_US.UTF-8 HISTCONTROL = ignoredups HOSTNAME = host.example.com XDG_SESSION_ID = 4 ...output omitted... Setting the Default Text Editor The EDITOR environment variable specifies the program you want to use as your default text editor for command-line programs. Many programs use vi or vim if it is not specified, but you can override this preference if required: [ user@host ~ ] $ export EDITOR = nano IMPORTANT By convention, environment variables and shell variables that are automatically set by the shell have names that use all uppercase characters. If you are setting your own variables, you may want to use names made up of lowercase characters to help avoid naming collisions.","title":"CONFIGURING PROGRAMS WITH ENVIRONMENT VARIABLES"},{"location":"redhat/edit/#setting-variables-automatically","text":"If you want to set shell or environment variables automatically when your shell starts, you can edit the Bash startup scripts. When Bash starts, several text files containing shell commands are run which initialize the shell environment. The exact scripts that run depend on how the shell was started, whether it is an interactive login shell, an interactive non-login shell, or a shell script. Assuming the default /etc/profile , /etc/bashrc , and ~/.bash_profile files, if you want to make a change to your user account that affects all your interactive shell prompts at startup, edit your ~/.bashrc file. For example, you could set that account's default editor to nano by editing the file to read: # .bashrc # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific environment PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\" export PATH # User specific aliases and functions export EDITOR=nano NOTE The best way to adjust settings that affect all user accounts is by adding a file with a name ending in .sh containing the changes to the /etc/profile.d directory. To do this, you need to be logged in as the root user.","title":"SETTING VARIABLES AUTOMATICALLY"},{"location":"redhat/edit/#unsetting-and-unexporting-variables","text":"To unset and unexport a variable entirely, use the unset command: [ user@host ~ ] $ echo $file1 /tmp/tmp.z9pXW0HqcC [ user@host ~ ] $ unset file1 [ user@host ~ ] $ echo $file1 [ user@host ~ ] $ To unexport a variable without unsetting it, use the export -n command: [ user@host ~ ] $ export -n PS1","title":"UNSETTING AND UNEXPORTING VARIABLES"},{"location":"redhat/edit/#summary","text":"In this chapter, you learned: Running programs, or processes, have three standard communication channels, standard input, standard output, and standard error. You can use I/O redirection to read standard input from a file or write the output or errors from a process to a file. Pipelines can be used to connect standard output from one process to standard input of another process, and can be used to format output or build complex commands. You should know how to use at least one command-line text editor, and Vim is generally installed. Shell variables can help you run commands and are unique to a particular shell session. Environment variables can help you configure the behavior of the shell or the processes it starts.","title":"SUMMARY"},{"location":"redhat/help/","text":"READING MANUAL PAGES \u00b6 INTRODUCING THE MAN COMMAND \u00b6 One source of documentation that is generally available on the local system are system manual pages or man pages These pages are shipped as part of the software packages for which they provide documentation, and can be accessed from the command line by using the man command. The historical Linux Programmer's Manual, from which man pages originate, was large enough to be multiple printed sections. Each section contains information about a particular topic. Common Sections of the Linux Manual SECTION CONTENT TYPE 1 User commands (both executable and shell programs) 2 System calls (kernel routines invoked from user space) 3 Library functions (provided by program libraries) 4 Special files (such as device files) 5 File formats (for many configuration files and structures) 6 Games (historical section for amusing programs) 7 Conventions, standards, and miscellaneous (protocols, file systems) 8 System administration and privileged commands (maintenance tasks) 9 Linux kernel API (internal kernel calls) To distinguish identical topic names in different sections, man page references include the section number in parentheses after the topic. For example, passwd (1) describes the command to change passwords, while passwd (5) explains the /etc/passwd file format for storing local user accounts. To read specific man pages, use man topic . Contents are displayed one screen at a time. The man command searches manual sections in alphanumeric order. For example, man passwd displays passwd(1) by default. To display the man page topic from a specific section, include the section number argument: man 5 passwd displays passwd(5). NAVIGATE AND SEARCH MAN PAGES \u00b6 The ability to efficiently search for topics and navigate man pages is a critical administration skill. GUI tools make it easy to configure common system resources, but using the command-line interface is still more efficient. To effectively navigate the command line, you must be able to find the information you need in man pages. The following table lists basic navigation commands when viewing man pages: Navigating Man Pages COMMAND RESULT Spacebar Scroll forward (down) one screen PageDown Scroll forward (down) one screen PageUp Scroll backward (up) one screen DownArrow Scroll forward (down) one line UpArrow Scroll backward (up) one line D Scroll forward (down) one half-screen U Scroll backward (up) one half-screen /string Search forward (down) for string in the man page N Repeat previous search forward (down) in the man page Shift+N Repeat previous search backward (up) in the man page G Go to start of the man page. Shift+G Go to end of the man page. Q Exit man and return to the command shell prompt IMPORTANT When performing searches, string allows regular expression syntax. While simple text (such as passwd) works as expected, regular expressions use meta-characters (such as $, *, ., and ^) for more sophisticated pattern matching. Therefore, searching with strings that include program expression meta-characters, such as make $$$, might yield unexpected results. Regular expressions and syntax are discussed in Red Hat System Administration II, and in the regex(7) man topic. Reading Man Pages Each topic is separated into several parts. Most topics share the same headings and are presented in the same order. Typically a topic does not feature all headings, because not all headings apply for all topics. Common headings are: HEADING DESCRIPTION NAME Subject name. Usually a command or file name. Very brief description. SYNOPSIS Summary of the command syntax. DESCRIPTION In-depth description to provide a basic understanding of the topic. OPTIONS Explanation of the command execution options. EXAMPLES Examples of how to use the command, function, or file. FILES A list of files and directories related to the man page. SEE ALSO Related information, normally other man page topics. BUGS Known bugs in the software. AUTHOR Information about who has contributed to the development of the topic. SEARCHING FOR MAN PAGES BY KEYWORD \u00b6 A keyword search of man pages is performed with man -k keyword , which displays a list of keyword-matching man page topics with section numbers. [ student@desktopX ~ ] $ man -k passwd checkPasswdAccess ( 3 ) - query the SELinux policy database in the kernel. chpasswd ( 8 ) - update passwords in batch mode ckpasswd ( 8 ) - nnrpd password authenticator fgetpwent_r ( 3 ) - get passwd file entry reentrantly getpwent_r ( 3 ) - get passwd file entry reentrantly ... passwd ( 1 ) - update user ' s authentication tokens sslpasswd ( 1ssl ) - compute password hashes passwd ( 5 ) - password file passwd.nntp ( 5 ) - Passwords for connecting to remote NNTP servers passwd2des ( 3 ) - RFS password encryption ... Popular system administration topics are in sections 1 (user commands), 5 (file formats), and 8 (administrative commands). Administrators using certain troubleshooting tools also use section 2 (system calls). The remaining sections are generally for programmer reference or advanced administration. Note Keyword searches rely on an index generated by the mandb(8) command, which must be run as root. The command runs daily through cron.daily , or by anacrontab within an hour of boot, if out of date. IMPORTANT The man command -K (uppercase) option performs a full-text page search, not just titles and descriptions like the -k option. A full-text search uses greater system resources and take more time. READING INFO DOCUMENTATION \u00b6 INTRODUCING GNU INFO \u00b6 Man pages have a format useful as a command reference, but less useful as general documentation. For such documents, the GNU Project developed a different online documentation system, known as GNU Info . Info documents are an important resource on a Red Hat Enterprise Linux system because many fundamental components and utilities, such as the coreutils package and glibc standard libraries, are either developed by the GNU Project or utilize the Info document system. IMPORTANT You might wonder why there are two local documentation systems, man pages and Info documents. Some of the reasons for this are practical in nature, and some have to do with the way Linux and its applications have been developed by various open source communities over the years. Man pages have a much more formal format, and typically document a specific command or function from a software package, and are structured as individual text files. Info documents typically cover particular software packages as a whole, tend to have more practical examples of how to use the software, and are structured as hypertext documents. You should be familiar with both systems in order to take maximum advantage of the information available to you from the system. Reading Info Documentation To launch the Info document viewer, use the pinfo command. pinfo opens in the top directory. Info documentation is comprehensive and hyperlinked. It is possible to output info pages to multiple formats. By contrast, man pages are optimized for printed output. The Info format is more flexible than man pages, allowing thorough discussion of complex commands and concepts. Like man pages, Info nodes are read from the command line, using the pinfo command. A typical man page has a small amount of content focusing on one particular topic, command, tool, or file. The Info documentation is a comprehensive document. Info provides the following improvements: One single document for a large system containing all the necessary information for that system Hyperlinks A complete browsable document index A full text search of the entire document Some commands and utilities have both man pages and info documentation; usually, the Info documentation is more in depth. Compare the differences in tar documentation using man and pinfo : [ user@host ~ ] $ man tar [ user@host ~ ] $ pinfo tar The pinfo reader is more advanced than the original info command. To browse a specific topic, use the pinfo topic command. The pinfo command without an argument opens the top directory. New documentation becomes available in pinfo when their software packages are installed. NOTE If no Info topic exists in the system for a particular entry that you requested, Info will look for a matching man page and display that instead. COMPARING GNU INFO AND MAN PAGE NAVIGATION \u00b6 The pinfo command and the man command use slightly different navigational keystrokes. The following table compares the navigational keystrokes for both commands: pinfo and man, key binding comparison NAVIGATION PINFO MAN Scroll forward (down) one screen PageDown or Space PageDown or Space Scroll backward (up) one screen PageUp or b PageUp or b Display the directory of topics D - Scroll forward (down) one half-screen - D Display the parent node of a topic U - Display the top (up) of a topic HOME G Scroll backward (up) one half-screen - U Scroll forward (down) to next hyperlink DownArrow - Open topic at cursor location ENTER - Scroll forward (down) one line - DownArrow or Enter Scroll backward (up) to previous hyperlink UpArrow - Scroll backward (up) one line - UpArrow Search for a pattern /string /string Display next node (chapter) in topic N - Repeat previous search forward (down) / then Enter n Display previous node (chapter) in topic P - Repeat previous search backward (up) - ShiftN Quit the program Q Q SUMMARY \u00b6 In this chapter, you learned: Man pages are viewed with the man command and provide information on components of a Linux system, such as files, commands, and functions. By convention, when referring to a man page the name of a page is followed by its section number in parentheses. Info documents are viewed with the pinfo command and are made up of a collection of hypertext nodes, providing information about software packages as a whole. The navigational keystrokes used by man and pinfo are slightly different.","title":"Getting Help In Red Hat Enterprise Linux"},{"location":"redhat/help/#reading-manual-pages","text":"","title":"READING MANUAL PAGES"},{"location":"redhat/help/#introducing-the-man-command","text":"One source of documentation that is generally available on the local system are system manual pages or man pages These pages are shipped as part of the software packages for which they provide documentation, and can be accessed from the command line by using the man command. The historical Linux Programmer's Manual, from which man pages originate, was large enough to be multiple printed sections. Each section contains information about a particular topic. Common Sections of the Linux Manual SECTION CONTENT TYPE 1 User commands (both executable and shell programs) 2 System calls (kernel routines invoked from user space) 3 Library functions (provided by program libraries) 4 Special files (such as device files) 5 File formats (for many configuration files and structures) 6 Games (historical section for amusing programs) 7 Conventions, standards, and miscellaneous (protocols, file systems) 8 System administration and privileged commands (maintenance tasks) 9 Linux kernel API (internal kernel calls) To distinguish identical topic names in different sections, man page references include the section number in parentheses after the topic. For example, passwd (1) describes the command to change passwords, while passwd (5) explains the /etc/passwd file format for storing local user accounts. To read specific man pages, use man topic . Contents are displayed one screen at a time. The man command searches manual sections in alphanumeric order. For example, man passwd displays passwd(1) by default. To display the man page topic from a specific section, include the section number argument: man 5 passwd displays passwd(5).","title":"INTRODUCING THE MAN COMMAND"},{"location":"redhat/help/#navigate-and-search-man-pages","text":"The ability to efficiently search for topics and navigate man pages is a critical administration skill. GUI tools make it easy to configure common system resources, but using the command-line interface is still more efficient. To effectively navigate the command line, you must be able to find the information you need in man pages. The following table lists basic navigation commands when viewing man pages: Navigating Man Pages COMMAND RESULT Spacebar Scroll forward (down) one screen PageDown Scroll forward (down) one screen PageUp Scroll backward (up) one screen DownArrow Scroll forward (down) one line UpArrow Scroll backward (up) one line D Scroll forward (down) one half-screen U Scroll backward (up) one half-screen /string Search forward (down) for string in the man page N Repeat previous search forward (down) in the man page Shift+N Repeat previous search backward (up) in the man page G Go to start of the man page. Shift+G Go to end of the man page. Q Exit man and return to the command shell prompt IMPORTANT When performing searches, string allows regular expression syntax. While simple text (such as passwd) works as expected, regular expressions use meta-characters (such as $, *, ., and ^) for more sophisticated pattern matching. Therefore, searching with strings that include program expression meta-characters, such as make $$$, might yield unexpected results. Regular expressions and syntax are discussed in Red Hat System Administration II, and in the regex(7) man topic. Reading Man Pages Each topic is separated into several parts. Most topics share the same headings and are presented in the same order. Typically a topic does not feature all headings, because not all headings apply for all topics. Common headings are: HEADING DESCRIPTION NAME Subject name. Usually a command or file name. Very brief description. SYNOPSIS Summary of the command syntax. DESCRIPTION In-depth description to provide a basic understanding of the topic. OPTIONS Explanation of the command execution options. EXAMPLES Examples of how to use the command, function, or file. FILES A list of files and directories related to the man page. SEE ALSO Related information, normally other man page topics. BUGS Known bugs in the software. AUTHOR Information about who has contributed to the development of the topic.","title":"NAVIGATE AND SEARCH MAN PAGES"},{"location":"redhat/help/#searching-for-man-pages-by-keyword","text":"A keyword search of man pages is performed with man -k keyword , which displays a list of keyword-matching man page topics with section numbers. [ student@desktopX ~ ] $ man -k passwd checkPasswdAccess ( 3 ) - query the SELinux policy database in the kernel. chpasswd ( 8 ) - update passwords in batch mode ckpasswd ( 8 ) - nnrpd password authenticator fgetpwent_r ( 3 ) - get passwd file entry reentrantly getpwent_r ( 3 ) - get passwd file entry reentrantly ... passwd ( 1 ) - update user ' s authentication tokens sslpasswd ( 1ssl ) - compute password hashes passwd ( 5 ) - password file passwd.nntp ( 5 ) - Passwords for connecting to remote NNTP servers passwd2des ( 3 ) - RFS password encryption ... Popular system administration topics are in sections 1 (user commands), 5 (file formats), and 8 (administrative commands). Administrators using certain troubleshooting tools also use section 2 (system calls). The remaining sections are generally for programmer reference or advanced administration. Note Keyword searches rely on an index generated by the mandb(8) command, which must be run as root. The command runs daily through cron.daily , or by anacrontab within an hour of boot, if out of date. IMPORTANT The man command -K (uppercase) option performs a full-text page search, not just titles and descriptions like the -k option. A full-text search uses greater system resources and take more time.","title":"SEARCHING FOR MAN PAGES BY KEYWORD"},{"location":"redhat/help/#reading-info-documentation","text":"","title":"READING INFO DOCUMENTATION"},{"location":"redhat/help/#introducing-gnu-info","text":"Man pages have a format useful as a command reference, but less useful as general documentation. For such documents, the GNU Project developed a different online documentation system, known as GNU Info . Info documents are an important resource on a Red Hat Enterprise Linux system because many fundamental components and utilities, such as the coreutils package and glibc standard libraries, are either developed by the GNU Project or utilize the Info document system. IMPORTANT You might wonder why there are two local documentation systems, man pages and Info documents. Some of the reasons for this are practical in nature, and some have to do with the way Linux and its applications have been developed by various open source communities over the years. Man pages have a much more formal format, and typically document a specific command or function from a software package, and are structured as individual text files. Info documents typically cover particular software packages as a whole, tend to have more practical examples of how to use the software, and are structured as hypertext documents. You should be familiar with both systems in order to take maximum advantage of the information available to you from the system. Reading Info Documentation To launch the Info document viewer, use the pinfo command. pinfo opens in the top directory. Info documentation is comprehensive and hyperlinked. It is possible to output info pages to multiple formats. By contrast, man pages are optimized for printed output. The Info format is more flexible than man pages, allowing thorough discussion of complex commands and concepts. Like man pages, Info nodes are read from the command line, using the pinfo command. A typical man page has a small amount of content focusing on one particular topic, command, tool, or file. The Info documentation is a comprehensive document. Info provides the following improvements: One single document for a large system containing all the necessary information for that system Hyperlinks A complete browsable document index A full text search of the entire document Some commands and utilities have both man pages and info documentation; usually, the Info documentation is more in depth. Compare the differences in tar documentation using man and pinfo : [ user@host ~ ] $ man tar [ user@host ~ ] $ pinfo tar The pinfo reader is more advanced than the original info command. To browse a specific topic, use the pinfo topic command. The pinfo command without an argument opens the top directory. New documentation becomes available in pinfo when their software packages are installed. NOTE If no Info topic exists in the system for a particular entry that you requested, Info will look for a matching man page and display that instead.","title":"INTRODUCING GNU INFO"},{"location":"redhat/help/#comparing-gnu-info-and-man-page-navigation","text":"The pinfo command and the man command use slightly different navigational keystrokes. The following table compares the navigational keystrokes for both commands: pinfo and man, key binding comparison NAVIGATION PINFO MAN Scroll forward (down) one screen PageDown or Space PageDown or Space Scroll backward (up) one screen PageUp or b PageUp or b Display the directory of topics D - Scroll forward (down) one half-screen - D Display the parent node of a topic U - Display the top (up) of a topic HOME G Scroll backward (up) one half-screen - U Scroll forward (down) to next hyperlink DownArrow - Open topic at cursor location ENTER - Scroll forward (down) one line - DownArrow or Enter Scroll backward (up) to previous hyperlink UpArrow - Scroll backward (up) one line - UpArrow Search for a pattern /string /string Display next node (chapter) in topic N - Repeat previous search forward (down) / then Enter n Display previous node (chapter) in topic P - Repeat previous search backward (up) - ShiftN Quit the program Q Q","title":"COMPARING GNU INFO AND MAN PAGE NAVIGATION"},{"location":"redhat/help/#summary","text":"In this chapter, you learned: Man pages are viewed with the man command and provide information on components of a Linux system, such as files, commands, and functions. By convention, when referring to a man page the name of a page is followed by its section number in parentheses. Info documents are viewed with the pinfo command and are made up of a collection of hypertext nodes, providing information about software packages as a whole. The navigational keystrokes used by man and pinfo are slightly different.","title":"SUMMARY"},{"location":"redhat/intro/","text":"RED HAT SYSTEM ADMINISTRATION I \u00b6 Red Hat System Administration I (RH124) is designed for IT professionals without previous Linux system administration experience. The course is intended to provide students with Linux administration \"survival skills\" by focusing on core administration tasks. SYSTEM-WIDE DEFAULT LANGUAGE SETTINGS \u00b6 The system's default language is set to US English, using the UTF-8 encoding of Unicode as its character set ( en_US.utf8 ), but this can be changed during or after installation. From the command line, the root user can change the system-wide locale settings with the localectl command. If localectl is run with no arguments, it displays the current system- wide locale settings. To set the system-wide default language, run the command localectl set-locale LANG=locale, where locale is the appropriate value for the LANG environment variable from the \"Language Codes Reference\" table in this chapter. The change will take effect for users on their next login, and is stored in /etc/locale.conf. [ root@host ~ ] # localectl set-locale LANG=fr_FR.utf8 WHY SHOULD YOU LEARN ABOUT LINUX? \u00b6 Linux is a critical technology for IT professionals to understand. Linux is in widespread use, and if you use the internet at all, you are probably already interacting with Linux systems in your daily life. Perhaps the most obvious way in which you interact with Linux systems is through browsing the World Wide Web and using e-commerce sites to buy and sell products. However, Linux is in use for much more than that. Linux manages point-of-sale systems and the world's stock markets, and also powers smart TVs and in-flight entertainment systems. It powers most of the top 500 supercomputers in the world. Linux provides the foundational technologies powering the cloud revolution and the tools used to build the next generation of container-based microservices applications, software-based storage technologies, and big data solutions. In the modern data center, Linux and Microsoft Windows are the major players, and Linux is a growing segment in that space. Some of the many reasons to learn Linux include: A Windows user needs to interoperate with Linux. In application development, Linux hosts the application or its runtime. In cloud computing, the cloud instances in the private or public cloud environment use Linux as the operating system. With mobile applications or the Internet of Things (IoT), the chances are high that the operating system of your device uses Linux. If you are looking for new opportunities in IT, Linux skills are in high demand. WHAT MAKES LINUX GREAT? \u00b6 There are many different answers to the question \"What makes Linux great?\", however, three of them are: Linux is open source software. Being open source does not just mean that you can see how the system works. You can also experiment with changes and share them freely for others to use. The open source model means that improvements are easier to make, enabling faster innovation. Linux provides easy access to a powerful and scriptable command-line interface (CLI). Linux was built around the basic design philosophy that users can perform all administration tasks from the CLI. It enables easier automation, deployment, and provisioning, and simplifies both local and remote system administration. Unlike other operating systems, these capabilities have been built in from the beginning, and the assumption has always been to enable these important capabilities. Linux is a modular operating system that allows you to easily replace or remove components. Components of the system can be upgraded and updated as needed. A Linux system can be a general-purpose development workstation or an extremely stripped-down software appliance. WHAT IS OPEN SOURCE SOFTWARE? \u00b6 Open source software is software with source code that anyone can use, study, modify, and share. Source code is the set of human-readable instructions that are used to make a program. It may be interpreted as a script or compiled into a binary executable which the computer runs directly. Upon creating source code, it gets copyrighted, and the copyright holder controls the terms under which the software can be copied, adapted, and distributed. Users can use this software under a software license. Some software has source code that only the person, team, or organization that created it can see, or change, or distribute. This software is sometimes called \"proprietary\" or \"closed source\" software. Typically the license only allows the end user to run the program, and provides no access, or tightly limited access, to the source. Open source software is different. When the copyright holder provides software under an open source license, they grant the user the right to run the program and also to view, modify, compile, and redistribute the source royalty-free to others. Open source promotes collaboration, sharing, transparency, and rapid innovation because it encourages people beyond the original developers to make modifications and improvements to the software and to share it with others. Just because the software is open source does not mean it is somehow not able to be used or provided commercially. Open source is a critical part of many organizations' commercial operations. Some open source licenses allow code to be reused in closed source products. One can sell open source code, but the terms of true open source licenses generally allow the customer to redistribute the source code. Most commonly, vendors such as Red Hat provide commercial help with deploying, supporting, and extending solutions based on open source products. Open source has many benefits for the user: Control : See what the code does and change it to improve it. Training : Learn from real-world code and develop more useful applications. Security : Inspect sensitive code, fix with or without the original developers' help. Stability : Code can survive the loss of the original developer or distributor. The bottom line is that open source allows the creation of better software with a higher return on investment by collaboration. TYPES OF OPEN SOURCE LICENSES \u00b6 There is more than one way to provide open source software. The terms of the software license control how the source can be combined with other code or reused, and hundreds of different open source licenses exist. However, to be open source, licenses must allow users to freely use, view, change, compile, and distribute the code. There are two broad classes of open source license that are particularly important: Copyleft licenses that are designed to encourage keeping code open source. Permissive licenses that are designed to maximize code reusability. Copyleft, or \"share-alike\" licenses, require that anyone who distributes the source code, with or without changes, must also pass along the freedom for others to also copy, change, and distribute the code. The basic advantage of these licenses is that they help to keep existing code, and improvements to that code, open and add to the amount of open source code available. Common copyleft licenses include the GNU General Public License (GPL) and the Lesser GNU Public License (LGPL). Permissive licenses are intended to maximize the reusability of source code. Users can use the source for any purpose as long as the copyright and license statements are preserved, including reusing that code under more restrictive or even proprietary licenses. This makes it very easy for this code to be reused, but at the risk of encouraging proprietary-only enhancements. Several commonly used permissive open source licenses include the MIT/X11 license, the Simplified BSD license, and the Apache Software License 2.0. WHO DEVELOPS OPEN SOURCE SOFTWARE? \u00b6 It is a misconception to think that open source is developed solely by an \"army of volunteers\" or even an army of individuals plus Red Hat. Open source development today is overwhelmingly professional. Many developers are paid by their organizations to work with open source projects to construct and contribute the enhancements they and their customers need. Volunteers and the academic community play a significant role and can make vital contributions, especially in new technology areas. The combination of formal and informal development provides a highly dynamic and productive environment. WHO IS RED HAT? \u00b6 Red Hat is the world's leading provider of open source software solutions, using a community- powered approach to reliable and high-performance cloud, Linux, middleware, storage, and virtualization technologies. Red Hat's mission is to be the catalyst in communities of customers, contributors, and partners creating better technology the open source way. Red Hat's role is to help customers connect with the open source community and their partners to effectively use open source software solutions. Red Hat actively participates in and supports the open source community and many years of experience have convinced the company of the importance of open source to the future of the IT industry. Red Hat is most well-known for their participation in the Linux community and the Red Hat Enterprise Linux distribution. However, Red Hat is also very active in other open source communities, including middleware projects centered on the JBoss developer community, virtualization solutions, cloud technologies such as OpenStack and OpenShift, and the Ceph and Gluster software-based storage projects, among others. WHAT IS A LINUX DISTRIBUTION? \u00b6 A Linux distribution is an installable operating system constructed from a Linux kernel and supporting user programs and libraries. A complete Linux operating system is not developed by a single organization, but by a collection of independent open source development communities working with individual software components. A distribution provides an easy way for users to install and manage a working Linux system. In 1991, a young computer science student named Linus Torvalds developed a Unix-like kernel he named Linux, licensed as open source software under the GPL. The kernel is the core component of the operating system, which manages hardware, memory, and the scheduling of running programs. This Linux kernel could then be supplemented with other open source software, such as utilities and programs from the GNU Project, the graphical interface from MIT's X Window System, and many other open source components, such as the Sendmail mail server or the Apache HTTP web server, in order to build a complete open source Unix-like operating system. However, one of the challenges for Linux users was to assemble all these pieces from many different sources. Very early in its history, Linux developers began working to provide a distribution of prebuilt and tested tools that users could download and use to set up their Linux systems quickly. Many different Linux distributions exist, with differing goals and criteria for selecting and supporting the software provided by their distribution. However, distributions generally have many common characteristics: Distributions consist of a Linux kernel and supporting user space programs. Distributions can be small and single-purpose or include thousands of open source programs. Distributions must provide a means of installing and updating the distribution and its components. The provider of the distribution must support that software, and ideally, be participating directly in the community developing that software. Red Hat Enterprise Linux is Red Hat's commercialized Linux distribution. SUMMARY \u00b6 In this chapter, you learned: Open source software is software with source code that anyone can freely use, study, modify, and share. A Linux distribution is an installable operating system constructed from a Linux kernel and supporting user programs and libraries. Red Hat participates in supporting and contributing code to open source projects, sponsors and integrates project software into community-driven distributions, and stabilizes the software to offer it as supported enterprise-ready products. Red Hat Enterprise Linux is Red Hat's open source, enterprise-ready, commercially-supported Linux distribution.","title":"Introduction"},{"location":"redhat/intro/#red-hat-system-administration-i","text":"Red Hat System Administration I (RH124) is designed for IT professionals without previous Linux system administration experience. The course is intended to provide students with Linux administration \"survival skills\" by focusing on core administration tasks.","title":"RED HAT SYSTEM ADMINISTRATION I  "},{"location":"redhat/intro/#system-wide-default-language-settings","text":"The system's default language is set to US English, using the UTF-8 encoding of Unicode as its character set ( en_US.utf8 ), but this can be changed during or after installation. From the command line, the root user can change the system-wide locale settings with the localectl command. If localectl is run with no arguments, it displays the current system- wide locale settings. To set the system-wide default language, run the command localectl set-locale LANG=locale, where locale is the appropriate value for the LANG environment variable from the \"Language Codes Reference\" table in this chapter. The change will take effect for users on their next login, and is stored in /etc/locale.conf. [ root@host ~ ] # localectl set-locale LANG=fr_FR.utf8","title":"SYSTEM-WIDE DEFAULT LANGUAGE SETTINGS"},{"location":"redhat/intro/#why-should-you-learn-about-linux","text":"Linux is a critical technology for IT professionals to understand. Linux is in widespread use, and if you use the internet at all, you are probably already interacting with Linux systems in your daily life. Perhaps the most obvious way in which you interact with Linux systems is through browsing the World Wide Web and using e-commerce sites to buy and sell products. However, Linux is in use for much more than that. Linux manages point-of-sale systems and the world's stock markets, and also powers smart TVs and in-flight entertainment systems. It powers most of the top 500 supercomputers in the world. Linux provides the foundational technologies powering the cloud revolution and the tools used to build the next generation of container-based microservices applications, software-based storage technologies, and big data solutions. In the modern data center, Linux and Microsoft Windows are the major players, and Linux is a growing segment in that space. Some of the many reasons to learn Linux include: A Windows user needs to interoperate with Linux. In application development, Linux hosts the application or its runtime. In cloud computing, the cloud instances in the private or public cloud environment use Linux as the operating system. With mobile applications or the Internet of Things (IoT), the chances are high that the operating system of your device uses Linux. If you are looking for new opportunities in IT, Linux skills are in high demand.","title":"WHY SHOULD YOU LEARN ABOUT LINUX?"},{"location":"redhat/intro/#what-makes-linux-great","text":"There are many different answers to the question \"What makes Linux great?\", however, three of them are: Linux is open source software. Being open source does not just mean that you can see how the system works. You can also experiment with changes and share them freely for others to use. The open source model means that improvements are easier to make, enabling faster innovation. Linux provides easy access to a powerful and scriptable command-line interface (CLI). Linux was built around the basic design philosophy that users can perform all administration tasks from the CLI. It enables easier automation, deployment, and provisioning, and simplifies both local and remote system administration. Unlike other operating systems, these capabilities have been built in from the beginning, and the assumption has always been to enable these important capabilities. Linux is a modular operating system that allows you to easily replace or remove components. Components of the system can be upgraded and updated as needed. A Linux system can be a general-purpose development workstation or an extremely stripped-down software appliance.","title":"WHAT MAKES LINUX GREAT?"},{"location":"redhat/intro/#what-is-open-source-software","text":"Open source software is software with source code that anyone can use, study, modify, and share. Source code is the set of human-readable instructions that are used to make a program. It may be interpreted as a script or compiled into a binary executable which the computer runs directly. Upon creating source code, it gets copyrighted, and the copyright holder controls the terms under which the software can be copied, adapted, and distributed. Users can use this software under a software license. Some software has source code that only the person, team, or organization that created it can see, or change, or distribute. This software is sometimes called \"proprietary\" or \"closed source\" software. Typically the license only allows the end user to run the program, and provides no access, or tightly limited access, to the source. Open source software is different. When the copyright holder provides software under an open source license, they grant the user the right to run the program and also to view, modify, compile, and redistribute the source royalty-free to others. Open source promotes collaboration, sharing, transparency, and rapid innovation because it encourages people beyond the original developers to make modifications and improvements to the software and to share it with others. Just because the software is open source does not mean it is somehow not able to be used or provided commercially. Open source is a critical part of many organizations' commercial operations. Some open source licenses allow code to be reused in closed source products. One can sell open source code, but the terms of true open source licenses generally allow the customer to redistribute the source code. Most commonly, vendors such as Red Hat provide commercial help with deploying, supporting, and extending solutions based on open source products. Open source has many benefits for the user: Control : See what the code does and change it to improve it. Training : Learn from real-world code and develop more useful applications. Security : Inspect sensitive code, fix with or without the original developers' help. Stability : Code can survive the loss of the original developer or distributor. The bottom line is that open source allows the creation of better software with a higher return on investment by collaboration.","title":"WHAT IS OPEN SOURCE SOFTWARE?"},{"location":"redhat/intro/#types-of-open-source-licenses","text":"There is more than one way to provide open source software. The terms of the software license control how the source can be combined with other code or reused, and hundreds of different open source licenses exist. However, to be open source, licenses must allow users to freely use, view, change, compile, and distribute the code. There are two broad classes of open source license that are particularly important: Copyleft licenses that are designed to encourage keeping code open source. Permissive licenses that are designed to maximize code reusability. Copyleft, or \"share-alike\" licenses, require that anyone who distributes the source code, with or without changes, must also pass along the freedom for others to also copy, change, and distribute the code. The basic advantage of these licenses is that they help to keep existing code, and improvements to that code, open and add to the amount of open source code available. Common copyleft licenses include the GNU General Public License (GPL) and the Lesser GNU Public License (LGPL). Permissive licenses are intended to maximize the reusability of source code. Users can use the source for any purpose as long as the copyright and license statements are preserved, including reusing that code under more restrictive or even proprietary licenses. This makes it very easy for this code to be reused, but at the risk of encouraging proprietary-only enhancements. Several commonly used permissive open source licenses include the MIT/X11 license, the Simplified BSD license, and the Apache Software License 2.0.","title":"TYPES OF OPEN SOURCE LICENSES"},{"location":"redhat/intro/#who-develops-open-source-software","text":"It is a misconception to think that open source is developed solely by an \"army of volunteers\" or even an army of individuals plus Red Hat. Open source development today is overwhelmingly professional. Many developers are paid by their organizations to work with open source projects to construct and contribute the enhancements they and their customers need. Volunteers and the academic community play a significant role and can make vital contributions, especially in new technology areas. The combination of formal and informal development provides a highly dynamic and productive environment.","title":"WHO DEVELOPS OPEN SOURCE SOFTWARE?"},{"location":"redhat/intro/#who-is-red-hat","text":"Red Hat is the world's leading provider of open source software solutions, using a community- powered approach to reliable and high-performance cloud, Linux, middleware, storage, and virtualization technologies. Red Hat's mission is to be the catalyst in communities of customers, contributors, and partners creating better technology the open source way. Red Hat's role is to help customers connect with the open source community and their partners to effectively use open source software solutions. Red Hat actively participates in and supports the open source community and many years of experience have convinced the company of the importance of open source to the future of the IT industry. Red Hat is most well-known for their participation in the Linux community and the Red Hat Enterprise Linux distribution. However, Red Hat is also very active in other open source communities, including middleware projects centered on the JBoss developer community, virtualization solutions, cloud technologies such as OpenStack and OpenShift, and the Ceph and Gluster software-based storage projects, among others.","title":"WHO IS RED HAT?"},{"location":"redhat/intro/#what-is-a-linux-distribution","text":"A Linux distribution is an installable operating system constructed from a Linux kernel and supporting user programs and libraries. A complete Linux operating system is not developed by a single organization, but by a collection of independent open source development communities working with individual software components. A distribution provides an easy way for users to install and manage a working Linux system. In 1991, a young computer science student named Linus Torvalds developed a Unix-like kernel he named Linux, licensed as open source software under the GPL. The kernel is the core component of the operating system, which manages hardware, memory, and the scheduling of running programs. This Linux kernel could then be supplemented with other open source software, such as utilities and programs from the GNU Project, the graphical interface from MIT's X Window System, and many other open source components, such as the Sendmail mail server or the Apache HTTP web server, in order to build a complete open source Unix-like operating system. However, one of the challenges for Linux users was to assemble all these pieces from many different sources. Very early in its history, Linux developers began working to provide a distribution of prebuilt and tested tools that users could download and use to set up their Linux systems quickly. Many different Linux distributions exist, with differing goals and criteria for selecting and supporting the software provided by their distribution. However, distributions generally have many common characteristics: Distributions consist of a Linux kernel and supporting user space programs. Distributions can be small and single-purpose or include thousands of open source programs. Distributions must provide a means of installing and updating the distribution and its components. The provider of the distribution must support that software, and ideally, be participating directly in the community developing that software. Red Hat Enterprise Linux is Red Hat's commercialized Linux distribution.","title":"WHAT IS A LINUX DISTRIBUTION?"},{"location":"redhat/intro/#summary","text":"In this chapter, you learned: Open source software is software with source code that anyone can freely use, study, modify, and share. A Linux distribution is an installable operating system constructed from a Linux kernel and supporting user programs and libraries. Red Hat participates in supporting and contributing code to open source projects, sponsors and integrates project software into community-driven distributions, and stabilizes the software to offer it as supported enterprise-ready products. Red Hat Enterprise Linux is Red Hat's open source, enterprise-ready, commercially-supported Linux distribution.","title":"SUMMARY"},{"location":"redhat/manage/","text":"DESCRIBING LINUX FILE SYSTEM HIERARCHY CONCEPTS \u00b6 THE FILE-SYSTEM HIERARCHY \u00b6 All files on a Linux system are stored on file systems, which are organized into a single inverted tree of directories, known as a file-system hierarchy. This tree is inverted because the root of the tree is said to be at the top of the hierarchy, and the branches of directories and subdirectories stretch below the root. The / directory is the root directory at the top of the file-system hierarchy. The / character is also used as a directory separator in file names. For example, if etc is a subdirectory of the / directory, you could refer to that directory as /etc. Likewise, if the /etc directory contained a file named issue, you could refer to that file as /etc/issue . Subdirectories of / are used for standardized purposes to organize files by type and purpose. This makes it easier to find files. For example, in the root directory, the subdirectory /boot is used for storing files needed to boot the system. NOTE The following terms help to describe file-system directory contents: static content remains unchanged until explicitly edited or reconfigured. dynamic or variable content may be modified or appended by active processes. persistent content remains after a reboot, like configuration settings. runtime content is process- or system-specific content that is deleted by a reboot. The following table lists some of the most important directories on the system by name and purpose. Important Red Hat Enterprise Linux Directories /usr Installed software, shared libraries, include files, and read-only program data. Important subdirectories include: /usr/bin : User commands. /usr/sbin : System administration commands. /usr/local : Locally customized software. /etc Configuration files specific to this system. /var Variable data specific to this system that should persist between boots. Files that dynamically change, such as databases, cache directories, log files, printer-spooled documents, and website content may be found under /var . /run Runtime data for processes started since the last boot. This includes process ID files and lock files, among other things. The contents of this directory are recreated on reboot. This directory consolidates /var/run and /var/lock from earlier versions of Red Hat Enterprise Linux. /home Home directories are where regular users store their personal data and configuration files. /root Home directory for the administrative superuser, root. /tmp A world-writable space for temporary files. Files which have not been accessed, changed, or modified for 10 days are deleted from this directory automatically. Another temporary directory exists, /var/tmp , in which files that have not been accessed, changed, or modified in more than 30 days are deleted automatically. /boot Files needed in order to start the boot process. /dev Contains special device files that are used by the system to access hardware. IMPORTANT In Red Hat Enterprise Linux 7 and later, four older directories in / have identical contents to their counterparts located in /usr : /bin and /usr/bin /sbin and /usr/sbin /lib and /usr/lib /lib64 and /usr/lib64 In earlier versions of Red Hat Enterprise Linux, these were distinct directories containing different sets of files. In Red Hat Enterprise Linux 7 and later, the directories in / are symbolic links to the matching directories in /usr . SPECIFYING FILES BY NAME \u00b6 ABSOLUTE PATHS AND RELATIVE PATHS \u00b6 The path of a file or directory specifies its unique file system location. Following a file path traverses one or more named subdirectories, delimited by a forward slash (/), until the destination is reached. Directories, also called folders, contain other files and other subdirectories. They can be referenced in the same manner as files. IMPORTANT A space character is acceptable as part of a Linux file name. However, spaces are also used by the shell to separate options and arguments on the command line. If you enter a command that includes a file that has a space in its name, the shell can misinterpret the command and assume that you want to start a new file name or other argument at the space. It is possible to avoid this by putting file names in quotes. However, if you do not need to use spaces in file names, it can be simpler to simply avoid using them. Absolute Paths An absolute path is a fully qualified name, specifying the files exact location in the file system hierarchy. It begins at the root (/) directory and specifies each subdirectory that must be traversed to reach the specific file. Every file in a file system has a unique absolute path name, recognized with a simple rule: A path name with a forward slash (/) as the first character is an absolute path name. For example, the absolute path name for the system message log file is /var/log/messages . Absolute path names can be long to type, so files may also be located relative to the current working directory for your shell prompt. The Current Working Directory and Relative Paths When a user logs in and opens a command window, the initial location is normally the user's home directory. System processes also have an initial directory. Users and processes navigate to other directories as needed; the terms working directory or current working directory refer to their current location. Like an absolute path, a relative path identifies a unique file, specifying only the path necessary to reach the file from the working directory. Recognizing relative path names follows a simple rule: A path name with anything other than a forward slash as the first character is a relative path name. A user in the /var directory could refer to the message log file relatively as log/messages . Linux file systems, including, but not limited to, ext4, XFS, GFS2, and GlusterFS, are case-sensitive. Creating FileCase.txt and filecase.txt in the same directory results in two unique files. Non-Linux file systems might work differently. For example, VFAT, Microsoft's NTFS, and Apple's HFS+ have case preserving behavior. Although these file systems are not case-sensitive, they do display file names with the original capitalization used when the file was created. Therefore, if you tried to make the files in the preceding example on a VFAT file system, both names would be treated as pointing to the same file instead of two different files. NAVIGATING PATHS \u00b6 The pwd command displays the full path name of the current working directory for that shell. This can help you determine the syntax to reach files using relative path names. The ls command lists directory contents for the specified directory or, if no directory is given, for the current working directory. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ ls Desktop Documents Downloads Music Pictures Public Templates Videos [ user@host ~ ] $ Use the cd command to change your shell's current working directory. If you do not specify any arguments to the command, it will change to your home directory. In the following example, a mixture of absolute and relative paths are used with the cd command to change the current working directory for the shell. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ cd Videos [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd /home/user/Documents [ user@host Documents ] $ pwd /home/user/Documents [ user@host Documents ] $ cd [ user@host ~ ] $ pwd /home/user As you can see in the preceding example, the default shell prompt also displays the last component of the absolute path to the current working directory. For example, for /home/user/Videos , only Videos displays. The prompt displays the tilde character (~) when your current working directory is your home directory. The touch command normally updates a file's timestamp to the current date and time without otherwise modifying it. This is useful for creating empty files, which can be used for practice, because \"touching\" a file name that does not exist causes the file to be created. In the following example, the touch command creates practice files in the Documents and Videos subdirectories. [ user@host ~ ] $ touch Videos/blockbuster1.ogg [ user@host ~ ] $ touch Videos/blockbuster2.ogg [ user@host ~ ] $ touch Documents/thesis_chapter1.odf [ user@host ~ ] $ touch Documents/thesis_chapter2.odf [ user@host ~ ] $ The ls command has multiple options for displaying attributes on files. The most common and useful are -l (long listing format), -a (all files, including hidden files), and -R (recursive, to include the contents of all subdirectories). [ user@host ~ ] $ ls -l total 15 drwxr-xr-x. 2 user user 4096 Feb 7 14 :02 Desktop drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Documents drwxr-xr-x. 3 user user 4096 Jan 9 15 :00 Downloads drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Music drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Pictures drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Public drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Templates drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Videos [ user@host ~ ] $ ls -la total 15 drwx------. 16 user user 4096 Feb 8 16 :15 . drwxr-xr-x. 6 root root 4096 Feb 8 16 :13 .. -rw-------. 1 user user 22664 Feb 8 00 :37 .bash_history -rw-r--r--. 1 user user 18 Jul 9 2013 .bash_logout -rw-r--r--. 1 user user 176 Jul 9 2013 .bash_profile -rw-r--r--. 1 user user 124 Jul 9 2013 .bashrc drwxr-xr-x. 4 user user 4096 Jan 20 14 :02 .cache drwxr-xr-x. 8 user user 4096 Feb 5 11 :45 .config drwxr-xr-x. 2 user user 4096 Feb 7 14 :02 Desktop drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Documents drwxr-xr-x. 3 user user 4096 Jan 25 20 :48 Downloads drwxr-xr-x. 11 user user 4096 Feb 6 13 :07 .gnome2 drwx------. 2 user user 4096 Jan 20 14 :02 .gnome2_private -rw-------. 1 user user 15190 Feb 8 09 :49 .ICEauthority drwxr-xr-x. 3 user user 4096 Jan 9 15 :00 .local drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Music drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Pictures drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Public drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Templates drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Videos The two special directories at the top of the listing refer to the current directory (.) and the parent directory (..). These special directories exist in every directory on the system. You will discover their usefulness when you start using file management commands. IMPORTANT File names beginning with a dot (.) indicate hidden files; you cannot see them in the normal view using ls and other commands. This is not a security feature. Hidden files keep necessary user configuration files from cluttering home directories. Many commands process hidden files only with specific command-line options, preventing one user's configuration from being accidentally copied to other directories or users. To protect file contents from improper viewing requires the use of file permissions . [ user@host ~ ] $ ls -R .: Desktop Documents Downloads Music Pictures Public Templates Videos ./Desktop: ./Documents: thesis_chapter1.odf thesis_chapter2.odf ./Downloads: ./Music: ./Pictures: ./Public: ./Templates: ./Videos: blockbuster1.ogg blockbuster2.ogg [ user@host ~ ] $ The cd command has many options. A few are so useful as to be worth practicing early and using often. The command cd - changes to the previous directory; where the user was previously to the current directory. The following example illustrates this behavior, alternating between two directories, which is useful when processing a series of similar tasks. [ user@host ~ ] $ cd Videos [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd /home/user/Documents [ user@host Documents ] $ pwd /home/user/Documents [ user@host Documents ] $ cd - [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd - [ user@host Documents ] $ pwd /home/user/Documents [ user@host Documents ] $ cd - [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd [ user@host ~ ] $ The cd .. command uses the .. hidden directory to move up one level to the parent directory, without needing to know the exact parent name. The other hidden directory (.) specifies the current directory on commands in which the current location is either the source or destination argument, avoiding the need to type out the directory's absolute path name. [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd . [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd .. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ cd .. [ user@host home ] $ pwd /home [ user@host home ] $ cd .. [ user@host / ] $ pwd / [ user@host / ] $ cd [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ MANAGING FILES USING COMMAND-LINE TOOLS \u00b6 COMMAND-LINE FILE MANAGEMENT \u00b6 To manage files, you need to be able to create, remove, copy, and move them. You also need to organize them logically into directories, which you also need to be able to create, remove, copy, and move. The following table summarizes some of the most common file management commands. The remainder of this section will discuss ways to use these commands in more detail. Common file management commands Create a directory mkdir directory Copy a file cp file new-file Copy a directory and its contents cp -r directory new-directory Move or rename a file or directory mv file new-file Remove a file rm file Remove a directory containing files rm -r directory Remove an empty directory rmdir directory Creating Directories \u00b6 The mkdir command creates one or more directories or subdirectories. It takes as arguments a list of paths to the directories you want to create. The mkdir command will fail with an error if the directory already exists, or if you are trying to create a subdirectory in a directory that does not exist. The -p (parent) option creates missing parent directories for the requested destination. Use the mkdir -p command with caution, because spelling mistakes can create unintended directories without generating error messages. In the following example, pretend that you are trying to create a directory in the Videos directory [ user@host ~ ] $ mkdir Video/Watched mkdir: cannot create directory ` Video/Watched ' : No such file or directory The mkdir command failed because Videos was misspelled and the directory Video does not exist. If you had used the mkdir command with the -p option, the directory Video would be created, which was not what you had intended, and the subdirectory Watched would be created in that incorrect directory. After correctly spelling the Videos parent directory, creating the Watched subdirectory will succeed. [ user@host ~ ] $ mkdir Videos/Watched [ user@host ~ ] $ ls -R Videos Videos/: blockbuster1.ogg blockbuster2.ogg Watched Videos/Watched: In the following example, files and directories are organized beneath the /home/user/ Documents directory. Use the mkdir command and a space-delimited list of the directory names to create multiple directories. [ user@host ~ ] $ cd Documents [ user@host Documents ] $ mkdir ProjectX ProjectY [ user@host Documents ] $ ls ProjectX ProjectY Use the mkdir -p command and space-delimited relative paths for each of the subdirectory names to create multiple parent directories with subdirectories. [ user@host Documents ] $ mkdir -p Thesis/Chapter1 Thesis/Chapter2 Thesis/Chapter3 [ user@host Documents ] $ cd [ user@host ~ ] $ ls -R Videos Documents Documents: ProjectX ProjectY Thesis Documents/ProjectX: Documents/ProjectY: Documents/Thesis: Chapter1 Chapter2 Chapter3 Documents/Thesis/Chapter1: Documents/Thesis/Chapter2: Documents/Thesis/Chapter3: Videos: blockbuster1.ogg blockbuster2.ogg Watched Videos/Watched: The last mkdir command created three ChapterN subdirectories with one command. The -p option created the missing parent directory Thesis. Copying Files \u00b6 The cp command copies a file, creating a new file either in the current directory or in a specified directory. It can also copy multiple files to a directory. WARNING If the destination file already exists, the cp command overwrites the file. [ user@host ~ ] $ cd Videos [ user@host Videos ] $ cp blockbuster1.ogg blockbuster3.ogg [ user@host Videos ] $ ls -l total 0 -rw-rw-r--. 1 user user 0 Feb 8 16 :23 blockbuster1.ogg -rw-rw-r--. 1 user user 0 Feb 8 16 :24 blockbuster2.ogg -rw-rw-r--. 1 user user 0 Feb 8 16 :34 blockbuster3.ogg drwxrwxr-x. 2 user user 4096 Feb 8 16 :05 Watched [ user@host Videos ] $ When copying multiple files with one command, the last argument must be a directory. Copied files retain their original names in the new directory. If a file with the same name exists in the target directory, the existing file is overwritten. By default, the cp does not copy directories; it ignores them. In the following example, two directories are listed, Thesis and ProjectX. Only the last argument, ProjectX is valid as a destination. The Thesis directory is ignored. [ user@host Videos ] $ cd ../Documents [ user@host Documents ] $ cp thesis_chapter1.odf thesis_chapter2.odf Thesis ProjectX cp: omitting directory ` Thesis ' [ user@host Documents ] $ ls Thesis ProjectX ProjectX: thesis_chapter1.odf thesis_chapter2.odf Thesis: Chapter1 Chapter2 Chapter3 In the first cp command, the Thesis directory failed to copy, but the thesis_chapter1.odf and thesis_chapter2.odf files succeeded. If you want to copy a file to the current working directory, you can use the special . directory: [ user@host ~ ] $ cp /etc/hostname . [ user@host ~ ] $ cat hostname host.example.com [ user@host ~ ] $ Use the copy command with the -r (recursive) option, to copy the Thesis directory and its contents to the ProjectX directory. [ user@host Documents ] $ cp -r Thesis ProjectX [ user@host Documents ] $ ls -R ProjectX ProjectX: Thesis thesis_chapter1.odf thesis_chapter2.odf ProjectX/Thesis: Chapter1 Chapter2 Chapter3 ProjectX/Thesis/Chapter1: ProjectX/Thesis/Chapter2: thesis_chapter2.odf ProjectX/Thesis/Chapter3: Moving Files \u00b6 The mv command moves files from one location to another. If you think of the absolute path to a file as its full name, moving a file is effectively the same as renaming a file. File contents remain unchanged. Use the mv command to rename a file. [ user@host Videos ] $ cd ../Documents [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter1.odf -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2.odf [ user@host Documents ] $ mv thesis_chapter2.odf thesis_chapter2_reviewed.odf [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter1.odf -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2_reviewed.odf Use the mv command to move a file to a different directory. [ user@host Documents ] $ ls Thesis/Chapter1 [ user@host Documents ] $ [ user@host Documents ] $ mv thesis_chapter1.odf Thesis/Chapter1 [ user@host Documents ] $ ls Thesis/Chapter1 thesis_chapter1.odf [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2_reviewed.odf Removing Files and Directories \u00b6 The rm command removes files. By default, rm will not remove directories that contain files, unless you add the -r or --recursive option. IMPORTANT There is no command-line undelete feature, nor a \"trash bin\" from which you can restore files staged for deletion. It is a good idea to verify your current working directory before removing a file or directory. [ user@host Documents ] $ pwd /home/student/Documents Use the rm command to remove a single file from your working directory. [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2_reviewed.odf [ user@host Documents ] $ rm thesis_chapter2_reviewed.odf [ user@host Documents ] $ ls -l thesis* ls: cannot access 'thesis*' : No such file or directory If you attempt to use the rm command to remove a directory without using the -r option, the command will fail. [ user@host Documents ] $ rm Thesis/Chapter1 rm: cannot remove ` Thesis/Chapter1 ' : Is a directory Use the rm -r command to remove a subdirectory and its contents. [ user@host Documents ] $ ls -R Thesis Thesis/: Chapter1 Chapter2 Chapter3 Thesis/Chapter1: thesis_chapter1.odf Thesis/Chapter2: thesis_chapter2.odf Thesis/Chapter3: [ user@host Documents ] $ rm -r Thesis/Chapter1 [ user@host Documents ] $ ls -l Thesis total 8 drwxrwxr-x. 2 user user 4096 Feb 11 12 :47 Chapter2 drwxrwxr-x. 2 user user 4096 Feb 11 12 :48 Chapter3 The rm -r command traverses each subdirectory first, individually removing their files before removing each directory. You can use the rm -ri command to interactively prompt for confirmation before deleting. This is essentially the opposite of using the -f option, which forces the removal without prompting the user for confirmation. [ user@host Documents ] $ rm -ri Thesis rm: descend into directory ` Thesis '? y rm: descend into directory `Thesis/Chapter2' ? y rm: remove regular empty file ` Thesis/Chapter2/thesis_chapter2.odf '? y rm: remove directory `Thesis/Chapter2' ? y rm: remove directory ` Thesis/Chapter3 '? y rm: remove directory `Thesis' ? y WARNING If you specify both the -i and -f options, the -f option takes priority and you will not be prompted for confirmation before rm deletes files. In the following example, the rmdir command only removes the directory that is empty. Just like the earlier example, you must use the rm -r command to remove a directory that contains content. [ user@host Documents ] $ pwd /home/student/Documents [ user@host Documents ] $ rmdir ProjectY [ user@host Documents ] $ rmdir ProjectX rmdir: failed to remove ` ProjectX ' : Directory not empty [ user@host Documents ] $ rm -r ProjectX [ user@host Documents ] $ ls -lR .: total 0 [ user@host Documents ] $ NOTE The rm command with no options cannot remove an empty directory. You must use the rmdir command, rm -d (which is equivalent to rmdir), or rm -r. MAKING LINKS BETWEEN FILES \u00b6 MANAGING LINKS BETWEEN FILES \u00b6 Hard Links and Soft Links It is possible to create multiple names that point to the same file. There are two ways to do this: by creating a hard link to the file, or by creating a soft link (sometimes called a symbolic link) to the file. Each has its advantages and disadvantages. Creating Hard Links Every file starts with a single hard link, from its initial name to the data on the file system. When you create a new hard link to a file, you create another name that points to that same data. The new hard link acts exactly like the original file name. Once created, you cannot tell the difference between the new hard link and the original name of the file. You can find out if a file has multiple hard links with the ls -l command. One of the things it reports is each file's link count, the number of hard links the file has. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ ls -l newfile.txt -rw-r--r--. 1 user user 0 Mar 11 19 :19 newfile.txt In the preceding example, the link count of newfile.txt is 1. It has exactly one absolute path, which is /home/user/newfile.txt. You can use the ln command to create a new hard link (another name) that points to an existing file. The command needs at least two arguments, a path to the existing file, and the path to the hard link that you want to create. The following example creates a hard link named newfile-link2.txt for the existing file newfile.txt in the /tmp directory. [ user@host ~ ] $ ln newfile.txt /tmp/newfile-hlink2.txt [ user@host ~ ] $ ls -l newfile.txt /tmp/newfile-hlink2.txt -rw-rw-r--. 2 user user 12 Mar 11 19 :19 newfile.txt -rw-rw-r--. 2 user user 12 Mar 11 19 :19 /tmp/newfile-hlink2.txt If you want to find out whether two files are hard links of each other, one way is to use the -i option with the ls command to list the files' inode number. If the files are on the same file system (discussed in a moment) and their inode numbers are the same, the files are hard links pointing to the same data. [ user@host ~ ] $ ls -il newfile.txt /tmp/newfile-hlink2.txt 8924107 -rw-rw-r--. 2 user user 12 Mar 11 19 :19 newfile.txt 8924107 -rw-rw-r--. 2 user user 12 Mar 11 19 :19 /tmp/newfile-hlink2.txt IMPORTANT All hard links that reference the same file will have the same link count, access permissions, user and group ownerships, time stamps, and file content. If any of that information is changed using one hard link, all other hard links pointing to the same file will show the new information as well. This is because each hard link points to the same data on the storage device. Even if the original file gets deleted, the contents of the file are still available as long as at least one hard link exists. Data is only deleted from storage when the last hard link is deleted. [ user@host ~ ] $ rm -f newfile.txt [ user@host ~ ] $ ls -l /tmp/newfile-hlink2.txt -rw-rw-r--. 1 user user 12 Mar 11 19 :19 /tmp/newfile-hlink2.txt [ user@host ~ ] $ cat /tmp/newfile-hlink2.txt Hello World Limitations of Hard Links \u00b6 Hard links have some limitations. Firstly, hard links can only be used with regular files. You cannot use ln to create a hard link to a directory or special file. Secondly, hard links can only be used if both files are on the same file system. The file-system hierarchy can be made up of multiple storage devices. Depending on the configuration of your system, when you change into a new directory, that directory and its contents may be stored on a different file system. You can use the df command to list the directories that are on different file systems. For example, you might see output like the following: [ user@host ~ ] $ df Filesystem 1K-blocks Used Available Use% Mounted on devtmpfs 886788 0 886788 0 % /dev tmpfs 902108 0 902108 0 % /dev/shm tmpfs 902108 8696 893412 1 % /run tmpfs 902108 0 902108 0 % /sys/fs/cgroup /dev/mapper/rhel_rhel8--root 10258432 1630460 8627972 16 % / /dev/sda1 1038336 167128 871208 17 % /boot tmpfs 180420 0 180420 0 % /run/user/1000 [ user@host ~ ] $ Files in two different \"Mounted on\" directories and their subdirectories are on different file systems. (The most specific match wins.) So, the system in this example, you can create a hard link between /var/tmp/link1 and /home/user/file because they are both subdirectories of / but not any other directory on the list. But you cannot create a hard link between /boot/ test/badlink and /home/user/file because the first file is in a subdirectory of /boot (on the \"Mounted on\" list) and the second file is not. Creating Soft Links \u00b6 The ln -s command creates a soft link, which is also called a \"symbolic link.\" A soft link is not a regular file, but a special type of file that points to an existing file or directory. Soft links have some advantages over hard links: - They can link two files on different file systems. - They can point to a directory or special file, not just a regular file. In the following example, the ln -s command is used to create a new soft link for the existing file /home/user/newfile-link2.txt that will be named /tmp/newfile-symlink.txt. [ user@host ~ ] $ ln -s /home/user/newfile-link2.txt /tmp/newfile-symlink.txt [ user@host ~ ] $ ls -l newfile-link2.txt /tmp/newfile-symlink.txt -rw-rw-r--. 1 user user 12 Mar 11 19 :19 newfile-link2.txt lrwxrwxrwx. 1 user user 11 Mar 11 20 :59 /tmp/newfile-symlink.txt -> /home/user/ newfile-link2.txt [ user@host ~ ] $ cat /tmp/newfile-symlink.txt Soft Hello World In the preceding example, the first character of the long listing for /tmp/newfile-symlink.txt is l instead of -. This indicates that the file is a soft link and not a regular file. (A d would indicate that the file is a directory.) When the original regular file gets deleted, the soft link will still point to the file but the target is gone. A soft link pointing to a missing file is called a \"dangling soft link.\" [ user@host ~ ] $ rm -f newfile-link2.txt [ user@host ~ ] $ ls -l /tmp/newfile-symlink.txt lrwxrwxrwx. 1 user user 11 Mar 11 20 :59 /tmp/newfile-symlink.txt -> /home/user/ newfile-link2.txt [ user@host ~ ] $ cat /tmp/newfile-symlink.txt cat: /tmp/newfile-symlink.txt: No such file or directory IMPORTANT One side-effect of the dangling soft link in the preceding example is that if you later create a new file with the same name as the deleted file (/home/user/newfile- link2.txt), the soft link will no longer be \"dangling\" and will point to the new file. Hard links do not work like this. If you delete a hard link and then use normal tools (rather than ln) to create a new file with the same name, the new file will not be linked to the old file. One way to compare hard links and soft links that might help you understand how they work: A hard link points a name to data on a storage device A soft link points a name to another name, that points to data on a storage device A soft link can point to a directory. The soft link then acts like a directory. Changing to the soft link with cd will make the current working directory the linked directory. Some tools may keep track of the fact that you followed a soft link to get there. For example, by default cd will update your current working directory using the name of the soft link rather than the name of the actual directory. (There is an option, -P, that will update it with the name of the actual directory instead.) In the following example, a soft link named /home/user/configfiles is created that points to the /etc directory. [ user@host ~ ] $ ln -s /etc /home/user/configfiles [ user@host ~ ] $ cd /home/user/configfiles [ user@host configfiles ] $ pwd /home/user/configfiles MATCHING FILE NAMES WITH SHELL EXPANSIONS \u00b6 COMMAND-LINE EXPANSIONS \u00b6 The Bash shell has multiple ways of expanding a command line including pattern matching , home directory expansion, string expansion, and variable substitution. Perhaps the most powerful of these is the path name-matching capability, historically called globbing . The Bash globbing feature, sometimes called \u201cwildcards\u201d, makes managing large numbers of files easier. Using metacharacters that \u201cexpand\u201d to match file and path names being sought, commands perform on a focused set of files at once. Pattern Matching Globbing is a shell command-parsing operation that expands a wildcard pattern into a list of matching path names. Command-line metacharacters are replaced by the match list prior to command execution. Patterns that do not return matches display the original pattern request as literal text. The following are common metacharacters and pattern classes. Table of Metacharacters and Matches PATTERN MATCHES * Any string of zero or more characters. ? Any single character. [abc...] Any one character in the enclosed class (between the square brackets). [!abc...] Any one character not in the enclosed class. [^abc...] Any one character not in the enclosed class. [[:alpha:]] Any alphabetic character. [[:lower:]] Any lowercase character. [[:upper:]] Any uppercase character. [[:alnum:]] Any alphabetic character or digit. [[:punct:]] Any printable character not a space or alphanumeric. [[:digit:]] Any single digit from 0 to 9. [[:space:]] Any single white space character. This may include tabs, newlines, carriage returns, form feeds, or spaces. For the next few examples, pretend that you have run the following commands to create some sample files. [ user@host ~ ] $ mkdir glob ; cd glob [ user@host glob ] $ touch alfa bravo charlie delta echo able baker cast dog easy [ user@host glob ] $ ls able alfa baker bravo cast charlie delta dog easy echo [ user@host glob ] $ The first example will use simple pattern matches with the asterisk (*) and question mark (?) characters, and a class of characters, to match some of those file names. [ user@host glob ] $ ls a* able alfa [ user@host glob ] $ ls *a* able alfa baker bravo cast charlie delta easy [ user@host glob ] $ ls [ ac ] * able alfa cast charlie [ user@host glob ] $ ls ???? able alfa cast easy echo [ user@host glob ] $ ls ????? baker bravo delta [ user@host glob ] $ Tilde Expansion The tilde character (~), matches the current user's home directory. If it starts a string of characters other than a slash (/), the shell will interpret the string up to that slash as a user name, if one matches, and replace the string with the absolute path to that user's home directory. If no user name matches, then an actual tilde followed by the string of characters will be used instead. In the following example the echo command is used to display the value of the tilde character. The echo command can also be used to display the values of brace and variable expansion characters, and others. [ user@host glob ] $ ls ~root /root [ user@host glob ] $ ls ~user /home/user [ user@host glob ] $ ls ~/glob able alfa baker bravo cast charlie delta dog easy echo [ user@host glob ] $ echo ~/glob /home/user/glob [ user@host glob ] $ Brace Expansion Brace expansion is used to generate discretionary strings of characters. Braces contain a comma- separated list of strings, or a sequence expression. The result includes the text preceding or following the brace definition. Brace expansions may be nested, one inside another. Also double- dot syntax (..) expands to a sequence such that {m..p} will expand to m n o p. [ user@host glob ] $ echo { Sunday,Monday,Tuesday,Wednesday } .log Sunday.log Monday.log Tuesday.log Wednesday.log [ user@host glob ] $ echo file { 1 ..3 } .txt file1.txt file2.txt file3.txt [ user@host glob ] $ echo file { a..c } .txt filea.txt fileb.txt filec.txt [ user@host glob ] $ echo file { a,b }{ 1 ,2 } .txt filea1.txt filea2.txt fileb1.txt fileb2.txt [ user@host glob ] $ echo file { a { 1 ,2 } ,b,c } .txt filea1.txt filea2.txt fileb.txt filec.txt [ user@host glob ] $ A practical use of brace expansion is to quickly create a number of files or directories. [ user@host glob ] $ mkdir ../RHEL { 6 ,7,8 } [ user@host glob ] $ ls ../RHEL* RHEL6 RHEL7 RHEL8 [ user@host glob ] $ Variable Expansion A variable acts like a named container that can store a value in memory. Variables make it easy to access and modify the stored data either from the command line or within a shell script. You can assign data as a value to a variable using the following syntax: [ user@host ~ ] $ VARIABLENAME = value You can use variable expansion to convert the variable name to its value on the command line. If a string starts with a dollar sign ($), then the shell will try to use the rest of that string as a variable name and replace it with whatever value the variable has. [ user@host ~ ] $ USERNAME = operator [ user@host ~ ] $ echo $USERNAME operator To help avoid mistakes due to other shell expansions, you can put the name of the variable in curly braces, for example ${VARIABLENAME}. [ user@host ~ ] $ USERNAME = operator [ user@host ~ ] $ echo ${ USERNAME } operator Shell variables and ways to use them will be covered in more depth later in this course. Command Substitution Command substitution allows the output of a command to replace the command itself on the command line. Command substitution occurs when a command is enclosed in parentheses, and preceded by a dollar sign ($). The $(command) form can nest multiple command expansions inside each other. [ user@host glob ] $ echo Today is $( date +%A ) . Today is Wednesday. [ user@host glob ] $ echo The time is $( date +%M ) minutes past $( date +%l%p ) . The time is 26 minutes past 11AM. [ user@host glob ] $ NOTE An older form of command substitution uses backticks. Disadvantages to the backticks form include: 1) it can be easy to visually confuse backticks with single quote marks, and 2) backticks cannot be nested. Protecting Arguments from Expansion Many characters have special meaning in the Bash shell. To keep the shell from performing shell expansions on parts of your command line, you can quote and escape characters and strings. The backslash \"\\\" is an escape character in the Bash shell. It will protect the character immediately following it from expansion. [ user@host glob ] $ echo The value of $HOME is your home directory. The value of /home/user is your home directory. [ user@host glob ] $ echo The value of \\$ HOME is your home directory. The value of $HOME is your home directory. [ user@host glob ] $ In the preceding example, protecting the dollar sign from expansion caused Bash to treat it as a regular character and it did not perform variable expansion on $HOME . To protect longer character strings, single quotes (') or double quotes (\") are used to enclose strings. They have slightly different effects. Single quotes stop all shell expansion. Double quotes stop most shell expansion. Use double quotation marks to suppress globbing and shell expansion, but still allow command and variable substitution. [ user@host glob ] $ myhost = $( hostname -s ) ; echo $myhost host [ user@host glob ] $ echo \"***** hostname is ${ myhost } *****\" ***** hostname is host ***** [ user@host glob ] $ Use single quotation marks to interpret all text literally. [ user@host glob ] $ echo \"Will variable $myhost evaluate to $( hostname -s ) ?\" Will variable myhost evaluate to host? [ user@host glob ] $ echo 'Will variable $myhost evaluate to $(hostname -s)?' Will variable $myhost evaluate to $( hostname -s ) ? [ user@host glob ] $ IMPORTANT The single quote (') and the command substitution backtick (`) can be easy to confuse, both on the screen and on the keyboard. Using one when you mean to use SUMMARY \u00b6 In this chapter, you learned: Files on a Linux system are organized into a single inverted tree of directories, known as a file- system hierarchy. Absolute paths start with a / and specify the location of a file in the file-system hierarchy. Relative paths do not start with a / and specify the location of a file relative to the current working directory. Five key commands are used to manage files: mkdir, rmdir, cp, mv, and rm. Hard links and soft links are different ways to have multiple file names point to the same data. The Bash shell provides pattern matching, expansion, and substitution features to help you efficiently run commands.","title":"Managing Files From The Command Line"},{"location":"redhat/manage/#describing-linux-file-system-hierarchy-concepts","text":"","title":"DESCRIBING LINUX FILE SYSTEM HIERARCHY CONCEPTS"},{"location":"redhat/manage/#the-file-system-hierarchy","text":"All files on a Linux system are stored on file systems, which are organized into a single inverted tree of directories, known as a file-system hierarchy. This tree is inverted because the root of the tree is said to be at the top of the hierarchy, and the branches of directories and subdirectories stretch below the root. The / directory is the root directory at the top of the file-system hierarchy. The / character is also used as a directory separator in file names. For example, if etc is a subdirectory of the / directory, you could refer to that directory as /etc. Likewise, if the /etc directory contained a file named issue, you could refer to that file as /etc/issue . Subdirectories of / are used for standardized purposes to organize files by type and purpose. This makes it easier to find files. For example, in the root directory, the subdirectory /boot is used for storing files needed to boot the system. NOTE The following terms help to describe file-system directory contents: static content remains unchanged until explicitly edited or reconfigured. dynamic or variable content may be modified or appended by active processes. persistent content remains after a reboot, like configuration settings. runtime content is process- or system-specific content that is deleted by a reboot. The following table lists some of the most important directories on the system by name and purpose. Important Red Hat Enterprise Linux Directories /usr Installed software, shared libraries, include files, and read-only program data. Important subdirectories include: /usr/bin : User commands. /usr/sbin : System administration commands. /usr/local : Locally customized software. /etc Configuration files specific to this system. /var Variable data specific to this system that should persist between boots. Files that dynamically change, such as databases, cache directories, log files, printer-spooled documents, and website content may be found under /var . /run Runtime data for processes started since the last boot. This includes process ID files and lock files, among other things. The contents of this directory are recreated on reboot. This directory consolidates /var/run and /var/lock from earlier versions of Red Hat Enterprise Linux. /home Home directories are where regular users store their personal data and configuration files. /root Home directory for the administrative superuser, root. /tmp A world-writable space for temporary files. Files which have not been accessed, changed, or modified for 10 days are deleted from this directory automatically. Another temporary directory exists, /var/tmp , in which files that have not been accessed, changed, or modified in more than 30 days are deleted automatically. /boot Files needed in order to start the boot process. /dev Contains special device files that are used by the system to access hardware. IMPORTANT In Red Hat Enterprise Linux 7 and later, four older directories in / have identical contents to their counterparts located in /usr : /bin and /usr/bin /sbin and /usr/sbin /lib and /usr/lib /lib64 and /usr/lib64 In earlier versions of Red Hat Enterprise Linux, these were distinct directories containing different sets of files. In Red Hat Enterprise Linux 7 and later, the directories in / are symbolic links to the matching directories in /usr .","title":"THE FILE-SYSTEM HIERARCHY"},{"location":"redhat/manage/#specifying-files-by-name","text":"","title":"SPECIFYING FILES BY NAME"},{"location":"redhat/manage/#absolute-paths-and-relative-paths","text":"The path of a file or directory specifies its unique file system location. Following a file path traverses one or more named subdirectories, delimited by a forward slash (/), until the destination is reached. Directories, also called folders, contain other files and other subdirectories. They can be referenced in the same manner as files. IMPORTANT A space character is acceptable as part of a Linux file name. However, spaces are also used by the shell to separate options and arguments on the command line. If you enter a command that includes a file that has a space in its name, the shell can misinterpret the command and assume that you want to start a new file name or other argument at the space. It is possible to avoid this by putting file names in quotes. However, if you do not need to use spaces in file names, it can be simpler to simply avoid using them. Absolute Paths An absolute path is a fully qualified name, specifying the files exact location in the file system hierarchy. It begins at the root (/) directory and specifies each subdirectory that must be traversed to reach the specific file. Every file in a file system has a unique absolute path name, recognized with a simple rule: A path name with a forward slash (/) as the first character is an absolute path name. For example, the absolute path name for the system message log file is /var/log/messages . Absolute path names can be long to type, so files may also be located relative to the current working directory for your shell prompt. The Current Working Directory and Relative Paths When a user logs in and opens a command window, the initial location is normally the user's home directory. System processes also have an initial directory. Users and processes navigate to other directories as needed; the terms working directory or current working directory refer to their current location. Like an absolute path, a relative path identifies a unique file, specifying only the path necessary to reach the file from the working directory. Recognizing relative path names follows a simple rule: A path name with anything other than a forward slash as the first character is a relative path name. A user in the /var directory could refer to the message log file relatively as log/messages . Linux file systems, including, but not limited to, ext4, XFS, GFS2, and GlusterFS, are case-sensitive. Creating FileCase.txt and filecase.txt in the same directory results in two unique files. Non-Linux file systems might work differently. For example, VFAT, Microsoft's NTFS, and Apple's HFS+ have case preserving behavior. Although these file systems are not case-sensitive, they do display file names with the original capitalization used when the file was created. Therefore, if you tried to make the files in the preceding example on a VFAT file system, both names would be treated as pointing to the same file instead of two different files.","title":"ABSOLUTE PATHS AND RELATIVE PATHS"},{"location":"redhat/manage/#navigating-paths","text":"The pwd command displays the full path name of the current working directory for that shell. This can help you determine the syntax to reach files using relative path names. The ls command lists directory contents for the specified directory or, if no directory is given, for the current working directory. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ ls Desktop Documents Downloads Music Pictures Public Templates Videos [ user@host ~ ] $ Use the cd command to change your shell's current working directory. If you do not specify any arguments to the command, it will change to your home directory. In the following example, a mixture of absolute and relative paths are used with the cd command to change the current working directory for the shell. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ cd Videos [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd /home/user/Documents [ user@host Documents ] $ pwd /home/user/Documents [ user@host Documents ] $ cd [ user@host ~ ] $ pwd /home/user As you can see in the preceding example, the default shell prompt also displays the last component of the absolute path to the current working directory. For example, for /home/user/Videos , only Videos displays. The prompt displays the tilde character (~) when your current working directory is your home directory. The touch command normally updates a file's timestamp to the current date and time without otherwise modifying it. This is useful for creating empty files, which can be used for practice, because \"touching\" a file name that does not exist causes the file to be created. In the following example, the touch command creates practice files in the Documents and Videos subdirectories. [ user@host ~ ] $ touch Videos/blockbuster1.ogg [ user@host ~ ] $ touch Videos/blockbuster2.ogg [ user@host ~ ] $ touch Documents/thesis_chapter1.odf [ user@host ~ ] $ touch Documents/thesis_chapter2.odf [ user@host ~ ] $ The ls command has multiple options for displaying attributes on files. The most common and useful are -l (long listing format), -a (all files, including hidden files), and -R (recursive, to include the contents of all subdirectories). [ user@host ~ ] $ ls -l total 15 drwxr-xr-x. 2 user user 4096 Feb 7 14 :02 Desktop drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Documents drwxr-xr-x. 3 user user 4096 Jan 9 15 :00 Downloads drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Music drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Pictures drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Public drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Templates drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Videos [ user@host ~ ] $ ls -la total 15 drwx------. 16 user user 4096 Feb 8 16 :15 . drwxr-xr-x. 6 root root 4096 Feb 8 16 :13 .. -rw-------. 1 user user 22664 Feb 8 00 :37 .bash_history -rw-r--r--. 1 user user 18 Jul 9 2013 .bash_logout -rw-r--r--. 1 user user 176 Jul 9 2013 .bash_profile -rw-r--r--. 1 user user 124 Jul 9 2013 .bashrc drwxr-xr-x. 4 user user 4096 Jan 20 14 :02 .cache drwxr-xr-x. 8 user user 4096 Feb 5 11 :45 .config drwxr-xr-x. 2 user user 4096 Feb 7 14 :02 Desktop drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Documents drwxr-xr-x. 3 user user 4096 Jan 25 20 :48 Downloads drwxr-xr-x. 11 user user 4096 Feb 6 13 :07 .gnome2 drwx------. 2 user user 4096 Jan 20 14 :02 .gnome2_private -rw-------. 1 user user 15190 Feb 8 09 :49 .ICEauthority drwxr-xr-x. 3 user user 4096 Jan 9 15 :00 .local drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Music drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Pictures drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Public drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Templates drwxr-xr-x. 2 user user 4096 Jan 9 15 :00 Videos The two special directories at the top of the listing refer to the current directory (.) and the parent directory (..). These special directories exist in every directory on the system. You will discover their usefulness when you start using file management commands. IMPORTANT File names beginning with a dot (.) indicate hidden files; you cannot see them in the normal view using ls and other commands. This is not a security feature. Hidden files keep necessary user configuration files from cluttering home directories. Many commands process hidden files only with specific command-line options, preventing one user's configuration from being accidentally copied to other directories or users. To protect file contents from improper viewing requires the use of file permissions . [ user@host ~ ] $ ls -R .: Desktop Documents Downloads Music Pictures Public Templates Videos ./Desktop: ./Documents: thesis_chapter1.odf thesis_chapter2.odf ./Downloads: ./Music: ./Pictures: ./Public: ./Templates: ./Videos: blockbuster1.ogg blockbuster2.ogg [ user@host ~ ] $ The cd command has many options. A few are so useful as to be worth practicing early and using often. The command cd - changes to the previous directory; where the user was previously to the current directory. The following example illustrates this behavior, alternating between two directories, which is useful when processing a series of similar tasks. [ user@host ~ ] $ cd Videos [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd /home/user/Documents [ user@host Documents ] $ pwd /home/user/Documents [ user@host Documents ] $ cd - [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd - [ user@host Documents ] $ pwd /home/user/Documents [ user@host Documents ] $ cd - [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd [ user@host ~ ] $ The cd .. command uses the .. hidden directory to move up one level to the parent directory, without needing to know the exact parent name. The other hidden directory (.) specifies the current directory on commands in which the current location is either the source or destination argument, avoiding the need to type out the directory's absolute path name. [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd . [ user@host Videos ] $ pwd /home/user/Videos [ user@host Videos ] $ cd .. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ cd .. [ user@host home ] $ pwd /home [ user@host home ] $ cd .. [ user@host / ] $ pwd / [ user@host / ] $ cd [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $","title":"NAVIGATING PATHS"},{"location":"redhat/manage/#managing-files-using-command-line-tools","text":"","title":"MANAGING FILES USING COMMAND-LINE TOOLS"},{"location":"redhat/manage/#command-line-file-management","text":"To manage files, you need to be able to create, remove, copy, and move them. You also need to organize them logically into directories, which you also need to be able to create, remove, copy, and move. The following table summarizes some of the most common file management commands. The remainder of this section will discuss ways to use these commands in more detail. Common file management commands Create a directory mkdir directory Copy a file cp file new-file Copy a directory and its contents cp -r directory new-directory Move or rename a file or directory mv file new-file Remove a file rm file Remove a directory containing files rm -r directory Remove an empty directory rmdir directory","title":"COMMAND-LINE FILE MANAGEMENT"},{"location":"redhat/manage/#creating-directories","text":"The mkdir command creates one or more directories or subdirectories. It takes as arguments a list of paths to the directories you want to create. The mkdir command will fail with an error if the directory already exists, or if you are trying to create a subdirectory in a directory that does not exist. The -p (parent) option creates missing parent directories for the requested destination. Use the mkdir -p command with caution, because spelling mistakes can create unintended directories without generating error messages. In the following example, pretend that you are trying to create a directory in the Videos directory [ user@host ~ ] $ mkdir Video/Watched mkdir: cannot create directory ` Video/Watched ' : No such file or directory The mkdir command failed because Videos was misspelled and the directory Video does not exist. If you had used the mkdir command with the -p option, the directory Video would be created, which was not what you had intended, and the subdirectory Watched would be created in that incorrect directory. After correctly spelling the Videos parent directory, creating the Watched subdirectory will succeed. [ user@host ~ ] $ mkdir Videos/Watched [ user@host ~ ] $ ls -R Videos Videos/: blockbuster1.ogg blockbuster2.ogg Watched Videos/Watched: In the following example, files and directories are organized beneath the /home/user/ Documents directory. Use the mkdir command and a space-delimited list of the directory names to create multiple directories. [ user@host ~ ] $ cd Documents [ user@host Documents ] $ mkdir ProjectX ProjectY [ user@host Documents ] $ ls ProjectX ProjectY Use the mkdir -p command and space-delimited relative paths for each of the subdirectory names to create multiple parent directories with subdirectories. [ user@host Documents ] $ mkdir -p Thesis/Chapter1 Thesis/Chapter2 Thesis/Chapter3 [ user@host Documents ] $ cd [ user@host ~ ] $ ls -R Videos Documents Documents: ProjectX ProjectY Thesis Documents/ProjectX: Documents/ProjectY: Documents/Thesis: Chapter1 Chapter2 Chapter3 Documents/Thesis/Chapter1: Documents/Thesis/Chapter2: Documents/Thesis/Chapter3: Videos: blockbuster1.ogg blockbuster2.ogg Watched Videos/Watched: The last mkdir command created three ChapterN subdirectories with one command. The -p option created the missing parent directory Thesis.","title":"Creating Directories"},{"location":"redhat/manage/#copying-files","text":"The cp command copies a file, creating a new file either in the current directory or in a specified directory. It can also copy multiple files to a directory. WARNING If the destination file already exists, the cp command overwrites the file. [ user@host ~ ] $ cd Videos [ user@host Videos ] $ cp blockbuster1.ogg blockbuster3.ogg [ user@host Videos ] $ ls -l total 0 -rw-rw-r--. 1 user user 0 Feb 8 16 :23 blockbuster1.ogg -rw-rw-r--. 1 user user 0 Feb 8 16 :24 blockbuster2.ogg -rw-rw-r--. 1 user user 0 Feb 8 16 :34 blockbuster3.ogg drwxrwxr-x. 2 user user 4096 Feb 8 16 :05 Watched [ user@host Videos ] $ When copying multiple files with one command, the last argument must be a directory. Copied files retain their original names in the new directory. If a file with the same name exists in the target directory, the existing file is overwritten. By default, the cp does not copy directories; it ignores them. In the following example, two directories are listed, Thesis and ProjectX. Only the last argument, ProjectX is valid as a destination. The Thesis directory is ignored. [ user@host Videos ] $ cd ../Documents [ user@host Documents ] $ cp thesis_chapter1.odf thesis_chapter2.odf Thesis ProjectX cp: omitting directory ` Thesis ' [ user@host Documents ] $ ls Thesis ProjectX ProjectX: thesis_chapter1.odf thesis_chapter2.odf Thesis: Chapter1 Chapter2 Chapter3 In the first cp command, the Thesis directory failed to copy, but the thesis_chapter1.odf and thesis_chapter2.odf files succeeded. If you want to copy a file to the current working directory, you can use the special . directory: [ user@host ~ ] $ cp /etc/hostname . [ user@host ~ ] $ cat hostname host.example.com [ user@host ~ ] $ Use the copy command with the -r (recursive) option, to copy the Thesis directory and its contents to the ProjectX directory. [ user@host Documents ] $ cp -r Thesis ProjectX [ user@host Documents ] $ ls -R ProjectX ProjectX: Thesis thesis_chapter1.odf thesis_chapter2.odf ProjectX/Thesis: Chapter1 Chapter2 Chapter3 ProjectX/Thesis/Chapter1: ProjectX/Thesis/Chapter2: thesis_chapter2.odf ProjectX/Thesis/Chapter3:","title":"Copying Files"},{"location":"redhat/manage/#moving-files","text":"The mv command moves files from one location to another. If you think of the absolute path to a file as its full name, moving a file is effectively the same as renaming a file. File contents remain unchanged. Use the mv command to rename a file. [ user@host Videos ] $ cd ../Documents [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter1.odf -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2.odf [ user@host Documents ] $ mv thesis_chapter2.odf thesis_chapter2_reviewed.odf [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter1.odf -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2_reviewed.odf Use the mv command to move a file to a different directory. [ user@host Documents ] $ ls Thesis/Chapter1 [ user@host Documents ] $ [ user@host Documents ] $ mv thesis_chapter1.odf Thesis/Chapter1 [ user@host Documents ] $ ls Thesis/Chapter1 thesis_chapter1.odf [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2_reviewed.odf","title":"Moving Files"},{"location":"redhat/manage/#removing-files-and-directories","text":"The rm command removes files. By default, rm will not remove directories that contain files, unless you add the -r or --recursive option. IMPORTANT There is no command-line undelete feature, nor a \"trash bin\" from which you can restore files staged for deletion. It is a good idea to verify your current working directory before removing a file or directory. [ user@host Documents ] $ pwd /home/student/Documents Use the rm command to remove a single file from your working directory. [ user@host Documents ] $ ls -l thesis* -rw-rw-r--. 1 user user 0 Feb 6 21 :16 thesis_chapter2_reviewed.odf [ user@host Documents ] $ rm thesis_chapter2_reviewed.odf [ user@host Documents ] $ ls -l thesis* ls: cannot access 'thesis*' : No such file or directory If you attempt to use the rm command to remove a directory without using the -r option, the command will fail. [ user@host Documents ] $ rm Thesis/Chapter1 rm: cannot remove ` Thesis/Chapter1 ' : Is a directory Use the rm -r command to remove a subdirectory and its contents. [ user@host Documents ] $ ls -R Thesis Thesis/: Chapter1 Chapter2 Chapter3 Thesis/Chapter1: thesis_chapter1.odf Thesis/Chapter2: thesis_chapter2.odf Thesis/Chapter3: [ user@host Documents ] $ rm -r Thesis/Chapter1 [ user@host Documents ] $ ls -l Thesis total 8 drwxrwxr-x. 2 user user 4096 Feb 11 12 :47 Chapter2 drwxrwxr-x. 2 user user 4096 Feb 11 12 :48 Chapter3 The rm -r command traverses each subdirectory first, individually removing their files before removing each directory. You can use the rm -ri command to interactively prompt for confirmation before deleting. This is essentially the opposite of using the -f option, which forces the removal without prompting the user for confirmation. [ user@host Documents ] $ rm -ri Thesis rm: descend into directory ` Thesis '? y rm: descend into directory `Thesis/Chapter2' ? y rm: remove regular empty file ` Thesis/Chapter2/thesis_chapter2.odf '? y rm: remove directory `Thesis/Chapter2' ? y rm: remove directory ` Thesis/Chapter3 '? y rm: remove directory `Thesis' ? y WARNING If you specify both the -i and -f options, the -f option takes priority and you will not be prompted for confirmation before rm deletes files. In the following example, the rmdir command only removes the directory that is empty. Just like the earlier example, you must use the rm -r command to remove a directory that contains content. [ user@host Documents ] $ pwd /home/student/Documents [ user@host Documents ] $ rmdir ProjectY [ user@host Documents ] $ rmdir ProjectX rmdir: failed to remove ` ProjectX ' : Directory not empty [ user@host Documents ] $ rm -r ProjectX [ user@host Documents ] $ ls -lR .: total 0 [ user@host Documents ] $ NOTE The rm command with no options cannot remove an empty directory. You must use the rmdir command, rm -d (which is equivalent to rmdir), or rm -r.","title":"Removing Files and Directories"},{"location":"redhat/manage/#making-links-between-files","text":"","title":"MAKING LINKS BETWEEN FILES"},{"location":"redhat/manage/#managing-links-between-files","text":"Hard Links and Soft Links It is possible to create multiple names that point to the same file. There are two ways to do this: by creating a hard link to the file, or by creating a soft link (sometimes called a symbolic link) to the file. Each has its advantages and disadvantages. Creating Hard Links Every file starts with a single hard link, from its initial name to the data on the file system. When you create a new hard link to a file, you create another name that points to that same data. The new hard link acts exactly like the original file name. Once created, you cannot tell the difference between the new hard link and the original name of the file. You can find out if a file has multiple hard links with the ls -l command. One of the things it reports is each file's link count, the number of hard links the file has. [ user@host ~ ] $ pwd /home/user [ user@host ~ ] $ ls -l newfile.txt -rw-r--r--. 1 user user 0 Mar 11 19 :19 newfile.txt In the preceding example, the link count of newfile.txt is 1. It has exactly one absolute path, which is /home/user/newfile.txt. You can use the ln command to create a new hard link (another name) that points to an existing file. The command needs at least two arguments, a path to the existing file, and the path to the hard link that you want to create. The following example creates a hard link named newfile-link2.txt for the existing file newfile.txt in the /tmp directory. [ user@host ~ ] $ ln newfile.txt /tmp/newfile-hlink2.txt [ user@host ~ ] $ ls -l newfile.txt /tmp/newfile-hlink2.txt -rw-rw-r--. 2 user user 12 Mar 11 19 :19 newfile.txt -rw-rw-r--. 2 user user 12 Mar 11 19 :19 /tmp/newfile-hlink2.txt If you want to find out whether two files are hard links of each other, one way is to use the -i option with the ls command to list the files' inode number. If the files are on the same file system (discussed in a moment) and their inode numbers are the same, the files are hard links pointing to the same data. [ user@host ~ ] $ ls -il newfile.txt /tmp/newfile-hlink2.txt 8924107 -rw-rw-r--. 2 user user 12 Mar 11 19 :19 newfile.txt 8924107 -rw-rw-r--. 2 user user 12 Mar 11 19 :19 /tmp/newfile-hlink2.txt IMPORTANT All hard links that reference the same file will have the same link count, access permissions, user and group ownerships, time stamps, and file content. If any of that information is changed using one hard link, all other hard links pointing to the same file will show the new information as well. This is because each hard link points to the same data on the storage device. Even if the original file gets deleted, the contents of the file are still available as long as at least one hard link exists. Data is only deleted from storage when the last hard link is deleted. [ user@host ~ ] $ rm -f newfile.txt [ user@host ~ ] $ ls -l /tmp/newfile-hlink2.txt -rw-rw-r--. 1 user user 12 Mar 11 19 :19 /tmp/newfile-hlink2.txt [ user@host ~ ] $ cat /tmp/newfile-hlink2.txt Hello World","title":"MANAGING LINKS BETWEEN FILES"},{"location":"redhat/manage/#limitations-of-hard-links","text":"Hard links have some limitations. Firstly, hard links can only be used with regular files. You cannot use ln to create a hard link to a directory or special file. Secondly, hard links can only be used if both files are on the same file system. The file-system hierarchy can be made up of multiple storage devices. Depending on the configuration of your system, when you change into a new directory, that directory and its contents may be stored on a different file system. You can use the df command to list the directories that are on different file systems. For example, you might see output like the following: [ user@host ~ ] $ df Filesystem 1K-blocks Used Available Use% Mounted on devtmpfs 886788 0 886788 0 % /dev tmpfs 902108 0 902108 0 % /dev/shm tmpfs 902108 8696 893412 1 % /run tmpfs 902108 0 902108 0 % /sys/fs/cgroup /dev/mapper/rhel_rhel8--root 10258432 1630460 8627972 16 % / /dev/sda1 1038336 167128 871208 17 % /boot tmpfs 180420 0 180420 0 % /run/user/1000 [ user@host ~ ] $ Files in two different \"Mounted on\" directories and their subdirectories are on different file systems. (The most specific match wins.) So, the system in this example, you can create a hard link between /var/tmp/link1 and /home/user/file because they are both subdirectories of / but not any other directory on the list. But you cannot create a hard link between /boot/ test/badlink and /home/user/file because the first file is in a subdirectory of /boot (on the \"Mounted on\" list) and the second file is not.","title":"Limitations of Hard Links"},{"location":"redhat/manage/#creating-soft-links","text":"The ln -s command creates a soft link, which is also called a \"symbolic link.\" A soft link is not a regular file, but a special type of file that points to an existing file or directory. Soft links have some advantages over hard links: - They can link two files on different file systems. - They can point to a directory or special file, not just a regular file. In the following example, the ln -s command is used to create a new soft link for the existing file /home/user/newfile-link2.txt that will be named /tmp/newfile-symlink.txt. [ user@host ~ ] $ ln -s /home/user/newfile-link2.txt /tmp/newfile-symlink.txt [ user@host ~ ] $ ls -l newfile-link2.txt /tmp/newfile-symlink.txt -rw-rw-r--. 1 user user 12 Mar 11 19 :19 newfile-link2.txt lrwxrwxrwx. 1 user user 11 Mar 11 20 :59 /tmp/newfile-symlink.txt -> /home/user/ newfile-link2.txt [ user@host ~ ] $ cat /tmp/newfile-symlink.txt Soft Hello World In the preceding example, the first character of the long listing for /tmp/newfile-symlink.txt is l instead of -. This indicates that the file is a soft link and not a regular file. (A d would indicate that the file is a directory.) When the original regular file gets deleted, the soft link will still point to the file but the target is gone. A soft link pointing to a missing file is called a \"dangling soft link.\" [ user@host ~ ] $ rm -f newfile-link2.txt [ user@host ~ ] $ ls -l /tmp/newfile-symlink.txt lrwxrwxrwx. 1 user user 11 Mar 11 20 :59 /tmp/newfile-symlink.txt -> /home/user/ newfile-link2.txt [ user@host ~ ] $ cat /tmp/newfile-symlink.txt cat: /tmp/newfile-symlink.txt: No such file or directory IMPORTANT One side-effect of the dangling soft link in the preceding example is that if you later create a new file with the same name as the deleted file (/home/user/newfile- link2.txt), the soft link will no longer be \"dangling\" and will point to the new file. Hard links do not work like this. If you delete a hard link and then use normal tools (rather than ln) to create a new file with the same name, the new file will not be linked to the old file. One way to compare hard links and soft links that might help you understand how they work: A hard link points a name to data on a storage device A soft link points a name to another name, that points to data on a storage device A soft link can point to a directory. The soft link then acts like a directory. Changing to the soft link with cd will make the current working directory the linked directory. Some tools may keep track of the fact that you followed a soft link to get there. For example, by default cd will update your current working directory using the name of the soft link rather than the name of the actual directory. (There is an option, -P, that will update it with the name of the actual directory instead.) In the following example, a soft link named /home/user/configfiles is created that points to the /etc directory. [ user@host ~ ] $ ln -s /etc /home/user/configfiles [ user@host ~ ] $ cd /home/user/configfiles [ user@host configfiles ] $ pwd /home/user/configfiles","title":"Creating Soft Links"},{"location":"redhat/manage/#matching-file-names-with-shell-expansions","text":"","title":"MATCHING FILE NAMES WITH SHELL EXPANSIONS"},{"location":"redhat/manage/#command-line-expansions","text":"The Bash shell has multiple ways of expanding a command line including pattern matching , home directory expansion, string expansion, and variable substitution. Perhaps the most powerful of these is the path name-matching capability, historically called globbing . The Bash globbing feature, sometimes called \u201cwildcards\u201d, makes managing large numbers of files easier. Using metacharacters that \u201cexpand\u201d to match file and path names being sought, commands perform on a focused set of files at once. Pattern Matching Globbing is a shell command-parsing operation that expands a wildcard pattern into a list of matching path names. Command-line metacharacters are replaced by the match list prior to command execution. Patterns that do not return matches display the original pattern request as literal text. The following are common metacharacters and pattern classes. Table of Metacharacters and Matches PATTERN MATCHES * Any string of zero or more characters. ? Any single character. [abc...] Any one character in the enclosed class (between the square brackets). [!abc...] Any one character not in the enclosed class. [^abc...] Any one character not in the enclosed class. [[:alpha:]] Any alphabetic character. [[:lower:]] Any lowercase character. [[:upper:]] Any uppercase character. [[:alnum:]] Any alphabetic character or digit. [[:punct:]] Any printable character not a space or alphanumeric. [[:digit:]] Any single digit from 0 to 9. [[:space:]] Any single white space character. This may include tabs, newlines, carriage returns, form feeds, or spaces. For the next few examples, pretend that you have run the following commands to create some sample files. [ user@host ~ ] $ mkdir glob ; cd glob [ user@host glob ] $ touch alfa bravo charlie delta echo able baker cast dog easy [ user@host glob ] $ ls able alfa baker bravo cast charlie delta dog easy echo [ user@host glob ] $ The first example will use simple pattern matches with the asterisk (*) and question mark (?) characters, and a class of characters, to match some of those file names. [ user@host glob ] $ ls a* able alfa [ user@host glob ] $ ls *a* able alfa baker bravo cast charlie delta easy [ user@host glob ] $ ls [ ac ] * able alfa cast charlie [ user@host glob ] $ ls ???? able alfa cast easy echo [ user@host glob ] $ ls ????? baker bravo delta [ user@host glob ] $ Tilde Expansion The tilde character (~), matches the current user's home directory. If it starts a string of characters other than a slash (/), the shell will interpret the string up to that slash as a user name, if one matches, and replace the string with the absolute path to that user's home directory. If no user name matches, then an actual tilde followed by the string of characters will be used instead. In the following example the echo command is used to display the value of the tilde character. The echo command can also be used to display the values of brace and variable expansion characters, and others. [ user@host glob ] $ ls ~root /root [ user@host glob ] $ ls ~user /home/user [ user@host glob ] $ ls ~/glob able alfa baker bravo cast charlie delta dog easy echo [ user@host glob ] $ echo ~/glob /home/user/glob [ user@host glob ] $ Brace Expansion Brace expansion is used to generate discretionary strings of characters. Braces contain a comma- separated list of strings, or a sequence expression. The result includes the text preceding or following the brace definition. Brace expansions may be nested, one inside another. Also double- dot syntax (..) expands to a sequence such that {m..p} will expand to m n o p. [ user@host glob ] $ echo { Sunday,Monday,Tuesday,Wednesday } .log Sunday.log Monday.log Tuesday.log Wednesday.log [ user@host glob ] $ echo file { 1 ..3 } .txt file1.txt file2.txt file3.txt [ user@host glob ] $ echo file { a..c } .txt filea.txt fileb.txt filec.txt [ user@host glob ] $ echo file { a,b }{ 1 ,2 } .txt filea1.txt filea2.txt fileb1.txt fileb2.txt [ user@host glob ] $ echo file { a { 1 ,2 } ,b,c } .txt filea1.txt filea2.txt fileb.txt filec.txt [ user@host glob ] $ A practical use of brace expansion is to quickly create a number of files or directories. [ user@host glob ] $ mkdir ../RHEL { 6 ,7,8 } [ user@host glob ] $ ls ../RHEL* RHEL6 RHEL7 RHEL8 [ user@host glob ] $ Variable Expansion A variable acts like a named container that can store a value in memory. Variables make it easy to access and modify the stored data either from the command line or within a shell script. You can assign data as a value to a variable using the following syntax: [ user@host ~ ] $ VARIABLENAME = value You can use variable expansion to convert the variable name to its value on the command line. If a string starts with a dollar sign ($), then the shell will try to use the rest of that string as a variable name and replace it with whatever value the variable has. [ user@host ~ ] $ USERNAME = operator [ user@host ~ ] $ echo $USERNAME operator To help avoid mistakes due to other shell expansions, you can put the name of the variable in curly braces, for example ${VARIABLENAME}. [ user@host ~ ] $ USERNAME = operator [ user@host ~ ] $ echo ${ USERNAME } operator Shell variables and ways to use them will be covered in more depth later in this course. Command Substitution Command substitution allows the output of a command to replace the command itself on the command line. Command substitution occurs when a command is enclosed in parentheses, and preceded by a dollar sign ($). The $(command) form can nest multiple command expansions inside each other. [ user@host glob ] $ echo Today is $( date +%A ) . Today is Wednesday. [ user@host glob ] $ echo The time is $( date +%M ) minutes past $( date +%l%p ) . The time is 26 minutes past 11AM. [ user@host glob ] $ NOTE An older form of command substitution uses backticks. Disadvantages to the backticks form include: 1) it can be easy to visually confuse backticks with single quote marks, and 2) backticks cannot be nested. Protecting Arguments from Expansion Many characters have special meaning in the Bash shell. To keep the shell from performing shell expansions on parts of your command line, you can quote and escape characters and strings. The backslash \"\\\" is an escape character in the Bash shell. It will protect the character immediately following it from expansion. [ user@host glob ] $ echo The value of $HOME is your home directory. The value of /home/user is your home directory. [ user@host glob ] $ echo The value of \\$ HOME is your home directory. The value of $HOME is your home directory. [ user@host glob ] $ In the preceding example, protecting the dollar sign from expansion caused Bash to treat it as a regular character and it did not perform variable expansion on $HOME . To protect longer character strings, single quotes (') or double quotes (\") are used to enclose strings. They have slightly different effects. Single quotes stop all shell expansion. Double quotes stop most shell expansion. Use double quotation marks to suppress globbing and shell expansion, but still allow command and variable substitution. [ user@host glob ] $ myhost = $( hostname -s ) ; echo $myhost host [ user@host glob ] $ echo \"***** hostname is ${ myhost } *****\" ***** hostname is host ***** [ user@host glob ] $ Use single quotation marks to interpret all text literally. [ user@host glob ] $ echo \"Will variable $myhost evaluate to $( hostname -s ) ?\" Will variable myhost evaluate to host? [ user@host glob ] $ echo 'Will variable $myhost evaluate to $(hostname -s)?' Will variable $myhost evaluate to $( hostname -s ) ? [ user@host glob ] $ IMPORTANT The single quote (') and the command substitution backtick (`) can be easy to confuse, both on the screen and on the keyboard. Using one when you mean to use","title":"COMMAND-LINE EXPANSIONS"},{"location":"redhat/manage/#summary","text":"In this chapter, you learned: Files on a Linux system are organized into a single inverted tree of directories, known as a file- system hierarchy. Absolute paths start with a / and specify the location of a file in the file-system hierarchy. Relative paths do not start with a / and specify the location of a file relative to the current working directory. Five key commands are used to manage files: mkdir, rmdir, cp, mv, and rm. Hard links and soft links are different ways to have multiple file names point to the same data. The Bash shell provides pattern matching, expansion, and substitution features to help you efficiently run commands.","title":"SUMMARY"},{"location":"redhat/monitor/","text":"LISTING PROCESSES \u00b6 DEFINITION OF A PROCESS \u00b6 A process is a running instance of a launched, executable program. A process consists of: An address space of allocated memory Security properties including ownership credentials and privileges One or more execution threads of program code Process state The environment of a process includes: Local and global variables A current scheduling context Allocated system resources, such as file descriptors and network ports An existing ( parent ) process duplicates its own address space ( fork ) to create a new ( child ) process structure. Every new process is assigned a unique process ID (PID) for tracking and security. The PID and the parent's process ID (PPID) are elements of the new process environment. Any process may create a child process. All processes are descendants of the first system process, systemd on a Red Hat Enterprise Linux 8 system). Through the fork routine, a child process inherits security identities, previous and current file descriptors, port and resource privileges, environment variables, and program code. A child process may then exec its own program code. Normally, a parent process sleeps while the child process runs, setting a request ( wait ) to be signaled when the child completes. Upon exit, the child process has already closed or discarded its resources and environment. The only remaining resource, called a zombie , is an entry in the process table. The parent, signaled awake when the child exited, cleans the process table of the child's entry, thus freeing the last resource of the child process. The parent process then continues with its own program code execution. DESCRIBING PROCESS STATES \u00b6 In a multitasking operating system, each CPU (or CPU core) can be working on one process at a single point in time. As a process runs, its immediate requirements for CPU time and resource allocation change. Processes are assigned a state , which changes as circumstances dictate. Linux process states are illustrated in the previous diagram and described in the following table: Linux Process States NAME FLAG KERNEL-DEFINED STATE NAME AND DESCRIPTION Running R TASK_RUNNING: The process is either executing on a CPU or waiting to run.Process can be executing user routines or kernel routines (system calls), or be queued and ready when in the Running (or Runnable) state. Sleeping S TASK_INTERRUPTIBLE: The process is waiting for some condition: a hardware request, system resource access, or signal. When an event or signal satisfies the condition, the process returns to Running . Sleeping D TASK_UNINTERRUPTIBLE: This process is also Sleeping, but unlike S state, does not respond to signals. Used only when process interruption may cause an unpredictable device state. Sleeping K TASK_KILLABLE: Identical to the uninterruptible D state, but modified to allow a waiting task to respond to the signal that it should be killed (exit completely). Utilities frequently display Killable processes as D state. Sleeping I TASK_REPORT_IDLE: A subset of state D . The kernel does not count these processes when calculating load average. Used for kernel threads. Flags TASK_UNINTERRUPTABLE and TASK_NOLOAD are set. Similar to TASK_KILLABLE, also a subset of state D . It accepts fatal signals. Stopped T TASK_STOPPED: The process has been Stopped (suspended), usually by being signaled by a user or another process. The process can be continued (resumed) by another signal to return to Running . Stopped T TASK_TRACED: A process that is being debugged is also temporarily Stopped and shares the same T state flag. Zombie Z EXIT_ZOMBIE: A child process signals its parent as it exits. All resources except for the process identity (PID) are released. Zombie X EXIT_DEAD: When the parent cleans up (reaps) the remaining child process structure, the process is now released completely. This state will never be observed in process-listing utilities. Why Process States are Important When troubleshooting a system, it is important to understand how the kernel communicates with processes and how processes communicate with each other. At process creation, the system assigns the process a state. The S column of the top command or the STAT column of the ps show the state of each process. On a single CPU system, only one process can run at a time. It is possible to see several processes with a state of R . However, not all of them will be running consecutively, some of them will be in status waiting . [ user@host ~ ] $ top PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 244344 13684 9024 S 0 .0 0 .7 0 :02.46 systemd 2 root 20 0 0 0 0 S 0 .0 0 .0 0 :00.00 kthreadd ...output omitted... [ user@host ~ ] $ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND ...output omitted... root 2 0 .0 0 .0 0 0 ? S 11 :57 0 :00 [ kthreadd ] student 3448 0 .0 0 .2 266904 3836 pts/0 R+ 18 :07 0 :00 ps aux ...output omitted... Process can be suspended, stopped, resumed, terminated, and interrupted using signals. Signals are discussed in more detail later in this chapter. Signals can be used by other processes, by the kernel itself, or by users logged into the system. LISTING PROCESSES \u00b6 The ps command is used for listing current processes. It can provide detailed process information, including: User identification (UID), which determines process privileges Unique process identification (PID) CPU and real time already expended How much memory the process has allocated in various locations The location of process stdout , known as the controlling terminal The current process state IMPORTANT The Linux version of ps supports three option formats: UNIX (POSIX) options, which may be grouped and must be preceded by a dash BSD options, which may be grouped and must not be used with a dash GNU long options, which are preceded by two dashes For example, ps -aux is not the same as ps aux . Perhaps the most common set of options, aux , displays all processes including processes without a controlling terminal. A long listing (options lax ) provides more technical detail, but may display faster by avoiding user name lookups. The similar UNIX syntax uses the options -ef to display all processes. [ user@host ~ ] $ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0 .1 0 .1 51648 7504 ? Ss 17 :45 0 :03 /usr/lib/systemd/ syst root 2 0 .0 0 .0 0 0 ? S 17 :45 0 :00 [ kthreadd ] root 3 0 .0 0 .0 0 0 ? S 17 :45 0 :00 [ ksoftirqd/0 ] root 5 0 .0 0 .0 0 0 ? S< 17 :45 0 :00 [ kworker/0:0H ] root 7 0 .0 0 .0 0 0 ? S 17 :45 0 :00 [ migration/0 ] ...output omitted... [ user@host ~ ] $ ps lax F UID PID PPID PRI NI VSZ RSS WCHAN STAT TTY TIME COMMAND 4 0 1 0 20 0 51648 7504 ep_pol Ss ? 0 :03 /usr/lib/ systemd/ 1 0 2 0 20 0 0 0 kthrea S ? 0 :00 [ kthreadd ] 1 0 3 2 20 0 0 0 smpboo S ? 0 :00 [ ksoftirqd/0 ] 1 0 5 2 0 -20 0 0 worker S< ? 0 :00 [ kworker/0:0H ] 1 0 7 2 -100 - 0 0 smpboo S ? 0 :00 [ migration/0 ] ...output omitted... [ user@host ~ ] $ ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 17 :45 ? 00 :00:03 /usr/lib/systemd/systemd -- switched-ro root 2 0 0 17 :45 ? 00 :00:00 [ kthreadd ] root 3 2 0 17 :45 ? 00 :00:00 [ ksoftirqd/0 ] root 5 2 0 17 :45 ? 00 :00:00 [ kworker/0:0H ] root 7 2 0 17 :45 ? 00 :00:00 [ migration/0 ] ...output omitted... By default, ps with no options selects all processes with the same effective user ID (EUID) as the current user, and which are associated with the same terminal where ps was invoked. Processes in brackets (usually at the top of the list) are scheduled kernel threads. Zombies are listed as exiting or defunct. The output of ps displays once. Use top for a process display that dynamically updates. ps can display in tree format so you can view relationships between parent and child processes. The default output is sorted by process ID number. At first glance, this may appear to be chronological order. However, the kernel reuses process IDs, so the order is less structured than it appears. To sort, use the -O or --sort options. Display order matches that of the system process table, which reuses table rows as processes die and new ones are created. Output may appear chronological, but is not guaranteed unless explicit -O or --sort options are used. CONTROLLING JOBS \u00b6 DESCRIBING JOBS AND SESSIONS \u00b6 Job control is a feature of the shell which allows a single shell instance to run and manage multiple commands. A job is associated with each pipeline entered at a shell prompt. All processes in that pipeline are part of the job and are members of the same process group. If only one command is entered at a shell prompt, that can be considered to be a minimal \u201cpipeline\u201d of one command, creating a job with only one member. Only one job can read input and keyboard generated signals from a particular terminal window at a time. Processes that are part of that job are foreground processes of that controlling terminal . A background process of that controlling terminal is a member of any other job associated with that terminal. Background processes of a terminal cannot read input or receive keyboard generated interrupts from the terminal, but may be able to write to the terminal. A job in the background may be stopped (suspended) or it may be running. If a running background job tries to read from the terminal, it will be automatically suspended. Each terminal is its own session, and can have a foreground process and any number of independent background processes. A job is part of exactly one session: the one belonging to its controlling terminal. The ps command shows the device name of the controlling terminal of a process in the TTY column. Some processes, such as system daemons, are started by the system and not from a shell prompt. These processes do not have a controlling terminal, are not members of a job, and cannot be brought to the foreground. The ps command displays a question mark ( ? ) in the TTY column for these processes. RUNNING JOBS IN THE BACKGROUND \u00b6 Any command or pipeline can be started in the background by appending an ampersand ( & ) to the end of the command line. The Bash shell displays a job number (unique to the session) and the PID of the new child process. The shell does not wait for the child process to terminate, but rather displays the shell prompt. [ user@host ~ ] $ sleep 10000 & [ 1 ] 5947 [ user@host ~ ] $ NOTE When a command line containing a pipe is sent to the background using an ampersand, the PID of the last command in the pipeline is used as output. All processes in the pipeline are still members of that job. [ user@host ~ ] $ example_command | sort | mail -s \"Sort output\" & [ 1 ] 5998 You can display the list of jobs that Bash is tracking for a particular session with the jobs command. [ user@host ~ ] $ jobs [ 1 ] + Running sleep 10000 & [ user@host ~ ] $ A background job can be brought to the foreground by using the fg command with its job ID (%job number). [ user@host ~ ] $ fg %1 sleep 10000 In the preceding example, the sleep command is now running in the foreground on the controlling terminal. The shell itself is again asleep, waiting for this child process to exit. To send a foreground process to the background, first press the keyboard generated suspend request ( Ctrl+Z ) in the terminal. sleep 10000 ^Z [ 1 ] + Stopped sleep 10000 [ user@host ~ ] $ The job is immediately placed in the background and is suspended. The ps j command displays information relating to jobs. The PID is the unique process ID of the process. THe PPID is the PID of the parent process of this process, the process that started (forked) it. The PGID is the PID of the process group leader, normally the first process in the job's pipeline. The SID is the PID of the session leader, which (for a job) is normally the interactive shell that is running on its controlling terminal. Since the example sleep command is currently suspended, its process state is T . [ user@host ~ ] $ ps j PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 2764 2768 2768 2768 pts/0 6377 Ss 1000 0 :00 /bin/bash 2768 5947 5947 2768 pts/0 6377 T 1000 0 :00 sleep 10000 2768 6377 6377 2768 pts/0 6377 R+ 1000 0 :00 ps j To start the suspended process running in the background, use the bg command with the same job ID. [ user@host ~ ] $ bg %1 [ 1 ] + sleep 10000 & The shell will warn a user who attempts to exit a terminal window (session) with suspended jobs. If the user tries exiting again immediately, the suspended jobs are killed. NOTE Note the + sign after the [1] in the examples above. The + sign indicates that this job is the current default job. That is, if a command is used that expects a %job number argument and a job number is not provided, then the action is taken on the job with the + indicator. KILLING PROCESSES \u00b6 PROCESS CONTROL USING SIGNALS \u00b6 A signal is a software interrupt delivered to a process. Signals report events to an executing program. Events that generate a signal can be an error, external event (such as an I/O request or an expired timer), or by explicit request (the use of a signal-sending command or by a keyboard sequence). The following table lists the fundamental signals used by system administrators for routine process management. Refer to signals by either their short (HUP) or proper (SIGHUP) name. Fundamental Process Management Signals SIGNAL NUMBER SHORT NAME DEFINITION PURPOSE 1 HUP Hangup Used to report termination of the controlling process of a terminal. Also used to request process reinitialization (configuration reload) without termination. 2 INT Keyboard interrupt Causes program termination. Can be blocked or handled. Sent by pressing INTR key combination ( Ctrl+C ). 3 QUIT Keyboard quit Similar to SIGINT, but also produces a process dump at termination. Sent by pressing QUIT key combination ( 'Ctrl+\\' ). 9 KILL Kill, unblockable Causes abrupt program termination. Cannot be blocked, ignored, or handled; always fatal. 15 TERM Terminate Causes program termination. Unlike SIGKILL, can be blocked, ignored, or handled. The \u201cpolite\u201d way to ask a program to terminate; allows self-cleanup. 18 CONT Continue Sent to a process to resume, if stopped. Cannot be blocked. Even if handled, always resumes the process. 19 STOP Stop, unblockable Suspends the process. Cannot be blocked or handled. 20 TSTP Keyboard stop Unlike SIGSTOP, can be blocked, ignored, or handled. Sent by pressing SUSP key combination ( Ctrl+Z ). NOTE Signal numbers vary on different Linux hardware platforms, but signal names and meanings are standardized. For command use, it is advised to use signal names instead of numbers. The numbers discussed in this section are for x86_64 systems. Each signal has a default action, usually one of the following: Term - Cause a program to terminate (exit) at once. Core - Cause a program to save a memory image (core dump), then terminate. Stop - Cause a program to stop executing (suspend) and wait to continue (resume). Programs can be prepared to react to expected event signals by implementing handler routines to ignore, replace, or extend a signal's default action. Commands for Sending Signals by Explicit Request You signal their current foreground process by pressing a keyboard control sequence to suspend ( Ctrl+Z ), kill ( Ctrl+C ), or core dump ( 'Ctrl+\\' ) the process. However, you will use signal-sending commands to send signals to a background process or to processes in a different session. Signals can be specified as options either by name (for example, -HUP or -SIGHUP ) or by number (the related -1 ). Users may kill their own processes, but root privilege is required to kill processes owned by others. The kill command sends a signal to a process by PID number. Despite its name, the kill command can be used for sending any signal, not just those for terminating programs. You can use the kill -l command to list the names and numbers of all available signals. [ user@host ~ ] $ kill -l 1 ) SIGHUP 2 ) SIGINT 3 ) SIGQUIT 4 ) SIGILL 5 ) SIGTRAP 6 ) SIGABRT 7 ) SIGBUS 8 ) SIGFPE 9 ) SIGKILL 10 ) SIGUSR1 11 ) SIGSEGV 12 ) SIGUSR2 13 ) SIGPIPE 14 ) SIGALRM 15 ) SIGTERM 16 ) SIGSTKFLT 17 ) SIGCHLD 18 ) SIGCONT 19 ) SIGSTOP 20 ) SIGTSTP ...output omitted... [ user@host ~ ] $ ps aux | grep job 5194 0 .0 0 .1 222448 2980 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job1 5199 0 .0 0 .1 222448 3132 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job2 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job3 5430 0 .0 0 .0 221860 1096 pts/1 S+ 16 :41 0 :00 grep --color = auto job [ user@host ~ ] $ kill 5194 [ user@host ~ ] $ ps aux | grep job user 5199 0 .0 0 .1 222448 3132 pts/1 S 16 :39 0 :00 /bin/bash /home/ user/bin/control job2 user 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/ user/bin/control job3 user 5783 0 .0 0 .0 221860 964 pts/1 S+ 16 :43 0 :00 grep --color = auto job [ 1 ] Terminated control job1 [ user@host ~ ] $ kill -9 5199 [ user@host ~ ] $ ps aux | grep job user 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/ user/bin/control job3 user 5930 0 .0 0 .0 221860 1048 pts/1 S+ 16 :44 0 :00 grep --color = auto job [ 2 ] - Killed control job2 [ user@host ~ ] $ kill -SIGTERM 5205 user 5986 0 .0 0 .0 221860 1048 pts/1 S+ 16 :45 0 :00 grep --color = auto job [ 3 ] + Terminated control job3 The killall command can signal multiple processes, based on their command name. [ user@host ~ ] $ ps aux | grep job 5194 0 .0 0 .1 222448 2980 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job1 5199 0 .0 0 .1 222448 3132 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job2 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job3 5430 0 .0 0 .0 221860 1096 pts/1 S+ 16 :41 0 :00 grep --color = auto job [ user@host ~ ] $ killall control [ 1 ] Terminated control job1 [ 2 ] - Terminated control job2 [ 3 ] + Terminated control job3 [ user@host ~ ] $ Use pkill to send a signal to one or more processes which match selection criteria. Selection criteria can be a command name, a processes owned by a specific user, or all system-wide processes. The pkill command includes advanced selection criteria: Command - Processes with a pattern-matched command name. UID - Processes owned by a Linux user account, effective or real. GID - Processes owned by a Linux group account, effective or real. Parent - Child processes of a specific parent process. Terminal - Processes running on a specific controlling terminal. [ user@host ~ ] $ ps aux | grep pkill user 5992 0 .0 0 .1 222448 3040 pts/1 S 16 :59 0 :00 /bin/bash /home/ user/bin/control pkill1 user 5996 0 .0 0 .1 222448 3048 pts/1 S 16 :59 0 :00 /bin/bash /home/ user/bin/control pkill2 user 6004 0 .0 0 .1 222448 3048 pts/1 S 16 :59 0 :00 /bin/bash /home/ user/bin/control pkill3 [ user@host ~ ] $ pkill control [ 1 ] Terminated control pkill1 [ 2 ] - Terminated control pkill2 [ user@host ~ ] $ ps aux | grep pkill user 6219 0 .0 0 .0 221860 1052 pts/1 S+ 17 :00 0 :00 grep --color = auto pkill [ 3 ] + Terminated control pkill3 [ user@host ~ ] $ ps aux | grep test user 6281 0 .0 0 .1 222448 3012 pts/1 S 17 :04 0 :00 /bin/bash /home/ user/bin/control test1 user 6285 0 .0 0 .1 222448 3128 pts/1 S 17 :04 0 :00 /bin/bash /home/ user/bin/control test2 user 6292 0 .0 0 .1 222448 3064 pts/1 S 17 :04 0 :00 /bin/bash /home/ user/bin/control test3 user 6318 0 .0 0 .0 221860 1080 pts/1 S+ 17 :04 0 :00 grep --color = auto test [ user@host ~ ] $ pkill -U user [ user@host ~ ] $ ps aux | grep test user 6870 0 .0 0 .0 221860 1048 pts/0 S+ 17 :07 0 :00 grep --color = auto test [ user@host ~ ] $ LOGGING USERS OUT ADMINISTRATIVELY \u00b6 You may need to log other users off for any of a variety of reasons. To name a few of the many possibilities: the user committed a security violation; the user may have overused resources; the user may have an unresponsive system; or the user has improper access to materials. In these cases, you may need to administratively terminate their session using signals. To log off a user, first identify the login session to be terminated. Use the w command to list user logins and current running processes. Note the TTY and FROM columns to determine the sessions to close. All user login sessions are associated with a terminal device ( TTY ). If the device name is of the form pts/N , it is a pseudo-terminal associated with a graphical terminal window or remote login session. If it is of the form ttyN , the user is on a system console, alternate console, or other directly connected terminal device. [ user@host ~ ] $ w 12 :43:06 up 27 min, 5 users, load average: 0 .03, 0 .17, 0 .66 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root tty2 12 :26 14 :58 0 .04s 0 .04s -bash bob tty3 12 :28 14 :42 0 .02s 0 .02s -bash user pts/1 desk.example.com 12 :41 2 .00s 0 .03s 0 .03s w [ user@host ~ ] $ Discover how long a user has been on the system by viewing the session login time. For each session, CPU resources consumed by current jobs, including background tasks and child processes, are in the JCPU column. Current foreground process CPU consumption is in the PCPU column. Processes and sessions can be individually or collectively signaled. To terminate all processes for one user, use the pkill command. Because the initial process in a login session (session leader) is designed to handle session termination requests and ignore unintended keyboard signals, killing all of a user's processes and login shells requires using the SIGKILL signal. IMPORTANT SIGKILL is commonly used too quickly by administrators. Since the SIGKILL signal cannot be handled or ignored, it is always fatal. However, it forces termination without allowing the killed process to run self-cleanup routines. It is recommended to send SIGTERM first, then try SIGINT, and only if both fail retry with SIGKILL. First identify the PID numbers to be killed using pgrep , which operates much like pkill , including using the same options, except that pgrep lists processes rather than killing them. [ root@host ~ ] # pgrep -l -u bob 6964 bash 6998 sleep 6999 sleep 7000 sleep [ root@host ~ ] # pkill -SIGKILL -u bob [ root@host ~ ] # pgrep -l -u bob [ root@host ~ ] # When processes requiring attention are in the same login session, it may not be necessary to kill all of a user's processes. Determine the controlling terminal for the session using the w command, then kill only processes referencing the same terminal ID. Unless SIGKILL is specified, the session leader (here, the Bash login shell) successfully handles and survives the termination request, but all other session processes are terminated. [ root@host ~ ] # pgrep -l -u bob 7391 bash 7426 sleep 7427 sleep 7428 sleep [ root@host ~ ] # w -h -u bob bob tty3 18 :37 5 :04 0 .03s 0 .03s -bash [ root@host ~ ] # pkill -t tty3 [ root@host ~ ] # pgrep -l -u bob 7391 bash [ root@host ~ ] # pkill -SIGKILL -t tty3 [ root@host ~ ] # pgrep -l -u bob [ root@host ~ ] # The same selective process termination can be applied using parent and child process relationships. Use the pstree command to view a process tree for the system or a single user. Use the parent process's PID to kill all children they have created. This time, the parent Bash login shell survives because the signal is directed only at its child processes. [ root@host ~ ] # pstree -p bob bash ( 8391 ) \u2500\u252c\u2500sleep ( 8425 ) \u251c\u2500sleep ( 8426 ) \u2514\u2500sleep ( 8427 ) [ root@host ~ ] # pkill -P 8391 [ root@host ~ ] # pgrep -l -u bob bash ( 8391 ) [ root@host ~ ] # pkill -SIGKILL -P 8391 [ root@host ~ ] # pgrep -l -u bob bash ( 8391 ) [ root@host ~ ] # MONITORING PROCESS ACTIVITY \u00b6 DESCRIBING LOAD AVERAGE \u00b6 Load average is a measurement provided by the Linux kernel that is a simple way to represent the perceived system load over time. It can be used as a rough gauge of how many system resource requests are pending, and to determine whether system load is increasing or decreasing over time. Every five seconds, the kernel collects the current load number, based on the number of processes in runnable and uninterruptible states. This number is accumulated and reported as an exponential moving average over the most recent 1, 5, and 15 minutes. Understanding the Linux Load Average Calculation The load average represents the perceived system load over a time period. Linux determines this by reporting how many processes are ready to run on a CPU, and how many processes are waiting for disk or network I/O to complete. The load number is essentially based on the number of processes that are ready to run (in process state R ) and are waiting for I/O to complete (in process state D ). Some UNIX systems only consider CPU utilization or run queue length to indicate system load. Linux also includes disk or network utilization because that can have as significant an impact on system performance as CPU load. When experiencing high load averages with minimal CPU activity, examine disk and network activity. Load average is a rough measurement of how many processes are currently waiting for a request to complete before they can do anything else. The request might be for CPU time to run the process. Alternatively, the request might be for a critical disk I/O operation to complete, and the process cannot be run on the CPU until the request completes, even if the CPU is idle. Either way, system load is impacted and the system appears to run more slowly because processes are waiting to run. Interpreting Displayed Load Average Values The uptime command is one way to display the current load average. It prints the current time, how long the machine has been up, how many user sessions are running, and the current load average. [ user@host ~ ] $ uptime 15 :29:03 up 14 min, 2 users, load average: 2 .92, 4 .48, 5 .20 The three values for the load average represent the load over the last 1, 5, and 15 minutes. A quick glance indicates whether system load appears to be increasing or decreasing. If the main contribution to load average is from processes waiting for the CPU, you can calculate the approximate per CPU load value to determine whether the system is experiencing significant waiting. The lscpu command can help you determine how many CPUs a system has. In the following example, the system is a dual-core single socket system with two hyperthreads per core. Roughly speaking, Linux will treat this as a four CPU system for scheduling purposes. [ user@host ~ ] $ lscpu Architecture: x86_64 CPU op-mode ( s ) : 32 -bit, 64 -bit Byte Order: Little Endian CPU ( s ) : 4 On-line CPU ( s ) list: 0 -3 Thread ( s ) per core: 2 Core ( s ) per socket: 2 Socket ( s ) : 1 NUMA node ( s ) : 1 ...output omitted... For a moment, imagine that the only contribution to the load number is from processes that need CPU time. Then you can divide the displayed load average values by the number of logical CPUs in the system. A value below 1 indicates satisfactory resource utilization and minimal wait times. A value above 1 indicates resource saturation and some amount of processing delay. # From lscpu, the system has four logical CPUs, so divide by 4: # load average: 2.92, 4.48, 5.20 # divide by number of logical CPUs: 4 4 4 # ---- ---- ---- # per-CPU load average: 0.73 1.12 1.30 # # This system's load average appears to be decreasing. # With a load average of 2.92 on four CPUs, all CPUs were in use ~73% of the time. # During the last 5 minutes, the system was overloaded by ~12%. # During the last 15 minutes, the system was overloaded by ~30%. An idle CPU queue has a load number of 0. Each process waiting for a CPU adds a count of 1 to the load number. If one process is running on a CPU, the load number is one, the resource (the CPU) is in use, but there are no requests waiting. If that process is running for a full minute, its contribution to the one-minute load average will be 1. However, processes uninterruptibly sleeping for critical I/O due to a busy disk or network resource are also included in the count and increase the load average. While not an indication of CPU utilization, these processes are added to the queue count because they are waiting for resources and cannot run on a CPU until they get them. This is still system load due to resource limitations that is causing processes not to run. Until resource saturation, a load average remains below 1, since tasks are seldom found waiting in queue. Load average only increases when resource saturation causes requests to remain queued and are counted by the load calculation routine. When resource utilization approaches 100%, each additional request starts experiencing service wait time. A number of additional tools report load average, including w and top . REAL-TIME PROCESS MONITORING \u00b6 The top program is a dynamic view of the system's processes, displaying a summary header followed by a process or thread list similar to ps information. Unlike the static ps output, top continuously refreshes at a configurable interval, and provides capabilities for column reordering, sorting, and highlighting. User configurations can be saved and made persistent. Default output columns are recognizable from other resource tools: The process ID ( PID ). User name ( USER ) is the process owner. Virtual memory ( VIRT ) is all memory the process is using, including the resident set, shared libraries, and any mapped or swapped memory pages. (Labeled VSZ in the ps command.) Resident memory ( RES ) is the physical memory used by the process, including any resident shared objects. (Labeled RSS in the ps command.) Process state ( S ) displays as: D = Uninterruptible Sleeping R = Running or Runnable S = Sleeping T = Stopped or Traced Z = Zombie CPU time ( TIME ) is the total processing time since the process started. May be toggled to include cumulative time of all previous children. The process command name ( COMMAND ). Fundamental Keystrokes in top KEY PURPOSE ? or H Help for interactive keystrokes. L, T, M Toggles for load, threads, and memory header lines. 1 Toggle showing individual CPUs or a summary for all CPUs in header. S(1) Change the refresh (screen) rate, in decimal seconds (e.g., 0.5, 1, 5). B Toggle reverse highlighting for Running processes; default is bold only. B Enables use of bold in display, in the header, and for Running processes. Shift+H Toggle threads; show process summary or individual threads. U, Shift+U Filter for any user name (effective, real). Shift+M Sorts process listing by memory usage, in descending order. Shift+P Sorts process listing by processor utilization, in descending order. K(1) Kill a process. When prompted, enter PID, then signal. R(1) Renice a process. When prompted, enter PID, then nice_value. Shift+W Write (save) the current display configuration for use at the next top restart. Q Quit. SUMMARY \u00b6 In this chapter, you learned: A process is a running instance of an executable program. Processes are assigned a state, which can be running, sleeping, stopped, or zombie. The ps command is used to list processes. Each terminal is its own session and can have foreground process and independent background processes. The jobs command displays processes within a terminal session. A signal is a software interrupt that reports events to an executing program. The kill, pkill , and killall commands use signals to control processes. Load average is an estimate of how busy the system is. To display load average values, you can use the top, uptime , or w command.","title":"Monitoring And Managing Linux Processes"},{"location":"redhat/monitor/#listing-processes","text":"","title":"LISTING PROCESSES"},{"location":"redhat/monitor/#definition-of-a-process","text":"A process is a running instance of a launched, executable program. A process consists of: An address space of allocated memory Security properties including ownership credentials and privileges One or more execution threads of program code Process state The environment of a process includes: Local and global variables A current scheduling context Allocated system resources, such as file descriptors and network ports An existing ( parent ) process duplicates its own address space ( fork ) to create a new ( child ) process structure. Every new process is assigned a unique process ID (PID) for tracking and security. The PID and the parent's process ID (PPID) are elements of the new process environment. Any process may create a child process. All processes are descendants of the first system process, systemd on a Red Hat Enterprise Linux 8 system). Through the fork routine, a child process inherits security identities, previous and current file descriptors, port and resource privileges, environment variables, and program code. A child process may then exec its own program code. Normally, a parent process sleeps while the child process runs, setting a request ( wait ) to be signaled when the child completes. Upon exit, the child process has already closed or discarded its resources and environment. The only remaining resource, called a zombie , is an entry in the process table. The parent, signaled awake when the child exited, cleans the process table of the child's entry, thus freeing the last resource of the child process. The parent process then continues with its own program code execution.","title":"DEFINITION OF A PROCESS"},{"location":"redhat/monitor/#describing-process-states","text":"In a multitasking operating system, each CPU (or CPU core) can be working on one process at a single point in time. As a process runs, its immediate requirements for CPU time and resource allocation change. Processes are assigned a state , which changes as circumstances dictate. Linux process states are illustrated in the previous diagram and described in the following table: Linux Process States NAME FLAG KERNEL-DEFINED STATE NAME AND DESCRIPTION Running R TASK_RUNNING: The process is either executing on a CPU or waiting to run.Process can be executing user routines or kernel routines (system calls), or be queued and ready when in the Running (or Runnable) state. Sleeping S TASK_INTERRUPTIBLE: The process is waiting for some condition: a hardware request, system resource access, or signal. When an event or signal satisfies the condition, the process returns to Running . Sleeping D TASK_UNINTERRUPTIBLE: This process is also Sleeping, but unlike S state, does not respond to signals. Used only when process interruption may cause an unpredictable device state. Sleeping K TASK_KILLABLE: Identical to the uninterruptible D state, but modified to allow a waiting task to respond to the signal that it should be killed (exit completely). Utilities frequently display Killable processes as D state. Sleeping I TASK_REPORT_IDLE: A subset of state D . The kernel does not count these processes when calculating load average. Used for kernel threads. Flags TASK_UNINTERRUPTABLE and TASK_NOLOAD are set. Similar to TASK_KILLABLE, also a subset of state D . It accepts fatal signals. Stopped T TASK_STOPPED: The process has been Stopped (suspended), usually by being signaled by a user or another process. The process can be continued (resumed) by another signal to return to Running . Stopped T TASK_TRACED: A process that is being debugged is also temporarily Stopped and shares the same T state flag. Zombie Z EXIT_ZOMBIE: A child process signals its parent as it exits. All resources except for the process identity (PID) are released. Zombie X EXIT_DEAD: When the parent cleans up (reaps) the remaining child process structure, the process is now released completely. This state will never be observed in process-listing utilities. Why Process States are Important When troubleshooting a system, it is important to understand how the kernel communicates with processes and how processes communicate with each other. At process creation, the system assigns the process a state. The S column of the top command or the STAT column of the ps show the state of each process. On a single CPU system, only one process can run at a time. It is possible to see several processes with a state of R . However, not all of them will be running consecutively, some of them will be in status waiting . [ user@host ~ ] $ top PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 244344 13684 9024 S 0 .0 0 .7 0 :02.46 systemd 2 root 20 0 0 0 0 S 0 .0 0 .0 0 :00.00 kthreadd ...output omitted... [ user@host ~ ] $ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND ...output omitted... root 2 0 .0 0 .0 0 0 ? S 11 :57 0 :00 [ kthreadd ] student 3448 0 .0 0 .2 266904 3836 pts/0 R+ 18 :07 0 :00 ps aux ...output omitted... Process can be suspended, stopped, resumed, terminated, and interrupted using signals. Signals are discussed in more detail later in this chapter. Signals can be used by other processes, by the kernel itself, or by users logged into the system.","title":"DESCRIBING PROCESS STATES"},{"location":"redhat/monitor/#listing-processes_1","text":"The ps command is used for listing current processes. It can provide detailed process information, including: User identification (UID), which determines process privileges Unique process identification (PID) CPU and real time already expended How much memory the process has allocated in various locations The location of process stdout , known as the controlling terminal The current process state IMPORTANT The Linux version of ps supports three option formats: UNIX (POSIX) options, which may be grouped and must be preceded by a dash BSD options, which may be grouped and must not be used with a dash GNU long options, which are preceded by two dashes For example, ps -aux is not the same as ps aux . Perhaps the most common set of options, aux , displays all processes including processes without a controlling terminal. A long listing (options lax ) provides more technical detail, but may display faster by avoiding user name lookups. The similar UNIX syntax uses the options -ef to display all processes. [ user@host ~ ] $ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0 .1 0 .1 51648 7504 ? Ss 17 :45 0 :03 /usr/lib/systemd/ syst root 2 0 .0 0 .0 0 0 ? S 17 :45 0 :00 [ kthreadd ] root 3 0 .0 0 .0 0 0 ? S 17 :45 0 :00 [ ksoftirqd/0 ] root 5 0 .0 0 .0 0 0 ? S< 17 :45 0 :00 [ kworker/0:0H ] root 7 0 .0 0 .0 0 0 ? S 17 :45 0 :00 [ migration/0 ] ...output omitted... [ user@host ~ ] $ ps lax F UID PID PPID PRI NI VSZ RSS WCHAN STAT TTY TIME COMMAND 4 0 1 0 20 0 51648 7504 ep_pol Ss ? 0 :03 /usr/lib/ systemd/ 1 0 2 0 20 0 0 0 kthrea S ? 0 :00 [ kthreadd ] 1 0 3 2 20 0 0 0 smpboo S ? 0 :00 [ ksoftirqd/0 ] 1 0 5 2 0 -20 0 0 worker S< ? 0 :00 [ kworker/0:0H ] 1 0 7 2 -100 - 0 0 smpboo S ? 0 :00 [ migration/0 ] ...output omitted... [ user@host ~ ] $ ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 17 :45 ? 00 :00:03 /usr/lib/systemd/systemd -- switched-ro root 2 0 0 17 :45 ? 00 :00:00 [ kthreadd ] root 3 2 0 17 :45 ? 00 :00:00 [ ksoftirqd/0 ] root 5 2 0 17 :45 ? 00 :00:00 [ kworker/0:0H ] root 7 2 0 17 :45 ? 00 :00:00 [ migration/0 ] ...output omitted... By default, ps with no options selects all processes with the same effective user ID (EUID) as the current user, and which are associated with the same terminal where ps was invoked. Processes in brackets (usually at the top of the list) are scheduled kernel threads. Zombies are listed as exiting or defunct. The output of ps displays once. Use top for a process display that dynamically updates. ps can display in tree format so you can view relationships between parent and child processes. The default output is sorted by process ID number. At first glance, this may appear to be chronological order. However, the kernel reuses process IDs, so the order is less structured than it appears. To sort, use the -O or --sort options. Display order matches that of the system process table, which reuses table rows as processes die and new ones are created. Output may appear chronological, but is not guaranteed unless explicit -O or --sort options are used.","title":"LISTING PROCESSES"},{"location":"redhat/monitor/#controlling-jobs","text":"","title":"CONTROLLING JOBS"},{"location":"redhat/monitor/#describing-jobs-and-sessions","text":"Job control is a feature of the shell which allows a single shell instance to run and manage multiple commands. A job is associated with each pipeline entered at a shell prompt. All processes in that pipeline are part of the job and are members of the same process group. If only one command is entered at a shell prompt, that can be considered to be a minimal \u201cpipeline\u201d of one command, creating a job with only one member. Only one job can read input and keyboard generated signals from a particular terminal window at a time. Processes that are part of that job are foreground processes of that controlling terminal . A background process of that controlling terminal is a member of any other job associated with that terminal. Background processes of a terminal cannot read input or receive keyboard generated interrupts from the terminal, but may be able to write to the terminal. A job in the background may be stopped (suspended) or it may be running. If a running background job tries to read from the terminal, it will be automatically suspended. Each terminal is its own session, and can have a foreground process and any number of independent background processes. A job is part of exactly one session: the one belonging to its controlling terminal. The ps command shows the device name of the controlling terminal of a process in the TTY column. Some processes, such as system daemons, are started by the system and not from a shell prompt. These processes do not have a controlling terminal, are not members of a job, and cannot be brought to the foreground. The ps command displays a question mark ( ? ) in the TTY column for these processes.","title":"DESCRIBING JOBS AND SESSIONS"},{"location":"redhat/monitor/#running-jobs-in-the-background","text":"Any command or pipeline can be started in the background by appending an ampersand ( & ) to the end of the command line. The Bash shell displays a job number (unique to the session) and the PID of the new child process. The shell does not wait for the child process to terminate, but rather displays the shell prompt. [ user@host ~ ] $ sleep 10000 & [ 1 ] 5947 [ user@host ~ ] $ NOTE When a command line containing a pipe is sent to the background using an ampersand, the PID of the last command in the pipeline is used as output. All processes in the pipeline are still members of that job. [ user@host ~ ] $ example_command | sort | mail -s \"Sort output\" & [ 1 ] 5998 You can display the list of jobs that Bash is tracking for a particular session with the jobs command. [ user@host ~ ] $ jobs [ 1 ] + Running sleep 10000 & [ user@host ~ ] $ A background job can be brought to the foreground by using the fg command with its job ID (%job number). [ user@host ~ ] $ fg %1 sleep 10000 In the preceding example, the sleep command is now running in the foreground on the controlling terminal. The shell itself is again asleep, waiting for this child process to exit. To send a foreground process to the background, first press the keyboard generated suspend request ( Ctrl+Z ) in the terminal. sleep 10000 ^Z [ 1 ] + Stopped sleep 10000 [ user@host ~ ] $ The job is immediately placed in the background and is suspended. The ps j command displays information relating to jobs. The PID is the unique process ID of the process. THe PPID is the PID of the parent process of this process, the process that started (forked) it. The PGID is the PID of the process group leader, normally the first process in the job's pipeline. The SID is the PID of the session leader, which (for a job) is normally the interactive shell that is running on its controlling terminal. Since the example sleep command is currently suspended, its process state is T . [ user@host ~ ] $ ps j PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 2764 2768 2768 2768 pts/0 6377 Ss 1000 0 :00 /bin/bash 2768 5947 5947 2768 pts/0 6377 T 1000 0 :00 sleep 10000 2768 6377 6377 2768 pts/0 6377 R+ 1000 0 :00 ps j To start the suspended process running in the background, use the bg command with the same job ID. [ user@host ~ ] $ bg %1 [ 1 ] + sleep 10000 & The shell will warn a user who attempts to exit a terminal window (session) with suspended jobs. If the user tries exiting again immediately, the suspended jobs are killed. NOTE Note the + sign after the [1] in the examples above. The + sign indicates that this job is the current default job. That is, if a command is used that expects a %job number argument and a job number is not provided, then the action is taken on the job with the + indicator.","title":"RUNNING JOBS IN THE BACKGROUND"},{"location":"redhat/monitor/#killing-processes","text":"","title":"KILLING PROCESSES"},{"location":"redhat/monitor/#process-control-using-signals","text":"A signal is a software interrupt delivered to a process. Signals report events to an executing program. Events that generate a signal can be an error, external event (such as an I/O request or an expired timer), or by explicit request (the use of a signal-sending command or by a keyboard sequence). The following table lists the fundamental signals used by system administrators for routine process management. Refer to signals by either their short (HUP) or proper (SIGHUP) name. Fundamental Process Management Signals SIGNAL NUMBER SHORT NAME DEFINITION PURPOSE 1 HUP Hangup Used to report termination of the controlling process of a terminal. Also used to request process reinitialization (configuration reload) without termination. 2 INT Keyboard interrupt Causes program termination. Can be blocked or handled. Sent by pressing INTR key combination ( Ctrl+C ). 3 QUIT Keyboard quit Similar to SIGINT, but also produces a process dump at termination. Sent by pressing QUIT key combination ( 'Ctrl+\\' ). 9 KILL Kill, unblockable Causes abrupt program termination. Cannot be blocked, ignored, or handled; always fatal. 15 TERM Terminate Causes program termination. Unlike SIGKILL, can be blocked, ignored, or handled. The \u201cpolite\u201d way to ask a program to terminate; allows self-cleanup. 18 CONT Continue Sent to a process to resume, if stopped. Cannot be blocked. Even if handled, always resumes the process. 19 STOP Stop, unblockable Suspends the process. Cannot be blocked or handled. 20 TSTP Keyboard stop Unlike SIGSTOP, can be blocked, ignored, or handled. Sent by pressing SUSP key combination ( Ctrl+Z ). NOTE Signal numbers vary on different Linux hardware platforms, but signal names and meanings are standardized. For command use, it is advised to use signal names instead of numbers. The numbers discussed in this section are for x86_64 systems. Each signal has a default action, usually one of the following: Term - Cause a program to terminate (exit) at once. Core - Cause a program to save a memory image (core dump), then terminate. Stop - Cause a program to stop executing (suspend) and wait to continue (resume). Programs can be prepared to react to expected event signals by implementing handler routines to ignore, replace, or extend a signal's default action. Commands for Sending Signals by Explicit Request You signal their current foreground process by pressing a keyboard control sequence to suspend ( Ctrl+Z ), kill ( Ctrl+C ), or core dump ( 'Ctrl+\\' ) the process. However, you will use signal-sending commands to send signals to a background process or to processes in a different session. Signals can be specified as options either by name (for example, -HUP or -SIGHUP ) or by number (the related -1 ). Users may kill their own processes, but root privilege is required to kill processes owned by others. The kill command sends a signal to a process by PID number. Despite its name, the kill command can be used for sending any signal, not just those for terminating programs. You can use the kill -l command to list the names and numbers of all available signals. [ user@host ~ ] $ kill -l 1 ) SIGHUP 2 ) SIGINT 3 ) SIGQUIT 4 ) SIGILL 5 ) SIGTRAP 6 ) SIGABRT 7 ) SIGBUS 8 ) SIGFPE 9 ) SIGKILL 10 ) SIGUSR1 11 ) SIGSEGV 12 ) SIGUSR2 13 ) SIGPIPE 14 ) SIGALRM 15 ) SIGTERM 16 ) SIGSTKFLT 17 ) SIGCHLD 18 ) SIGCONT 19 ) SIGSTOP 20 ) SIGTSTP ...output omitted... [ user@host ~ ] $ ps aux | grep job 5194 0 .0 0 .1 222448 2980 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job1 5199 0 .0 0 .1 222448 3132 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job2 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job3 5430 0 .0 0 .0 221860 1096 pts/1 S+ 16 :41 0 :00 grep --color = auto job [ user@host ~ ] $ kill 5194 [ user@host ~ ] $ ps aux | grep job user 5199 0 .0 0 .1 222448 3132 pts/1 S 16 :39 0 :00 /bin/bash /home/ user/bin/control job2 user 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/ user/bin/control job3 user 5783 0 .0 0 .0 221860 964 pts/1 S+ 16 :43 0 :00 grep --color = auto job [ 1 ] Terminated control job1 [ user@host ~ ] $ kill -9 5199 [ user@host ~ ] $ ps aux | grep job user 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/ user/bin/control job3 user 5930 0 .0 0 .0 221860 1048 pts/1 S+ 16 :44 0 :00 grep --color = auto job [ 2 ] - Killed control job2 [ user@host ~ ] $ kill -SIGTERM 5205 user 5986 0 .0 0 .0 221860 1048 pts/1 S+ 16 :45 0 :00 grep --color = auto job [ 3 ] + Terminated control job3 The killall command can signal multiple processes, based on their command name. [ user@host ~ ] $ ps aux | grep job 5194 0 .0 0 .1 222448 2980 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job1 5199 0 .0 0 .1 222448 3132 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job2 5205 0 .0 0 .1 222448 3124 pts/1 S 16 :39 0 :00 /bin/bash /home/user/bin/ control job3 5430 0 .0 0 .0 221860 1096 pts/1 S+ 16 :41 0 :00 grep --color = auto job [ user@host ~ ] $ killall control [ 1 ] Terminated control job1 [ 2 ] - Terminated control job2 [ 3 ] + Terminated control job3 [ user@host ~ ] $ Use pkill to send a signal to one or more processes which match selection criteria. Selection criteria can be a command name, a processes owned by a specific user, or all system-wide processes. The pkill command includes advanced selection criteria: Command - Processes with a pattern-matched command name. UID - Processes owned by a Linux user account, effective or real. GID - Processes owned by a Linux group account, effective or real. Parent - Child processes of a specific parent process. Terminal - Processes running on a specific controlling terminal. [ user@host ~ ] $ ps aux | grep pkill user 5992 0 .0 0 .1 222448 3040 pts/1 S 16 :59 0 :00 /bin/bash /home/ user/bin/control pkill1 user 5996 0 .0 0 .1 222448 3048 pts/1 S 16 :59 0 :00 /bin/bash /home/ user/bin/control pkill2 user 6004 0 .0 0 .1 222448 3048 pts/1 S 16 :59 0 :00 /bin/bash /home/ user/bin/control pkill3 [ user@host ~ ] $ pkill control [ 1 ] Terminated control pkill1 [ 2 ] - Terminated control pkill2 [ user@host ~ ] $ ps aux | grep pkill user 6219 0 .0 0 .0 221860 1052 pts/1 S+ 17 :00 0 :00 grep --color = auto pkill [ 3 ] + Terminated control pkill3 [ user@host ~ ] $ ps aux | grep test user 6281 0 .0 0 .1 222448 3012 pts/1 S 17 :04 0 :00 /bin/bash /home/ user/bin/control test1 user 6285 0 .0 0 .1 222448 3128 pts/1 S 17 :04 0 :00 /bin/bash /home/ user/bin/control test2 user 6292 0 .0 0 .1 222448 3064 pts/1 S 17 :04 0 :00 /bin/bash /home/ user/bin/control test3 user 6318 0 .0 0 .0 221860 1080 pts/1 S+ 17 :04 0 :00 grep --color = auto test [ user@host ~ ] $ pkill -U user [ user@host ~ ] $ ps aux | grep test user 6870 0 .0 0 .0 221860 1048 pts/0 S+ 17 :07 0 :00 grep --color = auto test [ user@host ~ ] $","title":"PROCESS CONTROL USING SIGNALS"},{"location":"redhat/monitor/#logging-users-out-administratively","text":"You may need to log other users off for any of a variety of reasons. To name a few of the many possibilities: the user committed a security violation; the user may have overused resources; the user may have an unresponsive system; or the user has improper access to materials. In these cases, you may need to administratively terminate their session using signals. To log off a user, first identify the login session to be terminated. Use the w command to list user logins and current running processes. Note the TTY and FROM columns to determine the sessions to close. All user login sessions are associated with a terminal device ( TTY ). If the device name is of the form pts/N , it is a pseudo-terminal associated with a graphical terminal window or remote login session. If it is of the form ttyN , the user is on a system console, alternate console, or other directly connected terminal device. [ user@host ~ ] $ w 12 :43:06 up 27 min, 5 users, load average: 0 .03, 0 .17, 0 .66 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root tty2 12 :26 14 :58 0 .04s 0 .04s -bash bob tty3 12 :28 14 :42 0 .02s 0 .02s -bash user pts/1 desk.example.com 12 :41 2 .00s 0 .03s 0 .03s w [ user@host ~ ] $ Discover how long a user has been on the system by viewing the session login time. For each session, CPU resources consumed by current jobs, including background tasks and child processes, are in the JCPU column. Current foreground process CPU consumption is in the PCPU column. Processes and sessions can be individually or collectively signaled. To terminate all processes for one user, use the pkill command. Because the initial process in a login session (session leader) is designed to handle session termination requests and ignore unintended keyboard signals, killing all of a user's processes and login shells requires using the SIGKILL signal. IMPORTANT SIGKILL is commonly used too quickly by administrators. Since the SIGKILL signal cannot be handled or ignored, it is always fatal. However, it forces termination without allowing the killed process to run self-cleanup routines. It is recommended to send SIGTERM first, then try SIGINT, and only if both fail retry with SIGKILL. First identify the PID numbers to be killed using pgrep , which operates much like pkill , including using the same options, except that pgrep lists processes rather than killing them. [ root@host ~ ] # pgrep -l -u bob 6964 bash 6998 sleep 6999 sleep 7000 sleep [ root@host ~ ] # pkill -SIGKILL -u bob [ root@host ~ ] # pgrep -l -u bob [ root@host ~ ] # When processes requiring attention are in the same login session, it may not be necessary to kill all of a user's processes. Determine the controlling terminal for the session using the w command, then kill only processes referencing the same terminal ID. Unless SIGKILL is specified, the session leader (here, the Bash login shell) successfully handles and survives the termination request, but all other session processes are terminated. [ root@host ~ ] # pgrep -l -u bob 7391 bash 7426 sleep 7427 sleep 7428 sleep [ root@host ~ ] # w -h -u bob bob tty3 18 :37 5 :04 0 .03s 0 .03s -bash [ root@host ~ ] # pkill -t tty3 [ root@host ~ ] # pgrep -l -u bob 7391 bash [ root@host ~ ] # pkill -SIGKILL -t tty3 [ root@host ~ ] # pgrep -l -u bob [ root@host ~ ] # The same selective process termination can be applied using parent and child process relationships. Use the pstree command to view a process tree for the system or a single user. Use the parent process's PID to kill all children they have created. This time, the parent Bash login shell survives because the signal is directed only at its child processes. [ root@host ~ ] # pstree -p bob bash ( 8391 ) \u2500\u252c\u2500sleep ( 8425 ) \u251c\u2500sleep ( 8426 ) \u2514\u2500sleep ( 8427 ) [ root@host ~ ] # pkill -P 8391 [ root@host ~ ] # pgrep -l -u bob bash ( 8391 ) [ root@host ~ ] # pkill -SIGKILL -P 8391 [ root@host ~ ] # pgrep -l -u bob bash ( 8391 ) [ root@host ~ ] #","title":"LOGGING USERS OUT ADMINISTRATIVELY"},{"location":"redhat/monitor/#monitoring-process-activity","text":"","title":"MONITORING PROCESS ACTIVITY"},{"location":"redhat/monitor/#describing-load-average","text":"Load average is a measurement provided by the Linux kernel that is a simple way to represent the perceived system load over time. It can be used as a rough gauge of how many system resource requests are pending, and to determine whether system load is increasing or decreasing over time. Every five seconds, the kernel collects the current load number, based on the number of processes in runnable and uninterruptible states. This number is accumulated and reported as an exponential moving average over the most recent 1, 5, and 15 minutes. Understanding the Linux Load Average Calculation The load average represents the perceived system load over a time period. Linux determines this by reporting how many processes are ready to run on a CPU, and how many processes are waiting for disk or network I/O to complete. The load number is essentially based on the number of processes that are ready to run (in process state R ) and are waiting for I/O to complete (in process state D ). Some UNIX systems only consider CPU utilization or run queue length to indicate system load. Linux also includes disk or network utilization because that can have as significant an impact on system performance as CPU load. When experiencing high load averages with minimal CPU activity, examine disk and network activity. Load average is a rough measurement of how many processes are currently waiting for a request to complete before they can do anything else. The request might be for CPU time to run the process. Alternatively, the request might be for a critical disk I/O operation to complete, and the process cannot be run on the CPU until the request completes, even if the CPU is idle. Either way, system load is impacted and the system appears to run more slowly because processes are waiting to run. Interpreting Displayed Load Average Values The uptime command is one way to display the current load average. It prints the current time, how long the machine has been up, how many user sessions are running, and the current load average. [ user@host ~ ] $ uptime 15 :29:03 up 14 min, 2 users, load average: 2 .92, 4 .48, 5 .20 The three values for the load average represent the load over the last 1, 5, and 15 minutes. A quick glance indicates whether system load appears to be increasing or decreasing. If the main contribution to load average is from processes waiting for the CPU, you can calculate the approximate per CPU load value to determine whether the system is experiencing significant waiting. The lscpu command can help you determine how many CPUs a system has. In the following example, the system is a dual-core single socket system with two hyperthreads per core. Roughly speaking, Linux will treat this as a four CPU system for scheduling purposes. [ user@host ~ ] $ lscpu Architecture: x86_64 CPU op-mode ( s ) : 32 -bit, 64 -bit Byte Order: Little Endian CPU ( s ) : 4 On-line CPU ( s ) list: 0 -3 Thread ( s ) per core: 2 Core ( s ) per socket: 2 Socket ( s ) : 1 NUMA node ( s ) : 1 ...output omitted... For a moment, imagine that the only contribution to the load number is from processes that need CPU time. Then you can divide the displayed load average values by the number of logical CPUs in the system. A value below 1 indicates satisfactory resource utilization and minimal wait times. A value above 1 indicates resource saturation and some amount of processing delay. # From lscpu, the system has four logical CPUs, so divide by 4: # load average: 2.92, 4.48, 5.20 # divide by number of logical CPUs: 4 4 4 # ---- ---- ---- # per-CPU load average: 0.73 1.12 1.30 # # This system's load average appears to be decreasing. # With a load average of 2.92 on four CPUs, all CPUs were in use ~73% of the time. # During the last 5 minutes, the system was overloaded by ~12%. # During the last 15 minutes, the system was overloaded by ~30%. An idle CPU queue has a load number of 0. Each process waiting for a CPU adds a count of 1 to the load number. If one process is running on a CPU, the load number is one, the resource (the CPU) is in use, but there are no requests waiting. If that process is running for a full minute, its contribution to the one-minute load average will be 1. However, processes uninterruptibly sleeping for critical I/O due to a busy disk or network resource are also included in the count and increase the load average. While not an indication of CPU utilization, these processes are added to the queue count because they are waiting for resources and cannot run on a CPU until they get them. This is still system load due to resource limitations that is causing processes not to run. Until resource saturation, a load average remains below 1, since tasks are seldom found waiting in queue. Load average only increases when resource saturation causes requests to remain queued and are counted by the load calculation routine. When resource utilization approaches 100%, each additional request starts experiencing service wait time. A number of additional tools report load average, including w and top .","title":"DESCRIBING LOAD AVERAGE"},{"location":"redhat/monitor/#real-time-process-monitoring","text":"The top program is a dynamic view of the system's processes, displaying a summary header followed by a process or thread list similar to ps information. Unlike the static ps output, top continuously refreshes at a configurable interval, and provides capabilities for column reordering, sorting, and highlighting. User configurations can be saved and made persistent. Default output columns are recognizable from other resource tools: The process ID ( PID ). User name ( USER ) is the process owner. Virtual memory ( VIRT ) is all memory the process is using, including the resident set, shared libraries, and any mapped or swapped memory pages. (Labeled VSZ in the ps command.) Resident memory ( RES ) is the physical memory used by the process, including any resident shared objects. (Labeled RSS in the ps command.) Process state ( S ) displays as: D = Uninterruptible Sleeping R = Running or Runnable S = Sleeping T = Stopped or Traced Z = Zombie CPU time ( TIME ) is the total processing time since the process started. May be toggled to include cumulative time of all previous children. The process command name ( COMMAND ). Fundamental Keystrokes in top KEY PURPOSE ? or H Help for interactive keystrokes. L, T, M Toggles for load, threads, and memory header lines. 1 Toggle showing individual CPUs or a summary for all CPUs in header. S(1) Change the refresh (screen) rate, in decimal seconds (e.g., 0.5, 1, 5). B Toggle reverse highlighting for Running processes; default is bold only. B Enables use of bold in display, in the header, and for Running processes. Shift+H Toggle threads; show process summary or individual threads. U, Shift+U Filter for any user name (effective, real). Shift+M Sorts process listing by memory usage, in descending order. Shift+P Sorts process listing by processor utilization, in descending order. K(1) Kill a process. When prompted, enter PID, then signal. R(1) Renice a process. When prompted, enter PID, then nice_value. Shift+W Write (save) the current display configuration for use at the next top restart. Q Quit.","title":"REAL-TIME PROCESS MONITORING"},{"location":"redhat/monitor/#summary","text":"In this chapter, you learned: A process is a running instance of an executable program. Processes are assigned a state, which can be running, sleeping, stopped, or zombie. The ps command is used to list processes. Each terminal is its own session and can have foreground process and independent background processes. The jobs command displays processes within a terminal session. A signal is a software interrupt that reports events to an executing program. The kill, pkill , and killall commands use signals to control processes. Load average is an estimate of how busy the system is. To display load average values, you can use the top, uptime , or w command.","title":"SUMMARY"},{"location":"redhat/secssh/","text":"ACCESSING THE REMOTE COMMAND LINE WITH SSH \u00b6 WHAT IS OPENSSH? \u00b6 OpenSSH implements the Secure Shell or SSH protocol in the Red Hat Enterprise Linux systems. The SSH protocol enables systems to communicate in an encrypted and secure fashion over an insecure network. You can use the ssh command to create a secure connection to a remote system, authenticate as a specific user, and get an interactive shell session on the remote system as that user. You may also use the ssh command to run an individual command on the remote system without running an interactive shell. SECURE SHELL EXAMPLES \u00b6 The following ssh command would log you in on the remote server remotehost using the same user name as the current local user. In this example, the remote system prompts you to authenticate with that user's password. [ user01@host ~ ] $ ssh remotehost user01@remotehost ' s password: redhat ...output omitted... [ user01@remotehost ~ ] $ You can the exit command to log out of the remote system. [ user01@remotehost ~ ] $ exit logout Connection to remotehost closed. [ user01@host ~ ] $ The next ssh command would log you in on the remote server remotehost using the user name user02 . Again, you are prompted by the remote system to authenticate with that user's password. [ user01@host ~ ] $ ssh user02@remotehost user02@remotehost ' s password: shadowman ...output omitted... [ user02@remotehost ~ ] $ This ssh command would run the hostname command on the remotehost remote system as the user02 user without accessing the remote interactive shell. [ user01@host ~ ] $ ssh user02@remotehost hostname user02@remotehost ' s password: shadowman remotehost.lab.example.com [ user01@host ~ ] $ Notice that the preceding command displayed the output in the local system's terminal. IDENTIFYING REMOTE USERS \u00b6 The w command displays a list of users currently logged into the computer. This is especially useful to show which users are logged in using ssh from which remote locations, and what they are doing. [ user01@host ~ ] $ ssh user01@remotehost user01@remotehost ' s password: redhat [ user01@remotehost ~ ] $ w 16 :13:38 up 36 min, 1 user, load average: 0 .00, 0 .00, 0 .00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT user02 pts/0 172 .25.250.10 16 :13 7 :30 0 .01s 0 .01s -bash user01 pts/1 172 .25.250.10 16 :24 3 .00s 0 .01s 0 .00s w [ user02@remotehost ~ ] $ The preceding output shows that the user02 user has logged in to the system on the pseudo- terminal 0 at 16:13 today from the host with the 172.25.250.10 IP address, and has been idle at a shell prompt for seven minutes and thirty seconds. The preceding output also shows that the user01 user has logged in to the system on the pseudo-terminal 1 and has been idle since since last three seconds after executing the w command. SSH HOST KEYS \u00b6 SSH secures communication through public-key encryption. When an SSH client connects to an SSH server, the server sends a copy of its public key to the client before the client logs in. This is used to set up the secure encryption for the communication channel and to authenticate the server to the client. When a user uses the ssh command to connect to an SSH server, the command checks to see if it has a copy of the public key for that server in its local known hosts files. The system administrator may have pre-configured it in /etc/ssh/ssh_known_hosts , or the user may have a ~/.ssh/ known_hosts file in their home directory that contains the key. If the client has a copy of the key, ssh will compare the key from the known hosts files for that server to the one it received. If the keys do not match, the client assumes that the network traffic to the server could be hijacked or that the server has been compromised, and seeks the user's confirmation on whether or not to continue with the connection. NOTE Set the StrictHostKeyChecking parameter to yes in the user-specific ~/.ssh/ config file or the system-wide /etc/ssh/ssh_config to cause the ssh command to always abort the SSH connection if the public keys do not match. If the client does not have a copy of the public key in its known hosts files, the ssh command will ask you if you want to log in anyway. If you do, a copy of the public key will be saved in your ~/.ssh/known_hosts file so that the server's identity can be automatically confirmed in the future. [ user01@host ~ ] $ ssh newhost The authenticity of host 'remotehost (172.25.250.12)' can 't be established. ECDSA key fingerprint is SHA256:qaS0PToLrqlCO2XGklA0iY7CaP7aPKimerDoaUkv720. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added ' newhost,172.25.250.12 ' (ECDSA) to the list of known hosts. user01@newhost' s password: redhat ...output omitted... [ user01@newhost ~ ] $ SSH Known Hosts Key Management If a server's public key is changed because the key was lost due to hard drive failure, or replaced for some legitimate reason, you will need to edit the known hosts files to make sure the entry for the old public key is replaced with an entry with the new public key in order to log in without errors. Public keys are stored in the /etc/ssh/ssh_known_hosts and each users' ~/.ssh/ known_hosts file on the SSH client. Each key is on one line. The first field is a list of hostnames and IP addresses that share that public key. The second field is the encryption algorithm for the key. The last field is the key itself. [ user01@host ~ ] $ cat ~/.ssh/known_hosts remotehost,172.25.250.11 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBOsEi0e+FlaNT6jul8Ag5Nj +RViZl0yE2w6iYUr+1fPtOIF0EaOgFZ1LXM37VFTxdgFxHS3D5WhnIfb+68zf8+w = Each remote SSH server that you conect to stores its public key in the /etc/ssh directory in files with the extension .pub . [ user01@remotehost ~ ] $ ls /etc/ssh/*key.pub /etc/ssh/ssh_host_ecdsa_key.pub /etc/ssh/ssh_host_ed25519_key.pub /etc/ssh/ ssh_host_rsa_key.pub NOTE It is a good practice to add entries matching a server's ssh_host_*key.pub files to your ~/.ssh/known_hosts file or the system-wide /etc/ssh/ ssh_known_hosts file. CONFIGURING SSH KEY-BASED AUTHENTICATION \u00b6 SSH KEY-BASED AUTHENTICATION \u00b6 You can configure an SSH server to allow you to authenticate without a password by using key- based authentication. This is based on a private-public key scheme. To do this, you generate a matched pair of cryptographic key files. One is a private key, the other a matching public key. The private key file is used as the authentication credential and, like a password, must be kept secret and secure. The public key is copied to systems the user wants to connect to, and is used to verify the private key. The public key does not need to be secret. You put a copy of the public key in your account on the server. When you try to log in, the SSH server can use the public key to issue a challenge that can only be correctly answered by using the private key. As a result, your ssh client can automatically authenticate your login to the server with your unique copy of the private key. This allows you to securely access systems in a way that doesn't require you to enter a password interactively every time. Generating SSH Keys To create a private key and matching public key for authentication, use the ssh-keygen command. By default, your private and public keys are saved in your ~/.ssh/id_rsa and ~/.ssh/id_rsa.pub files, respectively. [ user@host ~ ] $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key ( /home/user/.ssh/id_rsa ) : Enter Created directory '/home/user/.ssh' . Enter passphrase ( empty for no passphrase ) : Enter Enter same passphrase again: Enter Your identification has been saved in /home/user/.ssh/id_rsa. Your public key has been saved in /home/user/.ssh/id_rsa.pub. The key fingerprint is: SHA256:vxutUNPio3QDCyvkYm1oIx35hmMrHpPKWFdIYu3HV+w user@host.lab.example.com The key ' s randomart image is: +--- [ RSA 2048 ] ----+ | | | . . | | o o o | | . = o o . | | o + = S E . | | ..O o + * + | | .+% O . + B . | | = *oO . . + * | | ++. . +. | +---- [ SHA256 ] -----+ If you do not specify a passphrase when ssh-keygen prompts you, the generated private key is not protected. In this case, anyone with your private key file could use it for authentication. If you set a passphrase, then you will need to enter that passphrase when you use the private key for authentication. (Therefore, you would be using the private key's passphrase rather than your password on the remote host to authenticate.) You can run a helper program called ssh-agent which can temporarily cache your private key passphrase in memory at the start of your session to get true passwordless authentication. This will be discussed later in this section. The following example of the ssh-keygen command shows the creation of the passphrase- protected private key alongside the public key. [ user@host ~ ] $ ssh-keygen -f .ssh/key-with-pass Generating public/private rsa key pair. Enter passphrase ( empty for no passphrase ) : Enter same passphrase again: Your identification has been saved in .ssh/key-with-pass. Your public key has been saved in .ssh/key-with-pass.pub. The key fingerprint is: SHA256:w3GGB7EyHUry4aOcNPKmhNKS7dl1YsMVLvFZJ77VxAo user@host.lab.example.com The key ' s randomart image is: +--- [ RSA 2048 ] ----+ | . + = .o ... | | = B XEo o. | | . o O X = .... | | = = = B = o. | | = + * * S . | | .+ = o + . | | + . | | | | | +---- [ SHA256 ] -----+ The -f option with the ssh-keygen command determines the files where the keys are saved. In the preceding example, the private and public keys are saved in the /home/user/.ssh/key- with-pass /home/user/.ssh/key-with-pass.pub files, respectively. WARNING During further SSH keypair generation, unless you specify a unique file name, you are prompted for permission to overwrite the existing id_rsa and id_rsa.pub files. If you overwrite the existing id_rsa and id_rsa.pub files, then you must replace the old public key with the new one on all the SSH servers that have your old public key. Once the SSH keys have been generated, they are stored by default in the .ssh/ directory of the user's home directory. The permission modes must be 600 on the private key and 644 on the public key. Sharing the Public Key Before key-based authentication can be used, the public key needs to be copied to the destination system. The ssh-copy-id command copies the public key of the SSH keypair to the destination system. If you omit the path to the public key file while running ssh-copy-id , it uses the default /home/user/.ssh/id_rsa.pub file. [ user@host ~ ] $ ssh-copy-id -i .ssh/key-with-pass.pub user@remotehost /usr/bin/ssh-copy-id: INFO: Source of key ( s ) to be installed: \"/home/user/.ssh/ id_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key ( s ) , to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key ( s ) remain to be installed -- if you are prompted now it is to install the new keys user@remotehost 's password: redhat Number of key(s) added: 1 Now try logging into the machine, with: \"ssh ' user@remotehost ' \" and check to make sure that only the key(s) you wanted were added. After the public key is successfully transferred to a remote system, you can authenticate to the remote system using the corresponding private key while logging in to the remote system over SSH. If you omit the path to the private key file while running the ssh command, it uses the default /home/user/.ssh/id_rsa file. [ user@host ~ ] $ ssh -i .ssh/key-with-pass user@remotehost Enter passphrase for key '.ssh/key-with-pass' : redhatpass ...output omitted... [ user@remotehost ~ ] $ exit logout Connection to remotehost closed. [ user@host ~ ] $ Using ssh-agent for Non-interactive Authentication If your SSH private key is protected with a passphrase, you normally have to enter the passphrase to use the private key for authentication. However, you can use a program called ssh-agent to temporarily cache the passphrase in memory. Then any time that you use SSH to log in to another system with the private key, ssh-agent will automatically provide the passphrase for you. This is convenient, and can improve security by providing fewer opportunities for someone \"shoulder surfing\" to see you type the passphrase in. Depending on your local system's configuration, if you initially log in to the GNOME graphical desktop environment, the ssh-agent program might automatically be started and configured for you. If you log in on a text console, log in using ssh , or use sudo or su , you will probably need to start ssh-agent manually for that session. You can do this with the following command: [ user@host ~ ] $ eval $( ssh-agent ) Agent pid 10155 [ user@host ~ ] $ NOTE When you run ssh-agent , it prints out some shell commands. You need to run these commands to set environment variables used by programs like ssh-add to communicate with it. The eval $(ssh-agent) command starts ssh-agent and runs those commands to automatically set those environment variables for that shell session. It also displays the PID of the ssh-agent process. Once ssh-agent is running, you need to tell it the passphrase for your private key or keys. You can do this with the ssh-add command. The following ssh-add commands add the private keys from /home/user/.ssh/id_rsa (the default) and /home/user/.ssh/key-with-pass files, respectively. [ user@host ~ ] $ ssh-add Identity added: /home/user/.ssh/id_rsa ( user@host.lab.example.com ) [ user@host ~ ] $ ssh-add .ssh/key-with-pass Enter passphrase for .ssh/key-with-pass: redhatpass Identity added: .ssh/key-with-pass ( user@host.lab.example.com ) After successfully adding the private keys to the ssh-agent process, you can invoke an SSH connection using the ssh command. If you are using any private key file other than the default /home/user/.ssh/id_rsa file, then you must use the -i option with the ssh command to specify the path to the private key file. The following example of the ssh command uses the default private key file to authenticate to an SSH server. [ user@host ~ ] $ ssh user@remotehost Last login: Fri Apr 5 10 :53:50 2019 from host.example.com [ user@remotehost ~ ] $ The following example of the ssh command uses the /home/user/.ssh/key-with-pass (non- default) private key file to authenticate to an SSH server. The private key in the following example has already been decrypted and added to its parent ssh-agent process, so the ssh command does not prompt you to decrypt the private key by interactively entering its passphrase. [ user@host ~ ] $ ssh -i .ssh/key-with-pass user@remotehost Last login: Mon Apr 8 09 :44:20 2019 from host.example.com [ user@remotehost ~ ] $ When you log out of the session that started ssh-agent , the process will exit and your the passphrases for your private keys will be cleared from memory. CUSTOMIZING OPENSSH SERVICE CONFIGURATION \u00b6 CONFIGURING THE OPENSSH SERVER \u00b6 OpenSSH service is provided by a daemon called sshd. Its main configuration file is /etc/ssh/ sshd_config . The default configuration of the OpenSSH server works well. However, you might want to make some changes to strengthen the security of your system. There are two common changes you might want to make. You might want to prohibit direct remote login to the root account, and you might want to prohibit password-based authentication (in favor of SSH private key authentication). PROHIBIT THE SUPERUSER FROM LOGGING IN USING SSH \u00b6 It is a good practice to prohibit direct login to the root user account from remote systems. Some of the risks of allowing direct login as root include: The user name root exists on every Linux system by default, so a potential attacker only has to guess the password, instead of a valid user name and password combination. This reduces complexity for an attacker. The root user has unrestricted privileges, so its compromise can lead to maximum damage to the system. From an auditing perspective, it can be hard to track which authorized user logged in as root and made changes. If users have to log in as a regular user and switch to the root account, this generates a log event that can be used to help provide accountability. The OpenSSH server uses the PermitRootLogin configuration setting in the /etc/ssh/ sshd_config configuration file to allow or prohibit users logging in to the system as root. PermitRootLogin yes With the PermitRootLogin parameter to yes , as it is by default, people are permitted to log in as root. To prevent this, set the value to no . Alternatively, to prevent password-based authentication but allow private key-based authentication for root, set the PermitRootLogin parameter to without-password . The SSH server (sshd) must be reloaded for any changes to take effect. [ root@host ~ ] # systemctl reload sshd IMPORTANT The advantage of using systemctl reload sshd command is that it tells sshd to re-read its configuration file rather than completely restarting the service. A systemctl restart sshd command would also apply the changes, but would also stop and start the service, breaking all active SSH connections to that host. PROHIBITING PASSWORD-BASED AUTHENTICATION FOR SSH \u00b6 Allowing only private key-based logins to the remote command line has various advantages: Attackers cannot use password guessing attacks to remotely break into known accounts on the system. With passphrase-protected private keys, an attacker needs both the passphrase and a copy of the private key. With passwords, an attacker just needs the password. By using passphrase-protected private keys in conjunction with ssh-agent, the passphrase is exposed less frequently since it is entered less frequently, and logging in is more convenient for the user. The OpenSSH server uses the PasswordAuthentication parameter in the /etc/ssh/ sshd_config configuration file to control whether users can use password-based authentication to log in to the system. PasswordAuthentication yes The default value of yes for the PasswordAuthentication parameter in the /etc/ssh/ sshd_config configuration file causes the SSH server to allow users to use password-based authentication while logging in. The value of no for PasswordAuthentication prevents users from using password-based authentication. Keep in mind that whenever you change the /etc/ssh/sshd_config file, you must reload the sshd service for changes to take effect. IMPORTANT Remember, if you turn off password-based authentication for ssh, you need to have a way to ensure that the user's ~/.ssh/authorized_keys file on the remote server is populated with their public key, so that they can log in. SUMMARY \u00b6 In this chapter, you learned: The ssh command allows users to access remote systems securely using the SSH protocol. A client system stores remote servers' identities in ~/.ssh/known_hosts and /etc/ssh/ ssh_known_hosts . SSH supports both password-based and key-based authentication. The ssh-keygen command generates an SSH key pair for authentication. The ssh-copy-id command exports the public key to remote systems. The sshd service implements the SSH protocol on Red Hat Enterprise Linux systems. It is a recommended practice to configure sshd to disable remote logins as root and to require public key authentication rather than password-based authentication.","title":"Configuring And Securing Ssh"},{"location":"redhat/secssh/#accessing-the-remote-command-line-with-ssh","text":"","title":"ACCESSING THE REMOTE COMMAND LINE WITH SSH"},{"location":"redhat/secssh/#what-is-openssh","text":"OpenSSH implements the Secure Shell or SSH protocol in the Red Hat Enterprise Linux systems. The SSH protocol enables systems to communicate in an encrypted and secure fashion over an insecure network. You can use the ssh command to create a secure connection to a remote system, authenticate as a specific user, and get an interactive shell session on the remote system as that user. You may also use the ssh command to run an individual command on the remote system without running an interactive shell.","title":"WHAT IS OPENSSH?"},{"location":"redhat/secssh/#secure-shell-examples","text":"The following ssh command would log you in on the remote server remotehost using the same user name as the current local user. In this example, the remote system prompts you to authenticate with that user's password. [ user01@host ~ ] $ ssh remotehost user01@remotehost ' s password: redhat ...output omitted... [ user01@remotehost ~ ] $ You can the exit command to log out of the remote system. [ user01@remotehost ~ ] $ exit logout Connection to remotehost closed. [ user01@host ~ ] $ The next ssh command would log you in on the remote server remotehost using the user name user02 . Again, you are prompted by the remote system to authenticate with that user's password. [ user01@host ~ ] $ ssh user02@remotehost user02@remotehost ' s password: shadowman ...output omitted... [ user02@remotehost ~ ] $ This ssh command would run the hostname command on the remotehost remote system as the user02 user without accessing the remote interactive shell. [ user01@host ~ ] $ ssh user02@remotehost hostname user02@remotehost ' s password: shadowman remotehost.lab.example.com [ user01@host ~ ] $ Notice that the preceding command displayed the output in the local system's terminal.","title":"SECURE SHELL EXAMPLES"},{"location":"redhat/secssh/#identifying-remote-users","text":"The w command displays a list of users currently logged into the computer. This is especially useful to show which users are logged in using ssh from which remote locations, and what they are doing. [ user01@host ~ ] $ ssh user01@remotehost user01@remotehost ' s password: redhat [ user01@remotehost ~ ] $ w 16 :13:38 up 36 min, 1 user, load average: 0 .00, 0 .00, 0 .00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT user02 pts/0 172 .25.250.10 16 :13 7 :30 0 .01s 0 .01s -bash user01 pts/1 172 .25.250.10 16 :24 3 .00s 0 .01s 0 .00s w [ user02@remotehost ~ ] $ The preceding output shows that the user02 user has logged in to the system on the pseudo- terminal 0 at 16:13 today from the host with the 172.25.250.10 IP address, and has been idle at a shell prompt for seven minutes and thirty seconds. The preceding output also shows that the user01 user has logged in to the system on the pseudo-terminal 1 and has been idle since since last three seconds after executing the w command.","title":"IDENTIFYING REMOTE USERS"},{"location":"redhat/secssh/#ssh-host-keys","text":"SSH secures communication through public-key encryption. When an SSH client connects to an SSH server, the server sends a copy of its public key to the client before the client logs in. This is used to set up the secure encryption for the communication channel and to authenticate the server to the client. When a user uses the ssh command to connect to an SSH server, the command checks to see if it has a copy of the public key for that server in its local known hosts files. The system administrator may have pre-configured it in /etc/ssh/ssh_known_hosts , or the user may have a ~/.ssh/ known_hosts file in their home directory that contains the key. If the client has a copy of the key, ssh will compare the key from the known hosts files for that server to the one it received. If the keys do not match, the client assumes that the network traffic to the server could be hijacked or that the server has been compromised, and seeks the user's confirmation on whether or not to continue with the connection. NOTE Set the StrictHostKeyChecking parameter to yes in the user-specific ~/.ssh/ config file or the system-wide /etc/ssh/ssh_config to cause the ssh command to always abort the SSH connection if the public keys do not match. If the client does not have a copy of the public key in its known hosts files, the ssh command will ask you if you want to log in anyway. If you do, a copy of the public key will be saved in your ~/.ssh/known_hosts file so that the server's identity can be automatically confirmed in the future. [ user01@host ~ ] $ ssh newhost The authenticity of host 'remotehost (172.25.250.12)' can 't be established. ECDSA key fingerprint is SHA256:qaS0PToLrqlCO2XGklA0iY7CaP7aPKimerDoaUkv720. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added ' newhost,172.25.250.12 ' (ECDSA) to the list of known hosts. user01@newhost' s password: redhat ...output omitted... [ user01@newhost ~ ] $ SSH Known Hosts Key Management If a server's public key is changed because the key was lost due to hard drive failure, or replaced for some legitimate reason, you will need to edit the known hosts files to make sure the entry for the old public key is replaced with an entry with the new public key in order to log in without errors. Public keys are stored in the /etc/ssh/ssh_known_hosts and each users' ~/.ssh/ known_hosts file on the SSH client. Each key is on one line. The first field is a list of hostnames and IP addresses that share that public key. The second field is the encryption algorithm for the key. The last field is the key itself. [ user01@host ~ ] $ cat ~/.ssh/known_hosts remotehost,172.25.250.11 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBOsEi0e+FlaNT6jul8Ag5Nj +RViZl0yE2w6iYUr+1fPtOIF0EaOgFZ1LXM37VFTxdgFxHS3D5WhnIfb+68zf8+w = Each remote SSH server that you conect to stores its public key in the /etc/ssh directory in files with the extension .pub . [ user01@remotehost ~ ] $ ls /etc/ssh/*key.pub /etc/ssh/ssh_host_ecdsa_key.pub /etc/ssh/ssh_host_ed25519_key.pub /etc/ssh/ ssh_host_rsa_key.pub NOTE It is a good practice to add entries matching a server's ssh_host_*key.pub files to your ~/.ssh/known_hosts file or the system-wide /etc/ssh/ ssh_known_hosts file.","title":"SSH HOST KEYS"},{"location":"redhat/secssh/#configuring-ssh-key-based-authentication","text":"","title":"CONFIGURING SSH KEY-BASED AUTHENTICATION"},{"location":"redhat/secssh/#ssh-key-based-authentication","text":"You can configure an SSH server to allow you to authenticate without a password by using key- based authentication. This is based on a private-public key scheme. To do this, you generate a matched pair of cryptographic key files. One is a private key, the other a matching public key. The private key file is used as the authentication credential and, like a password, must be kept secret and secure. The public key is copied to systems the user wants to connect to, and is used to verify the private key. The public key does not need to be secret. You put a copy of the public key in your account on the server. When you try to log in, the SSH server can use the public key to issue a challenge that can only be correctly answered by using the private key. As a result, your ssh client can automatically authenticate your login to the server with your unique copy of the private key. This allows you to securely access systems in a way that doesn't require you to enter a password interactively every time. Generating SSH Keys To create a private key and matching public key for authentication, use the ssh-keygen command. By default, your private and public keys are saved in your ~/.ssh/id_rsa and ~/.ssh/id_rsa.pub files, respectively. [ user@host ~ ] $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key ( /home/user/.ssh/id_rsa ) : Enter Created directory '/home/user/.ssh' . Enter passphrase ( empty for no passphrase ) : Enter Enter same passphrase again: Enter Your identification has been saved in /home/user/.ssh/id_rsa. Your public key has been saved in /home/user/.ssh/id_rsa.pub. The key fingerprint is: SHA256:vxutUNPio3QDCyvkYm1oIx35hmMrHpPKWFdIYu3HV+w user@host.lab.example.com The key ' s randomart image is: +--- [ RSA 2048 ] ----+ | | | . . | | o o o | | . = o o . | | o + = S E . | | ..O o + * + | | .+% O . + B . | | = *oO . . + * | | ++. . +. | +---- [ SHA256 ] -----+ If you do not specify a passphrase when ssh-keygen prompts you, the generated private key is not protected. In this case, anyone with your private key file could use it for authentication. If you set a passphrase, then you will need to enter that passphrase when you use the private key for authentication. (Therefore, you would be using the private key's passphrase rather than your password on the remote host to authenticate.) You can run a helper program called ssh-agent which can temporarily cache your private key passphrase in memory at the start of your session to get true passwordless authentication. This will be discussed later in this section. The following example of the ssh-keygen command shows the creation of the passphrase- protected private key alongside the public key. [ user@host ~ ] $ ssh-keygen -f .ssh/key-with-pass Generating public/private rsa key pair. Enter passphrase ( empty for no passphrase ) : Enter same passphrase again: Your identification has been saved in .ssh/key-with-pass. Your public key has been saved in .ssh/key-with-pass.pub. The key fingerprint is: SHA256:w3GGB7EyHUry4aOcNPKmhNKS7dl1YsMVLvFZJ77VxAo user@host.lab.example.com The key ' s randomart image is: +--- [ RSA 2048 ] ----+ | . + = .o ... | | = B XEo o. | | . o O X = .... | | = = = B = o. | | = + * * S . | | .+ = o + . | | + . | | | | | +---- [ SHA256 ] -----+ The -f option with the ssh-keygen command determines the files where the keys are saved. In the preceding example, the private and public keys are saved in the /home/user/.ssh/key- with-pass /home/user/.ssh/key-with-pass.pub files, respectively. WARNING During further SSH keypair generation, unless you specify a unique file name, you are prompted for permission to overwrite the existing id_rsa and id_rsa.pub files. If you overwrite the existing id_rsa and id_rsa.pub files, then you must replace the old public key with the new one on all the SSH servers that have your old public key. Once the SSH keys have been generated, they are stored by default in the .ssh/ directory of the user's home directory. The permission modes must be 600 on the private key and 644 on the public key. Sharing the Public Key Before key-based authentication can be used, the public key needs to be copied to the destination system. The ssh-copy-id command copies the public key of the SSH keypair to the destination system. If you omit the path to the public key file while running ssh-copy-id , it uses the default /home/user/.ssh/id_rsa.pub file. [ user@host ~ ] $ ssh-copy-id -i .ssh/key-with-pass.pub user@remotehost /usr/bin/ssh-copy-id: INFO: Source of key ( s ) to be installed: \"/home/user/.ssh/ id_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key ( s ) , to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key ( s ) remain to be installed -- if you are prompted now it is to install the new keys user@remotehost 's password: redhat Number of key(s) added: 1 Now try logging into the machine, with: \"ssh ' user@remotehost ' \" and check to make sure that only the key(s) you wanted were added. After the public key is successfully transferred to a remote system, you can authenticate to the remote system using the corresponding private key while logging in to the remote system over SSH. If you omit the path to the private key file while running the ssh command, it uses the default /home/user/.ssh/id_rsa file. [ user@host ~ ] $ ssh -i .ssh/key-with-pass user@remotehost Enter passphrase for key '.ssh/key-with-pass' : redhatpass ...output omitted... [ user@remotehost ~ ] $ exit logout Connection to remotehost closed. [ user@host ~ ] $ Using ssh-agent for Non-interactive Authentication If your SSH private key is protected with a passphrase, you normally have to enter the passphrase to use the private key for authentication. However, you can use a program called ssh-agent to temporarily cache the passphrase in memory. Then any time that you use SSH to log in to another system with the private key, ssh-agent will automatically provide the passphrase for you. This is convenient, and can improve security by providing fewer opportunities for someone \"shoulder surfing\" to see you type the passphrase in. Depending on your local system's configuration, if you initially log in to the GNOME graphical desktop environment, the ssh-agent program might automatically be started and configured for you. If you log in on a text console, log in using ssh , or use sudo or su , you will probably need to start ssh-agent manually for that session. You can do this with the following command: [ user@host ~ ] $ eval $( ssh-agent ) Agent pid 10155 [ user@host ~ ] $ NOTE When you run ssh-agent , it prints out some shell commands. You need to run these commands to set environment variables used by programs like ssh-add to communicate with it. The eval $(ssh-agent) command starts ssh-agent and runs those commands to automatically set those environment variables for that shell session. It also displays the PID of the ssh-agent process. Once ssh-agent is running, you need to tell it the passphrase for your private key or keys. You can do this with the ssh-add command. The following ssh-add commands add the private keys from /home/user/.ssh/id_rsa (the default) and /home/user/.ssh/key-with-pass files, respectively. [ user@host ~ ] $ ssh-add Identity added: /home/user/.ssh/id_rsa ( user@host.lab.example.com ) [ user@host ~ ] $ ssh-add .ssh/key-with-pass Enter passphrase for .ssh/key-with-pass: redhatpass Identity added: .ssh/key-with-pass ( user@host.lab.example.com ) After successfully adding the private keys to the ssh-agent process, you can invoke an SSH connection using the ssh command. If you are using any private key file other than the default /home/user/.ssh/id_rsa file, then you must use the -i option with the ssh command to specify the path to the private key file. The following example of the ssh command uses the default private key file to authenticate to an SSH server. [ user@host ~ ] $ ssh user@remotehost Last login: Fri Apr 5 10 :53:50 2019 from host.example.com [ user@remotehost ~ ] $ The following example of the ssh command uses the /home/user/.ssh/key-with-pass (non- default) private key file to authenticate to an SSH server. The private key in the following example has already been decrypted and added to its parent ssh-agent process, so the ssh command does not prompt you to decrypt the private key by interactively entering its passphrase. [ user@host ~ ] $ ssh -i .ssh/key-with-pass user@remotehost Last login: Mon Apr 8 09 :44:20 2019 from host.example.com [ user@remotehost ~ ] $ When you log out of the session that started ssh-agent , the process will exit and your the passphrases for your private keys will be cleared from memory.","title":"SSH KEY-BASED AUTHENTICATION"},{"location":"redhat/secssh/#customizing-openssh-service-configuration","text":"","title":"CUSTOMIZING OPENSSH SERVICE CONFIGURATION"},{"location":"redhat/secssh/#configuring-the-openssh-server","text":"OpenSSH service is provided by a daemon called sshd. Its main configuration file is /etc/ssh/ sshd_config . The default configuration of the OpenSSH server works well. However, you might want to make some changes to strengthen the security of your system. There are two common changes you might want to make. You might want to prohibit direct remote login to the root account, and you might want to prohibit password-based authentication (in favor of SSH private key authentication).","title":"CONFIGURING THE OPENSSH SERVER"},{"location":"redhat/secssh/#prohibit-the-superuser-from-logging-in-using-ssh","text":"It is a good practice to prohibit direct login to the root user account from remote systems. Some of the risks of allowing direct login as root include: The user name root exists on every Linux system by default, so a potential attacker only has to guess the password, instead of a valid user name and password combination. This reduces complexity for an attacker. The root user has unrestricted privileges, so its compromise can lead to maximum damage to the system. From an auditing perspective, it can be hard to track which authorized user logged in as root and made changes. If users have to log in as a regular user and switch to the root account, this generates a log event that can be used to help provide accountability. The OpenSSH server uses the PermitRootLogin configuration setting in the /etc/ssh/ sshd_config configuration file to allow or prohibit users logging in to the system as root. PermitRootLogin yes With the PermitRootLogin parameter to yes , as it is by default, people are permitted to log in as root. To prevent this, set the value to no . Alternatively, to prevent password-based authentication but allow private key-based authentication for root, set the PermitRootLogin parameter to without-password . The SSH server (sshd) must be reloaded for any changes to take effect. [ root@host ~ ] # systemctl reload sshd IMPORTANT The advantage of using systemctl reload sshd command is that it tells sshd to re-read its configuration file rather than completely restarting the service. A systemctl restart sshd command would also apply the changes, but would also stop and start the service, breaking all active SSH connections to that host.","title":"PROHIBIT THE SUPERUSER FROM LOGGING IN USING SSH"},{"location":"redhat/secssh/#prohibiting-password-based-authentication-for-ssh","text":"Allowing only private key-based logins to the remote command line has various advantages: Attackers cannot use password guessing attacks to remotely break into known accounts on the system. With passphrase-protected private keys, an attacker needs both the passphrase and a copy of the private key. With passwords, an attacker just needs the password. By using passphrase-protected private keys in conjunction with ssh-agent, the passphrase is exposed less frequently since it is entered less frequently, and logging in is more convenient for the user. The OpenSSH server uses the PasswordAuthentication parameter in the /etc/ssh/ sshd_config configuration file to control whether users can use password-based authentication to log in to the system. PasswordAuthentication yes The default value of yes for the PasswordAuthentication parameter in the /etc/ssh/ sshd_config configuration file causes the SSH server to allow users to use password-based authentication while logging in. The value of no for PasswordAuthentication prevents users from using password-based authentication. Keep in mind that whenever you change the /etc/ssh/sshd_config file, you must reload the sshd service for changes to take effect. IMPORTANT Remember, if you turn off password-based authentication for ssh, you need to have a way to ensure that the user's ~/.ssh/authorized_keys file on the remote server is populated with their public key, so that they can log in.","title":"PROHIBITING PASSWORD-BASED AUTHENTICATION FOR SSH"},{"location":"redhat/secssh/#summary","text":"In this chapter, you learned: The ssh command allows users to access remote systems securely using the SSH protocol. A client system stores remote servers' identities in ~/.ssh/known_hosts and /etc/ssh/ ssh_known_hosts . SSH supports both password-based and key-based authentication. The ssh-keygen command generates an SSH key pair for authentication. The ssh-copy-id command exports the public key to remote systems. The sshd service implements the SSH protocol on Red Hat Enterprise Linux systems. It is a recommended practice to configure sshd to disable remote logins as root and to require public key authentication rather than password-based authentication.","title":"SUMMARY"},{"location":"redhat/service/","text":"IDENTIFYING AUTOMATICALLY STARTED SYSTEM PROCESSES \u00b6 INTRODUCTION TO systemd \u00b6 The systemd daemon manages startup for Linux, including service startup and service management in general. It activates system resources, server daemons, and other processes both at boot time and on a running system. Daemons are processes that either wait or run in the background, performing various tasks. Generally, daemons start automatically at boot time and continue to run until shutdown or until they are manually stopped. It is a convention for names of many daemon programs to end in the letter d . A service in the systemd sense often refers to one or more daemons, but starting or stopping a service may instead make a one-time change to the state of the system, which does not involve leaving a daemon process running afterward (called oneshot). In Red Hat Enterprise Linux, the first process that starts (PID 1) is systemd. A few of the features provided by systemd include: Parallelization capabilities (starting multiple services simultaneously), which increase the boot speed of a system. On-demand starting of daemons without requiring a separate service. Automatic service dependency management, which can prevent long timeouts. For example, a network-dependent service will not attempt to start up until the network is available. A method of tracking related processes together by using Linux control groups. DESCRIBING SERVICE UNITS \u00b6 systemd uses units to manage different types of objects. Some common unit types are listed below: Service units have a .service extension and represent system services. This type of unit is used to start frequently accessed daemons, such as a web server. Socket units have a .socket extension and represent inter-process communication (IPC) sockets that systemd should monitor. If a client connects to the socket, systemd will start a daemon and pass the connection to it. Socket units are used to delay the start of a service at boot time and to start less frequently used services on demand. Path units have a .path extension and are used to delay the activation of a service until a specific file system change occurs. This is commonly used for services which use spool directories such as a printing system. The systemctl command is used to manage units. For example, display available unit types with the systemctl -t help command. IMPORTANT When using systemctl , you can abbreviate unit names, process tree entries, and unit descriptions. LISTING SERVICE UNITS \u00b6 You use the systemctl command to explore the current state of the system. For example, the following command lists all currently loaded service units, paginating the output using less . [ root@host ~ ] # systemctl list-units --type=service UNIT LOAD ACTIVE SUB DESCRIPTION atd.service loaded active running Job spooling tools auditd.service loaded active running Security Auditing Service chronyd.service loaded active running NTP client/server crond.service loaded active running Command Scheduler dbus.service loaded active running D-Bus System Message Bus ...output omitted... The above output limits the type of unit listed to service units with the --type=service option. The output has the following columns: Columns in the systemctl list-units Command Output UNIT The service unit name. LOAD Whether systemd properly parsed the unit's configuration and loaded the unit into memory. ACTIVE The high-level activation state of the unit. This information indicates whether the unit has started successfully or not. SUB The low-level activation state of the unit. This information indicates more detailed information about the unit. The information varies based on unit type, state, and how the unit is executed. DESCRIPTION The short description of the unit. By default, the systemctl list-units --type=service command lists only the service units with active activation states. The --all option lists all service units regardless of the activation states. Use the --state= option to filter by the values in the LOAD, ACTIVE , or SUB fields. [ root@host ~ ] # systemctl list-units --type=service --all UNIT LOAD ACTIVE SUB DESCRIPTION atd.service loaded active running Job spooling tools auditd.service loaded active running Security Auditing ... auth-rpcgss-module.service loaded inactive dead Kernel Module ... chronyd.service loaded active running NTP client/server cpupower.service loaded inactive dead Configure CPU power ... crond.service loaded active running Command Scheduler dbus.service loaded active running D-Bus System Message Bus \u25cfdisplay-manager.service not-found inactive dead display-manager.service ...output omitted... The systemctl command without any arguments lists units that are both loaded and active. [ root@host ~ ] # systemctl UNIT LOAD ACTIVE SUB DESCRIPTION proc-sys-fs-binfmt_misc.automount loaded active waiting Arbitrary... sys-devices-....device loaded active plugged Virtio network... sys-subsystem-net-devices-ens3.deviceloaded active plugged Virtio network... ... -.mount loaded active mounted Root Mount boot.mount loaded active mounted /boot ... systemd-ask-password-plymouth.path loaded active waiting Forward Password... systemd-ask-password-wall.path loaded active waiting Forward Password... init.scope loaded active running System and Servi... session-1.scope loaded active running Session 1 of... atd.service loaded active running Job spooling tools auditd.service loaded active running Security Auditing... chronyd.service loaded active running NTP client/server crond.service loaded active running Command Scheduler ...output omitted... The systemctl list-units command displays units that the systemd service attempts to parse and load into memory; it does not display installed, but not enabled, services. To see the state of all unit files installed, use the systemctl list-unit-files command. For example: [ root@host ~ ] # systemctl list-unit-files --type=service UNIT FILE STATE arp-ethers.service disabled atd.service enabled auditd.service enabled auth-rpcgss-module.service static autovt@.service enabled blk-availability.service disabled ...output omitted... In the output of the systemctl list-units-files command, valid entries for the STATE field are enabled, disabled, static , and masked . VIEWING SERVICE STATES \u00b6 View the status of a specific unit with systemctl status name.type . If the unit type is not provided, systemctl will show the status of a service unit, if one exists. [ root@host ~ ] # systemctl status sshd.service \u25cf sshd.service - OpenSSH server daemon Loaded: loaded ( /usr/lib/systemd/system/sshd.service ; enabled ; vendor preset: enabled ) Active: active ( running ) since Thu 2019 -02-14 12 :07:45 IST ; 7h ago Main PID: 1073 ( sshd ) CGroup: /system.slice/sshd.service \u2514\u25001073 /usr/sbin/sshd -D ... Feb 14 11 :51:39 host.example.com systemd [ 1 ] : Started OpenSSH server daemon. Feb 14 11 :51:39 host.example.com sshd [ 1073 ] : Could not load host key: /et...y Feb 14 11 :51:39 host.example.com sshd [ 1073 ] : Server listening on 0 .0.0.0 .... Feb 14 11 :51:39 host.example.com sshd [ 1073 ] : Server listening on :: port 22 . Feb 14 11 :53:21 host.example.com sshd [ 1270 ] : error: Could not load host k...y Feb 14 11 :53:22 host.example.com sshd [ 1270 ] : Accepted password for root f...2 ...output omitted... This command displays the current status of the service. The meaning of the fields are: Service Unit Information FIELD DESCRIPTION Loaded Whether the service unit is loaded into memory. Active Whether the service unit is running and if so, how long it has been running. Main PID The main process ID of the service, including the command name. Status Additional information about the service. Several keywords indicating the state of the service can be found in the status output: Service States in the Output of systemctl KEYWORD DESCRIPTION loaded Unit configuration file has been processed. active (running) Running with one or more continuing processes. active (exited) Successfully completed a one-time configuration. active (waiting) Running but waiting for an event. inactive Not running. enabled Is started at boot time. disabled Is not set to be started at boot time. static Cannot be enabled, but may be started by an enabled unit automatically. NOTE The systemctl status NAME command replaces the service NAME status command used in Red Hat Enterprise Linux 6 and earlier. VERIFYING THE STATUS OF A SERVICE \u00b6 The systemctl command provides methods for verifying the specific states of a service. For example, use the following command to verify that the a service unit is currently active (running): [ root@host ~ ] # systemctl is-active sshd.service active The command returns state of the service unit, which is usually active or inactive . Run the following command to verify whether a service unit is enabled to start automatically during system boot: [ root@host ~ ] # systemctl is-enabled sshd.service enabled The command returns whether the service unit is enabled to start at boot time, which is usually enabled or disabled . To verify whether the unit failed during startup, run the following command: [ root@host ~ ] # systemctl is-failed sshd.service active The command either returns active if it is properly running or failed if an error has occurred during startup. In case the unit was stopped, it returns unknown or inactive . To list all the failed units, run the systemctl --failed --type=service command. CONTROLLING SYSTEM SERVICES \u00b6 STARTING AND STOPPING SERVICES \u00b6 Services need to be stopped or started manually for a number of reasons: perhaps the service needs to be updated; the configuration file may need to be changed; or a service may need to be uninstalled; or an administrator may manually start an infrequently used service. To start a service, first verify that it is not running with systemctl status . Then, use the systemctl start command as the root user (using sudo if necessary). The example below shows how to start the sshd.service service: [ root@host ~ ] # systemctl start sshd.service The systemd service looks for .service files for service management in commands in the absence of the service type with the service name. Thus the above command can be executed as: [ root@host ~ ] # systemctl start sshd To stop a currently running service, use the stop argument with the systemctl command. The example below shows how to stop the sshd.service service: [ root@host ~ ] # systemctl stop sshd.service RESTARTING AND RELOADING SERVICES \u00b6 During a restart of a running service, the service is stopped and then started. On the restart of service, the process ID changes and a new process ID gets associated during the startup. To restart a running service, use the restart argument with the systemctl command. The example below shows how to restart the sshd.service service: [ root@host ~ ] # systemctl restart sshd.service Some services have the ability to reload their configuration files without requiring a restart. This process is called a service reload. Reloading a service does not change the process ID associated with various service processes. To reload a running service, use the reload argument with the systemctl command. The example below shows how to reload the sshd.service service after configuration changes: [ root@host ~ ] # systemctl reload sshd.service In case you are not sure whether the service has the functionality to reload the configuration file changes, use the reload-or-restart argument with the systemctl command. The command reloads the configuration changes if the reloading functionality is available. Otherwise, the command restarts the service to implements the new configuration changes: [ root@host ~ ] # systemctl reload-or-restart sshd.service LISTING UNIT DEPENDENCIES \u00b6 Some services require that other services be running first, creating dependencies on the other services. Other services are not started at boot time but rather only on demand. In both cases, systemd and systemctl start services as needed whether to resolve the dependency or to start an infrequently used service. For example, if the CUPS print service is not running and a file is placed into the print spool directory, then the system will start CUPS-related daemons or commands to satisfy the print request. [ root@host ~ ] # systemctl stop cups.service Warning: Stopping cups, but it can still be activated by: cups.path cups.socket To completely stop printing services on a system, stop all three units. Disabling the service disables the dependencies. The systemctl list-dependencies UNIT command displays a hierarchy mapping of dependencies to start the service unit. To list reverse dependencies (units that depend on the specified unit), use the --reverse option with the command. [ root@host ~ ] # systemctl list-dependencies sshd.service sshd.service \u25cf \u251c\u2500system.slice \u25cf \u251c\u2500sshd-keygen.target \u25cf \u2502 \u251c\u2500sshd-keygen@ecdsa.service \u25cf \u2502 \u251c\u2500sshd-keygen@ed25519.service \u25cf \u2502 \u2514\u2500sshd-keygen@rsa.service \u25cf \u2514\u2500sysinit.target ...output omitted... MASKING AND UNMASKING SERVICES \u00b6 At times, a system may have different services installed that are conflicting with each other. For example, there are multiple methods to manage mail servers (postfix and sendmail, for example). Masking a service prevents an administrator from accidentally starting a service that conflicts with others. Masking creates a link in the configuration directories to the /dev/null file which prevents the service from starting. [ root@host ~ ] # systemctl mask sendmail.service Created symlink /etc/systemd/system/sendmail.service \u2192 /dev/null. [ root@host ~ ] # systemctl list-unit-files --type=service UNIT FILE STATE ...output omitted... sendmail.service masked ...output omitted... Attempting to start a masked service unit fails with the following output: [ root@host ~ ] # systemctl start sendmail.service Failed to start sendmail.service: Unit sendmail.service is masked. Use the systemctl unmask command to unmask the service unit. [ root@host ~ ] # systemctl unmask sendmail Removed /etc/systemd/system/sendmail.service. IMPORTANT A disabled service can be started manually or by other unit files but it does not start automatically at boot. A masked service does not start manually or automatically. ENABLING SERVICES TO START OR STOP AT BOOT \u00b6 Starting a service on a running system does not guarantee that the service automatically starts when the system reboots. Similarly, stopping a service on a running system does not keep it from starting again when the system reboots. Creating links in the systemd configuration directories enables the service to start at boot. The systemctl commands creates and removes these links. To start a service at boot, use the systemctl enable command. [ root@root ~ ] # systemctl enable sshd.service Created symlink /etc/systemd/system/multi-user.target.wants/sshd.service \u2192 /usr/ lib/systemd/system/sshd.service. The above command creates a symbolic link from the service unit file, usually in the /usr/lib/ systemd/system directory, to the location on disk where systemd looks for files, which is in the /etc/systemd/system/TARGETNAME.target.wants directory. Enabling a service does not start the service in the current session. To start the service and enable it to start automatically during boot, execute both the systemctl start and systemctl enable commands. To disable the service from starting automatically, use the following command, which removes the symbolic link created while enabling a service. Note that disabling a service does not stop the service. [ root@host ~ ] # systemctl disable sshd.service Removed /etc/systemd/system/multi-user.target.wants/sshd.service. To verify whether the service is enabled or disable, use the systemctl is-enabled command. SUMMARY OF systemctl COMMANDS \u00b6 Services can be started and stopped on a running system and enabled or disabled for an automatic start at boot time. Useful Service Management Commands TASK COMMAND View detailed information about a unit state. systemctl status UNIT Stop a service on a running system. systemctl stop UNIT Start a service on a running system. systemctl start UNIT Restart a service on a running system. systemctl restart UNIT Reload the configuration file of a running service. systemctl reload UNIT Completely disable a service from being started, both manually and at boot. systemctl mask UNIT Make a masked service available. systemctl unmask UNIT Configure a service to start at boot time. systemctl enable UNIT Disable a service from starting at boot time. systemctl disable UNIT List units required and wanted by the specified unit. systemctl list-dependencies UNIT SUMMARY \u00b6 In this chapter, you learned: systemd provides a method for activating system resources, server daemons, and other processes, both at boot time and on a running system. Use the systemctl to start, stop, reload, enable, and disable services. Use the systemctl status command to determine the status of system daemons and network services started by systemd. The systemctl list-dependencies command lists all service units upon which a specific service unit depends. systemd can mask a service unit so that it does not run even to satisfy dependencies.","title":"Controlling Services And Daemons"},{"location":"redhat/service/#identifying-automatically-started-system-processes","text":"","title":"IDENTIFYING AUTOMATICALLY STARTED SYSTEM PROCESSES"},{"location":"redhat/service/#introduction-to-systemd","text":"The systemd daemon manages startup for Linux, including service startup and service management in general. It activates system resources, server daemons, and other processes both at boot time and on a running system. Daemons are processes that either wait or run in the background, performing various tasks. Generally, daemons start automatically at boot time and continue to run until shutdown or until they are manually stopped. It is a convention for names of many daemon programs to end in the letter d . A service in the systemd sense often refers to one or more daemons, but starting or stopping a service may instead make a one-time change to the state of the system, which does not involve leaving a daemon process running afterward (called oneshot). In Red Hat Enterprise Linux, the first process that starts (PID 1) is systemd. A few of the features provided by systemd include: Parallelization capabilities (starting multiple services simultaneously), which increase the boot speed of a system. On-demand starting of daemons without requiring a separate service. Automatic service dependency management, which can prevent long timeouts. For example, a network-dependent service will not attempt to start up until the network is available. A method of tracking related processes together by using Linux control groups.","title":"INTRODUCTION TO systemd"},{"location":"redhat/service/#describing-service-units","text":"systemd uses units to manage different types of objects. Some common unit types are listed below: Service units have a .service extension and represent system services. This type of unit is used to start frequently accessed daemons, such as a web server. Socket units have a .socket extension and represent inter-process communication (IPC) sockets that systemd should monitor. If a client connects to the socket, systemd will start a daemon and pass the connection to it. Socket units are used to delay the start of a service at boot time and to start less frequently used services on demand. Path units have a .path extension and are used to delay the activation of a service until a specific file system change occurs. This is commonly used for services which use spool directories such as a printing system. The systemctl command is used to manage units. For example, display available unit types with the systemctl -t help command. IMPORTANT When using systemctl , you can abbreviate unit names, process tree entries, and unit descriptions.","title":"DESCRIBING SERVICE UNITS"},{"location":"redhat/service/#listing-service-units","text":"You use the systemctl command to explore the current state of the system. For example, the following command lists all currently loaded service units, paginating the output using less . [ root@host ~ ] # systemctl list-units --type=service UNIT LOAD ACTIVE SUB DESCRIPTION atd.service loaded active running Job spooling tools auditd.service loaded active running Security Auditing Service chronyd.service loaded active running NTP client/server crond.service loaded active running Command Scheduler dbus.service loaded active running D-Bus System Message Bus ...output omitted... The above output limits the type of unit listed to service units with the --type=service option. The output has the following columns: Columns in the systemctl list-units Command Output UNIT The service unit name. LOAD Whether systemd properly parsed the unit's configuration and loaded the unit into memory. ACTIVE The high-level activation state of the unit. This information indicates whether the unit has started successfully or not. SUB The low-level activation state of the unit. This information indicates more detailed information about the unit. The information varies based on unit type, state, and how the unit is executed. DESCRIPTION The short description of the unit. By default, the systemctl list-units --type=service command lists only the service units with active activation states. The --all option lists all service units regardless of the activation states. Use the --state= option to filter by the values in the LOAD, ACTIVE , or SUB fields. [ root@host ~ ] # systemctl list-units --type=service --all UNIT LOAD ACTIVE SUB DESCRIPTION atd.service loaded active running Job spooling tools auditd.service loaded active running Security Auditing ... auth-rpcgss-module.service loaded inactive dead Kernel Module ... chronyd.service loaded active running NTP client/server cpupower.service loaded inactive dead Configure CPU power ... crond.service loaded active running Command Scheduler dbus.service loaded active running D-Bus System Message Bus \u25cfdisplay-manager.service not-found inactive dead display-manager.service ...output omitted... The systemctl command without any arguments lists units that are both loaded and active. [ root@host ~ ] # systemctl UNIT LOAD ACTIVE SUB DESCRIPTION proc-sys-fs-binfmt_misc.automount loaded active waiting Arbitrary... sys-devices-....device loaded active plugged Virtio network... sys-subsystem-net-devices-ens3.deviceloaded active plugged Virtio network... ... -.mount loaded active mounted Root Mount boot.mount loaded active mounted /boot ... systemd-ask-password-plymouth.path loaded active waiting Forward Password... systemd-ask-password-wall.path loaded active waiting Forward Password... init.scope loaded active running System and Servi... session-1.scope loaded active running Session 1 of... atd.service loaded active running Job spooling tools auditd.service loaded active running Security Auditing... chronyd.service loaded active running NTP client/server crond.service loaded active running Command Scheduler ...output omitted... The systemctl list-units command displays units that the systemd service attempts to parse and load into memory; it does not display installed, but not enabled, services. To see the state of all unit files installed, use the systemctl list-unit-files command. For example: [ root@host ~ ] # systemctl list-unit-files --type=service UNIT FILE STATE arp-ethers.service disabled atd.service enabled auditd.service enabled auth-rpcgss-module.service static autovt@.service enabled blk-availability.service disabled ...output omitted... In the output of the systemctl list-units-files command, valid entries for the STATE field are enabled, disabled, static , and masked .","title":"LISTING SERVICE UNITS"},{"location":"redhat/service/#viewing-service-states","text":"View the status of a specific unit with systemctl status name.type . If the unit type is not provided, systemctl will show the status of a service unit, if one exists. [ root@host ~ ] # systemctl status sshd.service \u25cf sshd.service - OpenSSH server daemon Loaded: loaded ( /usr/lib/systemd/system/sshd.service ; enabled ; vendor preset: enabled ) Active: active ( running ) since Thu 2019 -02-14 12 :07:45 IST ; 7h ago Main PID: 1073 ( sshd ) CGroup: /system.slice/sshd.service \u2514\u25001073 /usr/sbin/sshd -D ... Feb 14 11 :51:39 host.example.com systemd [ 1 ] : Started OpenSSH server daemon. Feb 14 11 :51:39 host.example.com sshd [ 1073 ] : Could not load host key: /et...y Feb 14 11 :51:39 host.example.com sshd [ 1073 ] : Server listening on 0 .0.0.0 .... Feb 14 11 :51:39 host.example.com sshd [ 1073 ] : Server listening on :: port 22 . Feb 14 11 :53:21 host.example.com sshd [ 1270 ] : error: Could not load host k...y Feb 14 11 :53:22 host.example.com sshd [ 1270 ] : Accepted password for root f...2 ...output omitted... This command displays the current status of the service. The meaning of the fields are: Service Unit Information FIELD DESCRIPTION Loaded Whether the service unit is loaded into memory. Active Whether the service unit is running and if so, how long it has been running. Main PID The main process ID of the service, including the command name. Status Additional information about the service. Several keywords indicating the state of the service can be found in the status output: Service States in the Output of systemctl KEYWORD DESCRIPTION loaded Unit configuration file has been processed. active (running) Running with one or more continuing processes. active (exited) Successfully completed a one-time configuration. active (waiting) Running but waiting for an event. inactive Not running. enabled Is started at boot time. disabled Is not set to be started at boot time. static Cannot be enabled, but may be started by an enabled unit automatically. NOTE The systemctl status NAME command replaces the service NAME status command used in Red Hat Enterprise Linux 6 and earlier.","title":"VIEWING SERVICE STATES"},{"location":"redhat/service/#verifying-the-status-of-a-service","text":"The systemctl command provides methods for verifying the specific states of a service. For example, use the following command to verify that the a service unit is currently active (running): [ root@host ~ ] # systemctl is-active sshd.service active The command returns state of the service unit, which is usually active or inactive . Run the following command to verify whether a service unit is enabled to start automatically during system boot: [ root@host ~ ] # systemctl is-enabled sshd.service enabled The command returns whether the service unit is enabled to start at boot time, which is usually enabled or disabled . To verify whether the unit failed during startup, run the following command: [ root@host ~ ] # systemctl is-failed sshd.service active The command either returns active if it is properly running or failed if an error has occurred during startup. In case the unit was stopped, it returns unknown or inactive . To list all the failed units, run the systemctl --failed --type=service command.","title":"VERIFYING THE STATUS OF A SERVICE"},{"location":"redhat/service/#controlling-system-services","text":"","title":"CONTROLLING SYSTEM SERVICES"},{"location":"redhat/service/#starting-and-stopping-services","text":"Services need to be stopped or started manually for a number of reasons: perhaps the service needs to be updated; the configuration file may need to be changed; or a service may need to be uninstalled; or an administrator may manually start an infrequently used service. To start a service, first verify that it is not running with systemctl status . Then, use the systemctl start command as the root user (using sudo if necessary). The example below shows how to start the sshd.service service: [ root@host ~ ] # systemctl start sshd.service The systemd service looks for .service files for service management in commands in the absence of the service type with the service name. Thus the above command can be executed as: [ root@host ~ ] # systemctl start sshd To stop a currently running service, use the stop argument with the systemctl command. The example below shows how to stop the sshd.service service: [ root@host ~ ] # systemctl stop sshd.service","title":"STARTING AND STOPPING SERVICES"},{"location":"redhat/service/#restarting-and-reloading-services","text":"During a restart of a running service, the service is stopped and then started. On the restart of service, the process ID changes and a new process ID gets associated during the startup. To restart a running service, use the restart argument with the systemctl command. The example below shows how to restart the sshd.service service: [ root@host ~ ] # systemctl restart sshd.service Some services have the ability to reload their configuration files without requiring a restart. This process is called a service reload. Reloading a service does not change the process ID associated with various service processes. To reload a running service, use the reload argument with the systemctl command. The example below shows how to reload the sshd.service service after configuration changes: [ root@host ~ ] # systemctl reload sshd.service In case you are not sure whether the service has the functionality to reload the configuration file changes, use the reload-or-restart argument with the systemctl command. The command reloads the configuration changes if the reloading functionality is available. Otherwise, the command restarts the service to implements the new configuration changes: [ root@host ~ ] # systemctl reload-or-restart sshd.service","title":"RESTARTING AND RELOADING SERVICES"},{"location":"redhat/service/#listing-unit-dependencies","text":"Some services require that other services be running first, creating dependencies on the other services. Other services are not started at boot time but rather only on demand. In both cases, systemd and systemctl start services as needed whether to resolve the dependency or to start an infrequently used service. For example, if the CUPS print service is not running and a file is placed into the print spool directory, then the system will start CUPS-related daemons or commands to satisfy the print request. [ root@host ~ ] # systemctl stop cups.service Warning: Stopping cups, but it can still be activated by: cups.path cups.socket To completely stop printing services on a system, stop all three units. Disabling the service disables the dependencies. The systemctl list-dependencies UNIT command displays a hierarchy mapping of dependencies to start the service unit. To list reverse dependencies (units that depend on the specified unit), use the --reverse option with the command. [ root@host ~ ] # systemctl list-dependencies sshd.service sshd.service \u25cf \u251c\u2500system.slice \u25cf \u251c\u2500sshd-keygen.target \u25cf \u2502 \u251c\u2500sshd-keygen@ecdsa.service \u25cf \u2502 \u251c\u2500sshd-keygen@ed25519.service \u25cf \u2502 \u2514\u2500sshd-keygen@rsa.service \u25cf \u2514\u2500sysinit.target ...output omitted...","title":"LISTING UNIT DEPENDENCIES"},{"location":"redhat/service/#masking-and-unmasking-services","text":"At times, a system may have different services installed that are conflicting with each other. For example, there are multiple methods to manage mail servers (postfix and sendmail, for example). Masking a service prevents an administrator from accidentally starting a service that conflicts with others. Masking creates a link in the configuration directories to the /dev/null file which prevents the service from starting. [ root@host ~ ] # systemctl mask sendmail.service Created symlink /etc/systemd/system/sendmail.service \u2192 /dev/null. [ root@host ~ ] # systemctl list-unit-files --type=service UNIT FILE STATE ...output omitted... sendmail.service masked ...output omitted... Attempting to start a masked service unit fails with the following output: [ root@host ~ ] # systemctl start sendmail.service Failed to start sendmail.service: Unit sendmail.service is masked. Use the systemctl unmask command to unmask the service unit. [ root@host ~ ] # systemctl unmask sendmail Removed /etc/systemd/system/sendmail.service. IMPORTANT A disabled service can be started manually or by other unit files but it does not start automatically at boot. A masked service does not start manually or automatically.","title":"MASKING AND UNMASKING SERVICES"},{"location":"redhat/service/#enabling-services-to-start-or-stop-at-boot","text":"Starting a service on a running system does not guarantee that the service automatically starts when the system reboots. Similarly, stopping a service on a running system does not keep it from starting again when the system reboots. Creating links in the systemd configuration directories enables the service to start at boot. The systemctl commands creates and removes these links. To start a service at boot, use the systemctl enable command. [ root@root ~ ] # systemctl enable sshd.service Created symlink /etc/systemd/system/multi-user.target.wants/sshd.service \u2192 /usr/ lib/systemd/system/sshd.service. The above command creates a symbolic link from the service unit file, usually in the /usr/lib/ systemd/system directory, to the location on disk where systemd looks for files, which is in the /etc/systemd/system/TARGETNAME.target.wants directory. Enabling a service does not start the service in the current session. To start the service and enable it to start automatically during boot, execute both the systemctl start and systemctl enable commands. To disable the service from starting automatically, use the following command, which removes the symbolic link created while enabling a service. Note that disabling a service does not stop the service. [ root@host ~ ] # systemctl disable sshd.service Removed /etc/systemd/system/multi-user.target.wants/sshd.service. To verify whether the service is enabled or disable, use the systemctl is-enabled command.","title":"ENABLING SERVICES TO START OR STOP AT BOOT"},{"location":"redhat/service/#summary-of-systemctl-commands","text":"Services can be started and stopped on a running system and enabled or disabled for an automatic start at boot time. Useful Service Management Commands TASK COMMAND View detailed information about a unit state. systemctl status UNIT Stop a service on a running system. systemctl stop UNIT Start a service on a running system. systemctl start UNIT Restart a service on a running system. systemctl restart UNIT Reload the configuration file of a running service. systemctl reload UNIT Completely disable a service from being started, both manually and at boot. systemctl mask UNIT Make a masked service available. systemctl unmask UNIT Configure a service to start at boot time. systemctl enable UNIT Disable a service from starting at boot time. systemctl disable UNIT List units required and wanted by the specified unit. systemctl list-dependencies UNIT","title":"SUMMARY OF systemctl COMMANDS"},{"location":"redhat/service/#summary","text":"In this chapter, you learned: systemd provides a method for activating system resources, server daemons, and other processes, both at boot time and on a running system. Use the systemctl to start, stop, reload, enable, and disable services. Use the systemctl status command to determine the status of system daemons and network services started by systemd. The systemctl list-dependencies command lists all service units upon which a specific service unit depends. systemd can mask a service unit so that it does not run even to satisfy dependencies.","title":"SUMMARY"},{"location":"redhat/store/","text":"DESCRIBING SYSTEM LOG ARCHITECTURE \u00b6 SYSTEM LOGGING \u00b6 Processes and the operating system kernel record a log of events that happen. These logs are used to audit the system and troubleshoot problems. Many systems record logs of events in text files which are kept in the /var/log directory. These logs can be inspected using normal text utilities such as less and tail . A standard logging system based on the Syslog protocol is built into Red Hat Enterprise Linux. Many programs use this system to record events and organize them into log files. The systemd- journald and rsyslog services handle the syslog messages in Red Hat Enterprise Linux 8. The systemd-journald service is at the heart of the operating system event logging architecture. It collects event messages from many sources including the kernel, output from the early stages of the boot process, standard output and standard error from daemons as they start up and run, and syslog events. It then restructures them into a standard format, and writes them into a structured, indexed system journal. By default, this journal is stored on a file system that does not persist across reboots. However, the rsyslog service reads syslog messages received by systemd-journald from the journal as they arrive. It then processes the syslog events, recording them to its log files or forwarding them to other services according to its own configuration. The rsyslog service sorts and writes syslog messages to the log files that do persist across reboots in /var/log . The rsyslog service sorts the log messages to specific log files based on the type of program that sent each message, or facility, and the priority of each syslog message. In addition to syslog message files, the /var/log directory contains log files from other services on the system. The following table lists some useful files in the /var/log directory. Selected System Log Files LOG FILE TYPE OF MESSAGES STORED /var/log/messages Most syslog messages are logged here. Exceptions include messages related to authentication and email processing,scheduled job execution, and those which are purely debugging-related. /var/log/secure Syslog messages related to security and authentication events. /var/log/maillog Syslog messages related to the mail server. /var/log/cron Syslog messages related to scheduled job execution. /var/log/boot.log Non-syslog console messages related to system startup. NOTE Some applications do not use syslog to manage their log messages, although typically, they do place their log files in a subdirectory of /var/log. For example, the Apache Web Server saves log messages to files in a subddirectory of the /var/log directory. REVIEWING SYSLOG FILES \u00b6 LOGGING EVENTS TO THE SYSTEM \u00b6 Many programs use the syslog protocol to log events to the system. Each log message is categorized by a facility (the type of message) and a priority (the severity of the message). Available facilities are documented in the rsyslog.conf(5) man page. The following table lists the standard eight syslog priorities from highest to lowest. Overview of Syslog Priorities CODE PRIORITY SEVERITY 0 emerg System is unusable 1 alert Action must be taken immediately 2 crit Critical condition 3 err Non-critical error condition 4 warning Warning condition 5 notice Normal but significant event 6 info Informational event 7 debug Debugging-level message The rsyslog service uses the facility and priority of log messages to determine how to handle them. This is configured by rules in the /etc/rsyslog.conf file and any file in the /etc/ rsyslog.d directory that has a file name extension of .conf. Software packages can easily add rules by installing an appropriate file in the /etc/rsyslog.d directory. Each rule that controls how to sort syslog messages is a line in one of the configuration files. The left side of each line indicates the facility and severity of the syslog messages the rule matches. The right side of each line indicates what file to save the log message in (or where else to deliver the message). An asterisk ( * ) is a wildcard that matches all values. For example, the following line would record messages sent to the authpriv facility at any priority to the file /var/log/secure: authpriv.* /var/log/secure Log messages sometimes match more than one rule in rsyslog.conf . In such cases, one message is stored in more than one log file. To limit messages stored, the key word none in the priority field indicates that no messages for the indicated facility should be stored in the given file. Instead of logging syslog messages to a file, they can also be printed to the terminals of all logged- in users. The rsyslog.conf file has a setting to print all the syslog messages with the emerg priority to the terminals of all logged-in users. SAMPLE RULES OF RSYSLOG \u00b6 #### RULES #### # Log all kernel messages to the console. # Logging much else clutters up the screen. #kern.* /dev/console # Log anything (except mail) of level info or higher. # Don't log private authentication messages! *.info;mail.none;authpriv.none;cron.none /var/log/messages # The authpriv file has restricted access. authpriv.* /var/log/secure # Log all the mail messages in one place. mail.* -/var/log/maillog # Log cron stuff cron.* /var/log/cron # Everybody gets emergency messages *.emerg :omusrmsg:* # Save news errors of level crit and higher in a special file. uucp,news.crit /var/log/spooler # Save boot messages also to boot.log local7.* /var/log/boot.log NOTE The syslog subsystem has many more features beyond the scope of this course. For those who wish to explore further, consult the rsyslog.conf(5) man page and the extensive HTML documentation in /usr/share/doc/rsyslog/html/ index.html contained in the rsyslog-doc package, available from the AppStream repository in Red Hat Enterprise Linux 8. LOG FILE ROTATION \u00b6 The logrotate tool rotates log files to keep them from taking up too much space in the file system containing the /var/log directory . When a log file is rotated, it is renamed with an extension indicating the date it was rotated. For example, the old /var/log/messages file may become /var/log/messages-20190130 if it is rotated on 2019-01-30. Once the old log file is rotated, a new log file is created and the service that writes to it is notified. After a certain number of rotations, typically after four weeks, the oldest log file is discarded to free disk space. A scheduled job runs the logrotate program daily to see if any logs need to be rotated. Most log files are rotated weekly, but logrotate rotates some faster, or slower, or when they reach a certain size. Configuration of logrotate is not covered in this course. For more information, see the logrotate (8) man page. ANALYZING A SYSLOG ENTRY \u00b6 Log messages start with the oldest message on top and the newest message at the end of the log file. The rsyslog service uses a standard format while recording entries in log files. The following example explains the anatomy of a log message in the /var/log/secure log file. Feb 11 20:11:48 localhost sshd[1433]: Failed password for student from 172.25.0.10 port 59344 ssh2 Feb 11 20:11:48 The time stamp when the log entry was recorded localhost The host from which the log message was sent sshd[1433]: The program or process name and PID number that sent the log message Failed password The actual message sent MONITORING LOGS \u00b6 Monitoring one or more log files for events is helpful to reproduce problems and issues. The tail -f /path/to/file command outputs the last 10 lines of the file specified and continues to output new lines in the file as they get written. For example, to monitor for failed login attempts, run the tail command in one terminal and then in another terminal, run the ssh command as the root user while a user tries to log in to the system. In the first terminal, run the following tail command: [ root@host ~ ] # tail -f /var/log/secure In the second terminal, run the following ssh command: [ root@host ~ ] # ssh root@localhost root@localhost ' s password: redhat ...output omitted... [ root@host ~ ] # Return to the first terminal and view the logs. ...output omitted... Feb 10 09 :01:13 host sshd [ 2712 ] : Accepted password for root from 172 .25.254.254 Feb 10 09 :01:13 host sshd [ 2712 ] : pam_unix ( sshd:session ) : session opened for user root by ( uid = 0 ) SENDING SYSLOG MESSAGES MANUALLY \u00b6 The logger command can send messages to the rsyslog service. By default, it sends the message to the user facility with the notice priority (user.notice) unless specified otherwise with the -p option. It is useful to test any change to the rsyslog service configuration. To send a message to the rsyslog service that gets recorded in the /var/log/boot.log log file, execute the following logger command: [ root@host ~ ] # logger -p local7.notice \"Log entry created on host\" REVIEWING SYSTEM JOURNAL ENTRIES \u00b6 FINDING EVENTS \u00b6 The systemd-journald service stores logging data in a structured, indexed binary file called the journal. This data includes extra information about the log event. For example, for syslog events this includes the facility and the priority of the original message. IMPORTANT In Red Hat Enterprise Linux 8, the /run/log directory stores the system journal by default. The contents of the /run/log directory get cleared after a reboot. You can change this setting, and how to do so is discussed later in this chapter. To retrieve log messages from the journal, use the journalctl command. You can use this command to view all messages in the journal, or to search for specific events based on a wide range of options and criteria. If you run the command as root, you have full access to the journal. Regular users can also use this command, but might be restricted from seeing certain messages. [ root@host ~ ] # journalctl ...output omitted... Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Stopped target Sockets. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Closed D-Bus User Message Bus Socket. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Closed Multimedia System. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Reached target Shutdown. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Starting Exit the Session... Feb 21 17 :46:25 host.lab.example.com systemd [ 24268 ] : pam_unix ( systemd- user:session ) : session c> Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Stopped User Manager for UID 1001 . Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : user-runtime-dir@1001.service: Unit not neede> Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Stopping /run/user/1001 mount wrapper... Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Removed slice User Slice of UID 1001 . Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Stopped /run/user/1001 mount wrapper. Feb 21 17 :46:36 host.lab.example.com sshd [ 24434 ] : Accepted publickey for root from 172 .25.250.> Feb 21 17 :46:37 host.lab.example.com systemd [ 1 ] : Started Session 20 of user root. Feb 21 17 :46:37 host.lab.example.com systemd-logind [ 708 ] : New session 20 of user root. Feb 21 17 :46:37 host.lab.example.com sshd [ 24434 ] : pam_unix ( sshd:session ) : session opened for u> Feb 21 18 :01:01 host.lab.example.com CROND [ 24468 ] : ( root ) CMD ( run-parts /etc/ cron.hourly ) Feb 21 18 :01:01 host.lab.example.com run-parts [ 24471 ] : ( /etc/cron.hourly ) starting 0anacron Feb 21 18 :01:01 host.lab.example.com run-parts [ 24477 ] : ( /etc/cron.hourly ) finished 0anacron lines 1464 -1487/1487 ( END ) q The journalctl command highlights important log messages: messages at notice or warning priority are in bold text while messages at the error priority or higher are in red text. The key to successfully using the journal for troubleshooting and auditing is to limit journal searches to show only relevant output. By default, journalctl -n shows the last 10 log entries. You can adjust this with an optional argument that specifies how many log entries to display. For the last five log entries, run the following journalctl command: [ root@host ~ ] # journalctl -n 5 -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :01:01 +07. -- ...output omitted... Feb 21 17 :46:37 host.lab.example.com systemd-logind [ 708 ] : New session 20 of user root. Feb 21 17 :46:37 host.lab.example.com sshd [ 24434 ] : pam_unix ( sshd:session ) : session opened for u> Feb 21 18 :01:01 host.lab.example.com CROND [ 24468 ] : ( root ) CMD ( run-parts /etc/ cron.hourly ) Feb 21 18 :01:01 host.lab.example.com run-parts [ 24471 ] : ( /etc/cron.hourly ) starting 0anacron Feb 21 18 :01:01 host.lab.example.com run-parts [ 24477 ] : ( /etc/cron.hourly ) finished 0anacron lines 1 -6/6 ( END ) q Similar to the tail -f command, the journalctl -f command outputs the last 10 lines of the system journal and continues to output new journal entries as they get written to the journal. To exit the journalctl -f process, use the Ctrl+C key combination. [ root@host ~ ] # journalctl -f -- Logs begin at Wed 2019 -02-20 16 :01:17 +07. -- ...output omitted... Feb 21 18 :01:01 host.lab.example.com run-parts [ 24477 ] : ( /etc/cron.hourly ) finished 0anacron Feb 21 18 :22:42 host.lab.example.com sshd [ 24437 ] : Received disconnect from 172 .25.250.250 port 48710 :11: disconnected by user Feb 21 18 :22:42 host.lab.example.com sshd [ 24437 ] : Disconnected from user root 172 .25.250.250 port 48710 Feb 21 18 :22:42 host.lab.example.com sshd [ 24434 ] : pam_unix ( sshd:session ) : session closed for user root Feb 21 18 :22:42 host.lab.example.com systemd-logind [ 708 ] : Session 20 logged out. Waiting for processes to exit. Feb 21 18 :22:42 host.lab.example.com systemd-logind [ 708 ] : Removed session 20 . Feb 21 18 :22:43 host.lab.example.com sshd [ 24499 ] : Accepted publickey for root from 172 .25.250.250 port 48714 ssh2: RSA SHA256:1UGybTe52L2jzEJa1HLVKn9QUCKrTv3ZzxnMJol1Fro Feb 21 18 :22:44 host.lab.example.com systemd-logind [ 708 ] : New session 21 of user root. Feb 21 18 :22:44 host.lab.example.com systemd [ 1 ] : Started Session 21 of user root. Feb 21 18 :22:44 host.lab.example.com sshd [ 24499 ] : pam_unix ( sshd:session ) : session opened for user root by ( uid = 0 ) ^C [ root@host ~ ] # To help troubleshoot problems, you might want to filter the output of the journal based on the priority of the journal entries. The journalctl -p takes either the name or the number of a priority level and shows the journal entries for entries at that priority and above. The journalctl command understands the debug, info, notice, warning, err, crit, alert , and emerg priority levels. Run the following journalctl command to list journal entries at the err priority or higher: [ root@host ~ ] # journalctl -p err -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :01:01 +07. -- ..output omitted... Feb 20 16 :01:17 host.lab.example.com kernel: Detected CPU family 6 model 13 stepping 3 Feb 20 16 :01:17 host.lab.example.com kernel: Warning: Intel Processor - this hardware has not undergone testing by Red Hat and might not be certif> Feb 20 16 :01:20 host.lab.example.com smartd [ 669 ] : DEVICESCAN failed: glob ( 3 ) aborted matching pattern /dev/discs/disc* Feb 20 16 :01:20 host.lab.example.com smartd [ 669 ] : In the system ' s table of devices NO devices found to scan lines 1 -5/5 ( END ) q When looking for specific events, you can limit the output to a specific time frame. The journalctl command has two options to limit the output to a specific time range, the --since and --until options. Both options take a time argument in the format \" YYYY-MM-DD hh ss \" (the double-quotes are required to preserve the space in the option). If the date is omitted, the command assumes the current day, and if the time is omitted, the command assumes the whole day starting at 00:00:00. Both options take yesterday, today , and tomorrow as valid arguments in addition to the date and time field. Run the following journalctl command to list all journal entries from today's records. [ root@host ~ ] # journalctl --since today -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :31:14 +07. -- ...output omitted... Feb 21 18 :22:44 host.lab.example.com systemd-logind [ 708 ] : New session 21 of user root. Feb 21 18 :22:44 host.lab.example.com systemd [ 1 ] : Started Session 21 of user root. Feb 21 18 :22:44 host.lab.example.com sshd [ 24499 ] : pam_unix ( sshd:session ) : session Feb 21 18 :31:14 host.lab.example.com dnf [ 24533 ] : Red Hat Enterprise Linux 8 .0 AppStream ( dvd ) 637 kB/s | 2 .8 kB 00 :00 Feb 21 18 :31:14 host.lab.example.com dnf [ 24533 ] : Red Hat Enterprise Linux 8 .0 BaseOS ( dvd ) 795 kB/s | 2 .7 kB 00 :00 Feb 21 18 :31:14 host.lab.example.com dnf [ 24533 ] : Metadata cache created. Feb 21 18 :31:14 host.lab.example.com systemd [ 1 ] : Started dnf makecache. lines 533 -569/569 ( END ) q Run the following journalctl command to list all journal entries ranging from 2019-02-10 20:30:00 to 2019-02-13 12:00:00 . [ root@host ~ ] # journalctl --since \"2014-02-10 20:30:00\" --until \"2014-02-13 12 :00:00 \" ...output omitted... You can also specify all entries since a time relative to the present. For example, to specify all entries in the last hour, you can use the following command: [ root@host ~ ] # journalctl --since \"-1 hour\" ...output omitted... NOTE You can use other, more sophisticated time specifications with the --since and -- until options. For some examples, see the systemd.time(7) man page. In addition to the visible content of the journal, there are fields attached to the log entries that can only be seen when verbose output is turned on. Any displayed extra field can be used to filter the output of a journal query. This is useful to reduce the output of complex searches for certain events in the journal. [ root@host ~ ] # journalctl -o verbose -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :31:14 +07. -- ...output omitted... Thu 2019 -02-21 18 :31:14.509128 +07... PRIORITY = 6 _BOOT_ID = 4409bbf54680496d94e090de9e4a9e23 _MACHINE_ID = 73ab164e278e48be9bf80e80714a8cd5 SYSLOG_FACILITY = 3 SYSLOG_IDENTIFIER = systemd _UID = 0 _GID = 0 CODE_FILE = ../src/core/job.c CODE_LINE = 826 CODE_FUNC = job_log_status_message JOB_TYPE = start JOB_RESULT = done MESSAGE_ID = 39f53479d3a045ac8e11786248231fbf _TRANSPORT = journal _PID = 1 _COMM = systemd _EXE = /usr/lib/systemd/systemd _CMDLINE = /usr/lib/systemd/systemd --switched-root --system --deserialize 18 _CAP_EFFECTIVE = 3fffffffff _SELINUX_CONTEXT = system_u:system_r:init_t:s0 _SYSTEMD_CGROUP = /init.scope _SYSTEMD_UNIT = init.scope _SYSTEMD_SLICE = -.slice UNIT = dnf-makecache.service MESSAGE = Started dnf makecache. _HOSTNAME = host.lab.example.com INVOCATION_ID = d6f90184663f4309835a3e8ab647cb0e _SOURCE_REALTIME_TIMESTAMP = 1550748674509128 lines 32239 -32275/32275 ( END ) q The following list gives the common fields of the system journal that can be used to search for lines relevant to a particular process or event. _COMM The name of the command _EXE The path to the executable for the process _PID The PID of the process _UID The UID of the user running the process _SYSTEMD_UNIT The systemd unit that started the process More than one of the system journal fields can be combined to form a granular search query with the journalctl command. For example, the following journalctl command shows all journal entries related to the sshd.service systemd unit from a process with PID 1182. [ root@host ~ ] # journalctl _SYSTEMD_UNIT=sshd.service _PID=1182 Apr 03 19 :34:27 host.lab.example.com sshd [ 1182 ] : Accepted password for root from ::1 port 52778 ssh2 Apr 03 19 :34:28 host.lab.example.com sshd [ 1182 ] : pam_unix ( sshd:session ) : session opened for user root by ( uid = 0 ) ...output omitted... NOTE For a list of commonly used journal fields, consult the systemd.journal- fields(7) man page. PRESERVING THE SYSTEM JOURNAL \u00b6 STORING THE SYSTEM JOURNAL PERMANENTLY \u00b6 By default, the system journals are kept in the /run/log/journal directory, which means the journals are cleared when the system reboots. You can change the configuration settings of the systemd-journald service in the /etc/systemd/journald.conf file to make the journals persist across reboot. The Storage parameter in the /etc/systemd/journald.conf file defines whether to store system journals in a volatile manner or persistently across reboot. Set this parameter to persistent , volatile , or auto as follows: persistent : stores journals in the /var/log/journal directory which persists across reboots. If the /var/log/journal directory does not exist, the systemd-journald service creates it. volatile : stores journals in the volatile /run/log/journal directory. As the /run file system is temporary and exists only in the runtime memory, data stored in it, including system journals, do not persist across reboot. auto : rsyslog determines whether to use persistent or volatile storage. If the /var/log/ journal directory exists, then rsyslog uses persistent storage, otherwise it uses volatile storage. This is the default action if the Storage parameter is not set. The advantage of persistent system journals is that the historic data is available immediately at boot. However, even with a persistent journal, not all data is kept forever. The journal has a built-in log rotation mechanism that triggers monthly. In addition, by default, the journals are not allowed to get larger than 10% of the file system it is on, or leave less than 15% of the file system free. These values can be tuned for both the runtime and persistent journals in /etc/systemd/ journald.conf . The current limits on the size of the journal are logged when the systemd- journald process starts. The following command output shows the journal entries that reflect the current size limits: [ user@host ~ ] $ journalctl | grep -E 'Runtime|System journal' Feb 25 13 :01:46 localhost systemd-journald [ 147 ] : Runtime journal ( /run/log/ journal/ae06db7da89142138408d77efea9229c ) is 8 .0M, max 91 .4M, 83 .4M free. Feb 25 13 :01:48 remotehost.lab.example.com systemd-journald [ 548 ] : Runtime journal ( /run/log/journal/73ab164e278e48be9bf80e80714a8cd5 ) is 8 .0M, max 91 .4M, 83 .4M free. Feb 25 13 :01:48 remotehost.lab.example.com systemd-journald [ 548 ] : System journal ( /var/log/journal/73ab164e278e48be9bf80e80714a8cd5 ) is 8 .0M, max 3 .7G, 3 .7G free. Feb 25 13 :01:48 remotehost.lab.example.com systemd [ 1 ] : Starting Tell Plymouth To Write Out Runtime Data... Feb 25 13 :01:48 remotehost.lab.example.com systemd [ 1 ] : Started Tell Plymouth To Write Out Runtime Data. NOTE In the grep above, the pipe ( | ) symbol acts as an or indicator. That is, grep matches any line containing either the Runtime string or the System string from the journalctl output. This fetches the current size limits on the volatile (Runtime) journal store as well the persistent (System) journal store. Configuring Persistent System Journals To configure the systemd-journald service to preserve system journals persistently across reboot, set Storage to persistent in the /etc/systemd/journald.conf file. Run the text editor of your choice as the superuser to edit the /etc/systemd/journald.conf file. [ Journal ] Storage = persistent ...output omitted... After editing the configuration file, restart the systemd-journald service to bring the configuration changes into effect. [ root@host ~ ] # systemctl restart systemd-journald If the systemd-journald service successfully restarts, you can see that the /var/log/ journal directory is created and contains one or more subdirectories. These subdirectories have hexadecimal characters in their long names and contain .journal * files. The .journal * files are the binary files that store the structured and indexed journal entries. [ root@host ~ ] # ls /var/log/journal 73ab164e278e48be9bf80e80714a8cd5 [ root@host ~ ] # ls /var/log/journal/73ab164e278e48be9bf80e80714a8cd5 system.journal user-1000.journal While the system journals persist across reboot, you get an extensive number of entries in the output of the journalctl command that includes entries from the current system boot as well as the previous ones. To limit the output to a specific system boot, use the -b option with the journalctl command. The following journalctl command retrieves the entries limited to the first system boot: [ root@host ~ ] # journalctl -b 1 ...output omitted... The following journalctl command retrieves the entries limited to the second system boot. The following argument is meaningful only if the system has been rebooted for more than twice: [ root@host ~ ] # journalctl -b 2 The following journalctl command retrieves the entries limited to the current system boot: [ root@host ~ ] # journalctl -b NOTE When debugging a system crash with a persistent journal, it is usually required to limit the journal query to the reboot before the crash happened. The -b option can be accompanied by a negative number indicating how many prior system boots the output should include. For example, journalctl -b -1 limits the output to only the previous boot. MAINTAINING ACCURATE TIME \u00b6 SETTING LOCAL CLOCKS AND TIME ZONES \u00b6 Correct synchronized system time is critical for log file analysis across multiple systems. The Network Time Protocol (NTP) is a standard way for machines to provide and obtain correct time information on the Internet. A machine may get accurate time information from public NTP services on the Internet, such as the NTP Pool Project. A high-quality hardware clock to serve accurate time to local clients is another option. The timedatectl command shows an overview of the current time-related system settings, including current time, time zone, and NTP synchronization settings of the system. [ user@host ~ ] $ timedatectl Local time: Fri 2019 -04-05 16 :10:29 CDT Universal time: Fri 2019 -04-05 21 :10:29 UTC RTC time: Fri 2019 -04-05 21 :10:29 Time zone: America/Chicago ( CDT, -0500 ) System clock synchronized: yes NTP service: active RTC in local TZ: no A database of time zones is available and can be listed with the timedatectl list-timezones command. [ user@host ~ ] $ timedatectl list-timezones Africa/Abidjan Africa/Accra Africa/Addis_Ababa Africa/Algiers Africa/Asmara Africa/Bamako ... Time zone names are based on the public time zone database that IANA maintains. Time zones are named based on continent or ocean, then typically but not always the largest city within the time zone region. For example, most of the US Mountain time zone is America/Denver. Selecting the correct name can be non-intuitive in cases where localities inside the time zone have different daylight saving time rules. For example, in the USA, much of the state of Arizona (US Mountain time) does not have a daylight saving time adjustment at all and is in the time zone America/Phoenix. The command tzselect is useful for identifying correct zoneinfo time zone names. It interactively prompts the user with questions about the system's location, and outputs the name of the correct time zone. It does not make any change to the time zone setting of the system. The superuser can change the system setting to update the current time zone using the timedatectl set-timezone command. The following timedatectl command updates the current time zone to America/Phoenix . [ root@host ~ ] # timedatectl set-timezone America/Phoenix [ root@host ~ ] # timedatectl Local time: Fri 2019 -04-05 14 :12:39 MST Universal time: Fri 2019 -04-05 21 :12:39 UTC RTC time: Fri 2019 -04-05 21 :12:39 Time zone: America/Phoenix ( MST, -0700 ) System clock synchronized: yes NTP service: active RTC in local TZ: no NOTE Should you need to use the Coordinated Universal Time (UTC) on a particular server, set its time zone to UTC. The tzselect command does not include the name of the UTC time zone. Use the timedatectl set-timezone UTC command to set the system's current time zone to UTC . Use the timedatectl set-time command to change the system's current time. The time is specified in the \" YYYY-MM-DD hh ss \" format, where either date or time can be omitted. The following timedatectl command changes the time to 09:00:00 . [ root@host ~ ] # timedatectl set-time 9:00:00 [ root@serverX ~ ] $ timedatectl Local time: Fri 2019 -04-05 09 :00:27 MST Universal time: Fri 2019 -04-05 16 :00:27 UTC RTC time: Fri 2019 -04-05 16 :00:27 Time zone: America/Phoenix ( MST, -0700 ) System clock synchronized: yes NTP service: active RTC in local TZ: no The timedatectl set-ntp command enables or disables NTP synchronization for automatic time adjustment. The option requires either a true or false argument to turn it on or off. The following timedatectl command turns on NTP synchronization. [ root@host ~ ] # timedatectl set-ntp true NOTE In Red Hat Enterprise Linux 8, the timedatectl set-ntp command will adjust whether or not chronyd NTP service is operating. Other Linux distributions might use this setting to adjust a different NTP or SNTP service. Enabling or disabling NTP using other utilities in Red Hat Enterprise Linux, such as in the graphical GNOME Settings application, also updates this setting. CONFIGURING AND MONITORING CHRONYD \u00b6 The chronyd service keeps the usually-inaccurate local hardware clock (RTC) on track by synchronizing it to the configured NTP servers. If no network connectivity is available, chronyd calculates the RTC clock drift, which is recorded in the driftfile specified in the /etc/ chrony.conf configuration file. By default, the chronyd service uses servers from the NTP Pool Project for the time synchronization and does not need additional configuration. It may be useful to change the NTP servers when the machine in question is on an isolated network. The stratum of the NTP time source determines its quality. The stratum determines the number of hops the machine is away from a high-performance reference clock. The reference clock is a stratum 0 time source. An NTP server directly attached to it is a stratum 1 , while a machine synchronizing time from the NTP server is a stratum 2 time source. The server and peer are the two categories of time sources that you can in the /etc/ chrony.conf configuration file. The server is one stratum above the local NTP server, and the peer is at the same stratum level. More than one server and more than one peer can be specified, one per line. The first argument of the server line is the IP address or DNS name of the NTP server. Following the server IP address or name, a series of options for the server can be listed. It is recommended to use the iburst option, because after the service starts, four measurements are taken in a short time period for a more accurate initial clock synchronization. The following server classroom.example.com iburst line in the /etc/chrony.conf file causes the chronyd service to use the classroom.example.com NTP time source. # Use public servers from the pool.ntp.org project. ...output omitted... server classroom.example.com iburst ...output omitted... After pointing chronyd to the local time source, classroom.example.com, you should restart the service. [ root@host ~ ] # systemctl restart chronyd The chronyc command acts as a client to the chronyd service. After setting up NTP synchronization, you should verify that the local system is seamlessly using the NTP server to synchronize the system clock using the chrony sources command. For more verbose output with additional explanations about the output, use the chronyc sources -v command. [ root@host ~ ] # chronyc sources -v 210 Number of sources = 1 .-- Source mode '^' = server, '=' = peer, '#' = local clock. / .- Source state '*' = current synced, '+' = combined , '-' = not combined, | / '?' = unreachable, 'x' = time may be in error, '~' = time too variable. || .- xxxx [ yyyy ] +/- zzzz || / xxxx = adjusted offset, || Log2 ( Polling interval ) -. | yyyy = measured offset, || \\ | zzzz = estimated error. || | | MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* classroom.example.com 8 6 17 23 -497ns [ -7000ns ] +/- 956us The * character in the S** (Source state) field indicates that the classroom.example.com server has been used as a time source and is the NTP server the machine is currently synchronized to. SUMMARY \u00b6 In this chapter, you learned: The systemd-journald and rsyslog services capture and write log messages to the appropriate files. The /var/log directory contains log files. Periodic rotation of log files prevent them from filling up the file system space. The systemd journals are temporary and do not persist across reboot. The chronyd service helps to synchronize time settings with a time source.","title":"Analyzing And Storing Logs"},{"location":"redhat/store/#describing-system-log-architecture","text":"","title":"DESCRIBING SYSTEM LOG ARCHITECTURE"},{"location":"redhat/store/#system-logging","text":"Processes and the operating system kernel record a log of events that happen. These logs are used to audit the system and troubleshoot problems. Many systems record logs of events in text files which are kept in the /var/log directory. These logs can be inspected using normal text utilities such as less and tail . A standard logging system based on the Syslog protocol is built into Red Hat Enterprise Linux. Many programs use this system to record events and organize them into log files. The systemd- journald and rsyslog services handle the syslog messages in Red Hat Enterprise Linux 8. The systemd-journald service is at the heart of the operating system event logging architecture. It collects event messages from many sources including the kernel, output from the early stages of the boot process, standard output and standard error from daemons as they start up and run, and syslog events. It then restructures them into a standard format, and writes them into a structured, indexed system journal. By default, this journal is stored on a file system that does not persist across reboots. However, the rsyslog service reads syslog messages received by systemd-journald from the journal as they arrive. It then processes the syslog events, recording them to its log files or forwarding them to other services according to its own configuration. The rsyslog service sorts and writes syslog messages to the log files that do persist across reboots in /var/log . The rsyslog service sorts the log messages to specific log files based on the type of program that sent each message, or facility, and the priority of each syslog message. In addition to syslog message files, the /var/log directory contains log files from other services on the system. The following table lists some useful files in the /var/log directory. Selected System Log Files LOG FILE TYPE OF MESSAGES STORED /var/log/messages Most syslog messages are logged here. Exceptions include messages related to authentication and email processing,scheduled job execution, and those which are purely debugging-related. /var/log/secure Syslog messages related to security and authentication events. /var/log/maillog Syslog messages related to the mail server. /var/log/cron Syslog messages related to scheduled job execution. /var/log/boot.log Non-syslog console messages related to system startup. NOTE Some applications do not use syslog to manage their log messages, although typically, they do place their log files in a subdirectory of /var/log. For example, the Apache Web Server saves log messages to files in a subddirectory of the /var/log directory.","title":"SYSTEM LOGGING"},{"location":"redhat/store/#reviewing-syslog-files","text":"","title":"REVIEWING SYSLOG FILES"},{"location":"redhat/store/#logging-events-to-the-system","text":"Many programs use the syslog protocol to log events to the system. Each log message is categorized by a facility (the type of message) and a priority (the severity of the message). Available facilities are documented in the rsyslog.conf(5) man page. The following table lists the standard eight syslog priorities from highest to lowest. Overview of Syslog Priorities CODE PRIORITY SEVERITY 0 emerg System is unusable 1 alert Action must be taken immediately 2 crit Critical condition 3 err Non-critical error condition 4 warning Warning condition 5 notice Normal but significant event 6 info Informational event 7 debug Debugging-level message The rsyslog service uses the facility and priority of log messages to determine how to handle them. This is configured by rules in the /etc/rsyslog.conf file and any file in the /etc/ rsyslog.d directory that has a file name extension of .conf. Software packages can easily add rules by installing an appropriate file in the /etc/rsyslog.d directory. Each rule that controls how to sort syslog messages is a line in one of the configuration files. The left side of each line indicates the facility and severity of the syslog messages the rule matches. The right side of each line indicates what file to save the log message in (or where else to deliver the message). An asterisk ( * ) is a wildcard that matches all values. For example, the following line would record messages sent to the authpriv facility at any priority to the file /var/log/secure: authpriv.* /var/log/secure Log messages sometimes match more than one rule in rsyslog.conf . In such cases, one message is stored in more than one log file. To limit messages stored, the key word none in the priority field indicates that no messages for the indicated facility should be stored in the given file. Instead of logging syslog messages to a file, they can also be printed to the terminals of all logged- in users. The rsyslog.conf file has a setting to print all the syslog messages with the emerg priority to the terminals of all logged-in users.","title":"LOGGING EVENTS TO THE SYSTEM"},{"location":"redhat/store/#sample-rules-of-rsyslog","text":"#### RULES #### # Log all kernel messages to the console. # Logging much else clutters up the screen. #kern.* /dev/console # Log anything (except mail) of level info or higher. # Don't log private authentication messages! *.info;mail.none;authpriv.none;cron.none /var/log/messages # The authpriv file has restricted access. authpriv.* /var/log/secure # Log all the mail messages in one place. mail.* -/var/log/maillog # Log cron stuff cron.* /var/log/cron # Everybody gets emergency messages *.emerg :omusrmsg:* # Save news errors of level crit and higher in a special file. uucp,news.crit /var/log/spooler # Save boot messages also to boot.log local7.* /var/log/boot.log NOTE The syslog subsystem has many more features beyond the scope of this course. For those who wish to explore further, consult the rsyslog.conf(5) man page and the extensive HTML documentation in /usr/share/doc/rsyslog/html/ index.html contained in the rsyslog-doc package, available from the AppStream repository in Red Hat Enterprise Linux 8.","title":"SAMPLE RULES OF RSYSLOG"},{"location":"redhat/store/#log-file-rotation","text":"The logrotate tool rotates log files to keep them from taking up too much space in the file system containing the /var/log directory . When a log file is rotated, it is renamed with an extension indicating the date it was rotated. For example, the old /var/log/messages file may become /var/log/messages-20190130 if it is rotated on 2019-01-30. Once the old log file is rotated, a new log file is created and the service that writes to it is notified. After a certain number of rotations, typically after four weeks, the oldest log file is discarded to free disk space. A scheduled job runs the logrotate program daily to see if any logs need to be rotated. Most log files are rotated weekly, but logrotate rotates some faster, or slower, or when they reach a certain size. Configuration of logrotate is not covered in this course. For more information, see the logrotate (8) man page.","title":"LOG FILE ROTATION"},{"location":"redhat/store/#analyzing-a-syslog-entry","text":"Log messages start with the oldest message on top and the newest message at the end of the log file. The rsyslog service uses a standard format while recording entries in log files. The following example explains the anatomy of a log message in the /var/log/secure log file. Feb 11 20:11:48 localhost sshd[1433]: Failed password for student from 172.25.0.10 port 59344 ssh2 Feb 11 20:11:48 The time stamp when the log entry was recorded localhost The host from which the log message was sent sshd[1433]: The program or process name and PID number that sent the log message Failed password The actual message sent","title":"ANALYZING A SYSLOG ENTRY"},{"location":"redhat/store/#monitoring-logs","text":"Monitoring one or more log files for events is helpful to reproduce problems and issues. The tail -f /path/to/file command outputs the last 10 lines of the file specified and continues to output new lines in the file as they get written. For example, to monitor for failed login attempts, run the tail command in one terminal and then in another terminal, run the ssh command as the root user while a user tries to log in to the system. In the first terminal, run the following tail command: [ root@host ~ ] # tail -f /var/log/secure In the second terminal, run the following ssh command: [ root@host ~ ] # ssh root@localhost root@localhost ' s password: redhat ...output omitted... [ root@host ~ ] # Return to the first terminal and view the logs. ...output omitted... Feb 10 09 :01:13 host sshd [ 2712 ] : Accepted password for root from 172 .25.254.254 Feb 10 09 :01:13 host sshd [ 2712 ] : pam_unix ( sshd:session ) : session opened for user root by ( uid = 0 )","title":"MONITORING LOGS"},{"location":"redhat/store/#sending-syslog-messages-manually","text":"The logger command can send messages to the rsyslog service. By default, it sends the message to the user facility with the notice priority (user.notice) unless specified otherwise with the -p option. It is useful to test any change to the rsyslog service configuration. To send a message to the rsyslog service that gets recorded in the /var/log/boot.log log file, execute the following logger command: [ root@host ~ ] # logger -p local7.notice \"Log entry created on host\"","title":"SENDING SYSLOG MESSAGES MANUALLY"},{"location":"redhat/store/#reviewing-system-journal-entries","text":"","title":"REVIEWING SYSTEM JOURNAL ENTRIES"},{"location":"redhat/store/#finding-events","text":"The systemd-journald service stores logging data in a structured, indexed binary file called the journal. This data includes extra information about the log event. For example, for syslog events this includes the facility and the priority of the original message. IMPORTANT In Red Hat Enterprise Linux 8, the /run/log directory stores the system journal by default. The contents of the /run/log directory get cleared after a reboot. You can change this setting, and how to do so is discussed later in this chapter. To retrieve log messages from the journal, use the journalctl command. You can use this command to view all messages in the journal, or to search for specific events based on a wide range of options and criteria. If you run the command as root, you have full access to the journal. Regular users can also use this command, but might be restricted from seeing certain messages. [ root@host ~ ] # journalctl ...output omitted... Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Stopped target Sockets. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Closed D-Bus User Message Bus Socket. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Closed Multimedia System. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Reached target Shutdown. Feb 21 17 :46:25 host.lab.example.com systemd [ 24263 ] : Starting Exit the Session... Feb 21 17 :46:25 host.lab.example.com systemd [ 24268 ] : pam_unix ( systemd- user:session ) : session c> Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Stopped User Manager for UID 1001 . Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : user-runtime-dir@1001.service: Unit not neede> Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Stopping /run/user/1001 mount wrapper... Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Removed slice User Slice of UID 1001 . Feb 21 17 :46:25 host.lab.example.com systemd [ 1 ] : Stopped /run/user/1001 mount wrapper. Feb 21 17 :46:36 host.lab.example.com sshd [ 24434 ] : Accepted publickey for root from 172 .25.250.> Feb 21 17 :46:37 host.lab.example.com systemd [ 1 ] : Started Session 20 of user root. Feb 21 17 :46:37 host.lab.example.com systemd-logind [ 708 ] : New session 20 of user root. Feb 21 17 :46:37 host.lab.example.com sshd [ 24434 ] : pam_unix ( sshd:session ) : session opened for u> Feb 21 18 :01:01 host.lab.example.com CROND [ 24468 ] : ( root ) CMD ( run-parts /etc/ cron.hourly ) Feb 21 18 :01:01 host.lab.example.com run-parts [ 24471 ] : ( /etc/cron.hourly ) starting 0anacron Feb 21 18 :01:01 host.lab.example.com run-parts [ 24477 ] : ( /etc/cron.hourly ) finished 0anacron lines 1464 -1487/1487 ( END ) q The journalctl command highlights important log messages: messages at notice or warning priority are in bold text while messages at the error priority or higher are in red text. The key to successfully using the journal for troubleshooting and auditing is to limit journal searches to show only relevant output. By default, journalctl -n shows the last 10 log entries. You can adjust this with an optional argument that specifies how many log entries to display. For the last five log entries, run the following journalctl command: [ root@host ~ ] # journalctl -n 5 -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :01:01 +07. -- ...output omitted... Feb 21 17 :46:37 host.lab.example.com systemd-logind [ 708 ] : New session 20 of user root. Feb 21 17 :46:37 host.lab.example.com sshd [ 24434 ] : pam_unix ( sshd:session ) : session opened for u> Feb 21 18 :01:01 host.lab.example.com CROND [ 24468 ] : ( root ) CMD ( run-parts /etc/ cron.hourly ) Feb 21 18 :01:01 host.lab.example.com run-parts [ 24471 ] : ( /etc/cron.hourly ) starting 0anacron Feb 21 18 :01:01 host.lab.example.com run-parts [ 24477 ] : ( /etc/cron.hourly ) finished 0anacron lines 1 -6/6 ( END ) q Similar to the tail -f command, the journalctl -f command outputs the last 10 lines of the system journal and continues to output new journal entries as they get written to the journal. To exit the journalctl -f process, use the Ctrl+C key combination. [ root@host ~ ] # journalctl -f -- Logs begin at Wed 2019 -02-20 16 :01:17 +07. -- ...output omitted... Feb 21 18 :01:01 host.lab.example.com run-parts [ 24477 ] : ( /etc/cron.hourly ) finished 0anacron Feb 21 18 :22:42 host.lab.example.com sshd [ 24437 ] : Received disconnect from 172 .25.250.250 port 48710 :11: disconnected by user Feb 21 18 :22:42 host.lab.example.com sshd [ 24437 ] : Disconnected from user root 172 .25.250.250 port 48710 Feb 21 18 :22:42 host.lab.example.com sshd [ 24434 ] : pam_unix ( sshd:session ) : session closed for user root Feb 21 18 :22:42 host.lab.example.com systemd-logind [ 708 ] : Session 20 logged out. Waiting for processes to exit. Feb 21 18 :22:42 host.lab.example.com systemd-logind [ 708 ] : Removed session 20 . Feb 21 18 :22:43 host.lab.example.com sshd [ 24499 ] : Accepted publickey for root from 172 .25.250.250 port 48714 ssh2: RSA SHA256:1UGybTe52L2jzEJa1HLVKn9QUCKrTv3ZzxnMJol1Fro Feb 21 18 :22:44 host.lab.example.com systemd-logind [ 708 ] : New session 21 of user root. Feb 21 18 :22:44 host.lab.example.com systemd [ 1 ] : Started Session 21 of user root. Feb 21 18 :22:44 host.lab.example.com sshd [ 24499 ] : pam_unix ( sshd:session ) : session opened for user root by ( uid = 0 ) ^C [ root@host ~ ] # To help troubleshoot problems, you might want to filter the output of the journal based on the priority of the journal entries. The journalctl -p takes either the name or the number of a priority level and shows the journal entries for entries at that priority and above. The journalctl command understands the debug, info, notice, warning, err, crit, alert , and emerg priority levels. Run the following journalctl command to list journal entries at the err priority or higher: [ root@host ~ ] # journalctl -p err -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :01:01 +07. -- ..output omitted... Feb 20 16 :01:17 host.lab.example.com kernel: Detected CPU family 6 model 13 stepping 3 Feb 20 16 :01:17 host.lab.example.com kernel: Warning: Intel Processor - this hardware has not undergone testing by Red Hat and might not be certif> Feb 20 16 :01:20 host.lab.example.com smartd [ 669 ] : DEVICESCAN failed: glob ( 3 ) aborted matching pattern /dev/discs/disc* Feb 20 16 :01:20 host.lab.example.com smartd [ 669 ] : In the system ' s table of devices NO devices found to scan lines 1 -5/5 ( END ) q When looking for specific events, you can limit the output to a specific time frame. The journalctl command has two options to limit the output to a specific time range, the --since and --until options. Both options take a time argument in the format \" YYYY-MM-DD hh ss \" (the double-quotes are required to preserve the space in the option). If the date is omitted, the command assumes the current day, and if the time is omitted, the command assumes the whole day starting at 00:00:00. Both options take yesterday, today , and tomorrow as valid arguments in addition to the date and time field. Run the following journalctl command to list all journal entries from today's records. [ root@host ~ ] # journalctl --since today -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :31:14 +07. -- ...output omitted... Feb 21 18 :22:44 host.lab.example.com systemd-logind [ 708 ] : New session 21 of user root. Feb 21 18 :22:44 host.lab.example.com systemd [ 1 ] : Started Session 21 of user root. Feb 21 18 :22:44 host.lab.example.com sshd [ 24499 ] : pam_unix ( sshd:session ) : session Feb 21 18 :31:14 host.lab.example.com dnf [ 24533 ] : Red Hat Enterprise Linux 8 .0 AppStream ( dvd ) 637 kB/s | 2 .8 kB 00 :00 Feb 21 18 :31:14 host.lab.example.com dnf [ 24533 ] : Red Hat Enterprise Linux 8 .0 BaseOS ( dvd ) 795 kB/s | 2 .7 kB 00 :00 Feb 21 18 :31:14 host.lab.example.com dnf [ 24533 ] : Metadata cache created. Feb 21 18 :31:14 host.lab.example.com systemd [ 1 ] : Started dnf makecache. lines 533 -569/569 ( END ) q Run the following journalctl command to list all journal entries ranging from 2019-02-10 20:30:00 to 2019-02-13 12:00:00 . [ root@host ~ ] # journalctl --since \"2014-02-10 20:30:00\" --until \"2014-02-13 12 :00:00 \" ...output omitted... You can also specify all entries since a time relative to the present. For example, to specify all entries in the last hour, you can use the following command: [ root@host ~ ] # journalctl --since \"-1 hour\" ...output omitted... NOTE You can use other, more sophisticated time specifications with the --since and -- until options. For some examples, see the systemd.time(7) man page. In addition to the visible content of the journal, there are fields attached to the log entries that can only be seen when verbose output is turned on. Any displayed extra field can be used to filter the output of a journal query. This is useful to reduce the output of complex searches for certain events in the journal. [ root@host ~ ] # journalctl -o verbose -- Logs begin at Wed 2019 -02-20 16 :01:17 +07, end at Thu 2019 -02-21 18 :31:14 +07. -- ...output omitted... Thu 2019 -02-21 18 :31:14.509128 +07... PRIORITY = 6 _BOOT_ID = 4409bbf54680496d94e090de9e4a9e23 _MACHINE_ID = 73ab164e278e48be9bf80e80714a8cd5 SYSLOG_FACILITY = 3 SYSLOG_IDENTIFIER = systemd _UID = 0 _GID = 0 CODE_FILE = ../src/core/job.c CODE_LINE = 826 CODE_FUNC = job_log_status_message JOB_TYPE = start JOB_RESULT = done MESSAGE_ID = 39f53479d3a045ac8e11786248231fbf _TRANSPORT = journal _PID = 1 _COMM = systemd _EXE = /usr/lib/systemd/systemd _CMDLINE = /usr/lib/systemd/systemd --switched-root --system --deserialize 18 _CAP_EFFECTIVE = 3fffffffff _SELINUX_CONTEXT = system_u:system_r:init_t:s0 _SYSTEMD_CGROUP = /init.scope _SYSTEMD_UNIT = init.scope _SYSTEMD_SLICE = -.slice UNIT = dnf-makecache.service MESSAGE = Started dnf makecache. _HOSTNAME = host.lab.example.com INVOCATION_ID = d6f90184663f4309835a3e8ab647cb0e _SOURCE_REALTIME_TIMESTAMP = 1550748674509128 lines 32239 -32275/32275 ( END ) q The following list gives the common fields of the system journal that can be used to search for lines relevant to a particular process or event. _COMM The name of the command _EXE The path to the executable for the process _PID The PID of the process _UID The UID of the user running the process _SYSTEMD_UNIT The systemd unit that started the process More than one of the system journal fields can be combined to form a granular search query with the journalctl command. For example, the following journalctl command shows all journal entries related to the sshd.service systemd unit from a process with PID 1182. [ root@host ~ ] # journalctl _SYSTEMD_UNIT=sshd.service _PID=1182 Apr 03 19 :34:27 host.lab.example.com sshd [ 1182 ] : Accepted password for root from ::1 port 52778 ssh2 Apr 03 19 :34:28 host.lab.example.com sshd [ 1182 ] : pam_unix ( sshd:session ) : session opened for user root by ( uid = 0 ) ...output omitted... NOTE For a list of commonly used journal fields, consult the systemd.journal- fields(7) man page.","title":"FINDING EVENTS"},{"location":"redhat/store/#preserving-the-system-journal","text":"","title":"PRESERVING THE SYSTEM JOURNAL"},{"location":"redhat/store/#storing-the-system-journal-permanently","text":"By default, the system journals are kept in the /run/log/journal directory, which means the journals are cleared when the system reboots. You can change the configuration settings of the systemd-journald service in the /etc/systemd/journald.conf file to make the journals persist across reboot. The Storage parameter in the /etc/systemd/journald.conf file defines whether to store system journals in a volatile manner or persistently across reboot. Set this parameter to persistent , volatile , or auto as follows: persistent : stores journals in the /var/log/journal directory which persists across reboots. If the /var/log/journal directory does not exist, the systemd-journald service creates it. volatile : stores journals in the volatile /run/log/journal directory. As the /run file system is temporary and exists only in the runtime memory, data stored in it, including system journals, do not persist across reboot. auto : rsyslog determines whether to use persistent or volatile storage. If the /var/log/ journal directory exists, then rsyslog uses persistent storage, otherwise it uses volatile storage. This is the default action if the Storage parameter is not set. The advantage of persistent system journals is that the historic data is available immediately at boot. However, even with a persistent journal, not all data is kept forever. The journal has a built-in log rotation mechanism that triggers monthly. In addition, by default, the journals are not allowed to get larger than 10% of the file system it is on, or leave less than 15% of the file system free. These values can be tuned for both the runtime and persistent journals in /etc/systemd/ journald.conf . The current limits on the size of the journal are logged when the systemd- journald process starts. The following command output shows the journal entries that reflect the current size limits: [ user@host ~ ] $ journalctl | grep -E 'Runtime|System journal' Feb 25 13 :01:46 localhost systemd-journald [ 147 ] : Runtime journal ( /run/log/ journal/ae06db7da89142138408d77efea9229c ) is 8 .0M, max 91 .4M, 83 .4M free. Feb 25 13 :01:48 remotehost.lab.example.com systemd-journald [ 548 ] : Runtime journal ( /run/log/journal/73ab164e278e48be9bf80e80714a8cd5 ) is 8 .0M, max 91 .4M, 83 .4M free. Feb 25 13 :01:48 remotehost.lab.example.com systemd-journald [ 548 ] : System journal ( /var/log/journal/73ab164e278e48be9bf80e80714a8cd5 ) is 8 .0M, max 3 .7G, 3 .7G free. Feb 25 13 :01:48 remotehost.lab.example.com systemd [ 1 ] : Starting Tell Plymouth To Write Out Runtime Data... Feb 25 13 :01:48 remotehost.lab.example.com systemd [ 1 ] : Started Tell Plymouth To Write Out Runtime Data. NOTE In the grep above, the pipe ( | ) symbol acts as an or indicator. That is, grep matches any line containing either the Runtime string or the System string from the journalctl output. This fetches the current size limits on the volatile (Runtime) journal store as well the persistent (System) journal store. Configuring Persistent System Journals To configure the systemd-journald service to preserve system journals persistently across reboot, set Storage to persistent in the /etc/systemd/journald.conf file. Run the text editor of your choice as the superuser to edit the /etc/systemd/journald.conf file. [ Journal ] Storage = persistent ...output omitted... After editing the configuration file, restart the systemd-journald service to bring the configuration changes into effect. [ root@host ~ ] # systemctl restart systemd-journald If the systemd-journald service successfully restarts, you can see that the /var/log/ journal directory is created and contains one or more subdirectories. These subdirectories have hexadecimal characters in their long names and contain .journal * files. The .journal * files are the binary files that store the structured and indexed journal entries. [ root@host ~ ] # ls /var/log/journal 73ab164e278e48be9bf80e80714a8cd5 [ root@host ~ ] # ls /var/log/journal/73ab164e278e48be9bf80e80714a8cd5 system.journal user-1000.journal While the system journals persist across reboot, you get an extensive number of entries in the output of the journalctl command that includes entries from the current system boot as well as the previous ones. To limit the output to a specific system boot, use the -b option with the journalctl command. The following journalctl command retrieves the entries limited to the first system boot: [ root@host ~ ] # journalctl -b 1 ...output omitted... The following journalctl command retrieves the entries limited to the second system boot. The following argument is meaningful only if the system has been rebooted for more than twice: [ root@host ~ ] # journalctl -b 2 The following journalctl command retrieves the entries limited to the current system boot: [ root@host ~ ] # journalctl -b NOTE When debugging a system crash with a persistent journal, it is usually required to limit the journal query to the reboot before the crash happened. The -b option can be accompanied by a negative number indicating how many prior system boots the output should include. For example, journalctl -b -1 limits the output to only the previous boot.","title":"STORING THE SYSTEM JOURNAL PERMANENTLY"},{"location":"redhat/store/#maintaining-accurate-time","text":"","title":"MAINTAINING ACCURATE TIME"},{"location":"redhat/store/#setting-local-clocks-and-time-zones","text":"Correct synchronized system time is critical for log file analysis across multiple systems. The Network Time Protocol (NTP) is a standard way for machines to provide and obtain correct time information on the Internet. A machine may get accurate time information from public NTP services on the Internet, such as the NTP Pool Project. A high-quality hardware clock to serve accurate time to local clients is another option. The timedatectl command shows an overview of the current time-related system settings, including current time, time zone, and NTP synchronization settings of the system. [ user@host ~ ] $ timedatectl Local time: Fri 2019 -04-05 16 :10:29 CDT Universal time: Fri 2019 -04-05 21 :10:29 UTC RTC time: Fri 2019 -04-05 21 :10:29 Time zone: America/Chicago ( CDT, -0500 ) System clock synchronized: yes NTP service: active RTC in local TZ: no A database of time zones is available and can be listed with the timedatectl list-timezones command. [ user@host ~ ] $ timedatectl list-timezones Africa/Abidjan Africa/Accra Africa/Addis_Ababa Africa/Algiers Africa/Asmara Africa/Bamako ... Time zone names are based on the public time zone database that IANA maintains. Time zones are named based on continent or ocean, then typically but not always the largest city within the time zone region. For example, most of the US Mountain time zone is America/Denver. Selecting the correct name can be non-intuitive in cases where localities inside the time zone have different daylight saving time rules. For example, in the USA, much of the state of Arizona (US Mountain time) does not have a daylight saving time adjustment at all and is in the time zone America/Phoenix. The command tzselect is useful for identifying correct zoneinfo time zone names. It interactively prompts the user with questions about the system's location, and outputs the name of the correct time zone. It does not make any change to the time zone setting of the system. The superuser can change the system setting to update the current time zone using the timedatectl set-timezone command. The following timedatectl command updates the current time zone to America/Phoenix . [ root@host ~ ] # timedatectl set-timezone America/Phoenix [ root@host ~ ] # timedatectl Local time: Fri 2019 -04-05 14 :12:39 MST Universal time: Fri 2019 -04-05 21 :12:39 UTC RTC time: Fri 2019 -04-05 21 :12:39 Time zone: America/Phoenix ( MST, -0700 ) System clock synchronized: yes NTP service: active RTC in local TZ: no NOTE Should you need to use the Coordinated Universal Time (UTC) on a particular server, set its time zone to UTC. The tzselect command does not include the name of the UTC time zone. Use the timedatectl set-timezone UTC command to set the system's current time zone to UTC . Use the timedatectl set-time command to change the system's current time. The time is specified in the \" YYYY-MM-DD hh ss \" format, where either date or time can be omitted. The following timedatectl command changes the time to 09:00:00 . [ root@host ~ ] # timedatectl set-time 9:00:00 [ root@serverX ~ ] $ timedatectl Local time: Fri 2019 -04-05 09 :00:27 MST Universal time: Fri 2019 -04-05 16 :00:27 UTC RTC time: Fri 2019 -04-05 16 :00:27 Time zone: America/Phoenix ( MST, -0700 ) System clock synchronized: yes NTP service: active RTC in local TZ: no The timedatectl set-ntp command enables or disables NTP synchronization for automatic time adjustment. The option requires either a true or false argument to turn it on or off. The following timedatectl command turns on NTP synchronization. [ root@host ~ ] # timedatectl set-ntp true NOTE In Red Hat Enterprise Linux 8, the timedatectl set-ntp command will adjust whether or not chronyd NTP service is operating. Other Linux distributions might use this setting to adjust a different NTP or SNTP service. Enabling or disabling NTP using other utilities in Red Hat Enterprise Linux, such as in the graphical GNOME Settings application, also updates this setting.","title":"SETTING LOCAL CLOCKS AND TIME ZONES"},{"location":"redhat/store/#configuring-and-monitoring-chronyd","text":"The chronyd service keeps the usually-inaccurate local hardware clock (RTC) on track by synchronizing it to the configured NTP servers. If no network connectivity is available, chronyd calculates the RTC clock drift, which is recorded in the driftfile specified in the /etc/ chrony.conf configuration file. By default, the chronyd service uses servers from the NTP Pool Project for the time synchronization and does not need additional configuration. It may be useful to change the NTP servers when the machine in question is on an isolated network. The stratum of the NTP time source determines its quality. The stratum determines the number of hops the machine is away from a high-performance reference clock. The reference clock is a stratum 0 time source. An NTP server directly attached to it is a stratum 1 , while a machine synchronizing time from the NTP server is a stratum 2 time source. The server and peer are the two categories of time sources that you can in the /etc/ chrony.conf configuration file. The server is one stratum above the local NTP server, and the peer is at the same stratum level. More than one server and more than one peer can be specified, one per line. The first argument of the server line is the IP address or DNS name of the NTP server. Following the server IP address or name, a series of options for the server can be listed. It is recommended to use the iburst option, because after the service starts, four measurements are taken in a short time period for a more accurate initial clock synchronization. The following server classroom.example.com iburst line in the /etc/chrony.conf file causes the chronyd service to use the classroom.example.com NTP time source. # Use public servers from the pool.ntp.org project. ...output omitted... server classroom.example.com iburst ...output omitted... After pointing chronyd to the local time source, classroom.example.com, you should restart the service. [ root@host ~ ] # systemctl restart chronyd The chronyc command acts as a client to the chronyd service. After setting up NTP synchronization, you should verify that the local system is seamlessly using the NTP server to synchronize the system clock using the chrony sources command. For more verbose output with additional explanations about the output, use the chronyc sources -v command. [ root@host ~ ] # chronyc sources -v 210 Number of sources = 1 .-- Source mode '^' = server, '=' = peer, '#' = local clock. / .- Source state '*' = current synced, '+' = combined , '-' = not combined, | / '?' = unreachable, 'x' = time may be in error, '~' = time too variable. || .- xxxx [ yyyy ] +/- zzzz || / xxxx = adjusted offset, || Log2 ( Polling interval ) -. | yyyy = measured offset, || \\ | zzzz = estimated error. || | | MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* classroom.example.com 8 6 17 23 -497ns [ -7000ns ] +/- 956us The * character in the S** (Source state) field indicates that the classroom.example.com server has been used as a time source and is the NTP server the machine is currently synchronized to.","title":"CONFIGURING AND MONITORING CHRONYD"},{"location":"redhat/store/#summary","text":"In this chapter, you learned: The systemd-journald and rsyslog services capture and write log messages to the appropriate files. The /var/log directory contains log files. Periodic rotation of log files prevent them from filling up the file system space. The systemd journals are temporary and do not persist across reboot. The chronyd service helps to synchronize time settings with a time source.","title":"SUMMARY"},{"location":"redhat/users/","text":"DESCRIBING USER AND GROUP CONCEPTS \u00b6 WHAT IS A USER? \u00b6 A user account is used to provide security boundaries between different people and programs that can run commands. Users have user names to identify them to human users and make them easier to work with. Internally, the system distinguishes user accounts by the unique identification number assigned to them, the user ID or UID. If a user account is used by humans, it will generally be assigned a secret password that the user will use to prove that they are the actual authorized user when logging in. User accounts are fundamental to system security. Every process (running program) on the system runs as a particular user. Every file has a particular user as its owner. File ownership helps the system enforce access control for users of the files. The user associated with a running process determines the files and directories accessible to that process. There are three main types of user account: the superuser, system users , and regular users . The superuser account is for administration of the system. The name of the superuser is root and the account has UID 0. The superuser has full access to the system. The system has system user accounts which are used by processes that provide supporting services. These processes, or daemons, usually do not need to run as the superuser. They are assiged non-privileged accounts that allow them to secure their files and other resources from each other and from regular users on the system. Users do not interactively log in using a system user account. Most users have regular user accounts which they use for their day-to-day work. Like system You can use the id command to show information about the currently logged-in user. [ user01@host ~ ] $ id uid = 1000 ( user01 ) gid = 1000 ( user01 ) groups = 1000 ( user01 ) context = unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 To view basic information about another user, pass the username to the id command as an argument. [ user01@host ] $ id user02 uid = 1002 ( user02 ) gid = 1001 ( user02 ) groups = 1001 ( user02 ) context = unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 To view the owner of a file use the ls -l command. To view the owner of a directory use the ls - ld command. In the following output, the third column shows the username. [ user01@host ~ ] $ ls -l file1 -rw-rw-r--. 1 user01 user01 0 Feb 5 11 :10 file1 [ user01@host ] $ ls -ld dir1 drwxrwxr-x. 2 user01 user01 6 Feb 5 11 :10 dir1 To view process information, use the ps command. The default is to show only processes in the current shell. Add the a option to view all processes with a terminal. To view the user associated with a process, include the u option. In the following output, the first column shows the username. [ user01@host ] $ ps -au USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 777 0 .0 0 .0 225752 1496 tty1 Ss+ 11 :03 0 :00 /sbin/agetty -o - p -- \\u --noclear tty1 linux root 780 0 .0 0 .1 225392 2064 ttyS0 Ss+ 11 :03 0 :00 /sbin/agetty -o - p -- \\u --keep-baud 115200 ,38400,9600 user01 1207 0 .0 0 .2 234044 5104 pts/0 Ss 11 :09 0 :00 -bash user01 1319 0 .0 0 .2 266904 3876 pts/0 R+ 11 :33 0 :00 ps au The output of the preceding command displays users by name, but internally the operating system uses the UIDs to track users. The mapping of usernames to UIDs is defined in databases of account information. By default, systems use the /etc/passwd file to store information about local users. Each line in the /etc/passwd file contains information about one user. It is divided up into seven colon-separated fields. Here is an example of a line from /etc/passwd : user01:x:1000:1000:User One:/home/user01:/bin/bash user01 --> Username for this user (user01). x --> The user's password used to be stored here in encrypted format. That has been moved to the /etc/shadow file, which will be covered later. This field should always be x. 1000 --> The UID number for this user account (1000). 1000 --> The GID number for this user account's primary group (1000). Groups will be discussed later in this section. User One --> The real name for this user (User One). /home/user01 --> The home directory for this user ( /home/user01 ). This is the initial working directory when the shell starts and contains the user's data and configuration settings. /bin/bash --> The default shell program for this user, which runs on login ( /bin/bash ). For a regular user, this is normally the program that provides the user's command-line prompt. A system user might use /sbin/nologin if interactive logins are not allowed for that user. WHAT IS A GROUP? \u00b6 A group is a collection of users that need to share access to files and other system resources. Groups can be used to grant access to files to a set of users instead of just a single user. Like users, groups have group names to make them easier to work with. Internally, the system distinguishes groups by the unique identification number assigned to them, the group ID or GID. The mapping of group names to GIDs is defined in databases of group account information. By default, systems use the /etc/group file to store information about local groups. Each line in the /etc/group file contains information about one group. Each group entry is divided into four colon-separated fields. Here is an example of a line from /etc/group: group01:x:10000:user01,user02,user03 group01 --> Group name for this group (group01). x --> Obsolete group password field. This field should always be x. 10000 --> The GID number for this group (10000). user01 --> A list of users who are members of this group as a supplementary group (user01, user02, user03). Primary (or default) and supplementary groups are discussed later in this section. Primary Groups and Supplementary Groups Every user has exactly one primary group. For local users, this is the group listed by GID number in the /etc/passwd file. By default, this is the group that will own new files created by the user. Normally, when you create a new regular user, a new group with the same name as that user is created. That group is used as the primary group for the new user, and that user is the only member of this User Private Group. It turns out that this helps make management of file permissions simpler, which will be discussed later in this course. Users may also have supplementary groups. Membership in supplementary groups is determined by the /etc/group file. Users are granted access to files based on whether any of their groups have access. It doesn't matter if the group or groups that have access are primary or supplementary for the user. For example, if the user user01 has a primary group user01 and supplementary groups wheel and webadmin, then that user can read files readable by any of those three groups. The id command can also be used to find out about group membership for a user. [ user03@host ~ ] $ id uid = 1003 ( user03 ) gid = 1003 ( user03 ) groups = 1003 ( user03 ) ,10 ( wheel ) ,10000 ( group01 ) context = unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 In the preceding example, user03 has the group user03 as their primary group ( gid ). The groups item lists all groups for this user, and other than the primary group user03, the user has groups wheel and group01 as supplementary groups. GAINING SUPERUSER ACCESS \u00b6 THE SUPERUSER \u00b6 Most operating systems have some sort of superuser, a user that has all power over the system. In Red Hat Enterprise Linux this is the root user. This user has the power to override normal privileges on the file system, and is used to manage and administer the system. To perform tasks such as installing or removing software and to manage system files and directories, users must escalate their privileges to the root user. The root user only among normal users can control most devices, but there are a few exceptions. For example, normal users can control removable devices, such as USB devices. Thus, normal users can add and remove files and otherwise manage a removable device, but only root can manage \"fixed\" hard drives by default. This unlimited privilege, however, comes with responsibility. The root user has unlimited power to damage the system: remove files and directories, remove user accounts, add back doors, and so on. If the root user's account is compromised, someone else would have administrative control of the system. Throughout this course, administrators are encouraged to log in as a normal user and escalate privileges to root only when needed. The root account on Linux is roughly equivalent to the local Administrator account on Microsoft Windows. In Linux, most system administrators log in to the system as an unprivileged user and use various tools to temporarily gain root privileges. WARNING One common practice on Microsoft Windows in the past was for the local Administrator user to log in directly to perform system administrator duties. Although this is possible on Linux, Red Hat recommends that system administrators do not log in directly as root. Instead, system administrators should log in as a normal user and use other mechanisms ( su, sudo , or PolicyKit, for example) to temporarily gain superuser privileges. By logging in as the superuser, the entire desktop environment unnecessarily runs with administrative privileges. In that situation, any security vulnerability which would normally only compromise the user account has the potential to compromise the entire system. SWITCHING USERS \u00b6 The su command allows users to switch to a different user account. If you run su from a regular user account, you will be prompted for the password of the account to which you want to switch. When root runs su , you do not need to enter the user's password. [ user01@host ~ ] $ su - user02 Password: [ user02@host ~ ] $ If you omit the user name, the su or su - command attempts to switch to root by default. [ user01@host ~ ] $ su - Password: [ root@host ~ ] # The command su starts a non-login shell, while the command su - (with the dash option) starts a login shell. The main distinction between the two commands is that su - sets up the shell environment as if it were a new login as that user, while su just starts a shell as that user, but uses the original user's environment settings. In most cases, administrators should run su - to get a shell with the target user's normal environment settings. For more information, see the bash(1) man page. NOTE The su command is most frequently used to get a command-line interface (shell prompt) which is running as another user, typically root. However, with the -c option, it can be used like the Windows utility runas to run an arbitrary program as another user. Run info su to view more details. RUNNING COMMANDS WITH SUDO \u00b6 In some cases, the root user's account may not have a valid password at all for security reasons. In this case, users cannot log in to the system as root directly with a password, and su cannot be used to get an interactive shell. One tool that can be used to get root access in this case is sudo . Unlike su, sudo normally requires users to enter their own password for authentication, not the password of the user account they are trying to access. That is, users who use sudo to run commands as root do not need to know the root password. Instead, they use their own passwords to authenticate access. Additionally, sudo can be configured to allow specific users to run any command as some other user, or only some commands as that user. For example, when sudo is configured to allow the user01 user to run the command usermod as root, user01 could run the following command to lock or unlock a user account: [ user01@host ~ ] $ sudo usermod -L user02 [ sudo ] password for user01: [ user01@host ~ ] $ su - user02 Password: su: Authentication failure [ user01@host ~ ] $ If a user tries to run a command as another user, and the sudo configuration does not permit it, the command will be blocked, the attempt will be logged, and by default an email will be sent to the root user. [ user02@host ~ ] $ sudo tail /var/log/secure [ sudo ] password for user02: user02 is not in the sudoers file. This incident will be reported. [ user02@host ~ ] $ One additional benefit to using sudo is that all commands executed are logged by default to / var/log/secure . [ user01@host ~ ] $ sudo tail /var/log/secure ...output omitted... Feb 6 20 :45:46 host sudo [ 2577 ] : user01 : TTY = pts/0 ; PWD = /home/user01 ; USER = root ; COMMAND = /sbin/usermod -L user02 ...output omitted... In Red Hat Enterprise Linux 7 and Red Hat Enterprise Linux 8, all members of the wheel group can use sudo to run commands as any user, including root. The user is prompted for their own password. This is a change from Red Hat Enterprise Linux 6 and earlier, where users who were members of the wheel group did not get this administrative access by default. WARNING RHEL 6 did not grant the wheel group any special privileges by default. Sites that have been using this group for a non-standard purpose might be surprised when RHEL 7 and RHEL 8 automatically grants all members of wheel full sudo privileges. This could lead to unauthorized users getting administrative access to RHEL 7 and RHEL 8 systems. Historically, UNIX-like systems use membership in the wheel group to grant or control superuser access. Getting an Interactive Root Shell with Sudo If there is a nonadministrative user account on the system that can use sudo to run the su command, you can run sudo su - from that account to get an interactive root user shell. This works because sudo will run su - as root, and root does not need to enter a password to use su . Another way to access the root account with sudo is to use the sudo -i command. This will switch to the root account and run that user's default shell (usually bash ) and associated shell login scripts. If you just want to run the shell, you can use the sudo -s command. For example, an administrator might get an interactive shell as root on an AWS EC2 instance by using SSH public-key authentication to log in as the normal user ec2-user, and then by running sudo -i to get the root user's shell. [ ec2-user@host ~ ] $ sudo -i [ sudo ] password for ec2-user: [ root@host ~ ] # The sudo su - command and sudo -i do not behave exactly the same. This will be discussed briefly at the end of the section. Configuring Sudo The main configuration file for sudo is /etc/sudoers . To avoid problems if multiple administrators try to edit it at the same time, it should only be edited with the special visudo command. For example, the following line from the /etc/sudoers file enables sudo access for members of group wheel . %wheel ALL=(ALL) ALL In this line, %wheel is the user or group to whom the rule applies. A % specifies that this is a group, group wheel. The ALL=(ALL) specifies that on any host that might have this file, wheel can run any command. The final ALL specifies that wheel can run those commands as any user on the system. By default, /etc/sudoers also includes the contents of any files in the /etc/sudoers.d directory as part of the configuration file. This allows an administrator to add sudo access for a user simply by putting an appropriate file in that directory. NOTE Using supplementary files under the /etc/sudoers.d directory is convenient and simple. You can enable or disable sudo access simply by copying a file into the directory or removing it from the directory. In this course, you will create and remove files in the /etc/sudoers.d directory to configure sudo access for users and groups. To enable full sudo access for the user user01, you could create /etc/sudoers.d/user01 with the following content: user01 ALL=(ALL) ALL To enable full sudo access for the group group01, you could create /etc/sudoers.d/group01 with the following content: %group01 ALL=(ALL) ALL It is also possible to set up sudo to allow a user to run commands as another user without entering their password: ansible ALL=(ALL) NOPASSWD:ALL While there are obvious security risks to granting this level of access to a user or group, it is frequently used with cloud instances, virtual machines, and provisioning systems to help configure servers. The account with this access must be carefully protected and might require SSH public- key authentication in order for a user on a remote system to access it at all. For example, the official AMI for Red Hat Enterprise Linux in the Amazon Web Services Marketplace ships with the root and the ec2-user users' passwords locked. The ec2-user user account is set up to allow remote interactive access through SSH public-key authentication. The user ec2- user can also run any command as root without a password because the last line of the AMI's / etc/sudoers file is set up as follows: ec2-user ALL=(ALL) NOPASSWD: ALL The requirement to enter a password for sudo can be re-enabled or other changes may be made to tighten security as part of the process of configuring the system. NOTE In this course, you will frequently see sudo su - used instead of sudo -i . Both commands work, but there are some subtle differences between them. The sudo su - command sets up the root environment exactly like a normal login because the su - command ignores the settings made by sudo and sets up the environment from scratch. The default configuration of the sudo -i command actually sets up some details of the root user's environment differently than a normal login. For example, it sets the PATH environment variable slightly differently. This affects where the shell will look to find commands. You can make sudo -i behave more like su - by editing /etc/sudoers with visudo . Find the line Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin and replace it with the following two lines: Defaults secure_path = /usr/local/bin:/usr/bin Defaults>root secure_path = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin For most purposes, this is not a major difference. However, for consistency of PATH settings on systems with the default /etc/sudoers file, the authors of this course mostly use sudo su - in examples. MANAGING LOCAL USER ACCOUNTS \u00b6 MANAGING LOCAL USERS \u00b6 A number of command-line tools can be used to manage local user accounts. Creating Users from the Command Line The useradd username command creates a new user named username. It sets up the user's home directory and account information, and creates a private group for the user named username. At this point the account does not have a valid password set, and the user cannot log in until a password is set. The useradd --help command displays the basic options that can be used to override the defaults. In most cases, the same options can be used with the usermod command to modify an existing user. Some defaults, such as the range of valid UID numbers and default password aging rules, are read from the /etc/login.defs file. Values in this file are only used when creating new users. A change to this file does not affect existing users. Modifying Existing Users from the Command Line The usermod --help command displays the basic options that can be used to modify an account. Some common options include: USERMOD OPTIONS: USAGE -c, --comment COMMENT Add the user's real name to the comment field. -g, --gid GROUP Specify the primary group for the user account. -G, --groups GROUPS Specify a comma-separated list of supplementary groups for the user account. -a, --append Used with the -G option to add the supplementary groups to the user's current set of group memberships instead of replacing the set of supplementary groups with a new set. -d, --home HOME_DIR Specify a particular home directory for the user account. -m, --move-home Move the user's home directory to a new location. Must be used with the -d option. -s, --shell SHELL Specify a particular login shell for the user account. -L, --lock Lock the user account. -U, --unlock Unlock the user account. Deleting Users from the Command Line The userdel username command removes the details of username from /etc/passwd, but leaves the user's home directory intact. The userdel -r username command removes the details of username from /etc/passwd and also deletes the user's home directory. WARNING When a user is removed with userdel without the -r option specified, the system will have files that are owned by an unassigned UID. This can also happen when a file, having a deleted user as its owner, exists outside that user's home directory. This situation can lead to information leakage and other security issues. In Red Hat Enterprise Linux 7 and Red Hat Enterprise Linux 8, the useradd command assigns new users the first free UID greater than or equal to 1000, unless you explicitly specify one using the -u option. This is how information leakage can occur. If the first free UID had been previously assigned to a user account which has since been removed from the system, the old user's UID will get reassigned to the new user, giving the new user ownership of the old user's remaining files. The following scenario demonstrates this situation. [ root@host ~ ] # useradd user01 [ root@host ~ ] # ls -l /home drwx------. 3 user01 user01 74 Feb 4 15 :22 user01 [ root@host ~ ] # userdel user01 [ root@host ~ ] # ls -l /home drwx------. 3 1000 1000 74 Feb 4 15 :22 user01 [ root@host ~ ] # useradd user02 [ root@host ~ ] # ls -l /home drwx------. 3 user02 user02 74 Feb 4 15 :23 user02 drwx------. 3 user02 user02 74 Feb 4 15 :22 user01 Notice that user02 now owns all files that user01 previously owned. Depending on the situation, one solution to this problem is to remove all unowned files from the system when the user that created them is deleted. Another solution is to manually assign the unowned files to a different user. The root user can use the find / -nouser -o -nogroup command to find all unowned files and directories. Setting Passwords from the Command Line The passwd username command sets the initial password or changes the existing password of username. The root user can set a password to any value. A message is displayed if the password does not meet the minimum recommended criteria, but is followed by a prompt to retype the new password and all tokens are updated successfully. [ root@host ~ ] # passwd user01 Changing password for user user01. New password: redhat BAD PASSWORD: The password fails the dictionary check - it is based on a dictionary word Retype new password: redhat passwd: all authentication tokens updated successfully. [ root@host ~ ] # A regular user must choose a password at least eight characters long and is also not based on a dictionary word, the username, or the previous password. UID Ranges Specific UID numbers and ranges of numbers are used for specific purposes by Red Hat Enterprise Linux. UID 0 is always assigned to the superuser account, root . UID 1-200 is a range of \"system users\" assigned statically to system processes by Red Hat. UID 201-999 is a range of \"system users\" used by system processes that do not own files on the file system. They are typically assigned dynamically from the available pool when the software that needs them is installed. Programs run as these \"unprivileged\" system users in order to limit their access to only the resources they need to function. \u2022 UID 1000+ is the range available for assignment to regular users. NOTE Prior to RHEL 7, the convention was that UID 1-499 was used for system users and UID 500+ for regular users. Default ranges used by useradd and groupadd can be changed in the /etc/login.defs file. MANAGING LOCAL GROUP ACCOUNTS \u00b6 MANAGING LOCAL GROUPS \u00b6 A group must exist before a user can be added to that group. Several command-line tools are used to manage local group accounts. Creating Groups from the Command Line The groupadd command creates groups. Without options the groupadd command uses the next available GID from the range specified in the /etc/login.defs file while creating the groups. The -g option specifies a particular GID for the group to use. [ user01@host ~ ] $ sudo groupadd -g 10000 group01 [ user01@host ~ ] $ tail /etc/group ...output omitted... group01:x:10000: NOTE Given the automatic creation of user private groups (GID 1000+), it is generally recommended to set aside a range of GIDs to be used for supplementary groups. A higher range will avoid a collision with a system group (GID 0-999). The -r option creates a system group using a GID from the range of valid system GIDs listed in the /etc/login.defs file. The SYSGIDMIN and SYSGIDMAX configuration items in / etc/login.defs define the range of system GIDs. [ user01@host ~ ] $ sudo groupadd -r group02 [ user01@host ~ ] $ tail /etc/group ...output omitted... group01:x:10000: group02:x:988: Modifying Existing Groups from the Command Line The groupmod command changes the properties of an existing group. The -n option specifies a new name for the group. [ user01@host ~ ] $ sudo groupmod -n group0022 group02 [ user01@host ~ ] $ tail /etc/group ...output omitted... group0022:x:988: Notice that the group name is updated to group0022 from group02. The -g option specifies a new GID. [ user01@host ~ ] $ sudo groupmod -g 20000 group0022 [ user01@host ~ ] $ tail /etc/group ...output omitted... group0022:x:20000: Notice that the GID is updated to 20000 from 988. Deleting Groups from the Command Line The groupdel command removes groups. [ user01@host ~ ] $ sudo groupdel group0022 NOTE You cannot remove a group if it is the primary group of any existing user. As with userdel , check all file systems to ensure that no files remain on the system that are owned by the group. Changing Group Membership from the Command Line The membership of a group is controlled with user management. Use the usermod -g command to change a user's primary group. [ user01@host ~ ] $ id user02 uid = 1006 ( user02 ) gid = 1008 ( user02 ) groups = 1008 ( user02 ) [ user01@host ~ ] $ sudo usermod -g group01 user02 [ user01@host ~ ] $ id user02 uid = 1006 ( user02 ) gid = 10000 ( group01 ) groups = 10000 ( group01 ) Use the usermod -aG command to add a user to a supplementary group. [ user01@host ~ ] $ id user03 uid = 1007 ( user03 ) gid = 1009 ( user03 ) groups = 1009 ( user03 ) [ user01@host ~ ] $ sudo usermod -aG group01 user03 [ user01@host ~ ] $ id user03 uid = 1007 ( user03 ) gid = 1009 ( user03 ) groups = 1009 ( user03 ) ,10000 ( group01 ) IMPORTANT The use of the -a option makes usermod function in append mode. Without -a , the user will be removed from any of their current supplementary groups that are not included in the -G option's list. MANAGING USER PASSWORDS OBJECTIVES \u00b6 SHADOW PASSWORDS AND PASSWORD POLICY \u00b6 At one time, encrypted passwords were stored in the world-readable /etc/passwd file. This was thought to be reasonably secure until dictionary attacks on encrypted passwords became common. At that point, the encrypted passwords were moved to a separate /etc/shadow file which is readable only by root. This new file also allowed password aging and expiration features to be implemented. Like /etc/passwd , each user has a line in the /etc/shadow file. A sample line from /etc/ shadow with its nine colon-separated fields is shown below. user03:$6$CSsX...output omitted...:17933:0:99999:7:2:18113: user03 --> Username of the account this password belongs to. \\(6\\) CSsX...output omitted... --> The encrypted password of the user. The format of encrypted passwords is discussed later in this section. 17933 --> The day on which the password was last changed. This is set in days since 1970-01-01, and is calculated in the UTC time zone. 0 --> The minimum number of days that have to elapse since the last password change before the user can change it again. 99999 --> The maximum number of days that can pass without a password change before the password expires. An empty field means it does not expire based on time since the last change. 7 --> Warning period. The user will be warned about an expiring password when they login for this number of days before the deadline. 2 --> Inactivity period. Once the password has expired, it will still be accepted for login for this many days. After this period has elapsed, the account will be locked. 18113 --> The day on which the password expires. This is set in days since 1970-01-01, and is calculated in the UTC time zone. An empty field means it does not expire on a particular date. --> The last field is usually empty and is reserved for future use. Format of an Encrypted Password The encrypted password field stores three pieces of information: the hashing algorithm used, the salt , and the encrypted hash . Each piece of information is delimited by the $ sign. $6$CSsXcYG1L/4ZfHr/$2W6evvJahUfzfHpc9X.45Jc6H30E...output omitted... 6 --> The hashing algorithm used for this password. The number 6 indicates it is a SHA-512 hash, which is the default in Red Hat Enterprise Linux 8. A 1 would indicate MD5, a 5 SHA-256. CSsXcYG1L/4ZfHr/ --> The salt used to encrypt the password. This is originally chosen at random. 2W6evvJahUfzfHpc9X.45Jc6H30E...output omitted... --> The encrypted hash of the user's password. The salt and the unencrypted password are combined and encrypted to generate the encrypted hash of the password. The use of a salt prevents two users with the same password from having identical entries in the / etc/shadow file. For example, even if user01 and user02 both use redhat as their passwords, their encrypted passwords in /etc/shadow will be different if their salts are different. Password Verification When a user tries to log in, the system looks up the entry for the user in /etc/shadow , combines the salt for the user with the unencrypted password that was typed in, and encrypts them using the hashing algorithm specified. If the result matches the encrypted hash, the user typed in the right password. If the result does not match the encrypted hash, the user typed in the wrong password and the login attempt fails. This method allows the system to determine if the user typed in the correct password without storing that password in a form usable for logging in. CONFIGURING PASSWORD AGING \u00b6 The following diagram relates the relevant password aging parameters, which can be adjusted using the chage command to implement a password aging policy. [ user01@host ~ ] $ sudo chage -m 0 -M 90 -W 7 -I 14 user03 The preceding chage command uses the -m, -M, -W , and -I options to set the minimum age, maximum age, warning period, and inactivity period of the user's password, respectively. The chage -d 0 user03 command forces the user03 user to update its password on the next login. The chage -l user03 command displays the password aging details of user03. The chage -E 2019-08-05 user03 command causes the user03 user's account to expire on 2019-08-05 (in YYYY-MM-DD format). NOTE The date command can be used to calculate a date in the future. The -u option reports the time in UTC. [ user01@host ~ ] $ date -d \"+45 days\" -u Thu May 23 17 :01:20 UTC 2019 Edit the password aging configuration items in the /etc/login.defs file to set the default password aging policies. The PASSMAXDAYS sets the default maximum age of the password. The PASSMINDAYS sets the default minimum age of the password. The PASSWARNAGE sets the default warning period of the password. Any change in the default password aging policies will be effective for new users only. The existing users will continue to use the old password aging settings rather than the new ones. RESTRICTING ACCESS \u00b6 You can use the chage command to set account expiration dates. When that date is reached, the user cannot log in to the system interactively. The usermod command can lock an account with the -L option. [ user01@host ~ ] $ sudo usermod -L user03 [ user01@host ~ ] $ su - user03 Password: redhat su: Authentication failure If a user leaves the company, the administrator may lock and expire an account with a single usermod command. The date must be given as the number of days since 1970-01-01, or in the YYYY-MM-DD format. [ user01@host ~ ] $ sudo usermod -L -e 2019 -10-05 user03 The preceding usermod command uses the -e option to set the account expiry date for the given user account. The -L option locks the user's password. Locking the account prevents the user from authenticating with a password to the system. It is the recommended method of preventing access to an account by an employee who has left the company. If the employee returns, the account can later be unlocked with usermod -U . If the account was also expired, be sure to also change the expiration date. The nologin Shell The nologin shell acts as a replacement shell for the user accounts not intended to interactively log into the system. It is wise from the security standpoint to disable the user account from logging into the system when the user acount serves a responsibility that does not require the user to log into the system. For example, a mail server may require an account to store mail and a password for the user to authenticate with a mail client used to retrieve mail. That user does not need to log directly into the system. A common solution to this situation is to set the user's login shell to /sbin/nologin . If the user attempts to log in to the system directly, the nologin shell closes the connection. [ user01@host ~ ] $ usermod -s /sbin/nologin user03 [ user01@host ~ ] $ su - user03 Last login: Wed Feb 6 17 :03:06 IST 2019 on pts/0 This account is currently not available. IMPORTANT The nologin shell prevents interactive use of the system, but does not prevent all access. Users might be able to authenticate and upload or retrieve files through applications such as web applications, file transfer programs, or mail readers if they use the user's password for authentication. SUMMARY \u00b6 In this chapter, you learned: There are three main types of user account: the superuser, system users, and regular users. A user must have a primary group and may be a member of one or more supplementary groups. The three critical files containing user and group information are /etc/passwd, /etc/group , and /etc/shadow . The su and sudo commands can be used to run commands as the superuser. The useradd, usermod , and userdel commands can be used to manage users. The groupadd, groupmod , and groupdel commands can be used to manage groups. The chage command can be used to configure and view password expiration settings for users.","title":"Managing Local Users And Groups"},{"location":"redhat/users/#describing-user-and-group-concepts","text":"","title":"DESCRIBING USER AND GROUP CONCEPTS"},{"location":"redhat/users/#what-is-a-user","text":"A user account is used to provide security boundaries between different people and programs that can run commands. Users have user names to identify them to human users and make them easier to work with. Internally, the system distinguishes user accounts by the unique identification number assigned to them, the user ID or UID. If a user account is used by humans, it will generally be assigned a secret password that the user will use to prove that they are the actual authorized user when logging in. User accounts are fundamental to system security. Every process (running program) on the system runs as a particular user. Every file has a particular user as its owner. File ownership helps the system enforce access control for users of the files. The user associated with a running process determines the files and directories accessible to that process. There are three main types of user account: the superuser, system users , and regular users . The superuser account is for administration of the system. The name of the superuser is root and the account has UID 0. The superuser has full access to the system. The system has system user accounts which are used by processes that provide supporting services. These processes, or daemons, usually do not need to run as the superuser. They are assiged non-privileged accounts that allow them to secure their files and other resources from each other and from regular users on the system. Users do not interactively log in using a system user account. Most users have regular user accounts which they use for their day-to-day work. Like system You can use the id command to show information about the currently logged-in user. [ user01@host ~ ] $ id uid = 1000 ( user01 ) gid = 1000 ( user01 ) groups = 1000 ( user01 ) context = unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 To view basic information about another user, pass the username to the id command as an argument. [ user01@host ] $ id user02 uid = 1002 ( user02 ) gid = 1001 ( user02 ) groups = 1001 ( user02 ) context = unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 To view the owner of a file use the ls -l command. To view the owner of a directory use the ls - ld command. In the following output, the third column shows the username. [ user01@host ~ ] $ ls -l file1 -rw-rw-r--. 1 user01 user01 0 Feb 5 11 :10 file1 [ user01@host ] $ ls -ld dir1 drwxrwxr-x. 2 user01 user01 6 Feb 5 11 :10 dir1 To view process information, use the ps command. The default is to show only processes in the current shell. Add the a option to view all processes with a terminal. To view the user associated with a process, include the u option. In the following output, the first column shows the username. [ user01@host ] $ ps -au USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 777 0 .0 0 .0 225752 1496 tty1 Ss+ 11 :03 0 :00 /sbin/agetty -o - p -- \\u --noclear tty1 linux root 780 0 .0 0 .1 225392 2064 ttyS0 Ss+ 11 :03 0 :00 /sbin/agetty -o - p -- \\u --keep-baud 115200 ,38400,9600 user01 1207 0 .0 0 .2 234044 5104 pts/0 Ss 11 :09 0 :00 -bash user01 1319 0 .0 0 .2 266904 3876 pts/0 R+ 11 :33 0 :00 ps au The output of the preceding command displays users by name, but internally the operating system uses the UIDs to track users. The mapping of usernames to UIDs is defined in databases of account information. By default, systems use the /etc/passwd file to store information about local users. Each line in the /etc/passwd file contains information about one user. It is divided up into seven colon-separated fields. Here is an example of a line from /etc/passwd : user01:x:1000:1000:User One:/home/user01:/bin/bash user01 --> Username for this user (user01). x --> The user's password used to be stored here in encrypted format. That has been moved to the /etc/shadow file, which will be covered later. This field should always be x. 1000 --> The UID number for this user account (1000). 1000 --> The GID number for this user account's primary group (1000). Groups will be discussed later in this section. User One --> The real name for this user (User One). /home/user01 --> The home directory for this user ( /home/user01 ). This is the initial working directory when the shell starts and contains the user's data and configuration settings. /bin/bash --> The default shell program for this user, which runs on login ( /bin/bash ). For a regular user, this is normally the program that provides the user's command-line prompt. A system user might use /sbin/nologin if interactive logins are not allowed for that user.","title":"WHAT IS A USER?"},{"location":"redhat/users/#what-is-a-group","text":"A group is a collection of users that need to share access to files and other system resources. Groups can be used to grant access to files to a set of users instead of just a single user. Like users, groups have group names to make them easier to work with. Internally, the system distinguishes groups by the unique identification number assigned to them, the group ID or GID. The mapping of group names to GIDs is defined in databases of group account information. By default, systems use the /etc/group file to store information about local groups. Each line in the /etc/group file contains information about one group. Each group entry is divided into four colon-separated fields. Here is an example of a line from /etc/group: group01:x:10000:user01,user02,user03 group01 --> Group name for this group (group01). x --> Obsolete group password field. This field should always be x. 10000 --> The GID number for this group (10000). user01 --> A list of users who are members of this group as a supplementary group (user01, user02, user03). Primary (or default) and supplementary groups are discussed later in this section. Primary Groups and Supplementary Groups Every user has exactly one primary group. For local users, this is the group listed by GID number in the /etc/passwd file. By default, this is the group that will own new files created by the user. Normally, when you create a new regular user, a new group with the same name as that user is created. That group is used as the primary group for the new user, and that user is the only member of this User Private Group. It turns out that this helps make management of file permissions simpler, which will be discussed later in this course. Users may also have supplementary groups. Membership in supplementary groups is determined by the /etc/group file. Users are granted access to files based on whether any of their groups have access. It doesn't matter if the group or groups that have access are primary or supplementary for the user. For example, if the user user01 has a primary group user01 and supplementary groups wheel and webadmin, then that user can read files readable by any of those three groups. The id command can also be used to find out about group membership for a user. [ user03@host ~ ] $ id uid = 1003 ( user03 ) gid = 1003 ( user03 ) groups = 1003 ( user03 ) ,10 ( wheel ) ,10000 ( group01 ) context = unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 In the preceding example, user03 has the group user03 as their primary group ( gid ). The groups item lists all groups for this user, and other than the primary group user03, the user has groups wheel and group01 as supplementary groups.","title":"WHAT IS A GROUP?"},{"location":"redhat/users/#gaining-superuser-access","text":"","title":"GAINING SUPERUSER ACCESS"},{"location":"redhat/users/#the-superuser","text":"Most operating systems have some sort of superuser, a user that has all power over the system. In Red Hat Enterprise Linux this is the root user. This user has the power to override normal privileges on the file system, and is used to manage and administer the system. To perform tasks such as installing or removing software and to manage system files and directories, users must escalate their privileges to the root user. The root user only among normal users can control most devices, but there are a few exceptions. For example, normal users can control removable devices, such as USB devices. Thus, normal users can add and remove files and otherwise manage a removable device, but only root can manage \"fixed\" hard drives by default. This unlimited privilege, however, comes with responsibility. The root user has unlimited power to damage the system: remove files and directories, remove user accounts, add back doors, and so on. If the root user's account is compromised, someone else would have administrative control of the system. Throughout this course, administrators are encouraged to log in as a normal user and escalate privileges to root only when needed. The root account on Linux is roughly equivalent to the local Administrator account on Microsoft Windows. In Linux, most system administrators log in to the system as an unprivileged user and use various tools to temporarily gain root privileges. WARNING One common practice on Microsoft Windows in the past was for the local Administrator user to log in directly to perform system administrator duties. Although this is possible on Linux, Red Hat recommends that system administrators do not log in directly as root. Instead, system administrators should log in as a normal user and use other mechanisms ( su, sudo , or PolicyKit, for example) to temporarily gain superuser privileges. By logging in as the superuser, the entire desktop environment unnecessarily runs with administrative privileges. In that situation, any security vulnerability which would normally only compromise the user account has the potential to compromise the entire system.","title":"THE SUPERUSER"},{"location":"redhat/users/#switching-users","text":"The su command allows users to switch to a different user account. If you run su from a regular user account, you will be prompted for the password of the account to which you want to switch. When root runs su , you do not need to enter the user's password. [ user01@host ~ ] $ su - user02 Password: [ user02@host ~ ] $ If you omit the user name, the su or su - command attempts to switch to root by default. [ user01@host ~ ] $ su - Password: [ root@host ~ ] # The command su starts a non-login shell, while the command su - (with the dash option) starts a login shell. The main distinction between the two commands is that su - sets up the shell environment as if it were a new login as that user, while su just starts a shell as that user, but uses the original user's environment settings. In most cases, administrators should run su - to get a shell with the target user's normal environment settings. For more information, see the bash(1) man page. NOTE The su command is most frequently used to get a command-line interface (shell prompt) which is running as another user, typically root. However, with the -c option, it can be used like the Windows utility runas to run an arbitrary program as another user. Run info su to view more details.","title":"SWITCHING USERS"},{"location":"redhat/users/#running-commands-with-sudo","text":"In some cases, the root user's account may not have a valid password at all for security reasons. In this case, users cannot log in to the system as root directly with a password, and su cannot be used to get an interactive shell. One tool that can be used to get root access in this case is sudo . Unlike su, sudo normally requires users to enter their own password for authentication, not the password of the user account they are trying to access. That is, users who use sudo to run commands as root do not need to know the root password. Instead, they use their own passwords to authenticate access. Additionally, sudo can be configured to allow specific users to run any command as some other user, or only some commands as that user. For example, when sudo is configured to allow the user01 user to run the command usermod as root, user01 could run the following command to lock or unlock a user account: [ user01@host ~ ] $ sudo usermod -L user02 [ sudo ] password for user01: [ user01@host ~ ] $ su - user02 Password: su: Authentication failure [ user01@host ~ ] $ If a user tries to run a command as another user, and the sudo configuration does not permit it, the command will be blocked, the attempt will be logged, and by default an email will be sent to the root user. [ user02@host ~ ] $ sudo tail /var/log/secure [ sudo ] password for user02: user02 is not in the sudoers file. This incident will be reported. [ user02@host ~ ] $ One additional benefit to using sudo is that all commands executed are logged by default to / var/log/secure . [ user01@host ~ ] $ sudo tail /var/log/secure ...output omitted... Feb 6 20 :45:46 host sudo [ 2577 ] : user01 : TTY = pts/0 ; PWD = /home/user01 ; USER = root ; COMMAND = /sbin/usermod -L user02 ...output omitted... In Red Hat Enterprise Linux 7 and Red Hat Enterprise Linux 8, all members of the wheel group can use sudo to run commands as any user, including root. The user is prompted for their own password. This is a change from Red Hat Enterprise Linux 6 and earlier, where users who were members of the wheel group did not get this administrative access by default. WARNING RHEL 6 did not grant the wheel group any special privileges by default. Sites that have been using this group for a non-standard purpose might be surprised when RHEL 7 and RHEL 8 automatically grants all members of wheel full sudo privileges. This could lead to unauthorized users getting administrative access to RHEL 7 and RHEL 8 systems. Historically, UNIX-like systems use membership in the wheel group to grant or control superuser access. Getting an Interactive Root Shell with Sudo If there is a nonadministrative user account on the system that can use sudo to run the su command, you can run sudo su - from that account to get an interactive root user shell. This works because sudo will run su - as root, and root does not need to enter a password to use su . Another way to access the root account with sudo is to use the sudo -i command. This will switch to the root account and run that user's default shell (usually bash ) and associated shell login scripts. If you just want to run the shell, you can use the sudo -s command. For example, an administrator might get an interactive shell as root on an AWS EC2 instance by using SSH public-key authentication to log in as the normal user ec2-user, and then by running sudo -i to get the root user's shell. [ ec2-user@host ~ ] $ sudo -i [ sudo ] password for ec2-user: [ root@host ~ ] # The sudo su - command and sudo -i do not behave exactly the same. This will be discussed briefly at the end of the section. Configuring Sudo The main configuration file for sudo is /etc/sudoers . To avoid problems if multiple administrators try to edit it at the same time, it should only be edited with the special visudo command. For example, the following line from the /etc/sudoers file enables sudo access for members of group wheel . %wheel ALL=(ALL) ALL In this line, %wheel is the user or group to whom the rule applies. A % specifies that this is a group, group wheel. The ALL=(ALL) specifies that on any host that might have this file, wheel can run any command. The final ALL specifies that wheel can run those commands as any user on the system. By default, /etc/sudoers also includes the contents of any files in the /etc/sudoers.d directory as part of the configuration file. This allows an administrator to add sudo access for a user simply by putting an appropriate file in that directory. NOTE Using supplementary files under the /etc/sudoers.d directory is convenient and simple. You can enable or disable sudo access simply by copying a file into the directory or removing it from the directory. In this course, you will create and remove files in the /etc/sudoers.d directory to configure sudo access for users and groups. To enable full sudo access for the user user01, you could create /etc/sudoers.d/user01 with the following content: user01 ALL=(ALL) ALL To enable full sudo access for the group group01, you could create /etc/sudoers.d/group01 with the following content: %group01 ALL=(ALL) ALL It is also possible to set up sudo to allow a user to run commands as another user without entering their password: ansible ALL=(ALL) NOPASSWD:ALL While there are obvious security risks to granting this level of access to a user or group, it is frequently used with cloud instances, virtual machines, and provisioning systems to help configure servers. The account with this access must be carefully protected and might require SSH public- key authentication in order for a user on a remote system to access it at all. For example, the official AMI for Red Hat Enterprise Linux in the Amazon Web Services Marketplace ships with the root and the ec2-user users' passwords locked. The ec2-user user account is set up to allow remote interactive access through SSH public-key authentication. The user ec2- user can also run any command as root without a password because the last line of the AMI's / etc/sudoers file is set up as follows: ec2-user ALL=(ALL) NOPASSWD: ALL The requirement to enter a password for sudo can be re-enabled or other changes may be made to tighten security as part of the process of configuring the system. NOTE In this course, you will frequently see sudo su - used instead of sudo -i . Both commands work, but there are some subtle differences between them. The sudo su - command sets up the root environment exactly like a normal login because the su - command ignores the settings made by sudo and sets up the environment from scratch. The default configuration of the sudo -i command actually sets up some details of the root user's environment differently than a normal login. For example, it sets the PATH environment variable slightly differently. This affects where the shell will look to find commands. You can make sudo -i behave more like su - by editing /etc/sudoers with visudo . Find the line Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin and replace it with the following two lines: Defaults secure_path = /usr/local/bin:/usr/bin Defaults>root secure_path = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin For most purposes, this is not a major difference. However, for consistency of PATH settings on systems with the default /etc/sudoers file, the authors of this course mostly use sudo su - in examples.","title":"RUNNING COMMANDS WITH SUDO"},{"location":"redhat/users/#managing-local-user-accounts","text":"","title":"MANAGING LOCAL USER ACCOUNTS"},{"location":"redhat/users/#managing-local-users","text":"A number of command-line tools can be used to manage local user accounts. Creating Users from the Command Line The useradd username command creates a new user named username. It sets up the user's home directory and account information, and creates a private group for the user named username. At this point the account does not have a valid password set, and the user cannot log in until a password is set. The useradd --help command displays the basic options that can be used to override the defaults. In most cases, the same options can be used with the usermod command to modify an existing user. Some defaults, such as the range of valid UID numbers and default password aging rules, are read from the /etc/login.defs file. Values in this file are only used when creating new users. A change to this file does not affect existing users. Modifying Existing Users from the Command Line The usermod --help command displays the basic options that can be used to modify an account. Some common options include: USERMOD OPTIONS: USAGE -c, --comment COMMENT Add the user's real name to the comment field. -g, --gid GROUP Specify the primary group for the user account. -G, --groups GROUPS Specify a comma-separated list of supplementary groups for the user account. -a, --append Used with the -G option to add the supplementary groups to the user's current set of group memberships instead of replacing the set of supplementary groups with a new set. -d, --home HOME_DIR Specify a particular home directory for the user account. -m, --move-home Move the user's home directory to a new location. Must be used with the -d option. -s, --shell SHELL Specify a particular login shell for the user account. -L, --lock Lock the user account. -U, --unlock Unlock the user account. Deleting Users from the Command Line The userdel username command removes the details of username from /etc/passwd, but leaves the user's home directory intact. The userdel -r username command removes the details of username from /etc/passwd and also deletes the user's home directory. WARNING When a user is removed with userdel without the -r option specified, the system will have files that are owned by an unassigned UID. This can also happen when a file, having a deleted user as its owner, exists outside that user's home directory. This situation can lead to information leakage and other security issues. In Red Hat Enterprise Linux 7 and Red Hat Enterprise Linux 8, the useradd command assigns new users the first free UID greater than or equal to 1000, unless you explicitly specify one using the -u option. This is how information leakage can occur. If the first free UID had been previously assigned to a user account which has since been removed from the system, the old user's UID will get reassigned to the new user, giving the new user ownership of the old user's remaining files. The following scenario demonstrates this situation. [ root@host ~ ] # useradd user01 [ root@host ~ ] # ls -l /home drwx------. 3 user01 user01 74 Feb 4 15 :22 user01 [ root@host ~ ] # userdel user01 [ root@host ~ ] # ls -l /home drwx------. 3 1000 1000 74 Feb 4 15 :22 user01 [ root@host ~ ] # useradd user02 [ root@host ~ ] # ls -l /home drwx------. 3 user02 user02 74 Feb 4 15 :23 user02 drwx------. 3 user02 user02 74 Feb 4 15 :22 user01 Notice that user02 now owns all files that user01 previously owned. Depending on the situation, one solution to this problem is to remove all unowned files from the system when the user that created them is deleted. Another solution is to manually assign the unowned files to a different user. The root user can use the find / -nouser -o -nogroup command to find all unowned files and directories. Setting Passwords from the Command Line The passwd username command sets the initial password or changes the existing password of username. The root user can set a password to any value. A message is displayed if the password does not meet the minimum recommended criteria, but is followed by a prompt to retype the new password and all tokens are updated successfully. [ root@host ~ ] # passwd user01 Changing password for user user01. New password: redhat BAD PASSWORD: The password fails the dictionary check - it is based on a dictionary word Retype new password: redhat passwd: all authentication tokens updated successfully. [ root@host ~ ] # A regular user must choose a password at least eight characters long and is also not based on a dictionary word, the username, or the previous password. UID Ranges Specific UID numbers and ranges of numbers are used for specific purposes by Red Hat Enterprise Linux. UID 0 is always assigned to the superuser account, root . UID 1-200 is a range of \"system users\" assigned statically to system processes by Red Hat. UID 201-999 is a range of \"system users\" used by system processes that do not own files on the file system. They are typically assigned dynamically from the available pool when the software that needs them is installed. Programs run as these \"unprivileged\" system users in order to limit their access to only the resources they need to function. \u2022 UID 1000+ is the range available for assignment to regular users. NOTE Prior to RHEL 7, the convention was that UID 1-499 was used for system users and UID 500+ for regular users. Default ranges used by useradd and groupadd can be changed in the /etc/login.defs file.","title":"MANAGING LOCAL USERS"},{"location":"redhat/users/#managing-local-group-accounts","text":"","title":"MANAGING LOCAL GROUP ACCOUNTS"},{"location":"redhat/users/#managing-local-groups","text":"A group must exist before a user can be added to that group. Several command-line tools are used to manage local group accounts. Creating Groups from the Command Line The groupadd command creates groups. Without options the groupadd command uses the next available GID from the range specified in the /etc/login.defs file while creating the groups. The -g option specifies a particular GID for the group to use. [ user01@host ~ ] $ sudo groupadd -g 10000 group01 [ user01@host ~ ] $ tail /etc/group ...output omitted... group01:x:10000: NOTE Given the automatic creation of user private groups (GID 1000+), it is generally recommended to set aside a range of GIDs to be used for supplementary groups. A higher range will avoid a collision with a system group (GID 0-999). The -r option creates a system group using a GID from the range of valid system GIDs listed in the /etc/login.defs file. The SYSGIDMIN and SYSGIDMAX configuration items in / etc/login.defs define the range of system GIDs. [ user01@host ~ ] $ sudo groupadd -r group02 [ user01@host ~ ] $ tail /etc/group ...output omitted... group01:x:10000: group02:x:988: Modifying Existing Groups from the Command Line The groupmod command changes the properties of an existing group. The -n option specifies a new name for the group. [ user01@host ~ ] $ sudo groupmod -n group0022 group02 [ user01@host ~ ] $ tail /etc/group ...output omitted... group0022:x:988: Notice that the group name is updated to group0022 from group02. The -g option specifies a new GID. [ user01@host ~ ] $ sudo groupmod -g 20000 group0022 [ user01@host ~ ] $ tail /etc/group ...output omitted... group0022:x:20000: Notice that the GID is updated to 20000 from 988. Deleting Groups from the Command Line The groupdel command removes groups. [ user01@host ~ ] $ sudo groupdel group0022 NOTE You cannot remove a group if it is the primary group of any existing user. As with userdel , check all file systems to ensure that no files remain on the system that are owned by the group. Changing Group Membership from the Command Line The membership of a group is controlled with user management. Use the usermod -g command to change a user's primary group. [ user01@host ~ ] $ id user02 uid = 1006 ( user02 ) gid = 1008 ( user02 ) groups = 1008 ( user02 ) [ user01@host ~ ] $ sudo usermod -g group01 user02 [ user01@host ~ ] $ id user02 uid = 1006 ( user02 ) gid = 10000 ( group01 ) groups = 10000 ( group01 ) Use the usermod -aG command to add a user to a supplementary group. [ user01@host ~ ] $ id user03 uid = 1007 ( user03 ) gid = 1009 ( user03 ) groups = 1009 ( user03 ) [ user01@host ~ ] $ sudo usermod -aG group01 user03 [ user01@host ~ ] $ id user03 uid = 1007 ( user03 ) gid = 1009 ( user03 ) groups = 1009 ( user03 ) ,10000 ( group01 ) IMPORTANT The use of the -a option makes usermod function in append mode. Without -a , the user will be removed from any of their current supplementary groups that are not included in the -G option's list.","title":"MANAGING LOCAL GROUPS"},{"location":"redhat/users/#managing-user-passwords-objectives","text":"","title":"MANAGING USER PASSWORDS OBJECTIVES"},{"location":"redhat/users/#shadow-passwords-and-password-policy","text":"At one time, encrypted passwords were stored in the world-readable /etc/passwd file. This was thought to be reasonably secure until dictionary attacks on encrypted passwords became common. At that point, the encrypted passwords were moved to a separate /etc/shadow file which is readable only by root. This new file also allowed password aging and expiration features to be implemented. Like /etc/passwd , each user has a line in the /etc/shadow file. A sample line from /etc/ shadow with its nine colon-separated fields is shown below. user03:$6$CSsX...output omitted...:17933:0:99999:7:2:18113: user03 --> Username of the account this password belongs to. \\(6\\) CSsX...output omitted... --> The encrypted password of the user. The format of encrypted passwords is discussed later in this section. 17933 --> The day on which the password was last changed. This is set in days since 1970-01-01, and is calculated in the UTC time zone. 0 --> The minimum number of days that have to elapse since the last password change before the user can change it again. 99999 --> The maximum number of days that can pass without a password change before the password expires. An empty field means it does not expire based on time since the last change. 7 --> Warning period. The user will be warned about an expiring password when they login for this number of days before the deadline. 2 --> Inactivity period. Once the password has expired, it will still be accepted for login for this many days. After this period has elapsed, the account will be locked. 18113 --> The day on which the password expires. This is set in days since 1970-01-01, and is calculated in the UTC time zone. An empty field means it does not expire on a particular date. --> The last field is usually empty and is reserved for future use. Format of an Encrypted Password The encrypted password field stores three pieces of information: the hashing algorithm used, the salt , and the encrypted hash . Each piece of information is delimited by the $ sign. $6$CSsXcYG1L/4ZfHr/$2W6evvJahUfzfHpc9X.45Jc6H30E...output omitted... 6 --> The hashing algorithm used for this password. The number 6 indicates it is a SHA-512 hash, which is the default in Red Hat Enterprise Linux 8. A 1 would indicate MD5, a 5 SHA-256. CSsXcYG1L/4ZfHr/ --> The salt used to encrypt the password. This is originally chosen at random. 2W6evvJahUfzfHpc9X.45Jc6H30E...output omitted... --> The encrypted hash of the user's password. The salt and the unencrypted password are combined and encrypted to generate the encrypted hash of the password. The use of a salt prevents two users with the same password from having identical entries in the / etc/shadow file. For example, even if user01 and user02 both use redhat as their passwords, their encrypted passwords in /etc/shadow will be different if their salts are different. Password Verification When a user tries to log in, the system looks up the entry for the user in /etc/shadow , combines the salt for the user with the unencrypted password that was typed in, and encrypts them using the hashing algorithm specified. If the result matches the encrypted hash, the user typed in the right password. If the result does not match the encrypted hash, the user typed in the wrong password and the login attempt fails. This method allows the system to determine if the user typed in the correct password without storing that password in a form usable for logging in.","title":"SHADOW PASSWORDS AND PASSWORD POLICY"},{"location":"redhat/users/#configuring-password-aging","text":"The following diagram relates the relevant password aging parameters, which can be adjusted using the chage command to implement a password aging policy. [ user01@host ~ ] $ sudo chage -m 0 -M 90 -W 7 -I 14 user03 The preceding chage command uses the -m, -M, -W , and -I options to set the minimum age, maximum age, warning period, and inactivity period of the user's password, respectively. The chage -d 0 user03 command forces the user03 user to update its password on the next login. The chage -l user03 command displays the password aging details of user03. The chage -E 2019-08-05 user03 command causes the user03 user's account to expire on 2019-08-05 (in YYYY-MM-DD format). NOTE The date command can be used to calculate a date in the future. The -u option reports the time in UTC. [ user01@host ~ ] $ date -d \"+45 days\" -u Thu May 23 17 :01:20 UTC 2019 Edit the password aging configuration items in the /etc/login.defs file to set the default password aging policies. The PASSMAXDAYS sets the default maximum age of the password. The PASSMINDAYS sets the default minimum age of the password. The PASSWARNAGE sets the default warning period of the password. Any change in the default password aging policies will be effective for new users only. The existing users will continue to use the old password aging settings rather than the new ones.","title":"CONFIGURING PASSWORD AGING"},{"location":"redhat/users/#restricting-access","text":"You can use the chage command to set account expiration dates. When that date is reached, the user cannot log in to the system interactively. The usermod command can lock an account with the -L option. [ user01@host ~ ] $ sudo usermod -L user03 [ user01@host ~ ] $ su - user03 Password: redhat su: Authentication failure If a user leaves the company, the administrator may lock and expire an account with a single usermod command. The date must be given as the number of days since 1970-01-01, or in the YYYY-MM-DD format. [ user01@host ~ ] $ sudo usermod -L -e 2019 -10-05 user03 The preceding usermod command uses the -e option to set the account expiry date for the given user account. The -L option locks the user's password. Locking the account prevents the user from authenticating with a password to the system. It is the recommended method of preventing access to an account by an employee who has left the company. If the employee returns, the account can later be unlocked with usermod -U . If the account was also expired, be sure to also change the expiration date. The nologin Shell The nologin shell acts as a replacement shell for the user accounts not intended to interactively log into the system. It is wise from the security standpoint to disable the user account from logging into the system when the user acount serves a responsibility that does not require the user to log into the system. For example, a mail server may require an account to store mail and a password for the user to authenticate with a mail client used to retrieve mail. That user does not need to log directly into the system. A common solution to this situation is to set the user's login shell to /sbin/nologin . If the user attempts to log in to the system directly, the nologin shell closes the connection. [ user01@host ~ ] $ usermod -s /sbin/nologin user03 [ user01@host ~ ] $ su - user03 Last login: Wed Feb 6 17 :03:06 IST 2019 on pts/0 This account is currently not available. IMPORTANT The nologin shell prevents interactive use of the system, but does not prevent all access. Users might be able to authenticate and upload or retrieve files through applications such as web applications, file transfer programs, or mail readers if they use the user's password for authentication.","title":"RESTRICTING ACCESS"},{"location":"redhat/users/#summary","text":"In this chapter, you learned: There are three main types of user account: the superuser, system users, and regular users. A user must have a primary group and may be a member of one or more supplementary groups. The three critical files containing user and group information are /etc/passwd, /etc/group , and /etc/shadow . The su and sudo commands can be used to run commands as the superuser. The useradd, usermod , and userdel commands can be used to manage users. The groupadd, groupmod , and groupdel commands can be used to manage groups. The chage command can be used to configure and view password expiration settings for users.","title":"SUMMARY"},{"location":"setup/integrating-metadata-removal/","text":"When sharing files, it's important to remove associated metadata. Image files commonly include Exif data, and sometimes photos even include GPS coordinates within its metadata. While there are plenty of metadata removal tools, they typically aren't convenient to use. The guides featured here aim to detail how to integrate metadata removal tools in a simple fashion by utilizing easy-to-access system features. Recommended metadata removal tools macOS \u00b6 This guide uses the Shortcuts app to add an ExifTool script to the Quick Actions context menu within Finder. Shortcuts is developed by Apple and bundled in with macOS by default. Shortcuts is quite intuitive to work with, so if you don't like the behavior demoed here then experiment with your own solution. For example, you could set the shortcut to take a clipboard input instead. The sky's the limit. Prerequisites \u00b6 Homebrew : a package manager. /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" ExifTool is a tool for viewing and manipulating image, audio, video, and PDF metadata. brew install exiftool Note You can check if ExifTool is installed by running exiftool -ver . You should see a version number. Creating the Shortcut \u00b6 Open Shortcuts.app and create a new shortcut In the shortcut's options, check Use as Quick Action and Finder Set up the retrieval options: Receive Images, Media, and PDFs input from Quick Actions If there is no input select Continue Add the Run Shell Script action to the shortcut. You may need to enable Allow Running Scripts in Shortcut.app's settings Set up the shell script action: Select zsh from the shell list Set the input to Shortcut Input Select as arguments for the pass input Leave Run as administrator unchecked Use the following as the body of the script: for f in \" $@ \" do exiftool -all = \" $f \" ; done Worth Mentioning The open source ImageOptim app integrates into Finder's Services context menu by default. While it is primarily an image optimization app, it also removes metadata. Enabling & using the Shortcut \u00b6 The shortcut will be accessible through Quick Actions context menu within Finder. If you want to reposition the shortcut within the context menu, go to: System Preferences \u2192 Extensions \u2192 Finder and drag the shortcut's position . iOS and iPadOS \u00b6 Shortcuts can be made accessible through the system Share Sheet, making accessing those shortcuts very convenient. This guide will show you how to build a metadata removal shortcut and integrate it into the system Share Sheet . Attention This method of metadata removal is not as comprehensive at removing metadata as utilities like ExifTool and mat2 are. The lack of good metadata removal apps on the App Store is what makes this solution worthwhile. Prerequisites \u00b6 Shortcuts via the App Store. Creating the Shortcut \u00b6 Create a new Shortcut Enter the Shortcut's settings and check Show in Share Sheet Add a Receive action and set it to receive Images from Share Sheet Add an If action Set the If action to Shortcut Input and has any value Add an Otherwise action Add an End If action Add a Convert action and set it to If Result and Match Input Finally, add a Share action and set that to Converted Image Make sure that you uncheck preserve metadata Enabling & using the Shortcut \u00b6 The shortcut should be available through the system Share Sheet. If it is not, then a device restart may be required. Optionally, you can add the shortcut to your home screen. Windows \u00b6 Windows allows you to place files in a SendTo folder which then appear in the Send to context menu. This guide will show you how to add an ExifTool batch script to this menu. Prerequisites \u00b6 ExifTool is a tool for viewing and manipulating image, audio, video, and PDF metadata. We suggest you read the Installation instructions on the official website. Note You can check if ExifTool is present in your PATH by running exiftool -ver in Command Prompt. You should see a version number. Creating the shortcut \u00b6 Navigate to %appdata%\\Microsoft\\Windows\\SendTo Right click in the SendTo folder and create a new Text Document Name the file ExifTool.bat (any name works, however it must end in .bat ) Note You may need to check if file name extensions are enabled. Open ExifTool.bat in Notepad Copy the following into the document: exiftool -fast4 -if \"$filepermissions =~ /^.w/\" %* if not errorlevel 0 ( echo Some files are write protected exit /b %errorlevel% ) exiftool -all= %* Save Using the shortcut \u00b6 Right click a supported file and choose ExifTool.bat within the Send to context menu.","title":"Integrating Metadata Removal"},{"location":"setup/integrating-metadata-removal/#macos","text":"This guide uses the Shortcuts app to add an ExifTool script to the Quick Actions context menu within Finder. Shortcuts is developed by Apple and bundled in with macOS by default. Shortcuts is quite intuitive to work with, so if you don't like the behavior demoed here then experiment with your own solution. For example, you could set the shortcut to take a clipboard input instead. The sky's the limit.","title":"macOS"},{"location":"setup/integrating-metadata-removal/#prerequisites","text":"Homebrew : a package manager. /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" ExifTool is a tool for viewing and manipulating image, audio, video, and PDF metadata. brew install exiftool Note You can check if ExifTool is installed by running exiftool -ver . You should see a version number.","title":"Prerequisites"},{"location":"setup/integrating-metadata-removal/#creating-the-shortcut","text":"Open Shortcuts.app and create a new shortcut In the shortcut's options, check Use as Quick Action and Finder Set up the retrieval options: Receive Images, Media, and PDFs input from Quick Actions If there is no input select Continue Add the Run Shell Script action to the shortcut. You may need to enable Allow Running Scripts in Shortcut.app's settings Set up the shell script action: Select zsh from the shell list Set the input to Shortcut Input Select as arguments for the pass input Leave Run as administrator unchecked Use the following as the body of the script: for f in \" $@ \" do exiftool -all = \" $f \" ; done Worth Mentioning The open source ImageOptim app integrates into Finder's Services context menu by default. While it is primarily an image optimization app, it also removes metadata.","title":"Creating the Shortcut"},{"location":"setup/integrating-metadata-removal/#enabling-using-the-shortcut","text":"The shortcut will be accessible through Quick Actions context menu within Finder. If you want to reposition the shortcut within the context menu, go to: System Preferences \u2192 Extensions \u2192 Finder and drag the shortcut's position .","title":"Enabling &amp; using the Shortcut"},{"location":"setup/integrating-metadata-removal/#ios-and-ipados","text":"Shortcuts can be made accessible through the system Share Sheet, making accessing those shortcuts very convenient. This guide will show you how to build a metadata removal shortcut and integrate it into the system Share Sheet . Attention This method of metadata removal is not as comprehensive at removing metadata as utilities like ExifTool and mat2 are. The lack of good metadata removal apps on the App Store is what makes this solution worthwhile.","title":"iOS and iPadOS"},{"location":"setup/integrating-metadata-removal/#prerequisites_1","text":"Shortcuts via the App Store.","title":"Prerequisites"},{"location":"setup/integrating-metadata-removal/#creating-the-shortcut_1","text":"Create a new Shortcut Enter the Shortcut's settings and check Show in Share Sheet Add a Receive action and set it to receive Images from Share Sheet Add an If action Set the If action to Shortcut Input and has any value Add an Otherwise action Add an End If action Add a Convert action and set it to If Result and Match Input Finally, add a Share action and set that to Converted Image Make sure that you uncheck preserve metadata","title":"Creating the Shortcut"},{"location":"setup/integrating-metadata-removal/#enabling-using-the-shortcut_1","text":"The shortcut should be available through the system Share Sheet. If it is not, then a device restart may be required. Optionally, you can add the shortcut to your home screen.","title":"Enabling &amp; using the Shortcut"},{"location":"setup/integrating-metadata-removal/#windows","text":"Windows allows you to place files in a SendTo folder which then appear in the Send to context menu. This guide will show you how to add an ExifTool batch script to this menu.","title":"Windows"},{"location":"setup/integrating-metadata-removal/#prerequisites_2","text":"ExifTool is a tool for viewing and manipulating image, audio, video, and PDF metadata. We suggest you read the Installation instructions on the official website. Note You can check if ExifTool is present in your PATH by running exiftool -ver in Command Prompt. You should see a version number.","title":"Prerequisites"},{"location":"setup/integrating-metadata-removal/#creating-the-shortcut_2","text":"Navigate to %appdata%\\Microsoft\\Windows\\SendTo Right click in the SendTo folder and create a new Text Document Name the file ExifTool.bat (any name works, however it must end in .bat ) Note You may need to check if file name extensions are enabled. Open ExifTool.bat in Notepad Copy the following into the document: exiftool -fast4 -if \"$filepermissions =~ /^.w/\" %* if not errorlevel 0 ( echo Some files are write protected exit /b %errorlevel% ) exiftool -all= %* Save","title":"Creating the shortcut"},{"location":"setup/integrating-metadata-removal/#using-the-shortcut","text":"Right click a supported file and choose ExifTool.bat within the Send to context menu.","title":"Using the shortcut"}]}